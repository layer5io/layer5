{"data":{"allMdx":{"nodes":[{"id":"78f74621-a748-5ec4-941e-25d98788714e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport CTA_FullWidth from \"../../../../components/Call-To-Actions/CTA_FullWidth\";\nimport CTAImg from \"../../../../assets/images/layer5/5 icon/png/light/5-light-no-trim.webp\";\n\n<BlogWrapper>\n\n<div class=\"intro\">\n  <p>\n    As AI-powered coding assistants become essential development tools, managing file access permissions efficiently is crucial. If you're using Gemini CLI and finding yourself repeatedly approving the same directory prompts, this guide will help you configure trusted directories and reclaim your valuable development time.\n  </p>\n</div>\n\nThe Gemini CLI is Google's powerful command-line interface for interacting with Gemini AI models directly from your terminal. Whether you're building <Link to=\"/cloud-native-management/meshery\">cloud native applications</Link>, automating infrastructure tasks, or leveraging AI for code generation, the Gemini CLI can significantly enhance your productivity‚Äîbut only if it's properly configured.\n\n## The Trust Prompt Challenge\n\nWhen you first run Gemini CLI in a new directory, you'll encounter trust dialogs that ask for permission to access files in that location. While this security feature protects your sensitive data, it can become a productivity bottleneck when working across multiple projects or frequently switching between directories.\n\n**The problem:** Every time you navigate to a new folder, you're interrupted by permission requests. For platform engineers and DevOps practitioners managing multiple repositories, microservices, or infrastructure-as-code projects, these interruptions add up quickly.\n\n**The solution:** Configure trusted directories once, and work uninterrupted across all your projects.\n\n## Three Ways to Configure Trusted Directories\n\nGemini CLI offers three flexible approaches to managing trusted directories, each suited to different workflows and preferences. Let's explore each method in detail.\n\n### 1. Interactive Prompts: The Quick Start Method\n\nThe most straightforward way to configure trust settings is through the interactive prompts that appear when you first use Gemini CLI in a new directory.\n\n#### How It Works\n\nWhen running Gemini CLI in an untrusted folder, you'll see a dialog with two primary options:\n\n**Trust Folder**: This option trusts only the current directory. Choose this when:\n- You're working in a single, isolated project\n- The directory contains sensitive information and you want granular control\n- You want to test Gemini CLI functionality in a specific location\n\n**Trust Parent Folder**: This option trusts the current folder and all its subdirectories. This is ideal when:\n- You're managing a monorepo with multiple projects\n- Your workspace contains related microservices\n- You want to streamline trust management across a project hierarchy\n\n<Blockquote\n  quote=\"Trusting parent folders intelligently reduces configuration overhead‚Äîone decision covers an entire project tree, letting you focus on building rather than managing permissions.\"\n  person=\"Platform Engineering Best Practice\"\n  title=\"Layer5 Community\"\n/>\n\n#### Modifying Trust Settings\n\nAlready working in a directory but want to change its trust level? No problem. Simply run:\n\n```bash\n/permissions\n```\n\nThis command brings up the interactive dialog from within your current directory, allowing you to adjust trust settings on the fly without leaving your workflow.\n\n### 2. Command-Line Multi-Directory Support\n\nFor engineers who prefer command-line efficiency or need to work across multiple unrelated directories simultaneously, Gemini CLI provides powerful command-line options for directory management.\n\n#### Starting a Session with Multiple Directories\n\nTo give Gemini CLI access to multiple directories from the start, use the `--include-directories` flag:\n\n```bash\ngemini --include-directories path/to/dir1,path/to/dir2,path/to/dir3\n```\n\n**Key points:**\n- Paths can be **absolute** (e.g., `/home/user/projects/api`) or **relative** (e.g., `../frontend`)\n- Separate multiple paths with commas (no spaces)\n- This is particularly useful for cross-project workflows\n\n**Example use case:** A platform engineer working on a <Link to=\"/cloud-native-management/meshery\">Meshery</Link> deployment might need access to:\n- The main application repository\n- A shared Kubernetes manifests directory\n- Infrastructure-as-code configurations\n- Documentation repository\n\n```bash\ngemini --include-directories ~/projects/meshery-app,~/k8s/manifests,~/terraform/prod,~/docs/api\n```\n\n#### Adding Directories During an Active Session\n\nAlready in a Gemini CLI session and need to add another directory? Use the `/directory add` command:\n\n```bash\n/directory add <path>\n```\n\nYou can even add multiple directories at once by separating them with commas:\n\n```bash\n/directory add ~/new-project,~/shared-utils,~/config\n```\n\nThe alias `/dir` works identically for convenience:\n\n```bash\n/dir add ~/another-project\n```\n\n#### Viewing Active Directories\n\nTo see all directories currently accessible in your session:\n\n```bash\n/directory show\n```\n\nOr using the shorter alias:\n\n```bash\n/dir show\n```\n\nThis command displays a complete list of all trusted directories for the current session, helping you verify your configuration and understand the scope of file access.\n\n<div class=\"tip\">\n  <h3>üí° Pro Tip for DevOps Teams</h3>\n  <p>When working with <Link to=\"/cloud-native-management/kanvas\">infrastructure design tools like Kanvas</Link>, organize your Kubernetes manifests, Helm charts, and configuration files in a parent directory. Trust that parent folder once, and Gemini CLI will have seamless access to your entire infrastructure-as-code setup.</p>\n</div>\n\n### 3. Manual Configuration: The Power User Approach\n\nFor advanced users, automation enthusiasts, or those managing multiple machines, manually editing the trusted folders configuration file provides the ultimate control and reproducibility.\n\n#### Understanding the Configuration File\n\nTrusted folder rules are stored in a JSON file located at:\n\n```bash\n~/.gemini/trustedFolders.json\n```\n\nThis file resides in your home directory's `.gemini` folder and persists across CLI sessions.\n\n#### File Structure and Format\n\nThe `trustedFolders.json` file uses a straightforward JSON structure. Here's an example:\n\n```json\n{\n  \"trustedFolders\": [\n    \"/home/username/projects/meshery\",\n    \"/home/username/kubernetes/clusters\",\n    \"/home/username/terraform/infrastructure\",\n    \"/opt/shared/configs\"\n  ]\n}\n```\n\n#### Editing the Configuration File\n\nYou can edit this file directly using any text editor:\n\n```bash\nnano ~/.gemini/trustedFolders.json\n```\n\nOr with your preferred editor:\n\n```bash\nvim ~/.gemini/trustedFolders.json\ncode ~/.gemini/trustedFolders.json  # VS Code\n```\n\n#### Adding and Removing Paths\n\n**To add a new trusted directory:**\n1. Open the file in your editor\n2. Add the full path to the `trustedFolders` array\n3. Ensure proper JSON formatting (commas between entries, quotes around paths)\n4. Save the file\n\n**To remove a trusted directory:**\n1. Open the file\n2. Delete the line containing the path (and any trailing comma if it's the last entry)\n3. Save the file\n\n**Example workflow:**\n\n```bash\n# Backup your current configuration\ncp ~/.gemini/trustedFolders.json ~/.gemini/trustedFolders.json.backup\n\n# Edit the configuration\nnano ~/.gemini/trustedFolders.json\n\n# Verify JSON syntax (optional but recommended)\npython3 -m json.tool \"$HOME/.gemini/trustedFolders.json\" > /dev/null\n```\n\n<Blockquote\n  quote=\"Manual configuration enables version control and automation‚Äîcommit your trustedFolders.json to your dotfiles repository and deploy consistent Gemini CLI settings across all your development machines.\"\n  person=\"DevOps Automation Strategy\"\n  title=\"Infrastructure as Code\"\n/>\n\n#### Applying Changes\n\nAfter editing the file, changes take effect when you:\n- Restart your current Gemini CLI session\n- Start a new Gemini CLI session\n\n**Important:** Changes to `trustedFolders.json` do **not** apply to already-running CLI sessions. Simply exit and restart the CLI to pick up your modifications.\n\n## Best Practices for Trusted Directories\n\n### Security Considerations\n\nWhile configuring trusted directories improves workflow efficiency, it's essential to maintain security best practices:\n\n1. **Be selective**: Only trust directories you actively use with Gemini CLI\n2. **Avoid overly broad permissions**: Trusting your entire home directory (`~`) exposes all files‚Äîuse specific project directories instead\n3. **Regular audits**: Periodically review `~/.gemini/trustedFolders.json` and remove directories for completed or archived projects\n4. **Sensitive data**: Keep directories containing secrets, credentials, or PII (Personally Identifiable Information) untrusted unless absolutely necessary\n\n### Organizational Strategies\n\n**For Solo Developers:**\n- Trust parent folders for active projects\n- Use specific folder trust for exploratory or temporary work\n- Maintain a clean project directory structure to minimize trust scope\n\n**For Teams and Organizations:**\n- Standardize project directory layouts across the team\n- Document trusted directory policies in team onboarding materials\n- Consider using absolute paths in shared documentation for consistency\n- Leverage version-controlled dotfiles to distribute configuration\n\n**For Multi-Environment Workflows:**\n- Separate development, staging, and production directories\n- Apply stricter trust policies to production-related directories\n- Use environment-specific parent folders (e.g., `~/dev/`, `~/staging/`, `~/prod/`)\n\n## Integration with Cloud Native Workflows\n\nGemini CLI's trusted directories feature becomes even more powerful when integrated into cloud native development workflows. Here are practical examples:\n\n### Kubernetes and Container Development\n\nWhen working with <Link to=\"/cloud-native-management/meshery\">Kubernetes orchestration</Link>, trust your entire K8s workspace:\n\n```bash\n# Trust your Kubernetes project root\n/permissions  # Select \"Trust parent folder\" for ~/projects/k8s-apps/\n\n# Or via command line\ngemini --include-directories ~/projects/k8s-apps,~/helm-charts,~/.kube/configs\n```\n\nThis configuration allows Gemini CLI to assist with:\n- Generating and validating YAML manifests\n- Troubleshooting deployment configurations\n- Analyzing pod logs and resource definitions\n- Creating Helm chart templates\n\n### Infrastructure as Code\n\nFor infrastructure automation with tools like Terraform, Pulumi, or Ansible:\n\n```bash\ngemini --include-directories ~/infrastructure/terraform,~/infrastructure/ansible-playbooks,~/infrastructure/scripts\n```\n\nBenefits include:\n- AI-assisted infrastructure code generation\n- Configuration validation and best practice suggestions\n- Documentation generation from IaC definitions\n- Troubleshooting infrastructure drift\n\n### Multi-Repository Projects\n\nModern cloud native applications often span multiple repositories. Configure Gemini CLI to work seamlessly across your architecture:\n\n```bash\n# Add all microservice repositories\n/dir add ~/services/api-gateway\n/dir add ~/services/auth-service\n/dir add ~/services/data-processing\n/dir add ~/services/notification-service\n/dir add ~/shared/common-libraries\n```\n\n## Troubleshooting Common Issues\n\n### Permission Prompts Still Appearing\n\n**Problem:** You've configured trusted directories, but prompts still appear.\n\n**Solutions:**\n1. Verify the exact path in `~/.gemini/trustedFolders.json` matches your working directory\n2. Check for typos in paths (case-sensitive on Unix-like systems)\n3. Ensure you've restarted the Gemini CLI session after configuration changes\n4. Confirm you're working in a subdirectory of a trusted parent folder\n\n### JSON Syntax Errors\n\n**Problem:** Configuration changes aren't working, or Gemini CLI reports errors.\n\n**Solutions:**\n1. Validate JSON syntax: `python3 -c \"import json; json.load(open('$HOME/.gemini/trustedFolders.json'))\"`\n2. Check for missing commas between array entries\n3. Ensure all paths are enclosed in double quotes\n4. Verify the closing bracket and brace are present\n\n### Symbolic Links and Mount Points\n\n**Problem:** Trusted directories aren't recognized when accessed via symbolic links.\n\n**Solutions:**\n1. Add both the real path and symlink path to trusted folders\n2. Use absolute paths to avoid resolution issues\n3. Check with `realpath <directory>` to find the canonical path\n\n## Maximizing Productivity\n\nWith trusted directories properly configured, you can fully leverage Gemini CLI's capabilities without interruption:\n\n- **Code generation**: Generate boilerplate, utility functions, or entire components\n- **Documentation**: Create comprehensive docs from code comments and structure\n- **Debugging**: Get AI-powered assistance analyzing logs and stack traces\n- **Refactoring**: Safely modernize codebases with intelligent suggestions\n- **Learning**: Explore unfamiliar codebases with AI-guided explanations\n\n<CTA_FullWidth \n  image={CTAImg}\n  heading=\"Design, Deploy, and Manage Cloud Native Infrastructure\"\n  alt=\"Layer5 - Cloud Native Management Platform\"\n  content=\"Explore Layer5's suite of tools including Meshery for Kubernetes management and Kanvas for visual infrastructure design. Join thousands of engineers building better cloud native systems.\"\n  button_text=\"Explore Layer5 Projects\"\n  url=\"/projects\"\n  external_link={false}\n/>\n\n## Conclusion\n\nConfiguring Gemini CLI trusted directories is a one-time investment that pays continuous dividends in productivity and workflow smoothness. Whether you choose interactive prompts for simplicity, command-line options for flexibility, or manual configuration for automation, the result is the same: uninterrupted access to AI-powered assistance across all your development projects.\n\n**Quick Recap:**\n- **Interactive prompts**: Fast and intuitive for ad-hoc configuration\n- **Command-line flags**: Powerful for multi-directory workflows and scripting\n- **Manual editing**: Ultimate control for automation and reproducibility\n\nBy implementing these configurations, platform engineers, DevOps practitioners, and cloud native developers can focus on what matters most: building innovative infrastructure and applications without the friction of repetitive permission requests.\n\nReady to accelerate your development workflow? Configure your trusted directories today and experience the full power of AI-assisted development with Gemini CLI.\n\n---\n\n*Want to learn more about AI-powered development tools and cloud native best practices? Join the <Link to=\"/community\">Layer5 community</Link> on [Slack](https://slack.layer5.io) to connect with platform engineers, DevOps practitioners, and cloud native experts from around the world.*\n\n</BlogWrapper>\n","frontmatter":{"title":"Streamline Your Gemini CLI Workflow with Trusted Directories","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAPoAAAD6AG1e1JrAAAB0klEQVR42mOYUr5uSmbrxPjo5Rlua4q8VlaELM3wWJLksjLTeVNH0ubpBasnZa7uSFpVEbAmx2VBskdtdIpjRKts8iLmwqMMS0qmBPpES0grqho4mjunWTkmWtlEu9glBDgmeVn4hdsG+xk7+hpYCYmKICMTfZu8kmUMe8qKPMyMDXwLTb3ztU29vYObjUx9UyMnRngUhDvFNYdVVXolJ1u7oWnW0rFJzN/IsKCi1swjRVxWScPU09I928Yxxdo2Tk/Xwck8yNcmxNXYJcbaN9DIFk2zso6tX8EWBrGcHVJGXorK6gpKKsqqauKSEmjqsCIpHVv1/O0MTFEbRLTdFJVVgZohSEpWBojwmyKvY6dVsIOB0XqmqIajvKKyjJw8EEmBSTFpGQkpoH4pUXEJIAKyZWTkICKS0rJAzRLadnoFQJuNJoqq2ssqKcvKK4hJiAORtLQ0UK2ElBSQLSouBkRScopSMgpAESAC6gdqltG2lc0Datbt4ZU2IcafyMjKUNehaD0Dk0I9n7gRqZo9jVV212UxMMnVs8olsqqEsquGsaoGs6mHs+nFsFsma9onGzskGTokZrrZ5rtZlPmYVYda1kRY18Y410fYLE1yeNwYDgDuOYdsqvIMUwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/71d4d/gemini-cli-hero.webp","srcSet":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/a66aa/gemini-cli-hero.webp 750w,\n/static/09a7de2ccfe4b08e95b1795f3a7058b5/65dd5/gemini-cli-hero.webp 1080w,\n/static/09a7de2ccfe4b08e95b1795f3a7058b5/71d4d/gemini-cli-hero.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/gemini-cli-hero.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAPoAAAD6AG1e1JrAAAB0klEQVR42mOYUr5uSmbrxPjo5Rlua4q8VlaELM3wWJLksjLTeVNH0ubpBasnZa7uSFpVEbAmx2VBskdtdIpjRKts8iLmwqMMS0qmBPpES0grqho4mjunWTkmWtlEu9glBDgmeVn4hdsG+xk7+hpYCYmKICMTfZu8kmUMe8qKPMyMDXwLTb3ztU29vYObjUx9UyMnRngUhDvFNYdVVXolJ1u7oWnW0rFJzN/IsKCi1swjRVxWScPU09I928Yxxdo2Tk/Xwck8yNcmxNXYJcbaN9DIFk2zso6tX8EWBrGcHVJGXorK6gpKKsqqauKSEmjqsCIpHVv1/O0MTFEbRLTdFJVVgZohSEpWBojwmyKvY6dVsIOB0XqmqIajvKKyjJw8EEmBSTFpGQkpoH4pUXEJIAKyZWTkICKS0rJAzRLadnoFQJuNJoqq2ssqKcvKK4hJiAORtLQ0UK2ElBSQLSouBkRScopSMgpAESAC6gdqltG2lc0Datbt4ZU2IcafyMjKUNehaD0Dk0I9n7gRqZo9jVV212UxMMnVs8olsqqEsquGsaoGs6mHs+nFsFsma9onGzskGTokZrrZ5rtZlPmYVYda1kRY18Y410fYLE1yeNwYDgDuOYdsqvIMUwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/71d4d/gemini-cli-hero.webp","srcSet":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/a66aa/gemini-cli-hero.webp 750w,\n/static/09a7de2ccfe4b08e95b1795f3a7058b5/65dd5/gemini-cli-hero.webp 1080w,\n/static/09a7de2ccfe4b08e95b1795f3a7058b5/71d4d/gemini-cli-hero.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/09a7de2ccfe4b08e95b1795f3a7058b5/gemini-cli-hero.png"}},"fields":{"slug":"/blog/ai/streamline-your-gemini-cli-workflow-with-trusted-directories"}},{"id":"4fb6f151-2f63-5f64-8ecb-2d416a60a970","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nIf you've ever used Miro, you know the appeal of a collaborative visual workspace. Sticky notes, diagrams, infinite canvases‚Äîit's a designer's playground. But what happens when engineers need more than just pretty diagrams? What happens when those boxes and arrows need to actually **do something**?\n\nThat's where <Link to=\"/cloud-native-management/kanvas\">Kanvas</Link> comes in.\n\nKanvas is what you get when you take the collaborative visual thinking of Miro and infuse it with the power of infrastructure-as-code, Kubernetes orchestration, and GitOps workflows. It's not just a whiteboard‚Äîit's a **complete engineering platform** for cloud-native infrastructure.\n\n## The Miro Experience (And Its Limits)\n\nLet's be fair: Miro is excellent at what it does. Teams use it to:\n- Brainstorm ideas with virtual sticky notes\n- Map out user journeys and customer experiences\n- Create wireframes and mockups\n- Run design thinking workshops\n- Collaborate asynchronously across time zones\n\nFor product designers, UX researchers, and agile teams, Miro is invaluable. The problem emerges when you try to move from **design to deployment**.\n\nPicture this: Your team has just spent two hours mapping out your microservices architecture in Miro. Beautiful diagram. Everyone's aligned. Great meeting. \n\nNow what?\n\nSomeone has to translate that diagram into YAML. Someone has to configure the ingress controllers. Someone has to set up the service mesh. Someone has to ensure the production deployment actually matches what's on the whiteboard.\n\n**The diagram and reality immediately diverge.**\n\n## The Infrastructure Gap\n\nThis gap between design and reality is what we call the **infrastructure gap**. Traditional diagramming tools create a one-way street: you design, then you implement separately. There's no connection between the visual representation and the actual infrastructure.\n\nThis leads to:\n- **Drift**: Your diagrams become outdated the moment infrastructure changes\n- **Manual Translation**: Engineers spend hours converting boxes and arrows into YAML manifests\n- **No Single Source of Truth**: Is the diagram right? Is the code right? Who knows?\n- **Limited Collaboration**: DevOps engineers can't \"play\" in the same visual space as the rest of the team because the tool doesn't speak their language\n\n## Enter Kanvas: Where Design Meets Deployment\n\nKanvas is fundamentally different. It's built on the principle of **Infrastructure as Design**‚Äîthe idea that your visual representation and your actual infrastructure should be the same thing.\n\nWhen you drag a Kubernetes Deployment onto the Kanvas canvas, you're not drawing a picture of a deployment. You're **creating an actual Kubernetes deployment manifest**. When you connect two services, you're not sketching a relationship‚Äîyou're **defining network policies and service meshes**.\n\n### What Makes Kanvas an Engineer's Tool\n\n#### 1. **Live Infrastructure Integration**\n\nKanvas operates in two modes:\n- **Designer Mode**: Create and design infrastructure patterns, applications, and deployments\n- **Operator Mode**: Visualize and manage your live, running infrastructure in real-time\n\nIn Operator mode, Kanvas connects directly to your Kubernetes clusters. You can see what's actually running, what's healthy, what's failing‚Äîall visually. No more `kubectl get pods` in 47 terminal windows.\n\n#### 2. **Import Existing Infrastructure**\n\nAlready have Kubernetes manifests? Helm charts? Docker Compose files? Kustomize configurations?\n\nImport them directly into Kanvas. The platform automatically converts them into visual components on the canvas, giving you instant visual insight into what you've already built. This is crucial for teams inheriting complex infrastructure or working with legacy systems.\n\n#### 3. **GitOps-Native Workflow**\n\nKanvas integrates seamlessly with GitOps workflows. Every change you make in the visual designer can be tracked, versioned, and managed through Git. Your infrastructure-as-design becomes infrastructure-as-code automatically.\n\nThis means:\n- Full audit trail of who changed what and when\n- Ability to roll back to previous infrastructure states\n- Collaboration through pull requests and code reviews\n- Consistency with your existing CI/CD pipelines\n\n#### 4. **Multi-Cluster, Multi-Cloud Management**\n\nBuilt on top of <Link to=\"/cloud-native-management/meshery\">Meshery</Link>, Kanvas supports managing infrastructure across:\n- Multiple Kubernetes clusters\n- Different cloud providers (AWS, GCP, Azure)\n- Various service meshes (Istio, Linkerd, Consul, etc.)\n- Hundreds of cloud-native technologies\n\nYou can design once and deploy everywhere, or visualize your entire distributed infrastructure in a single pane of glass.\n\n#### 5. **Component Library with Real Infrastructure**\n\nWhere Miro gives you shapes and connector lines, Kanvas gives you **actual infrastructure components**:\n- Kubernetes Deployments, Services, ConfigMaps, and Secrets\n- Istio VirtualServices and DestinationRules\n- Prometheus monitoring configurations\n- Database operators\n- Custom Resource Definitions (CRDs)\n- And thousands more from the ecosystem\n\nEach component comes with its full configuration exposed, not just a pretty icon.\n\n#### 6. **Collaboration That Scales**\n\nLike Miro, Kanvas supports multi-user collaboration. But unlike Miro, when multiple engineers are working together in Kanvas, they're not just moving sticky notes around‚Äîthey're **co-authoring production infrastructure**.\n\nChanges are collaborative, but also controlled. You can share designs, publish them to the <Link to=\"/cloud-native-management/catalog\">Kanvas Catalog</Link> for others to clone, and standardize deployment patterns across your organization.\n\n## Real-World Use Cases\n\n### Scenario 1: Onboarding New Team Members\n\n**With Miro:** \"Here's a diagram of our infrastructure. Good luck figuring out what's actually deployed.\"\n\n**With Kanvas:** Import your production Kubernetes manifests, visualize them on the canvas, and let new engineers explore the actual infrastructure visually. They can see relationships, configurations, and dependencies‚Äîall mapped to real resources.\n\n### Scenario 2: Designing a New Microservice\n\n**With Miro:** Sketch the architecture, export a PNG, hand it off to DevOps to implement.\n\n**With Kanvas:** Design the service architecture visually, configure the Kubernetes resources, define the service mesh policies, set up observability, and deploy‚Äîall from the same canvas.\n\n### Scenario 3: Troubleshooting Production Issues\n\n**With Miro:** Diagrams are useless. Back to the terminal.\n\n**With Kanvas:** Switch to Operator mode, see the live state of your infrastructure, identify failing components visually, and drill down into logs and metrics‚Äîwithout leaving the visual context.\n\n### Scenario 4: Standardizing Deployment Patterns\n\n**With Miro:** Copy-paste diagrams and hope teams implement them correctly.\n\n**With Kanvas:** Create a design pattern, publish it to the Catalog, and teams can clone and deploy it exactly as designed. Consistency guaranteed.\n\n## The Best of Both Worlds\n\nHere's the thing: **Kanvas doesn't replace the brainstorming aspect of Miro**. You can still sketch, annotate, and collaborate visually. The difference is that when you're ready to move from idea to implementation, Kanvas goes with you.\n\nYou can start with high-level architecture diagrams and progressively add detail, configuration, and deployment logic‚Äîall in the same tool. The barrier between \"design time\" and \"runtime\" dissolves.\n\n## Who Should Use Kanvas?\n\nKanvas is ideal for:\n- **Platform Engineers** building internal developer platforms\n- **DevOps and SRE Teams** managing complex infrastructure\n- **Cloud Architects** designing multi-cloud strategies\n- **Infrastructure Teams** migrating to Kubernetes\n- **Anyone** tired of YAML hell\n\nIf you're working with cloud-native infrastructure and you've wished for a better way to visualize, design, and operate it‚ÄîKanvas is your tool.\n\n## Beyond the Whiteboard: Infrastructure That Works\n\nMiro is fantastic for what it does. But when you need to design infrastructure that actually runs, deploys, scales, and operates‚Äîyou need more than a whiteboard.\n\nYou need Kanvas.\n\n**Infrastructure as Design.** Not infrastructure as an afterthought.\n\nReady to see the difference? <Link to=\"/cloud-native-management/kanvas\">Try Kanvas today</Link> and experience what it's like to work with a tool built for engineers, by engineers.\n\n---\n\n*Want to learn more? Check out the <Link to=\"/cloud-native-management/catalog\">Kanvas Catalog</Link> for ready-to-use infrastructure patterns, or dive into the <Link to=\"/cloud-native-management/meshery\">Meshery documentation</Link> to understand the powerful engine behind Kanvas.*\n\n</BlogWrapper>\n","frontmatter":{"title":"Kanvas: Like Miro, But Much, Much More","type":"Blog","technology":null,"product":"Kanvas","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAADF0lEQVR42pVVS08TURT+UIQgiWGFG4KPX6ALJXGhiSvjI2qUhSbGGI0BYogS48qkiXtICBurnSktj05vOy19UJ5SQ4AViVBK2ylQIBgNGHVlwiPt9dxpKS0FwbOauZP7ne985ztngP2C8yIYDEcKzsWZ+PZfwXMu+c3X4JKuQGM3EFLupL+jCKz2KD0dACyyb7NSP1ShR2rDmMoR6GrAt94mrA5xTCsmxNiZbBV8jyoykc5mtZbDK7+Gr30Nw7Ykxl0cDlMd4uwlvg9wLHiSmGW/CPgt4h0nsowLIhgshk9+TGBhDNmIlTVFz+s6oEuqJ1ZNOmBIWUfUkULCS892DSHbc4RZSSHgBCuD22TEiJ1jsEuAJeE1bxYAziibxC6JuDuFZb9I0E7n5flMp6jMMDNR5ktU3nl4pBEduL9zE6NODmcG8GsfR9y1gSUCmrGPYkG9AIdUQ8mNGLCW77BjhhLSJo75HsGgDVH3aajSfdIxhtAgh9dSR5df4c84J/3mEXE8gL/zFFXUgqFujk+2uI6RjUBrKVGPQaPylnx0yfETs/ZGyloJt9xK4E8QYS/o7D3G1Uq4qEl+y1qmCkoox3SMbAhRZ0hgARhStohBCos+wTaBqHIvbWZqmku6SZc1HajXInTeSgOaNbDcxhQAOgmQuhi2R4jtbQIsRjxQCg+Z3CNPUYkcfeQCz36ABSWzVUTJDqLkHhLcKT2F5mikxFbS+iScpkek7wqCjGOgi5PdovnWEegJasqcW5TZTB+r4ZQf0tglMF3QlBVElGcIdlSRlu90psO2ufymCNtMk+Cz3TVgHy8SqzEEheAdGxhV820TUzd0/4WVSWjKZbjN56j0llzbpM3oNR6n2TXjsyijU+jzb2NrrhRWAkJnFYvuiuxsZ2PSeEwfPR+N3vABoxfZHj1ljhI0YKK5LI9c3oug7pPeoLf9B810EmMCMGc5zNNyCLPfBGbAF3PF/sth9/ryWqppBMnI1Kh+W/3O+rJJ0JxnD7O+di3YTNaAfAuqfJVAriPE7mYZ1R5mwe7+Bey16g/4BfwFnv8zUZvC4ikAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/7b643017b888e339b099aa6f9ed83acd/13677/kanvas-icon-color.png","srcSet":"/static/7b643017b888e339b099aa6f9ed83acd/f054e/kanvas-icon-color.png 750w,\n/static/7b643017b888e339b099aa6f9ed83acd/13677/kanvas-icon-color.png 1000w","sizes":"100vw"},"sources":[{"srcSet":"/static/7b643017b888e339b099aa6f9ed83acd/4f03f/kanvas-icon-color.webp 750w,\n/static/7b643017b888e339b099aa6f9ed83acd/3cd29/kanvas-icon-color.webp 1000w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}},"extension":"png","publicURL":"/static/7b643017b888e339b099aa6f9ed83acd/kanvas-icon-color.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB8UlEQVR42p2Vz0tUURiGZ6ZGm5JIxKiNMFILXQUtogjUhRDR0C0IN9UqCV2ohUWF4Z/gTqR0I20ipsCNBdVKYtqoZEqTRIo7oWarRvf6fPSO3LlzbzPjgYfvzD1z3/P9OOe7sVjE8DwvDomQ5wlbi9Uy/C9hL8AZyIDj2+xARWEJJTQ/Dg9c1/2J7bG5929MQvp/UeyFKJuCm/AelhFcw171Cf7l2W/sCPao/92g4EG4Ai9hBRbhkwSvwUMJboGreZ71XmyyTJCFehYewXf4Cp8hJ0HHJ7hjXvpEp6GhxFMmR2AKLsJpGLfdYR5+BDzclp2Dc9AOTyxV/nDr5JknsTR0QhYPC3Cd+bDWbYNbcBIGLM/w1lIWDPebXvD4/QuGmDZh72EvwyA8g2YV6YOi+GIbl+RRHual96eYHx2ZG/pPUinJqhgLyrMJvq5KUF47Op+H4DxCL/TcTkEuVDAYMmMT+ixkVd6O032JnYBLMKu8L8GrMA+LRRmDFuiGmZCibMBdFeWOPH1XUhR+HIYJhdSGfa4NisfGCTk2ttYFp1S4VPCmWI6ewqrCqPZgv4HGsiuoq5ep8erZ5v3mTJigvzncho92BSOaQwE7Cscim0NI+7JqPob1QPuyK9pasX1FNVi86WB+dl8NNuQTEK/1E7AL3//umadWf0cAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/1e93082c7ffa236852d939180bde0ff6/13677/kanvas-icon-white.png","srcSet":"/static/1e93082c7ffa236852d939180bde0ff6/f054e/kanvas-icon-white.png 750w,\n/static/1e93082c7ffa236852d939180bde0ff6/13677/kanvas-icon-white.png 1000w","sizes":"100vw"},"sources":[{"srcSet":"/static/1e93082c7ffa236852d939180bde0ff6/4f03f/kanvas-icon-white.webp 750w,\n/static/1e93082c7ffa236852d939180bde0ff6/3cd29/kanvas-icon-white.webp 1000w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}},"extension":"png","publicURL":"/static/1e93082c7ffa236852d939180bde0ff6/kanvas-icon-white.png"}},"fields":{"slug":"/blog/kanvas/kanvas-like-miro-but-much-much-more"}},{"id":"d47787bd-4982-5d4c-89d7-c99fbcb183d1","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nA common point of confusion when working with Kubernetes is understanding how `ConfigMap` updates are handled. You‚Äôve pushed a change to your ConfigMap, but your application isn't seeing the new values. What's going on?\n\nThe answer depends entirely on **how your application consumes the ConfigMap**. There isn't a \"type\" of ConfigMap object itself, but rather two distinct *methods of consumption* by a Pod, and each has drastically different behavior regarding updates.\n\nTo tell what \"kind\" you have, you need to look at your Pod or Deployment's YAML definition.\n\n## How to Check Your Pod's ConfigMap Consumption\n\nYou can find out how a Pod is using a ConfigMap by inspecting its YAML definition. üßê  Run this command to get the running YAML for a specific pod:\n\n```bash\nkubectl get pod <your-pod-name> -o yaml\n```\n\nNow, look for two key sections in the `spec.containers` list:\n\n1.  **Environment Variables:** Look for `env` or `envFrom`.\n2.  **Mounted Volumes:** Look for `volumeMounts` and the corresponding `volumes` section at the Pod spec level.\n\nLet's break down what each one means for reloading.\n\n## 1. Consumed as Environment Variables\n\nThis is when your Pod's YAML injects ConfigMap data directly as environment variables for the container.\n\n### How to Identify It\n\nIn your Pod spec, you'll see blocks like this:\n\n```yaml\n# ...\nspec:\n  containers:\n  - name: my-app-container\n    image: my-app\n    env: # <-- Look here\n      - name: MY_CONFIG_KEY\n        valueFrom: # <-- Or here\n          configMapKeyRef:\n            name: my-special-config\n            key: some.config.key\n    envFrom: # <-- Or here\n      - configMapRef:\n          name: my-special-config\n# ...\n```\n\nIf you see `env` or `envFrom` pointing to a `configMapKeyRef` or `configMapRef`, your application is consuming the ConfigMap as environment variables.\n\n### Reload Behavior: üõë No Hot-Reload\n\nThis is the most critical difference: **Changes to a ConfigMap are NOT reflected in running Pods that use them as environment variables.**\n\nEnvironment variables are set by the container runtime *only when the container is created*. They are immutable for the life of that running process.\n\n**How to Apply Changes:** To make the application see the new ConfigMap values, you **must restart the Pod**. The simplest way to do this for a `Deployment` is with a rolling restart:\n\n```bash\nkubectl rollout restart deployment <your-deployment-name>\n```\n\nWhen the new Pods are created, they will read the *updated* ConfigMap data and set the new environment variables.\n\n\n## 2. Consumed as a Mounted Volume\n\nThis method mounts your ConfigMap as one or more files inside your Pod's filesystem. Your application is programmed to read its configuration from these files (e.g., `/app/config/settings.properties`).\n\n### How to Identify It\n\nYou'll see two corresponding sections in your Pod spec:\n\n1.  `spec.containers.volumeMounts`: This tells the container where to mount the volume.\n2.  `spec.volumes`: This defines the volume itself and links it to the ConfigMap.\n\n\n```yaml\n# ...\nspec:\n  containers:\n  - name: my-app-container\n    image: my-app\n    volumeMounts: # <-- Look here\n    - name: config-volume\n      mountPath: /etc/config\n  volumes: # <-- And here\n  - name: config-volume\n    configMap:\n      name: my-special-config\n# ...\n```\n\nIf you see this `volumes` and `volumeMounts` pairing, your application is consuming the ConfigMap as files.\n\n### Reload Behavior: ‚úÖ Automatic... With a Catch\n\nThis method **does support hot-reloading**, but with two important caveats:\n\n1.  **There is a delay.** When you update the ConfigMap object, the `kubelet` on the node is responsible for updating the mounted files. This is not instantaneous. It relies on a periodic sync cycle, and the total delay can be **60 to 90 seconds (or even longer)** before the files at `mountPath` are actually updated.\n\n2.  **Your application must support it.** Kubernetes *only* updates the files on disk. It does **not** send a signal (like `SIGHUP`) to the process or restart the container. Your application must be built to:\n\n      * Watch the configuration files for changes (using a library like `fsnotify`).\n      * Periodically re-read the configuration files on its own timer.\n\nIf your application only reads its config files on startup, it will behave just like the environment variable method: **it will not see the changes until it is restarted.**\n\n\n## ConfigMap Reload Behavior Summary\n\nHere‚Äôs a simple table to remember the differences:\n\n| Consumption Method | How to Identify in Pod YAML | Are Changes Updated in Running Pod? | How Are Changes Seen? |\n| :--- | :--- | :--- | :--- |\n| **Environment Variables** | `spec.containers.env` `spec.containers.envFrom` | **No** ‚ùå | Pod must be **restarted**. |\n| **Mounted Volume** | `spec.containers.volumeMounts` `spec.volumes` | **Yes** ‚úÖ (with delay) | Kubelet updates files. **Application must be coded** to reload the updated file. |\n\n### What If I Need Automatic Restarts?\n\nIf you are using the volume mount method but your application doesn't support live reloading, you can use a \"reloader\" tool. A popular open-source controller like [**Stakater's Reloader**](https://github.com/stakater/Reloader) can watch for ConfigMap changes and automatically trigger a rolling restart of any Deployment that uses it. This gives you the best of both worlds: configuration in files and automatic updates for apps that can't reload on their own.\n\n<br />\n<hr />\n<br />\n\n## Skip the CLI. Power up with Kanvas\n\nAlternatively, you can skip the YAML editing and make these changes visually. That is, if you're managing your Kubernetes cluster using Kanvas. Let's break down how to use it to manage your resources, like a `ConfigMap`. \n\n## ü§î What is Kanvas Designer?\n\n[Layer5's Kanvas](https://layer5.io/kanvas) is a powerful tool for designing, deploying, and managing your Kubernetes and Cloud infrastructure and workloads from a visual interface. Instead of writing hundreds of lines of YAML by hand, you build a **Design**. This design is a visual representation of your components (`Deployment`, `Service`, `ConfigMap`, etc.) and their relationships.\n\n## üé® How to Update a ConfigMap in Kanvas Designer\n\nUpdating a `ConfigMap` through the Designer follows this \"design-first\" workflow. You don't just \"edit\" the live resource in the cluster; you **update your design** and then **(re-)deploy it**.\n\nHere is the step-by-step process:\n\n1.  **Open Kanvas Designer:** Log in to your Kanvas UI and navigate to Designer mode (the default mode).\n\n2.  **Load Your Design:** Open the design file that contains the `ConfigMap` you want to edit. If you don't have a design yet, you can import your existing `ConfigMap` from your cluster directly onto the canvas.\n\n3.  **Find the ConfigMap Component:** On the visual canvas, find the block representing your `ConfigMap`. It will have the Kubernetes icon and the \"ConfigMap\" kind.\n\n4.  **Edit the Configuration:** Click on the component. A configuration panel will slide out, often with a 'Configure' tab or an editor icon. This will show you the key/value pairs for that *specific* `ConfigMap` resource.\n\n5.  **Deploy the Design:** Changes are automatically saved in your design as you make them. Use the **Deploy** button to send your entire design to your target Kubernetes or Cloud environment. Kanvas will calculate the difference (a \"diff\") and apply the updated `ConfigMap` manifest to your cluster. This action is the equivalent of running `kubectl` server-side apply using your design.\n\n\n## üõë The Most Important Part: Reload Behavior\n\nThis is critical: **Using Kanvas Designer to update a ConfigMap does NOT change how your application reloads it.**\n\nDeploying from Kanvas is just a friendly, visual way to run `kubectl apply`. The rules we discussed in our previous post about ConfigMap behavior still apply completely:\n\n  * **If your Pod consumes the ConfigMap as Environment Variables:** Your running Pods **will not** see the change. You must still restart them (e.g., `kubectl rollout restart deployment ...`).\n  * **If your Pod consumes the ConfigMap as a Mounted Volume:** The files inside the Pod **will** be updated (after the kubelet sync delay), but your application *still* needs to be smart enough to re-read that file from disk.\n\nKanvas Designer simplifies the *applying* of the change and helps you visually manage your application's state, but it doesn't change the fundamental Kubernetes behavior of *how* that change is consumed by your workloads.\n\n</BlogWrapper>\n","frontmatter":{"title":"How can you tell what kind of Kubernetes Configmap you have?","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVR42gGfAmD9APzQBffNCPbJC+S8GaKZNFlzTC5YWw89WBw9XWl8lWeAp32Polh0ill7lF6Em1aDmk2Al0d9lUZ8lEd8kgDduiDPsyq5qTmZnE9yi2RNeHZCc4U9a4XJ0dTp8f+Nr/Tr8v/T1tdsi6BtkqhgjKJRhZxIfpZGfpZFfpcAmpxUiZZgaop6UoSUW42iaJiviK3Bp73J09TVysvNqK+8vr7Av8XKk66+g6a5bpuxWY+pS4ahRIGgQYCiAFqFhlWEkk2FqFWQwHqp0a3K4ODr8d7g4dDR0t3d3eHi4dLW2cPQ2LbN2Ze7zXmrw1+cukyRtUCKtDuHtQA6eKNBfq5SjcF0pdeoyOni7fj7/P3g4+Pj5+bl6OfW4uT////u9fjH3+mgy9x8uNNep8xHm8k5k8oyj8sAMnCqQHy1XpPHjLTextrx9Pf8////5e7txeDd9vLz+fv7+Pv75PL1weLrmc/hc77aVK/YPaTZLpzdJpfhADFnnUN1qWaRvZe11c7c7fb6/f/9/snh367o4f////b6+ejw8s3k6arX4IPJ2mC92EOz2y2p4h+h6hmd8QAwWYJCaY5khKSSqL/G0d3x9Pb////T4N/T5eP////r8PHR3uCuzdGIwspkvMhFt8wss9Qard8Qpu0LovkAK0ZdO1RrV22BfY6dq7S92Nve/P398PDw7evr////3uLjr77BhqqvYqarQqmwKK+5FbLCCrDMBKreAqb1ACMyNy8+RkNTXV9td36Ij56lqdDU1eLo59PV1trb3K6ytXqHjFd9gTuFhyOWlRGnowWzqgK0qAKxrwCtzAAdIhomLis0P0NGUlhUX2ZVYGVTYGVebXFPXWJEVlpYXGJET1UwVVgfbGwPiIEEoZECspQQuIQ5uGx6ulHgG5cIXzLUqQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/88427231d61b05cc39b0208166c642ea/87706/image.png","srcSet":"/static/88427231d61b05cc39b0208166c642ea/0dee1/image.png 750w,\n/static/88427231d61b05cc39b0208166c642ea/8beaa/image.png 1080w,\n/static/88427231d61b05cc39b0208166c642ea/87706/image.png 1280w","sizes":"100vw"},"sources":[{"srcSet":"/static/88427231d61b05cc39b0208166c642ea/a66aa/image.webp 750w,\n/static/88427231d61b05cc39b0208166c642ea/65dd5/image.webp 1080w,\n/static/88427231d61b05cc39b0208166c642ea/71d4d/image.webp 1280w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/88427231d61b05cc39b0208166c642ea/image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVR42gGfAmD9APzQBffNCPbJC+S8GaKZNFlzTC5YWw89WBw9XWl8lWeAp32Polh0ill7lF6Em1aDmk2Al0d9lUZ8lEd8kgDduiDPsyq5qTmZnE9yi2RNeHZCc4U9a4XJ0dTp8f+Nr/Tr8v/T1tdsi6BtkqhgjKJRhZxIfpZGfpZFfpcAmpxUiZZgaop6UoSUW42iaJiviK3Bp73J09TVysvNqK+8vr7Av8XKk66+g6a5bpuxWY+pS4ahRIGgQYCiAFqFhlWEkk2FqFWQwHqp0a3K4ODr8d7g4dDR0t3d3eHi4dLW2cPQ2LbN2Ze7zXmrw1+cukyRtUCKtDuHtQA6eKNBfq5SjcF0pdeoyOni7fj7/P3g4+Pj5+bl6OfW4uT////u9fjH3+mgy9x8uNNep8xHm8k5k8oyj8sAMnCqQHy1XpPHjLTextrx9Pf8////5e7txeDd9vLz+fv7+Pv75PL1weLrmc/hc77aVK/YPaTZLpzdJpfhADFnnUN1qWaRvZe11c7c7fb6/f/9/snh367o4f////b6+ejw8s3k6arX4IPJ2mC92EOz2y2p4h+h6hmd8QAwWYJCaY5khKSSqL/G0d3x9Pb////T4N/T5eP////r8PHR3uCuzdGIwspkvMhFt8wss9Qard8Qpu0LovkAK0ZdO1RrV22BfY6dq7S92Nve/P398PDw7evr////3uLjr77BhqqvYqarQqmwKK+5FbLCCrDMBKreAqb1ACMyNy8+RkNTXV9td36Ij56lqdDU1eLo59PV1trb3K6ytXqHjFd9gTuFhyOWlRGnowWzqgK0qAKxrwCtzAAdIhomLis0P0NGUlhUX2ZVYGVTYGVebXFPXWJEVlpYXGJET1UwVVgfbGwPiIEEoZECspQQuIQ5uGx6ulHgG5cIXzLUqQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/88427231d61b05cc39b0208166c642ea/87706/image.png","srcSet":"/static/88427231d61b05cc39b0208166c642ea/0dee1/image.png 750w,\n/static/88427231d61b05cc39b0208166c642ea/8beaa/image.png 1080w,\n/static/88427231d61b05cc39b0208166c642ea/87706/image.png 1280w","sizes":"100vw"},"sources":[{"srcSet":"/static/88427231d61b05cc39b0208166c642ea/a66aa/image.webp 750w,\n/static/88427231d61b05cc39b0208166c642ea/65dd5/image.webp 1080w,\n/static/88427231d61b05cc39b0208166c642ea/71d4d/image.webp 1280w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/88427231d61b05cc39b0208166c642ea/image.png"}},"fields":{"slug":"/blog/kubernetes/how-can-you-tell-what-kind-of-kubernetes-configmap-you-have"}},{"id":"754ab117-0e63-5293-baa0-2009a3b8e50c","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport ReadmeAgents from \"./readme-agents.webp\";\n\n<BlogWrapper>\n\nAI coding assistants are everywhere. They live in our terminals, they're built into our IDEs, and they've fundamentally changed how we write software. From Codex and Copilot to Gemini and Claude, developers now have a powerful new collaborator.\n\nBut, there's a problem. To be effective, these AI agents need context. They need to understand your project's architecture, coding standards, and specific rules. This guidance lives in configuration files, but every agent speaks a different language.\n\nYou might have a `CLAUDE.md` for Claude, a `.cursor/rules/` directory for Cursor, and `.github/copilot-instructions.md` for Copilot, and a `JULES.md` for Google Jules. This fragmentation creates a digital Tower of Babel in your repository. When you switch tools or collaborate with a team using different agents, you're stuck translating the same core instructions into multiple formats.\n\nWhat if there was a universal translator? A single, standardized file to provide context to *any* AI coding agent?\n\nThat‚Äôs the idea behind **AGENTS.md**: an open standard for guiding AI coding agents.\n\n### What We'll Cover\n\n* **What is AGENTS.md?** The \"README for AI.\"  \n* **Why Do We Need It?** Taming the chaos of configuration files.  \n* **What Goes Inside?** A practical guide to crafting your own AGENTS.md.  \n* **Making It Work Today:** Bridging AGENTS.md with your current tools.  \n* **The Future is Unified:** What's next for AI-native development.\n\n### What is AGENTS.md?\n\nThink of it this way: README.md is the front door for human developers. It's the first place you look to understand a project's purpose, setup, and contribution guidelines.\n\n<img src={ReadmeAgents}  width=\"50%\" />\n\n**AGENTS.md is the front door for AI agents.** It‚Äôs a single, standardized markdown file in the root of your project where AI assistants can get all the context they need to become a high-performing teammate.\n\nThis simple idea is already gaining traction. With support from tools like Codex, Cursor, and Gemini CLI, AGENTS.md has been adopted by over 40,000 open-source projects.\n\n### Why AGENTS.md? The Case for a Universal Standard\n\nDevelopers are already feeling the pain of config fragmentation. On GitHub, users of tools like Claude Code and Cline have opened issues asking for a unified standard, specifically pointing to AGENTS.md.\n\nHere‚Äôs the problem without a standard:\n\n* **Tool Lock-in:** Switching to a new, better AI agent means rewriting your project's context from scratch in a new format.  \n* **Team Friction:** When your team members use different agents, your repository gets cluttered with redundant config files (.cursor/, claude.md, gemini.md), all containing slight variations of the same information.  \n* **Maintenance Nightmare:** Every time a rule changes‚Äîlike updating your deployment command or linting standard‚Äîyou have to update it in multiple places, hoping you don't miss one.\n\nAGENTS.md solves this by creating a single source of truth.\n\nInstead of a tangled mess of agent-specific files, you have one clean, universal file that works across all tools, which can come with its own drawbacks.\n\n### Why you might want to use multiple AI code assistant configuration files\n\nUsing multiple configuration files for an AI code assistant can offer a few benefits, most noteably is that of allowing for specialization, consistency, and tighter control in more complex projects. \n\n#### Improved project-specific customization\n\n- Tailored behavior: A configuration file can be set up for a specific project or microservice to guide the AI with project-specific settings. This ensures the AI understands the unique context, coding style, and framework of that codebase, providing more accurate and relevant suggestions.\n- Contextual awareness: For large codebases, AI assistants perform better when the code is organized into modular files. This allows the AI to process each file's context more effectively without being overloaded, leading to faster and more accurate suggestions.\n- Optimized performance: You can create lightweight configurations for smaller tasks or projects that don't require the AI to have a deep understanding of the entire codebase. This can reduce processing time and resource consumption. \n\n#### Enhanced flexibility and control\n\n- Switching models: By having multiple configurations, you can easily switch between different AI models, like Claude, GitHub Copilot, or a self-hosted model, to determine which is best for a specific task. This prevents vendor lock-in and allows you to always use the most effective tool.\n- Experimentation: Developers can experiment with different prompts, settings, and AI models by creating separate, isolated configuration files. This allows for testing and fine-tuning without disrupting the main project workflow. \n\n#### Streamlined team collaboration\n\n- Consistent guidance: A team can share a standard configuration file to ensure all members receive the same AI guidance. This helps enforce consistent coding practices, security rules, and tool usage across the entire development workflow.\n- Centralized management: Centralizing API keys and other secrets within managed configurations allows for secure collaboration. Teams can roll out pre-approved AI models and workflows while retaining oversight of their data.\n- Reduced inconsistency: A standard configuration file prevents inconsistent AI outputs that can arise when different team members use different settings or prompts, which is a major headache for Python projects and others\n\n### What's the difference between AI code assistant configuration files?\n\nTo improve the AI's relevance and prevent security issues, developers can explicitly control which parts of a codebase the AI should focus on or ignore.\n- `.aiignore`: Similar to a `.gitignore` file, this file tells the AI which files and folders to exclude from its analysis. This is critical for security, as it prevents the AI from being exposed to sensitive information.\n- `.github/copilot-instructions.md`: This file contains custom instructions specifically for GitHub Copilot, guiding its behavior and code generation according to project standards or user preferences.\n- `AGENTS.md`: These files are associated with the concept of \"agents\" in AI coding, particularly with tools like GitHub Copilot's coding agent. They can define behaviors and instructions for these agents, potentially at a more granular level than the general copilot-instructions.md. AGENTS.md suggests a collection of agent definitions.\n- `CLAUDE.md`: This file serves a similar purpose to copilot-instructions.md but is specifically designed for the Claude AI model, allowing users to provide custom instructions for its interactions and code generation.\n- `.cursorrules`, `.windsurfrules`, `.clinerules`: These files, and their directory counterparts, contain configuration or rule sets for specific AI coding tools.\n\n\nREADME.md: This is a standard Markdown file used in most software projects to provide an overview, instructions, and other essential information about the project. While not directly tied to AI assistant configuration, it can implicitly guide AI tools by providing context about the codebase.\n\nThe key distinction is between files designed to configure and instruct specific AI coding assistants (e.g., Copilot, Claude, Cursor, Windsurf) and general project documentation (README.md) that provides human-readable information about the project. The AI configuration files differ based on the particular AI tool they target and the specific instructions or rules they convey to that tool.\n\n\n### What Goes Inside an AGENTS.md File?\n\nAGENTS.md consolidates the essential knowledge required to contribute to your project effectively. It's a living document that captures your team's conventions, architectural decisions, and operational knowledge.\n\nHere‚Äôs a practical example of what a robust AGENTS.md might look like:\n\n```markdown\n# AGENTS.md: Project Constitution for AI Assistants\n\n## 1. Project Overview & Core Purpose  \n- **Purpose:** This is a customer support ticketing system built with a React frontend and a Node.js (Express) backend.  \n- **Tech Stack:** TypeScript, React, Tailwind CSS, Node.js, Express, PostgreSQL.  \n- **Key Goal:** Provide a fast, reliable, and user-friendly interface for support agents to manage customer issues.\n\n## 2. Architecture & Design Patterns  \n- **Database:** We use PostgreSQL for its reliability and ACID compliance. All business logic involving payments or user accounts must be transactional.  \n- **Caching:** Redis is used for session storage and caching non-critical data. Never cache user-private data.  \n- **State Management (Frontend):** Use React Query for server state and Zustand for global UI state. Avoid prop-drilling.  \n- **API Design:** We follow RESTful principles. All API error responses must include a \\`requestId\\` for easier debugging.\n\n## 3. Code Standards & Conventions  \n- **Formatting:** We use Prettier with the settings in \\`.prettierrc\\`. All code must be formatted on commit.  \n- **Linting:** ESLint is configured with rules in \\`.eslintrc.js\\`. Pay close attention to rules against using \\`any\\`.  \n- **Naming:**  \n    - Components: \\`PascalCase\\` (e.g., \\`TicketList.tsx\\`)  \n    - API endpoints: \\`kebab-case\\` (e.g., \\`/api/user-tickets\\`)  \n    - Functions: \\`camelCase\\` (e.g., \\`fetchUserData\\`)  \n- **Testing:** Use Jest and React Testing Library. All new components must have at least 80% test coverage for critical paths.\n\n## 4. Build, Test, & Deploy Pipeline  \n- **Local Setup:** Run \\`npm install\\` and then \\`npm run dev\\`.  \n- **Running Tests:** \\`npm test\\`  \n- **Build Command:** \\`npm run build\\`  \n- **Deployment:** Pushes to the \\`main\\` branch trigger a GitHub Actions workflow that deploys to Vercel.\n\n## 5. Common Pitfalls & API Nuances  \n- **Stripe API:** All POST requests are idempotent. It's safe to retry them.  \n- **SendGrid API:** This API has strict rate limits. All email-sending tasks should be pushed to our Redis queue.  \n- **Authentication:** If you see auth errors locally, it's likely because the Redis server died. Restart it with \\`redis-server\\`.\n\n## 6. Git & PR Workflow  \n- **Branch Naming:** \\`feature/ticket-123-add-search-bar\\`  \n- **Commit Messages:** Follow the Conventional Commits specification. (e.g., \\`feat: add user profile page\\`)  \n- **Pull Requests:** Must be reviewed by at least one other team member before merging. Link the associated ticket in the PR description.\n```\n\n*Start small, and let it grow.* Your AGENTS.md doesn't need to be perfect on day one. Begin with the most critical information and expand it over time. Each time a developer (or an agent) learns something new about the project, add it to the file.\n\n### Bridging AGENTS.md with Existing Tools\n\nWhile many modern agents support AGENTS.md out of the box, some older tools still look for their own native config files. For those, you can use two simple bridging strategies to get them to read your central AGENTS.md file.\n\n#### Method 1: Symbolic Linking\n\nA symbolic link (symlink) is a pointer to another file. You can create symlinks that trick agents into reading AGENTS.md while looking for their native file.\n\nOpen your terminal in the project root and run these commands for the tools you use:\n\n<pre><code className=\"language-markdown\">\n# For Claude Code  \nln -s AGENTS.md CLAUDE.md\n\n# For Cursor  \nmkdir -p .cursor/rules  \nln -s ../../AGENTS.md .cursor/rules/rules.mdc\n\n# For GitHub Copilot  \nmkdir -p .github  \nln -s ../AGENTS.md .github/copilot-instructions.md\n</code></pre>\n\nYour tools continue to work as expected, but now they all draw their context from a single source.\n\n#### Method 2: Using Imports\n\nSome agents support importing one markdown file into another. For example, in Claude Code's CLAUDE.md file, you can simply add a line to import your universal file:\n\n```markdown\n# In ./CLAUDE.md\n\n@AGENTS.md\n\n# You can add Claude-specific instructions below if needed\n```\n\nThis approach keeps your setup clean and ensures AGENTS.md remains the primary source of truth.\n\n#### What's the difference between agents.md and prompt.md?\n\n`AGENTS.md` and `.prompt.md` files serve different purposes in guiding an AI coding assistant. AGENTS.md provides general, project-level context, while .prompt.md files define reusable, task-specific instructions. A `.prompt.md` file defines a reusable, task-specific prompt that can be executed directly by an AI assistant. \nPurpose: Automate common, repeatable development tasks. A `.prompt.md`:\n\n- Encapsulates complex tasks: Lets you define and reuse complex, multi-step instructions for specific jobs.\n- Task specialization: Creates a specialized prompt for common tasks, such as generating a test case or scaffolding a component.\n- Chat integration: Some AI assistants, like GitHub Copilot in VS Code, allow developers to run prompt files directly from the chat interface using a slash command.\n\n**Key differences summarized**\n\n|| Aspect \t|| AGENTS.md\t|| .prompt.md ||\n| Scope\t| Project-wide | Task-specific |\n| Purpose\t| Defines general rules and project context for any task\t| Automates specific, repeatable tasks |\n| Trigger\t| Automatically referenced by the AI for every interaction\t| Manually invoked by the user, often via a chat command |\n| Content\t| High-level instructions, conventions, and setup details\t| Detailed instructions and examples for a single, focused task |\n| Analogy\t| A handbook for the AI\t| A macro or recipe for the AI |\n\n\n### What's Next: The Future of AI Collaboration\n\n`AGENTS.md` is more than just a configuration file; it's a step toward a future where AI and human developers collaborate seamlessly.\n\nImagine a world where any AI agent can clone a repository and instantly understand its context, conventions, and goals. Onboarding a new AI assistant becomes as simple as pointing it to a URL. Open-source projects can accept high-quality contributions from autonomous agents because the rules of engagement are clearly defined.\n\nThis is the future that a common standard like `AGENTS.md` enables. For now, we can use simple bridges like symlinks to make it work. But as the ecosystem evolves, expect more and more tools to adopt AGENTS.md as the default.\n\nOne file to guide them all. One file to align them. One file to bring them all and in the codebase bind them.\n\n</BlogWrapper>     \n","frontmatter":{"title":"AGENTS.md: One File to Guide Them All","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRt4AAABXRUJQVlA4INIAAACQBQCdASoUABQAPtFepE6oJSMiKAqpABoJZAC7IL/gxgtwliiZFtY75vb8EhnuduxtT67WAAD+0523iSp2vhGudQcqSwlMVooqbXEMhAJ2Pxy9FvRTatzsWBvdn64OyxP5Do0y6Qlv8VivPIA8F48MnVTg6HECex7bSYtBDkI+i1NKw/c+urmKsqgbPPCvPmf5JKqxXb7NnCWNIExtN+9yQ/sU8KFUBB8NTgj0z1bZeXmu89979AcVTae5s+P8gd/V2VpAwMlp4KANrnia0aQAAAA="},"images":{"fallback":{"src":"/static/76c19b76901449806f78915cf47038aa/67ded/readme-agents.webp","srcSet":"/static/76c19b76901449806f78915cf47038aa/4f03f/readme-agents.webp 750w,\n/static/76c19b76901449806f78915cf47038aa/67ded/readme-agents.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/76c19b76901449806f78915cf47038aa/readme-agents.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRt4AAABXRUJQVlA4INIAAACQBQCdASoUABQAPtFepE6oJSMiKAqpABoJZAC7IL/gxgtwliiZFtY75vb8EhnuduxtT67WAAD+0523iSp2vhGudQcqSwlMVooqbXEMhAJ2Pxy9FvRTatzsWBvdn64OyxP5Do0y6Qlv8VivPIA8F48MnVTg6HECex7bSYtBDkI+i1NKw/c+urmKsqgbPPCvPmf5JKqxXb7NnCWNIExtN+9yQ/sU8KFUBB8NTgj0z1bZeXmu89979AcVTae5s+P8gd/V2VpAwMlp4KANrnia0aQAAAA="},"images":{"fallback":{"src":"/static/76c19b76901449806f78915cf47038aa/67ded/readme-agents.webp","srcSet":"/static/76c19b76901449806f78915cf47038aa/4f03f/readme-agents.webp 750w,\n/static/76c19b76901449806f78915cf47038aa/67ded/readme-agents.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/76c19b76901449806f78915cf47038aa/readme-agents.webp"}},"fields":{"slug":"/blog/ai/agentsmd-one-file-to-guide-them-all"}},{"id":"6cf0b49c-2a8a-5605-b99d-e02e227b0d29","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nOver the course of [this series](/blog/category/docker), we've embarked on a deep technical dive into Docker Model Runner, moving beyond surface-level descriptions to uncover the engineering principles and practical implications of this innovative toolkit. From its foundational architecture to its integration with the broader developer ecosystem, Model Runner presents a compelling vision for the future of local AI development. In this concluding post, we'll synthesize the key engineering takeaways and explore the promising horizons as Docker Model Runner matures.\n\n## **Key Engineering Takeaways: A Recap**\n\nOur journey has illuminated several critical aspects that define Docker Model Runner's value proposition for engineers:\n\n1. **OCI for Robust Model Management:** Model Runner's strategic adoption of the Open Container Initiative (OCI) standard for packaging and distributing AI models is transformative. It brings DevOps-like rigor to model lifecycle management, enabling versioning, provenance, and the use of existing container registries and CI/CD pipelines for AI models.  \n2. **Performance via Host-Native Execution:** The decision to run inference engines (like llama.cpp) as host-native processes, with direct GPU access (especially Metal API on Apple Silicon), prioritizes local performance. This minimizes latency and provides a responsive experience crucial for iterative development.  \n3. **OpenAI-Compatible API for Seamless Integration:** By offering an API compatible with OpenAI's standards, Model Runner drastically lowers the barrier to entry. Engineers can leverage existing SDKs, tools like LangChain and LlamaIndex, and familiar coding patterns with minimal friction.  \n4. **Docker Compose for Orchestrated AI Stacks:** The introduction of the provider service type in Docker Compose allows AI models to be declared and managed as integral components of multi-service applications, simplifying the orchestration of complex local AI development environments.  \n5. **Ecosystem Synergy (e.g., Spring AI):** Integrations with frameworks like Spring AI demonstrate Model Runner's ability to seamlessly fit into established development ecosystems, enabling Java developers, for instance, to easily incorporate local LLMs.  \n6. **Advanced Local Workflows & Fine-Grained Control:** Model Runner empowers engineers to execute sophisticated, multi-stage AI pipelines locally. The ability to dynamically tune model parameters for specific tasks without API costs fosters deep experimentation and accelerates the development of nuanced AI features.\n\nCollectively, these features address core engineering challenges in local AI development: cost, privacy, iteration speed, complexity, and environmental control.\n\n## **Future Horizons: From Beta to Mainstream**\n\nAs Docker Model Runner evolves beyond its Beta phase, several key developments will shape its impact:\n\n1. API Stability and Maturation:  \n   A crucial step will be the stabilization of its APIs. As noted during its Beta, APIs were subject to change. A stable API will provide the confidence developers need to build more robust and long-lasting integrations.  \n2. **Expanded Platform and Hardware Support:**  \n   * **Windows GPU Acceleration:** The full realization of performant GPU acceleration on Windows (especially for NVIDIA GPUs) will be a significant milestone, broadening its accessibility to a large segment of the developer community.  \n   * **Linux Enhancements:** While a Docker Engine plugin exists, further enhancements for Linux environments, potentially with more streamlined management features akin to Docker Desktop, will be important for server-side local development or specialized Linux-based AI workstations.  \n3. Comprehensive Custom Model Management:  \n   The ability for users to easily package, docker model push their own custom or fine-tuned models to any OCI-compliant registry, and then docker model pull and run them seamlessly is paramount. This will unlock Model Runner's full potential for organizations with bespoke AI needs, moving beyond curated public models.  \n4. Deeper Ecosystem Integrations:  \n   Expect continued and deeper integrations with:  \n   * **MLOps Tools:** Tighter connections with MLOps platforms for experiment tracking, model monitoring (even locally), and smoother transitions from local development to production deployment pipelines.  \n   * **IDEs:** More direct integrations within popular Integrated Development Environments for an even more fluid \"inner loop\" experience.  \n   * **More Inference Engines:** While llama.cpp is a strong start, the potential for a pluggable engine architecture could see Model Runner supporting a wider array of inference backends optimized for different model types or hardware.  \n5. Enhanced Observability and Debugging:  \n   As local AI workflows become more complex, improved tools for observing model behavior, debugging inference issues, and monitoring resource consumption locally will become increasingly valuable.\n\n## **The Enduring Impact: Local AI as a Standard Engineering Practice**\n\nDocker Model Runner is more than just a feature; it represents a significant step towards making local AI development a standard, accessible, and efficient engineering practice. By integrating AI model execution directly into the familiar and powerful Docker ecosystem, it lowers barriers, fosters innovation, and empowers developers to build the next generation of AI-powered applications with greater speed, control, and confidence.  \nThe journey from Beta to a fully mature product will undoubtedly bring further refinements and capabilities. However, the foundational principles and architectural choices already evident in Docker Model Runner signal a bright future for local-first AI development, driven by the needs and workflows of engineers.  \n\n*This blog post series has been based on information available about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change as the product evolves.*\n</BlogWrapper>     ","frontmatter":{"title":"Docker Model Runner: Engineering Summary & Future Horizons","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACjElEQVR42jWL7U8SARzH7+/orZubL7TNpQJqNS2zthweYcZTVMp4UBAFR4gPyBFwR8CdHB54Cgp33qFCbekos6XZ1KWb5ZT1JpsL9YVtNR/Wi17E6do+++7z+2w/gDpjE2cs/Yfl5BcTP2Kp02TiJEmdsuzfGeosmeBO9gLqQo4ZjhMGiOSixI8xdDMGz8bs5DjxJUEexkcP6ZED2rEUwL+NjRzEubKfIPfjJLf/OUgAE0drkb1Xvo0J91pQ1GVxvaTw3VhghxTDxpKbtaJelYEeDH6lvFskmo0GslGUI3ZOFIA/T8f2t1LHe8xJ1pok76tc8DsGhGxXW3XGKBpI4O1wwIFT4U/p/pVh5yoJrY5wrOSFBExzmGluqH85PfP7pz+VKahpLRPaSxsttwx2kRGGzQg9veTcWA+/XeiZCpvfhLozRPdrIr/mDAGomZBmEm+Z8BleRBq6bIW324uExksVoECpr1Wa9U8gCMKFTKoLj1OLH7STuIbFtecvagYHJAQmiwxJw6gQcddqew32cWxq0YAydUYvXzcotvmsEVbcMtCsggl6vnOUbnyOSIZRGYFJQigAerFGyCd86rP4Z1ILOx+3c6vbueXNXXZ+HaIyIihcZXDVW9B7PcPNjijYm5b5ZuXB8B0IAREMqLN6ZRgdSi6Nz634mYyFYFXesXrtQBVodAcnlXrbZbCt4K6mqMlU2NBZLIXI99nlre8t/ugNqxeo1nmu65G6DqRS5ahoHeSrnQLNsyqdq1rtrHncV6m0XWvzCJR9pU2mkiZjsbjjkY3ow9OWoelqjQuokHl4Une51M2TwwIFUqlABHmRe/hymKeA+QqE6w+RPFyRuMolzrIH0JVmJ0/m+QemD2rnUbfIewAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/079679ec12e22e5eaead3990ab81da4f/366fe/hero-image.jpg","srcSet":"/static/079679ec12e22e5eaead3990ab81da4f/9b503/hero-image.jpg 750w,\n/static/079679ec12e22e5eaead3990ab81da4f/321ef/hero-image.jpg 1080w,\n/static/079679ec12e22e5eaead3990ab81da4f/84dcd/hero-image.jpg 1366w,\n/static/079679ec12e22e5eaead3990ab81da4f/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/079679ec12e22e5eaead3990ab81da4f/5f850/hero-image.webp 750w,\n/static/079679ec12e22e5eaead3990ab81da4f/2c010/hero-image.webp 1080w,\n/static/079679ec12e22e5eaead3990ab81da4f/5126b/hero-image.webp 1366w,\n/static/079679ec12e22e5eaead3990ab81da4f/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/079679ec12e22e5eaead3990ab81da4f/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACjElEQVR42jWL7U8SARzH7+/orZubL7TNpQJqNS2zthweYcZTVMp4UBAFR4gPyBFwR8CdHB54Cgp33qFCbekos6XZ1KWb5ZT1JpsL9YVtNR/Wi17E6do+++7z+2w/gDpjE2cs/Yfl5BcTP2Kp02TiJEmdsuzfGeosmeBO9gLqQo4ZjhMGiOSixI8xdDMGz8bs5DjxJUEexkcP6ZED2rEUwL+NjRzEubKfIPfjJLf/OUgAE0drkb1Xvo0J91pQ1GVxvaTw3VhghxTDxpKbtaJelYEeDH6lvFskmo0GslGUI3ZOFIA/T8f2t1LHe8xJ1pok76tc8DsGhGxXW3XGKBpI4O1wwIFT4U/p/pVh5yoJrY5wrOSFBExzmGluqH85PfP7pz+VKahpLRPaSxsttwx2kRGGzQg9veTcWA+/XeiZCpvfhLozRPdrIr/mDAGomZBmEm+Z8BleRBq6bIW324uExksVoECpr1Wa9U8gCMKFTKoLj1OLH7STuIbFtecvagYHJAQmiwxJw6gQcddqew32cWxq0YAydUYvXzcotvmsEVbcMtCsggl6vnOUbnyOSIZRGYFJQigAerFGyCd86rP4Z1ILOx+3c6vbueXNXXZ+HaIyIihcZXDVW9B7PcPNjijYm5b5ZuXB8B0IAREMqLN6ZRgdSi6Nz634mYyFYFXesXrtQBVodAcnlXrbZbCt4K6mqMlU2NBZLIXI99nlre8t/ugNqxeo1nmu65G6DqRS5ahoHeSrnQLNsyqdq1rtrHncV6m0XWvzCJR9pU2mkiZjsbjjkY3ow9OWoelqjQuokHl4Une51M2TwwIFUqlABHmRe/hymKeA+QqE6w+RPFyRuMolzrIH0JVmJ0/m+QemD2rnUbfIewAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/079679ec12e22e5eaead3990ab81da4f/366fe/hero-image.jpg","srcSet":"/static/079679ec12e22e5eaead3990ab81da4f/9b503/hero-image.jpg 750w,\n/static/079679ec12e22e5eaead3990ab81da4f/321ef/hero-image.jpg 1080w,\n/static/079679ec12e22e5eaead3990ab81da4f/84dcd/hero-image.jpg 1366w,\n/static/079679ec12e22e5eaead3990ab81da4f/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/079679ec12e22e5eaead3990ab81da4f/5f850/hero-image.webp 750w,\n/static/079679ec12e22e5eaead3990ab81da4f/2c010/hero-image.webp 1080w,\n/static/079679ec12e22e5eaead3990ab81da4f/5126b/hero-image.webp 1366w,\n/static/079679ec12e22e5eaead3990ab81da4f/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/079679ec12e22e5eaead3990ab81da4f/hero-image.png"}},"fields":{"slug":"/blog/docker/docker-model-runner-engineering-summary-future-horizons"}},{"id":"cd1299a5-8e67-5835-9211-e24b698da225","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nIn our [ongoing exploration](/blog/category/docker) of Docker Model Runner, we've covered its OCI-based model management, performance architecture, OpenAI-compatible API, and Docker Compose integration. Now, we turn to a specific, yet highly impactful, synergy: how Docker Model Runner empowers **Java developers using the Spring AI framework** to seamlessly incorporate local Large Language Models (LLMs) into their applications.  \nFor Java engineers vested in the Spring ecosystem, Spring AI offers a familiar and powerful abstraction layer for interacting with various AI models. Docker Model Runner's compatibility provides a straightforward path to leverage these local models without stepping outside the conventional Spring development paradigm.\n\n## **Spring AI: Simplifying AI for Java Applications**\n\nBefore diving into the integration, it's worth briefly understanding Spring AI's mission. Spring AI aims to apply core Spring principles‚Äîsuch as autoconfiguration, dependency injection, and portable service abstractions‚Äîto the domain of artificial intelligence. It provides Java developers with:\n\n* **Consistent APIs:** A unified API for interacting with different AI models (both local and remote), reducing the need to learn multiple vendor-specific SDKs.  \n* **Abstraction Layers:** Components like ChatClient, EmbeddingClient, and ImageClient abstract away the underlying model provider.  \n* **Integration with Spring Boot:** Easy setup and configuration within Spring Boot applications.\n\n## **Docker Model Runner as a Local \"Ollama\" for Spring AI**\n\nSpring AI supports various AI model providers, including commercial cloud services (like OpenAI, Azure OpenAI) and self-hosted solutions (like Ollama). From Spring AI's perspective, Docker Model Runner, with its OpenAI-compatible API, effectively acts like a local, easily manageable Ollama-style endpoint.  \nWhen Docker Model Runner is active and serving a model (e.g., Llama 3, Gemma) with its API endpoint accessible (typically http://localhost:12434 or http://model-runner.docker.internal if accessed from another container), Spring AI can be configured to point to it.  \nHere's how a Java engineer benefits:\n\n1. **Simplified Configuration in Spring Boot**\n  \n   Spring AI's autoconfiguration can often detect and set up the necessary beans to interact with an OpenAI-compatible endpoint. For Docker Model Runner, this typically involves setting a few properties in your application.properties or application.yml file:  \n   \n   ```java\n   \\# For Spring AI 0.8.x (or similar versions)  \n   spring.ai.openai.chat.base-url=http://localhost:12434/engines/v1 \n   \\# Or your specific DMR endpoint  \n   spring.ai.openai.chat.options.model=ai/llama3.2:1B-Q8\\_0 \n   \\# The model you want to use  \n   use  \n   spring.ai.openai.api-key=YOUR\\_DUMMY\\_API\\_KEY\\_OR\\_EMPTY\n   \\# Potentially disable API key if DMR doesn't require it strictly for local \n   ```\n\n   _(Note: The exact property names and structure might vary slightly based on the Spring AI version and whether you're configuring a generic OpenAI client or a more specific Ollama-like client type if Spring AI introduces more direct DMR support.)_  \n\n2. **Leveraging Spring AI's ChatClient and EmbeddingClient**\n\n   Once configured, developers can inject and use Spring AI's standard clients without needing to know that the underlying provider is Docker Model Runner. \n\n```java \n   import org.springframework.ai.chat.ChatClient;  \n   import org.springframework.ai.chat.prompt.Prompt;  \n   import org.springframework.beans.factory.annotation.Autowired;  \n   import org.springframework.stereotype.Service;\n\n   @Service  \n   public class MyAiService {\n\n       private final ChatClient chatClient;\n\n       @Autowired  \n       public MyAiService(ChatClient chatClient) {  \n           this.chatClient \\= chatClient;  \n       }\n\n       public String getJokeAbout(String topic) {  \n           Prompt prompt \\= new Prompt(\"Tell me a short joke about \" \\+ topic);  \n           return chatClient.call(prompt).getResult().getOutput().getContent();  \n       }  \n   }\n```\n\n   This code remains the same whether Spring AI is talking to OpenAI's cloud API, a self-hosted Ollama instance, or Docker Model Runner serving a local model. This portability is a huge win.  \n\n3. **Seamless Local Development and Testing**\n   Engineers can develop and test AI-driven features entirely locally using their preferred Java tools and the Spring framework. Docker Model Runner handles the model serving, and Spring AI provides the clean Java interface. This speeds up iteration cycles and reduces reliance on potentially costly cloud APIs during development.  \n\n4. **Consistency with Production (Potentially)**  \n   While Docker Model Runner is primarily for local development, the abstraction provided by Spring AI means that switching to a production-grade, potentially cloud-hosted model provider for deployment can be achieved mainly through configuration changes, without altering the core application logic.\n\n## **The Bigger Picture: Local AI in Enterprise Java**\n\nThe integration with Spring AI is significant because it brings the ease of local LLM experimentation directly into the robust, enterprise-focused Java and Spring ecosystem. It allows Java teams to:\n\n* **Prototype AI features rapidly.**  \n* **Upskill on AI concepts using familiar tools.**  \n* **Conduct local, private testing of AI interactions with business data.**  \n* **Integrate AI into existing Spring Boot applications with minimal friction.**\n\nDocker's collaboration with Spring AI (as noted in some announcements) underscores a shared vision of making AI more accessible and developer-friendly across different programming environments. By ensuring Docker Model Runner presents an API that Spring AI can readily consume, both platforms contribute to lowering the barrier to entry for sophisticated AI development.  \nFor Java engineers, this means Docker Model Runner isn't just another tool; it's a key enabler for leveraging the power of local LLMs within the comfort and productivity of the Spring framework.\n\n## **Next, we'll delve into some practical, task-specific configurations and advanced use cases you can explore with Docker Model Runner, moving beyond basic chat completions.**\n\n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change. Configuration details for Spring AI may vary based on specific versions.*\n\n</BlogWrapper>","frontmatter":{"title":"Spring AI: Streamlining Local LLM Integration for Java Developers","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACbklEQVR42iXC2U/aYAAA8D5uQ6FA6devx9eLQqHcYqWc5daqUAVUBDGbYzpx80DmtWQvZolLfFjiFh+W/a0z2S8/zEkiAgVfuqAwx0hzJHrthg5WBksFkK/SK23SMN2pjIMWX+HQAXgHiRw+7n/MBQSCV4ES84qqS1TfUAIym8bBUWR1g0ploGGCxTwo1kI7IzZXfg34Oc4/x8gORnIwMoYD3gkFlxRyy+GXZN0qXcy0xgphWfTlBZnUiWTaV8jzZjWwNfQUa05RnVc0TzDmlkIYEU155bCLlnA+KKx3woO3QDdctYpv02bqy0yxgterhFkGqQyIL6G9d55syR2IwrjuS2exeSjgWoIIxXGSE3pDulJjbBt0NzyjXdTpekrm4P2gtNbOjSfeRgX1trlOH2hJIqHjkQUMp3iCU4Bfg5mC/8stvbyKDg/FRiPbtsL394q91fk8rt7crE1mnlwettrq9JrUkl5OIQMxDMoRSgqhzS3l9Fz78TO72k70u0S7RQ93tMnJ5O6Mu5o2H393p3ep/k6s2488/xEHIyqpA9aPQSFMGUX/7JrNmMGzq8T4ZLE3QkbZndLTdfvb17vO7ezg4VfJ3jVarYXj0+D0BpWb0um5R1Ix1h8D4YR4fCL0R0AIIctW9sdiuye1evbjs/3wZH9/7D/9Vfc/8MMDtLENtZRYqIv9PUKJYGJEByjoMwq8ZUuJLBtJw/oytNappSKTr/KVJqqtUJUGiOsQymzDkqYzIWuSaoyRo5gPBdy06PTQPkGF6RxbaQpHH4XJJz6U5sQoG88I00ux1eGrFp8x2WIVFMpupDh9rJdT/gG8qIzT1/dCagAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7a5be1548e7efed21a2ef4929e78a5ab/366fe/hero-image.jpg","srcSet":"/static/7a5be1548e7efed21a2ef4929e78a5ab/9b503/hero-image.jpg 750w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/321ef/hero-image.jpg 1080w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/84dcd/hero-image.jpg 1366w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/7a5be1548e7efed21a2ef4929e78a5ab/5f850/hero-image.webp 750w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/2c010/hero-image.webp 1080w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/5126b/hero-image.webp 1366w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/7a5be1548e7efed21a2ef4929e78a5ab/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACbklEQVR42iXC2U/aYAAA8D5uQ6FA6devx9eLQqHcYqWc5daqUAVUBDGbYzpx80DmtWQvZolLfFjiFh+W/a0z2S8/zEkiAgVfuqAwx0hzJHrthg5WBksFkK/SK23SMN2pjIMWX+HQAXgHiRw+7n/MBQSCV4ES84qqS1TfUAIym8bBUWR1g0ploGGCxTwo1kI7IzZXfg34Oc4/x8gORnIwMoYD3gkFlxRyy+GXZN0qXcy0xgphWfTlBZnUiWTaV8jzZjWwNfQUa05RnVc0TzDmlkIYEU155bCLlnA+KKx3woO3QDdctYpv02bqy0yxgterhFkGqQyIL6G9d55syR2IwrjuS2exeSjgWoIIxXGSE3pDulJjbBt0NzyjXdTpekrm4P2gtNbOjSfeRgX1trlOH2hJIqHjkQUMp3iCU4Bfg5mC/8stvbyKDg/FRiPbtsL394q91fk8rt7crE1mnlwettrq9JrUkl5OIQMxDMoRSgqhzS3l9Fz78TO72k70u0S7RQ93tMnJ5O6Mu5o2H393p3ep/k6s2488/xEHIyqpA9aPQSFMGUX/7JrNmMGzq8T4ZLE3QkbZndLTdfvb17vO7ezg4VfJ3jVarYXj0+D0BpWb0um5R1Ix1h8D4YR4fCL0R0AIIctW9sdiuye1evbjs/3wZH9/7D/9Vfc/8MMDtLENtZRYqIv9PUKJYGJEByjoMwq8ZUuJLBtJw/oytNappSKTr/KVJqqtUJUGiOsQymzDkqYzIWuSaoyRo5gPBdy06PTQPkGF6RxbaQpHH4XJJz6U5sQoG88I00ux1eGrFp8x2WIVFMpupDh9rJdT/gG8qIzT1/dCagAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7a5be1548e7efed21a2ef4929e78a5ab/366fe/hero-image.jpg","srcSet":"/static/7a5be1548e7efed21a2ef4929e78a5ab/9b503/hero-image.jpg 750w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/321ef/hero-image.jpg 1080w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/84dcd/hero-image.jpg 1366w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/7a5be1548e7efed21a2ef4929e78a5ab/5f850/hero-image.webp 750w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/2c010/hero-image.webp 1080w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/5126b/hero-image.webp 1366w,\n/static/7a5be1548e7efed21a2ef4929e78a5ab/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/7a5be1548e7efed21a2ef4929e78a5ab/hero-image.png"}},"fields":{"slug":"/blog/docker/spring-ai-streamlining-local-llm-integration-for-java-developers"}},{"id":"e9a58b6f-459e-5026-bb39-eb2ce65f1ab5","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nSo far in our [series on Docker Model Runner](/blog/category/docker), we've dissected its OCI-based model management, its performance-optimized execution architecture, and its OpenAI-compatible API. Now, we explore a feature that truly elevates its utility for engineers building complex systems: **deep integration with Docker Compose via a novel provider service type.**  \n\nFor engineers, Docker Compose is the go-to tool for defining and running multi-container Docker applications. The introduction of the provider service type specifically for Model Runner bridges the gap between local AI model execution and the broader application stack, allowing you to define and manage AI models as integral components of your local development environment declaratively.\n\n## **Beyond CLI: Models as First-Class Services in Compose**\n\nWhile docker model run is handy for quick tests, real-world applications often involve multiple interacting services‚Äîa web frontend, a backend API, a database, and now, an AI model. Docker Model Runner's Compose integration allows you to define the AI model itself as a service within your `docker-compose.yml` file.  \n\nThe key innovation here is the provider attribute within a service definition. Here's a conceptual example based on Docker's documentation:\n\n```yaml\nservices:  \n  model\\_provider\\_service: \\# You can name this service as you like  \n    provider:  \n      type: model        \\# Specifies this is a model provider  \n      image: ai/llama3.2:1B-Q8\\_0 \\# The OCI image for the model  \n    \\# No 'build' or 'image' directives here in the traditional sense for the provider\n\n  my\\_app\\_service:  \n    build: ./app  \n    ports:  \n      \\- \"8080:80\"  \n    depends\\_on:  \n      \\- model\\_provider\\_service \\# Ensures model is ready before the app starts  \n    environment:  \n      \\# Environment variables will be injected here (see below)  \n      MODEL\\_NAME: ${MODEL\\_PROVIDER\\_SERVICE\\_MODEL}  \n      MODEL\\_URL: ${MODEL\\_PROVIDER\\_SERVICE\\_URL}\n```\n\nIn this setup:\n\n* model\\_provider\\_service doesn't run a traditional container in the same way my\\_app\\_service does. Instead, it instructs Docker Compose to leverage Docker Model Runner.  \n* Docker Model Runner, when processing this provider service, will ensure the specified image (the AI model) is pulled and made available via its host-native inference engine.\n\n## **Automatic Model Provisioning and Service Discovery**\n\nThis Compose integration brings significant benefits for engineers:\n\n1. **Declarative Model Dependencies:**  \n   * You declare your AI model dependency directly in your docker-compose.yml. Docker Model Runner handles the provisioning (pulling and preparing the model if needed) when you run docker compose up.  \n   * This is a stark improvement over manual docker model run commands or custom scripts to manage model lifecycle alongside your application stack.  \n2. **Automated Service Discovery via Environment Variables:**  \n   * This is a crucial feature for seamless integration. When my\\_app\\_service starts (after model\\_provider\\_service is ready), Docker Compose automatically injects environment variables into my\\_app\\_service.  \n   * These variables typically follow the pattern: PROVIDER\\_SERVICE\\_NAME\\_MODEL and PROVIDER\\_SERVICE\\_NAME\\_URL.  \n     * MODEL\\_PROVIDER\\_SERVICE\\_MODEL: Contains the name/tag of the model being served (e.g., ai/llama3.2:1B-Q8\\_0).  \n     * MODEL\\_PROVIDER\\_SERVICE\\_URL: Provides the URL your application should use to access the Model Runner's API endpoint for this model. This would often point to the internal DNS http://model-runner.docker.internal or a host-accessible TCP port if configured.  \n   * Your application code can then dynamically use these environment variables to configure its AI client, making the connection to the local model effortless and portable.  \n3. **Simplified depends\\_on for Startup Order:**  \n   * Using depends\\_on ensures that your application services only start after Model Runner has signaled that the model provider is ready. This prevents your application from trying to connect to a model that isn't yet available.\n\n## **Engineering Benefits for Complex AI Applications**\n\nThis declarative, integrated approach offers tangible advantages:\n\n* **Reproducible AI Development Environments:** Your entire local stack, including the specific AI model version, is defined in code (docker-compose.yml), making it easy to share, version control, and ensure consistency across development team members.  \n* **Simplified Onboarding:** New developers can get a complex AI-powered application stack running locally with a single docker compose up command.  \n* **Streamlined Local Testing of AI Features:** Test end-to-end flows involving your application logic and AI model interactions in a fully integrated local environment that mirrors how services would interact.  \n* **Foundation for Local MLOps Loops:** While focused on local development, this pattern lays a conceptual foundation for how AI models can be treated as manageable dependencies within larger application architectures, aligning with MLOps principles.\n\nBy treating AI models as discoverable services managed by Compose, Docker Model Runner significantly lowers the barrier to building and iterating on sophisticated multi-service applications that leverage local AI capabilities. This moves beyond simply running a model in isolation to truly integrating AI into your development workflow.  \nNext up, we'll explore how Docker Model Runner specifically caters to Java developers through its integration with frameworks like Spring AI, further simplifying the adoption of local AI.  \n\n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.*\n\n</BlogWrapper>","frontmatter":{"title":"Docker Compose: Orchestrating Multi-Service AI Applications Locally","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACo0lEQVR42jWL209SAQDGz1/Rk+VDq1aGpQk6BW2o6NDkKiTZFJAIsABJwbiIoAgcOQeO4EFuAuq84FDIynJuqZslm6WUa5lTmm3OFfrQW08d59p++/b9tu8DQqfR4GnkjGwkeBLBVLPUr5jXeQ7DhvURZHdq/M+c7zTsz4b82TA2wAicnJcwgBygrn3UkwkMH4Y8P4LQN/Qmt6HerJfPT+D4WmlsciAWcyzNIpno8E+/+8A/lAm4/wMEf6WQ/Tn7F79hGbZto/aU9yHseBx5LZ5ISkYjzoCprktlDIxb4vH2mX5wxzuwhdrSXus2ak2jQN9WDN7fmPx79DQwRWnp4um8DwSWwnrJxQrm3YbniMJr29s2H3+FkottPrf544huza1f8ehW3fo1D9C/s2LYmFcv+jhGa04+s5CqqpX7KyXQ5Sp2GVXmV010WMM8KGGZWVVPL90HbfK4s+PVkCKJKBeGAGHE2Zve7E2nJCNBls5xncS5w1ZWCuw1T1CqzKexzT2yTFHEo0zNLA9+IzCPkVsNLX6obcwliLoAjhPiumDF2+Wed+sMZW85Q1zKU4gMwxRe97Xy1oI6OaszZEtsBJY/d7gTL9/vhl9siqYTXATiOGGAZoZpJked3krrg8kKfXGzNK+WV0AT3Wvvq1eZyO3aS0VsYTQZzByv7f7+9D2b2jvSji9Qe0C62QlUqxwYlGcwRQXVqhFKp7NCai5gS3JLGxrVlq5gvKkbMgYWzEsfdOGEVAsTyNx8IrtKCWIXgMgHSQKQyLeTBHYsia02knCwQgSX8EyExs5KvgZfzRNKrQy28sYtyoXckpy8GhxVhr2IAhDA0+14BgZ4XghM8EzpNgJrEM9y4GqMV4iynNtNuUXNV8vEuGp1Ed1azIbO9gzwH9t6T8ElxPFqAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/97d66df31989169322ece96b70bfd7a8/366fe/hero-image.jpg","srcSet":"/static/97d66df31989169322ece96b70bfd7a8/9b503/hero-image.jpg 750w,\n/static/97d66df31989169322ece96b70bfd7a8/321ef/hero-image.jpg 1080w,\n/static/97d66df31989169322ece96b70bfd7a8/84dcd/hero-image.jpg 1366w,\n/static/97d66df31989169322ece96b70bfd7a8/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/97d66df31989169322ece96b70bfd7a8/5f850/hero-image.webp 750w,\n/static/97d66df31989169322ece96b70bfd7a8/2c010/hero-image.webp 1080w,\n/static/97d66df31989169322ece96b70bfd7a8/5126b/hero-image.webp 1366w,\n/static/97d66df31989169322ece96b70bfd7a8/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/97d66df31989169322ece96b70bfd7a8/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACo0lEQVR42jWL209SAQDGz1/Rk+VDq1aGpQk6BW2o6NDkKiTZFJAIsABJwbiIoAgcOQeO4EFuAuq84FDIynJuqZslm6WUa5lTmm3OFfrQW08d59p++/b9tu8DQqfR4GnkjGwkeBLBVLPUr5jXeQ7DhvURZHdq/M+c7zTsz4b82TA2wAicnJcwgBygrn3UkwkMH4Y8P4LQN/Qmt6HerJfPT+D4WmlsciAWcyzNIpno8E+/+8A/lAm4/wMEf6WQ/Tn7F79hGbZto/aU9yHseBx5LZ5ISkYjzoCprktlDIxb4vH2mX5wxzuwhdrSXus2ak2jQN9WDN7fmPx79DQwRWnp4um8DwSWwnrJxQrm3YbniMJr29s2H3+FkottPrf544huza1f8ehW3fo1D9C/s2LYmFcv+jhGa04+s5CqqpX7KyXQ5Sp2GVXmV010WMM8KGGZWVVPL90HbfK4s+PVkCKJKBeGAGHE2Zve7E2nJCNBls5xncS5w1ZWCuw1T1CqzKexzT2yTFHEo0zNLA9+IzCPkVsNLX6obcwliLoAjhPiumDF2+Wed+sMZW85Q1zKU4gMwxRe97Xy1oI6OaszZEtsBJY/d7gTL9/vhl9siqYTXATiOGGAZoZpJked3krrg8kKfXGzNK+WV0AT3Wvvq1eZyO3aS0VsYTQZzByv7f7+9D2b2jvSji9Qe0C62QlUqxwYlGcwRQXVqhFKp7NCai5gS3JLGxrVlq5gvKkbMgYWzEsfdOGEVAsTyNx8IrtKCWIXgMgHSQKQyLeTBHYsia02knCwQgSX8EyExs5KvgZfzRNKrQy28sYtyoXckpy8GhxVhr2IAhDA0+14BgZ4XghM8EzpNgJrEM9y4GqMV4iynNtNuUXNV8vEuGp1Ed1azIbO9gzwH9t6T8ElxPFqAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/97d66df31989169322ece96b70bfd7a8/366fe/hero-image.jpg","srcSet":"/static/97d66df31989169322ece96b70bfd7a8/9b503/hero-image.jpg 750w,\n/static/97d66df31989169322ece96b70bfd7a8/321ef/hero-image.jpg 1080w,\n/static/97d66df31989169322ece96b70bfd7a8/84dcd/hero-image.jpg 1366w,\n/static/97d66df31989169322ece96b70bfd7a8/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/97d66df31989169322ece96b70bfd7a8/5f850/hero-image.webp 750w,\n/static/97d66df31989169322ece96b70bfd7a8/2c010/hero-image.webp 1080w,\n/static/97d66df31989169322ece96b70bfd7a8/5126b/hero-image.webp 1366w,\n/static/97d66df31989169322ece96b70bfd7a8/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/97d66df31989169322ece96b70bfd7a8/hero-image.png"}},"fields":{"slug":"/blog/docker/docker-compose-orchestrating-multi-service-ai-applications-locally"}},{"id":"0c082d17-11b2-511a-bc98-be03ac9474a3","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nIn our series on [Docker Model Runner](/blog/category/docker), we've explored Docker Model Runner's role in simplifying local AI development and its strategic use of OCI artifacts for model management. Now, we peel back another layer to examine a critical aspect for any engineer working with Large Language Models (LLMs): **performance**. How does Docker Model Runner achieve the responsiveness needed for an efficient local development loop? The answers lie in its architectural choices, particularly its embrace of host-native execution and direct GPU access.  \n\nFor engineers, \"local\" often implies a trade-off: convenience versus raw power. Docker Model Runner attempts to bridge this gap, and understanding its performance model is key to leveraging it effectively.\n\n## **The Architectural Pivot: Why docker model run Isn't docker container run**\n\nOne of the most crucial, and perhaps initially counter-intuitive, aspects of Docker Model Runner is how it executes AI models. Seasoned Docker users might expect docker model run some-model to spin up an isolated Docker container housing the model and its inference engine. However, Model Runner takes a more direct path to prioritize local performance.  \n\nAs detailed in multiple technical breakdowns and official documentation, when you execute `docker model run`:\n\n* **No Traditional Container for Inference:** The command doesn't launch a standard Docker container for the core inference task.  \n* **Host-Native Inference Server:** Instead, it interacts with an inference server (initially built on the efficient llama.cpp engine) that runs as a **native process directly on your host machine**. This server is managed as part of Docker Desktop or the Model Runner plugin.\n\nThis is a deliberate engineering decision. Docker's own statements reveal that this approach was chosen to \"significantly improve performance by eliminating containerization overhead for resource-intensive AI workloads\" and to avoid the \"performance limitations of running models inside virtual machines.\" While Docker's traditional strength lies in containerization for isolation and portability, for the demanding task of LLM inference locally, the raw performance gains from direct host execution were deemed paramount.\n\n## **Unlocking Hardware: Direct GPU Acceleration**\n\nA major bottleneck for LLM performance is often GPU access. Docker Model Runner addresses this head-on:\n\n1. **Optimized for Apple Silicon (Metal API):**  \n   * For developers on macOS with Apple Silicon (M-series chips), Model Runner's host-native inference engine is designed to **directly access Apple's Metal API**. This provides a highly optimized path to the GPU, bypassing virtualization layers that can throttle performance. This direct access can offer a noticeable speed advantage compared to running models within a container that has to go through more layers to reach the GPU.  \n2. **Windows GPU Support on the Roadmap:**  \n   * Recognizing the diverse hardware landscape, Docker has explicitly included support for GPU acceleration on Windows platforms (primarily targeting NVIDIA GPUs) in its development plans. This is a critical feature for broadening Model Runner's appeal and utility.\n\nThis strategy of direct hardware access, especially for GPUs, is a pragmatic choice. It acknowledges that for the \"inner loop\" of local AI development‚Äîwhere rapid iteration and experimentation are key‚Äîminimizing inference latency is crucial.\n\n## **Intelligent Resource Management: Efficiency Under the Hood**\n\nBeyond raw execution speed, Docker Model Runner incorporates features for efficient resource utilization:\n\n* **On-Demand Model Loading:** Models are not kept in memory at all times. When you make a request to a specific model (e.g., via an API call from your application or a docker model run command), Model Runner loads it into memory \"on-demand,\" provided the model files have already been pulled locally. This means you don't necessarily have to issue a docker model run before your application can start interacting with a model.  \n* **Memory Caching with Inactivity Timeout:** Once loaded, a model remains in memory to serve subsequent requests quickly. However, to conserve system resources, models are automatically unloaded if they remain inactive for a predefined period. This inactivity timeout is **currently set to 5 minutes**. This is a practical detail that impacts how long a model stays \"warm\" and ready for immediate use during an interactive development session.\n\nThis combination of on-demand loading and inactivity-based unloading helps balance responsiveness with efficient use of your local machine's memory.\n\n## **The Engineering Trade-Off: Performance vs. Isolation**\n\nThe decision to run the inference engine as a host-native process is a clear trade-off: Docker is prioritizing local inference speed and direct hardware access over the complete process isolation typically provided by containers *for the inference step itself*. While the applications *using* the model can still be containerized and benefit from Docker's isolation, the model execution core operates closer to the metal.  \nThis architectural choice highlights Docker's commitment to making the local AI development experience as smooth and fast as possible, even if it means deviating slightly from its traditional container-centric execution model for this specific, performance-sensitive component.  \nUnderstanding this performance architecture‚Äîhost-native execution, direct GPU access, and smart resource management‚Äîallows engineers to better anticipate Model Runner's behavior, optimize their local AI workflows, and appreciate the engineering decisions aimed at making local LLM development more practical and efficient.  \n\nIn our next post, we'll explore the API architecture of Docker Model Runner, focusing on its OpenAI compatibility and the various ways you can connect your applications to the local inference engine.  \n\n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.*\n</BlogWrapper>","frontmatter":{"title":"Host-Native Execution & GPU Deep Dive","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACjElEQVR42iXNW1MSAQAF4C0XFGHl5goLC7sEI7IgIsvuIpQQ4KiIgJcAQS4qchMEVEAQNcnMnExsGrtM9ebUc8/9uLBmvjlPZ84BhmJl/kZdmGuLy53hwyvJ2a308pPs5of88z369Sfa/Y5EM0goKTu6kNzdS999k7y+g0+6w423onIH4K5keJEiFK8ObdUFhbZg96Wg9kZ0/J7f+cCP7yAGRm6y4W6v0r0AF1u8vVf86rmwdMrPtKBUDRj0JblLaSich+IVKLUPZVv8dI0fy6l2245qm86UJ1NFUyyvDSRM6V3n2RUSy/OSe7xEFYqWAM5MeNC7zvWu82bDUCgDL23IXYuYzRO8+DiRr0hXo8pgXBlJYYthZDPtuO5qGLfctzYULQ4GNoE+av6RzQ8xs5JxRj4TxDx+hJzWeIJU9QT2+rXhxFrpgNhpocm0Yn7ZkCjIjDZrrknsn7PcIQAO5ZnGBe72YwvLCpcXexEdYRxqd1CbKaGBkK3UoGvHloOKvrE/Fs0SGznFfMB+dGU9vWU/WwIsX35lf/8Z8y+j4ajSv6JKb0vdc/hzHxHN6bYKU6Wmr3O5064zsYghWzWnKwjjcHVuqNY1m5wDQPXUgMEFEbRYa4SN9Aj9VKQxwmOkpdDSRwqYc8WZbwaOu1RybzJdtx+ei0mrNVMb3W4+HrUDLIwGcYatorhKPYewcUfNfJ1JoNIpaKdqNiCzOGRWl4Jyan2rT3yryDgtlKnFBMWZ8PRpbAAoJ1mohaWkehMgbmXhTD9OctWkkKDgqWnYQEtoO2ywiPRmsZES6UiB3srGLCBG914BEJl8IDP/XwF7FDSI0mwF1Y+RPQNK8wBOcjBzTz9OPRTQfymz/AX1Lad060IfMQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a0d502a06407981844fc859ba51cbc91/366fe/hero-image.jpg","srcSet":"/static/a0d502a06407981844fc859ba51cbc91/9b503/hero-image.jpg 750w,\n/static/a0d502a06407981844fc859ba51cbc91/321ef/hero-image.jpg 1080w,\n/static/a0d502a06407981844fc859ba51cbc91/84dcd/hero-image.jpg 1366w,\n/static/a0d502a06407981844fc859ba51cbc91/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/a0d502a06407981844fc859ba51cbc91/5f850/hero-image.webp 750w,\n/static/a0d502a06407981844fc859ba51cbc91/2c010/hero-image.webp 1080w,\n/static/a0d502a06407981844fc859ba51cbc91/5126b/hero-image.webp 1366w,\n/static/a0d502a06407981844fc859ba51cbc91/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/a0d502a06407981844fc859ba51cbc91/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACjElEQVR42iXNW1MSAQAF4C0XFGHl5goLC7sEI7IgIsvuIpQQ4KiIgJcAQS4qchMEVEAQNcnMnExsGrtM9ebUc8/9uLBmvjlPZ84BhmJl/kZdmGuLy53hwyvJ2a308pPs5of88z369Sfa/Y5EM0goKTu6kNzdS999k7y+g0+6w423onIH4K5keJEiFK8ObdUFhbZg96Wg9kZ0/J7f+cCP7yAGRm6y4W6v0r0AF1u8vVf86rmwdMrPtKBUDRj0JblLaSich+IVKLUPZVv8dI0fy6l2245qm86UJ1NFUyyvDSRM6V3n2RUSy/OSe7xEFYqWAM5MeNC7zvWu82bDUCgDL23IXYuYzRO8+DiRr0hXo8pgXBlJYYthZDPtuO5qGLfctzYULQ4GNoE+av6RzQ8xs5JxRj4TxDx+hJzWeIJU9QT2+rXhxFrpgNhpocm0Yn7ZkCjIjDZrrknsn7PcIQAO5ZnGBe72YwvLCpcXexEdYRxqd1CbKaGBkK3UoGvHloOKvrE/Fs0SGznFfMB+dGU9vWU/WwIsX35lf/8Z8y+j4ajSv6JKb0vdc/hzHxHN6bYKU6Wmr3O5064zsYghWzWnKwjjcHVuqNY1m5wDQPXUgMEFEbRYa4SN9Aj9VKQxwmOkpdDSRwqYc8WZbwaOu1RybzJdtx+ei0mrNVMb3W4+HrUDLIwGcYatorhKPYewcUfNfJ1JoNIpaKdqNiCzOGRWl4Jyan2rT3yryDgtlKnFBMWZ8PRpbAAoJ1mohaWkehMgbmXhTD9OctWkkKDgqWnYQEtoO2ywiPRmsZES6UiB3srGLCBG914BEJl8IDP/XwF7FDSI0mwF1Y+RPQNK8wBOcjBzTz9OPRTQfymz/AX1Lad060IfMQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a0d502a06407981844fc859ba51cbc91/366fe/hero-image.jpg","srcSet":"/static/a0d502a06407981844fc859ba51cbc91/9b503/hero-image.jpg 750w,\n/static/a0d502a06407981844fc859ba51cbc91/321ef/hero-image.jpg 1080w,\n/static/a0d502a06407981844fc859ba51cbc91/84dcd/hero-image.jpg 1366w,\n/static/a0d502a06407981844fc859ba51cbc91/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/a0d502a06407981844fc859ba51cbc91/5f850/hero-image.webp 750w,\n/static/a0d502a06407981844fc859ba51cbc91/2c010/hero-image.webp 1080w,\n/static/a0d502a06407981844fc859ba51cbc91/5126b/hero-image.webp 1366w,\n/static/a0d502a06407981844fc859ba51cbc91/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/a0d502a06407981844fc859ba51cbc91/hero-image.png"}},"fields":{"slug":"/blog/docker/host-native-execution-gpu-deep-dive"}},{"id":"35e2e324-224b-5a3d-a67d-0b8ed1694ace","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nIn our last [post in this series](/blog/category/docker), explored Docker Model Runner's OCI-based model management and its performance-centric execution model, we now turn our attention to another critical area for engineers: its **API architecture and connectivity options**. How do your applications actually *talk* to the models running locally via Model Runner? The answer lies in a thoughtfully designed API layer, with OpenAI compatibility at its core, and flexible connection methods to suit diverse development scenarios.  \n\nFor engineers, a well-defined and accessible API is paramount. It dictates the ease of integration, the reusability of existing code, and the overall developer experience when building AI-powered applications.\n\n## **The Heart of the Engine: llama.cpp and a Pluggable Future**\n\nIn its initial Beta release, Docker Model Runner's inference capabilities are powered by an integrated engine built on llama.cpp. This open-source project is renowned for its efficient execution of LLMs across various hardware, making it a solid foundation for local inference.  \n\nWhen you interact with Model Runner, you're essentially communicating with this llama.cpp-based server, which runs as a native host process. The API paths often reflect this underlying engine, for example, with endpoints structured under /engines/llama.cpp/v1/... or a more generalized `/engines/v1/...`.  \nWhile llama.cpp provides a robust initial backbone, the API path structure (e.g., `/engines/...`) hints at a potentially pluggable architecture. This is a common design pattern that could allow Docker to integrate other inference engines or model serving technologies in the future. This foresight means Model Runner could evolve to support a wider array of model types, quantization methods, or hardware acceleration frameworks without requiring a fundamental redesign of its API interaction model.\n\n## **The \"Superpower\": OpenAI-Compatible API**\n\nPerhaps the most strategically significant aspect of Model Runner's API is its **OpenAI compatibility**. This is a game-changer for several reasons:\n\n1. **Leverage Existing SDKs and Tools:** Engineers can use their existing OpenAI SDKs (Python, Node.js, etc.) and a vast ecosystem of compatible tools like LangChain or LlamaIndex with minimal, if any, code changes. This dramatically lowers the barrier to adoption.  \n2. **Simplified Migration:** If you've been developing against OpenAI's cloud APIs, transitioning to local models with Model Runner can often be as simple as changing the baseURL in your client configuration. This seamless switch accelerates local development and testing.  \n3. **Reduced Learning Curve:** There's no need to learn a new, proprietary API. The familiar OpenAI request/response structures for tasks like chat completions (`/chat/completions`) or embeddings (`/embeddings`) remain consistent. \n\nThis adherence to a de facto industry standard API is a deliberate choice by Docker to maximize interoperability and ease of integration, allowing developers to focus on application logic rather than wrestling with new API paradigms.\n\n## **Connecting Your Applications: A Multi-Pronged Approach**\n\nDocker Model Runner offers several ways for your applications and tools to connect to the local inference engine, providing flexibility for different development setups:\n\n1. **Internal DNS for Containerized Applications (model-runner.docker.internal):**  \n   * **How it works:** For applications running as Docker containers themselves (e.g., a backend API service), Model Runner provides a stable internal DNS name: http://model-runner.docker.internal.  \n   * **Benefit for Engineers:** This is incredibly convenient. Your containerized service can simply target this DNS name to reach the Model Runner API, without needing to know the host's IP address or worry about dynamic port mappings. It simplifies network configuration within your Docker environment.  \n   * **Endpoint Example:** http://model-runner.docker.internal/engines/v1/chat/completions  \n2. **Host TCP Port for Direct Access:**  \n   * **How it works:** You can configure Model Runner to listen on a specific TCP port on your host machine. This is typically done via a Docker Desktop setting or a command like docker desktop enable model-runner \\--tcp \\<port\\> (e.g., port 12434).  \n   * **Benefit for Engineers:** This allows applications running directly on your host (outside of Docker containers)‚Äîsuch as IDEs, local scripts, or standalone Java applications using Spring AI‚Äîto connect to the Model Runner.  \n   * **Endpoint Example:** http://localhost:12434/engines/v1/chat/completions  \n3. **Docker Socket (Advanced/CLI Use):**  \n   * **How it works:** For direct interactions via the Docker API or for certain CLI scripting scenarios, the Docker socket (/var/run/docker.sock on Linux/macOS) can be used. API calls through the socket might have a specific path prefix (e.g., `/exp/vDD4.40/...` as seen in early versions).  \n   * **Benefit for Engineers:** This offers a lower-level interface, useful for automation scripts or tools that integrate deeply with the Docker daemon.\n\nThis multi-faceted approach to connectivity ensures that whether your application is containerized, running natively on the host, or interacting via CLI tools, there's a clear and supported path to communicate with the local AI models managed by Docker Model Runner.  \n\nUnderstanding these API mechanics and connection options is crucial for effectively integrating Docker Model Runner into your development workflows. It allows you to choose the most appropriate method for your specific application architecture and leverage the power of local AI models with ease.  \nIn our next post, we'll explore how Docker Model Runner integrates with Docker Compose, enabling the orchestration of complex, multi-service AI applications locally.  \n\n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.*\n\n</BlogWrapper>","frontmatter":{"title":"API Architecture, OpenAI Compatibility, and Connection Strategies","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqElEQVR42hXCW09SAQAA4PMvqrWVEwM9hzsIKIqc4CAcBJE7HORyuB9QkCb3CZh4D/BCDlbW1pjpbGtqoqXmrOWq1Xyg3nvspYceeq6+fYCYGDFmIoNjCUNq1pwrVw/eN1s/yieX86/O04cXheN3+ZfHmcbuvdWaNz7lTOSckbjZGx6dSBbrT4EnzRdvvl4mV5Z3zk7k/hCIYnQV1mvxK1M57WTeUVjC5lesq4+JWj3T2MkdXkyUaxgRe3Z51fr9BzhtfZurb0am5jBfDFZZw4tZb2qSZyOYdo86EM9GfaJACF2s8tLZ+N7Rwy/fI9VNe6pQOPmwfPEJiFZKbbAYUqJkmfQOG86sF5OlYpfeTkb0I8pgPRVTJhLaszN4f99Yf1T79TO+vWPPz0y3rrKfPwLOdOEWU06DjXSZFhIpYNwE4zaG1UVSWKyI+W0htFqvuI/2+itlKbHkLe3icxUsPx05fx05PQLyG5XrHAZZLAWRoY5upB9V8RA10+qjaIwDXCQ56YnP5Aa0AZba2WsieIbxbl0Um037m9u27QawcdzMlx+gRkMXj9vO4kNqeeegvM/uGcD99B45iSEdj8U1DoKKantcmGDUwdEFRe4xz1ZJu1kF+ou58eeNhYP99MONwtq6LUBIRzRsRCq0Y3cJr8DmGo6F5JiFIkF5Nh1bP0wRGKgwFt2aVawtAJxoFAoGaeGwIJlAZ+47VyqhUkXtDtD5IjpbKNSoekZtzGGT0GVmaYZI3YMkjpLM11GH8Z50AmDgfhYe+Jfh9EGjbrLV2eXwMn0hph0HUTXU10fpFnfyZRKr+doNys1O8W26pI0ha+eoaFobABnw/404aHDRTG662UM1uiG9CzJ5IKsXtHhAnR1UaEARQqGzO6h8MlcKcsVUvoQrhP8CrjoFDpQfwNgAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/7ad71d9ddffb4f0135947f5b528e0c93/366fe/hero-image.jpg","srcSet":"/static/7ad71d9ddffb4f0135947f5b528e0c93/9b503/hero-image.jpg 750w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/321ef/hero-image.jpg 1080w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/84dcd/hero-image.jpg 1366w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ad71d9ddffb4f0135947f5b528e0c93/5f850/hero-image.webp 750w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/2c010/hero-image.webp 1080w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/5126b/hero-image.webp 1366w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/7ad71d9ddffb4f0135947f5b528e0c93/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqElEQVR42hXCW09SAQAA4PMvqrWVEwM9hzsIKIqc4CAcBJE7HORyuB9QkCb3CZh4D/BCDlbW1pjpbGtqoqXmrOWq1Xyg3nvspYceeq6+fYCYGDFmIoNjCUNq1pwrVw/eN1s/yieX86/O04cXheN3+ZfHmcbuvdWaNz7lTOSckbjZGx6dSBbrT4EnzRdvvl4mV5Z3zk7k/hCIYnQV1mvxK1M57WTeUVjC5lesq4+JWj3T2MkdXkyUaxgRe3Z51fr9BzhtfZurb0am5jBfDFZZw4tZb2qSZyOYdo86EM9GfaJACF2s8tLZ+N7Rwy/fI9VNe6pQOPmwfPEJiFZKbbAYUqJkmfQOG86sF5OlYpfeTkb0I8pgPRVTJhLaszN4f99Yf1T79TO+vWPPz0y3rrKfPwLOdOEWU06DjXSZFhIpYNwE4zaG1UVSWKyI+W0htFqvuI/2+itlKbHkLe3icxUsPx05fx05PQLyG5XrHAZZLAWRoY5upB9V8RA10+qjaIwDXCQ56YnP5Aa0AZba2WsieIbxbl0Um037m9u27QawcdzMlx+gRkMXj9vO4kNqeeegvM/uGcD99B45iSEdj8U1DoKKantcmGDUwdEFRe4xz1ZJu1kF+ou58eeNhYP99MONwtq6LUBIRzRsRCq0Y3cJr8DmGo6F5JiFIkF5Nh1bP0wRGKgwFt2aVawtAJxoFAoGaeGwIJlAZ+47VyqhUkXtDtD5IjpbKNSoekZtzGGT0GVmaYZI3YMkjpLM11GH8Z50AmDgfhYe+Jfh9EGjbrLV2eXwMn0hph0HUTXU10fpFnfyZRKr+doNys1O8W26pI0ha+eoaFobABnw/404aHDRTG662UM1uiG9CzJ5IKsXtHhAnR1UaEARQqGzO6h8MlcKcsVUvoQrhP8CrjoFDpQfwNgAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/7ad71d9ddffb4f0135947f5b528e0c93/366fe/hero-image.jpg","srcSet":"/static/7ad71d9ddffb4f0135947f5b528e0c93/9b503/hero-image.jpg 750w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/321ef/hero-image.jpg 1080w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/84dcd/hero-image.jpg 1366w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ad71d9ddffb4f0135947f5b528e0c93/5f850/hero-image.webp 750w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/2c010/hero-image.webp 1080w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/5126b/hero-image.webp 1366w,\n/static/7ad71d9ddffb4f0135947f5b528e0c93/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/7ad71d9ddffb4f0135947f5b528e0c93/hero-image.png"}},"fields":{"slug":"/blog/docker/api-architecture-openai-compatibility-and-connection-strategies"}},{"id":"3178e285-15ec-5ce8-9bc1-fd0a4eb61036","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\nIn our [previous post](https://layer5.io/blog/docker/docker-model-runner), we introduced Docker Model Runner as a promising new toolkit for simplifying local AI development. Now, let's delve into one of its foundational‚Äîand perhaps most strategically significant‚Äîaspects: its deep reliance on the Open Container Initiative (OCI) standard for managing AI models.\n\nIf you've wrestled with AI models, you know the \"messy landscape\" of model distribution. Models often arrive as loose files, tucked behind proprietary download tools, or lacking clear versioning. This fragmentation makes standardization, reproducibility, and integration into automated workflows a real headache for engineers. Docker Model Runner aims to bring order to this chaos by treating AI models as OCI artifacts, and this decision has profound implications for how you, as an engineer, can manage the entire lifecycle of your AI models.\n\n## **OCI: More Than Just docker model pull**\n\nYou might see docker model pull `ai/llama3.2:1B-Q8_0` and think it's just a convenient way to download models. But packaging models as OCI artifacts is a strategic move by Docker that goes far deeper. It aligns AI model management with the mature, robust ecosystem already built around OCI for container images.  \n\nEssentially, Docker is working to make AI models **first-class citizens within the Docker ecosystem**. This means the same trusted registries and workflows you use for your application containers can now, in principle, be applied to your AI models. Imagine the possibilities:\n\n* **Unified Workflows:** Manage, version, and distribute your AI models using the same tools and processes you already use for your containerized applications. No more separate, bespoke systems for model management.  \n* **Leveraging Existing Infrastructure:** Your existing private container registries (like Docker Hub, Artifactory, Harbor, etc.) can become repositories for your AI models. This allows you to apply the same security scanning, access control policies, and auditing mechanisms you trust for your containers directly to your AI assets.\n\n## **Engineering Benefits: What OCI Brings to Your AI Model Lifecycle**\n\nAdopting OCI for models isn't just about tidiness; it brings tangible engineering benefits:\n\n1. **Robust Versioning & Provenance:**  \n   * **How you benefit:** OCI's tagging system (e.g., :1B-Q8\\_0, :latest, :v2.1-finetuned) provides robust version control for your models. This is critical for reproducibility in experiments and ensuring stability in deployments. You can track exactly which model version was used for a particular result or release.  \n   * **Immutability:** Like container images, OCI artifacts can be treated as immutable. Once a version is tagged and pushed, it remains consistent, preventing accidental modifications and ensuring that when you pull my-model:v1.0, you always get the same bits.  \n2. **Streamlined CI/CD for ML Models:**  \n   * **How you benefit:** This is a big one. Your existing CI/CD pipelines, likely already geared to handle OCI artifacts for application builds and deployments, can be extended to manage your AI models.  \n   * **Think about it:**  \n     * Automated testing and validation of new model versions.  \n     * Triggering model deployments based on updates in your model training repositories.  \n     * Integrating model security scanning into your pipeline.  \n   * This moves you closer to comprehensive MLOps automation by leveraging familiar tools and processes.  \n3. **Enhanced Governance and Security:**  \n   * **How you benefit:** By storing models in your existing OCI-compliant registries, you can apply consistent governance. Use the same tools for vulnerability scanning on your models as you do for your container images. Enforce role-based access control (RBAC) to determine who can pull or push specific models or versions.\n\n## **The Future is Custom: Pushing Your Own Models**\n\nWhile Docker Model Runner currently provides access to curated models from Docker Hub (often under the ai/ namespace or from partners like Hugging Face via hf.co/), the real power of OCI will unlock when you can easily manage your *own* custom models.  \n\nThe inclusion of commands like docker model push and docker model tag in the CLI strongly signals this future direction. Imagine:\n\n* Training or fine-tuning a model for your specific needs.  \n* Packaging it as an OCI artifact.  \n* Pushing it to your private or public OCI registry.  \n* Seamlessly pulling and running it with docker model pull your-namespace/your-custom-model:v1 and docker model run ....\n\nThis capability will be transformative, allowing you to integrate bespoke AI directly into your standardized Docker workflows, free from vendor lock-in for model storage and distribution.\n\n## **A More Cohesive AI Development World**\n\nBy embracing OCI, Docker Model Runner isn't just offering a new command; it's paving the way for a more unified and manageable AI development landscape. As an engineer, this means you can apply familiar, battle-tested DevOps principles and tools to your AI models, reducing complexity and accelerating your path from experimentation to production. This strategic choice for an open standard also offers a degree of future-proofing. As the AI ecosystem evolves, models packaged as OCI artifacts will likely be manageable by an ever-expanding array of tools and platforms that support this widely adopted standard.  \n\nIn our next post, we'll shift gears and look under the hood at Docker Model Runner's performance architecture, particularly its use of host-native execution and GPU acceleration.  \n\n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.*\n</BlogWrapper>","frontmatter":{"title":"Taming the Wild West of AI Model Management","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVR42gGfAmD9AEx0mkdpi0VlhUhqi0xvkk5zllB3m1F2mUZifVh/olqDp1uBo1d7m1R2k1FwjE5rhUtmfUdfc0NXaj5PYABHZX9Na4VPbolTdZFRcYtWeJNYeJFIX28xP0pLXm5bfI5Ve4pVdYVbcYNheIlmfo9qgpJzi5t/mqqForMAf6/DVnmRXoCXdp+1hK3AiK/Bd5aqV6awL4CDWIuZd6S0etvchcrNirzAirC2j6GqjJ+mkaOpnK+0obO3AJK4vllwf3OLk3SNlkJYblRvhDVBWRhfbBmEhiRGSUVLV3+cpJm7t5TXzqjKw7S8t7fBubvAt7/AtMTBswC30sZ/mp1sgoxxgogPHToaKUUeKT4dWWYacXVccWtjWViYlpadrayNu7W7w7HVxa7SxKzayK3hzq7n1bAArK+cn66fQlVeJUdbJ0JXGCw+GS9BF2FrFnF2WXV2ZXh2b6miYGZwW11hm5SI38mp992y79uv9ee5+vHIANLIqezQqKiSfik/VTRRXB9AURo4SRwwSCM5USAvRyU+VR0+SCwyPTNJZERggGV4iL2ymPbgs/zuwP763ACKmZ+guLZ8jI4hMkgtNkIkNUMqO08aJj8dMEkqSGEyUGswPFQjMEIjNFI6XnMlOEklMUKYjYnQtaDq17AAUG6QUnKSZYyiY4yUQ2NsM0hfSV96TWaDMURhGytFHzRPLUNhMUhmIzVQGjFBJy89JjE+Nj1LmYmP1cGiAEBcg0Bcgz1VfkppjWqVqXWisGKKokdkhDRFXS08Uy5BYR4uRx0sRSU2Tyw8WSs2Sy02R09UaIV8iM27nAAuRnEvRnAxSHItQ28sQm9BX4F1prN5qKYkMD4vRGs4UHozSnAwRGkzR2o9UXZCVXpGWHpRX39san7AsJUIaSe4l4uqbwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/ad894700277bdd8c181ccbffc7dc4e16/366fe/hero-image.jpg","srcSet":"/static/ad894700277bdd8c181ccbffc7dc4e16/9b503/hero-image.jpg 750w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/321ef/hero-image.jpg 1080w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/84dcd/hero-image.jpg 1366w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/ad894700277bdd8c181ccbffc7dc4e16/5f850/hero-image.webp 750w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/2c010/hero-image.webp 1080w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/5126b/hero-image.webp 1366w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/ad894700277bdd8c181ccbffc7dc4e16/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVR42gGfAmD9AEx0mkdpi0VlhUhqi0xvkk5zllB3m1F2mUZifVh/olqDp1uBo1d7m1R2k1FwjE5rhUtmfUdfc0NXaj5PYABHZX9Na4VPbolTdZFRcYtWeJNYeJFIX28xP0pLXm5bfI5Ve4pVdYVbcYNheIlmfo9qgpJzi5t/mqqForMAf6/DVnmRXoCXdp+1hK3AiK/Bd5aqV6awL4CDWIuZd6S0etvchcrNirzAirC2j6GqjJ+mkaOpnK+0obO3AJK4vllwf3OLk3SNlkJYblRvhDVBWRhfbBmEhiRGSUVLV3+cpJm7t5TXzqjKw7S8t7fBubvAt7/AtMTBswC30sZ/mp1sgoxxgogPHToaKUUeKT4dWWYacXVccWtjWViYlpadrayNu7W7w7HVxa7SxKzayK3hzq7n1bAArK+cn66fQlVeJUdbJ0JXGCw+GS9BF2FrFnF2WXV2ZXh2b6miYGZwW11hm5SI38mp992y79uv9ee5+vHIANLIqezQqKiSfik/VTRRXB9AURo4SRwwSCM5USAvRyU+VR0+SCwyPTNJZERggGV4iL2ymPbgs/zuwP763ACKmZ+guLZ8jI4hMkgtNkIkNUMqO08aJj8dMEkqSGEyUGswPFQjMEIjNFI6XnMlOEklMUKYjYnQtaDq17AAUG6QUnKSZYyiY4yUQ2NsM0hfSV96TWaDMURhGytFHzRPLUNhMUhmIzVQGjFBJy89JjE+Nj1LmYmP1cGiAEBcg0Bcgz1VfkppjWqVqXWisGKKokdkhDRFXS08Uy5BYR4uRx0sRSU2Tyw8WSs2Sy02R09UaIV8iM27nAAuRnEvRnAxSHItQ28sQm9BX4F1prN5qKYkMD4vRGs4UHozSnAwRGkzR2o9UXZCVXpGWHpRX39san7AsJUIaSe4l4uqbwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/ad894700277bdd8c181ccbffc7dc4e16/366fe/hero-image.jpg","srcSet":"/static/ad894700277bdd8c181ccbffc7dc4e16/9b503/hero-image.jpg 750w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/321ef/hero-image.jpg 1080w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/84dcd/hero-image.jpg 1366w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/ad894700277bdd8c181ccbffc7dc4e16/5f850/hero-image.webp 750w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/2c010/hero-image.webp 1080w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/5126b/hero-image.webp 1366w,\n/static/ad894700277bdd8c181ccbffc7dc4e16/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/ad894700277bdd8c181ccbffc7dc4e16/hero-image.png"}},"fields":{"slug":"/blog/docker/taming-the-wild-west-of-ai-model-management"}},{"id":"77e04089-65ad-5a89-976c-c56185e19307","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\nThe shift towards local-first AI development is undeniable, driven by engineers seeking to overcome the practical hurdles of cloud-centric model interaction. Escalating API costs, data privacy concerns when handling sensitive information, network latency impacting iteration speed, and the desire for finer-grained control over execution environments have all highlighted the need for robust local solutions. Docker Model Runner is Docker's response to these engineering challenges, aiming to significantly streamline how we develop and test AI models locally.  \n\nThis post, the first in a series, will dissect Docker Model Runner from an engineering perspective. We'll explore its core technical value propositions and how you can leverage this new toolkit to enhance your AI development workflows.\n\n## **The Engineering Case for Local AI Development**\n\nFor engineers, the \"local-first\" approach to AI isn't just a trend; it's a pragmatic choice offering tangible benefits:\n\n* **Reduced Iteration Costs:** Experimenting with prompts, parameters, and model variations can lead to substantial API expenses. Local execution eliminates these costs during the crucial development and debugging phases.  \n* **Enhanced Data Privacy & Security:** Working with proprietary or sensitive datasets locally mitigates the risks associated with transmitting data to external services, a critical consideration for many enterprise applications.  \n* **Accelerated Development Cycles:** Eliminating network latency allows for near-instantaneous feedback, dramatically speeding up iterative tasks like prompt engineering, parameter tuning, and debugging model behavior.  \n* **Granular Environmental Control:** Local execution provides engineers with complete control over the model's runtime environment, dependencies, and specific configurations, facilitating reproducible experiments and precise debugging.\n\n## **Docker Model Runner: Key Technical Capabilities for Engineers**\n\nDocker Model Runner aims to integrate local AI model execution seamlessly into the familiar Docker ecosystem. Here are some of its core technical aspects beneficial for engineers:\n\n1. Simplified Local Inference Setup:  \n   While the \"Docker\" name might imply traditional containerization for the model itself, Model Runner takes a different architectural path for performance. It facilitates running models like ai/llama3.2:1B-Q8\\_0 or hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF via commands such as docker model pull and docker model run. The key is that the inference itself often runs as a host-native process (initially leveraging llama.cpp), interacting with Docker Desktop or a Model Runner plugin. This design choice, which we'll explore in detail later, prioritizes direct hardware access.  \n2. Performance through Host-Native Execution & GPU Access:  \n   To tackle the performance demands of LLMs, Model Runner enables the inference engine to directly access host resources. For macOS users with Apple Silicon, this means direct Metal API utilization for GPU acceleration. Windows GPU support is also on the roadmap. This approach aims to minimize the overhead often associated with virtualized GPU access in containerized environments, offering a potential speed advantage for local development.  \n3. OpenAPI-Compatible API for Seamless Integration:  \n   One of the most significant engineering benefits is the provision of an OpenAI-compatible API. This allows you to reuse existing codebases, SDKs (like LangChain or LlamaIndex), and tools with minimal, if any, modification. For many, transitioning to a local model might be as simple as changing an API endpoint URL, drastically reducing the integration effort and learning curve.  \n4. Standardized Model Management with OCI Artifacts:  \n   Docker Model Runner treats AI models as Open Container Initiative (OCI) artifacts. This is a strategic move towards standardizing model distribution, versioning, and management, aligning it with the mature ecosystem already in place for container images. This opens the door to leveraging existing container registries and CI/CD pipelines for models, a crucial step towards robust MLOps practices. We'll dedicate our next post to a deep dive into this OCI integration.\n\n## **Beyond Single Invocations: The Potential for Local AI Pipelines**\n\nWhile running individual models is a core function, the architecture of Docker Model Runner also supports the local orchestration of more complex, multi-stage AI workflows. As detailed in examples like the Gemma 3 Comment Processing System, engineers can design and debug entire pipelines‚Äîinvolving synthetic data generation, categorization, embedding generation, feature extraction, and response generation‚Äîall on their local machines. This capability for end-to-end local development of AI-driven features is invaluable.\n\n## **Engineering the Future of Local AI**\n\nDocker Model Runner, even in its Beta phase (introduced with Docker Desktop 4.40, with APIs still evolving), presents a compelling toolkit for engineers looking to overcome the traditional challenges of local AI development. It offers a pathway to faster iteration, greater control, enhanced privacy, and reduced costs.  \nIn our next post, we will delve into the technical specifics of how Docker Model Runner's use of **OCI artifacts is set to revolutionize AI model management**, bringing DevOps principles to your MLOps workflows.  \n*This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.*\n\n</BlogWrapper>","frontmatter":{"title":"Docker Model Runner","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVR42h3I+U+SAQDG8fefqX6stozlLN1Qcy2MEC8QlcO4FDQQEUVADgF5CYUXUQE1jjIQSo4RqNhSJ+bUXmkqvByKd/0Rgdtn3z17gMXC6MeUxJ2VudKyhWOJMy11pko+5WW+G9XSlcpzqSz6clGq91q1dD1WPIvDe6MCZv4oR7x9o8t8eUAgXuyT+nnyYL/sK08VFkwn5XN59edbcPGv3vPP4L7UOc7GHQXQWdA7iz0HgRlk0gSDk/s64wEIwaBxv1g9dDBu2AMVIbnQOCiEZB1afvuMQL3zwXZqtmWMtixkzZqsORMAnVjNiM2SsU8hdnPabsnMWbJ2S9YtjVsofqhaI68kt1axSfewmKedzRT7iPXaZUrbTMezs8gCoEs6dEkneEd36CpWveci6SUP0NXPzTq0AypndGj1YqJQcL8GXcWlD32d9cDR4NWG5cQLKPb9Rco7ij3f2FGQ4p56hG+p7aShJKIXfB6WzapchpgiybNKDJreixvUGuxu1/kv63EcGE5ESrZLJDvf+yK+Ro3hDZ5ehyE/VioeNhIHxRq13Upk95a3Upuk2joy551gNJbLrd1eAPyf60W8H2v9m+vccJDAFpGkYJsMbBWqsCJF/YCUOWEjyw2Y90Mv6dwyXMvrbj7dMC2Oxwc21wFObKckmuiN73JWtrDz8/Um49seYcOwqkEowzEHaghdZfiWJ9jminYmTmXqi27ztuCe1QRnJQHQAzAzBHOiSf5Gaujogp+/JARjVVQuCtOEwjSjavEVBNYrvqZtapkV+N29mmKEYEbggBU+ZIZhgOpDaD6EGchwYvme1TNGJNf1DSEt7DZNRBrBING6RfEc0UOFruApzY9QvCdUX5rmL6H6kP851nx/MSExEQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/dfd3200061f7dd06b9c2ae3283e13437/366fe/hero-image.jpg","srcSet":"/static/dfd3200061f7dd06b9c2ae3283e13437/9b503/hero-image.jpg 750w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/321ef/hero-image.jpg 1080w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/84dcd/hero-image.jpg 1366w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/dfd3200061f7dd06b9c2ae3283e13437/5f850/hero-image.webp 750w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/2c010/hero-image.webp 1080w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/5126b/hero-image.webp 1366w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/dfd3200061f7dd06b9c2ae3283e13437/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVR42h3I+U+SAQDG8fefqX6stozlLN1Qcy2MEC8QlcO4FDQQEUVADgF5CYUXUQE1jjIQSo4RqNhSJ+bUXmkqvByKd/0Rgdtn3z17gMXC6MeUxJ2VudKyhWOJMy11pko+5WW+G9XSlcpzqSz6clGq91q1dD1WPIvDe6MCZv4oR7x9o8t8eUAgXuyT+nnyYL/sK08VFkwn5XN59edbcPGv3vPP4L7UOc7GHQXQWdA7iz0HgRlk0gSDk/s64wEIwaBxv1g9dDBu2AMVIbnQOCiEZB1afvuMQL3zwXZqtmWMtixkzZqsORMAnVjNiM2SsU8hdnPabsnMWbJ2S9YtjVsofqhaI68kt1axSfewmKedzRT7iPXaZUrbTMezs8gCoEs6dEkneEd36CpWveci6SUP0NXPzTq0AypndGj1YqJQcL8GXcWlD32d9cDR4NWG5cQLKPb9Rco7ij3f2FGQ4p56hG+p7aShJKIXfB6WzapchpgiybNKDJreixvUGuxu1/kv63EcGE5ESrZLJDvf+yK+Ro3hDZ5ehyE/VioeNhIHxRq13Upk95a3Upuk2joy551gNJbLrd1eAPyf60W8H2v9m+vccJDAFpGkYJsMbBWqsCJF/YCUOWEjyw2Y90Mv6dwyXMvrbj7dMC2Oxwc21wFObKckmuiN73JWtrDz8/Um49seYcOwqkEowzEHaghdZfiWJ9jminYmTmXqi27ztuCe1QRnJQHQAzAzBHOiSf5Gaujogp+/JARjVVQuCtOEwjSjavEVBNYrvqZtapkV+N29mmKEYEbggBU+ZIZhgOpDaD6EGchwYvme1TNGJNf1DSEt7DZNRBrBING6RfEc0UOFruApzY9QvCdUX5rmL6H6kP851nx/MSExEQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/dfd3200061f7dd06b9c2ae3283e13437/366fe/hero-image.jpg","srcSet":"/static/dfd3200061f7dd06b9c2ae3283e13437/9b503/hero-image.jpg 750w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/321ef/hero-image.jpg 1080w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/84dcd/hero-image.jpg 1366w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/366fe/hero-image.jpg 1408w","sizes":"100vw"},"sources":[{"srcSet":"/static/dfd3200061f7dd06b9c2ae3283e13437/5f850/hero-image.webp 750w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/2c010/hero-image.webp 1080w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/5126b/hero-image.webp 1366w,\n/static/dfd3200061f7dd06b9c2ae3283e13437/83fb1/hero-image.webp 1408w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5454545454545455}},"extension":"png","publicURL":"/static/dfd3200061f7dd06b9c2ae3283e13437/hero-image.png"}},"fields":{"slug":"/blog/docker/docker-model-runner"}},{"id":"502a14e9-7bd6-5e45-867b-bd9c5f1455d7","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\n**Tired of typing long Git commands?**\n\nGit is an incredibly powerful tool, but its command-line interface can sometimes feel cumbersome. Fortunately, Git allows you to create custom aliases to simplify your workflow. By assigning short, easy-to-remember names to frequently used commands, you can significantly boost your productivity and reduce the time spent on repetitive tasks.\n\n\n  <div>\n\n<iframe width=\"800\" height=\"490\" src=\"https://www.youtube.com/embed/vkk2jHUgbNQ?si=ohL-fnpZJDkwHO6w\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerPolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n    Video: `git lg` alias for a more visually appealing log\n</div>\n\n### Why Use Git Aliases?\n\n* **Efficiency:**  Quickly execute complex commands with a single keystroke.\n* **Consistency:** Reduce the risk of typos and errors in your Git commands.\n* **Personalization:** Tailor your Git experience to your specific needs and preferences.\n\n### Essential Git Aliases\n\nHere are some essential Git aliases that can revolutionize your workflow:\n\n**Navigation and Branching:**\n\n* **git co:**  Quickly switch branches.\n    ```bash\n    git config --global alias.co checkout\n    ```\n* **git br:** List all branches.\n    ```bash\n    git config --global alias.br branch\n    ```\n* **git new:** Create a new branch and switch to it.\n    ```bash\n    git config --global alias.new '!git checkout -b'\n    ```\n\n**Staging and Committing:**\n\n* **git a:** Stage all changes.\n    ```bash\n    git config --global alias.a add\n    ```\n* **git cm:** Commit with a message.\n    ```bash\n    git config --global alias.cm commit -m\n    ```\n* **git cam:** Amend the last commit.\n    ```bash\n    git config --global alias.cam commit --amend -m\n    ```\n* **git ca:** Stage all and commit with a message.\n    ```bash\n    git config --global alias.ca '!git add -A && git commit -m' \n    ```\n\n**Viewing and Comparing:**\n\n* **git st:** Check the state of your repository.\n    ```bash\n    git config --global alias.st status\n    ```\n* **git lg:** View a more visually appealing log.\n    ```bash\n    git config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\n    ```\n* **git df:** Show the diff of unstaged changes.\n    ```bash\n    git config --global alias.df diff\n    ```\n* **git dc:** Show the diff of staged changes.\n    ```bash\n    git config --global alias.dc diff --cached\n    ```\n\n**Undoing Changes:**\n\n* **git undo:** Reset the last commit, keeping your changes.\n    ```bash\n    git config --global alias.undo 'reset HEAD^' \n    ```\n\n**Remote Interactions:**\n\n* **git fch:** Fetch all changes from remotes.\n    ```bash\n    git config --global alias.fch fetch\n    ```\n* **git pl:** Pull the latest changes from the current branch's remote.\n    ```bash\n    git config --global alias.pl pull\n    ```\n* **git ps:** Push your local changes to the remote branch.\n    ```bash\n    git config --global alias.ps push\n    ```\n\n### Setting Up Git Aliases\n\nTo set up these aliases, you can edit your global Git configuration file:\n\n1. **Open your `.gitconfig` file:**\n   - **Global:** `~/.gitconfig`\n   - **Local:** `.git/config`\n2. **Add the aliases:** Use the `git config` command to add each alias. For example:\n   ```bash\n   git config --global alias.co checkout\n   ```\n\n### Streamline your cloud native workflow (just like git aliases)\n\nJust as git aliases simplify your development workflow, <Link to=\"/meshery\">Meshery</Link> streamlines the management of your cloud native infrastructure.  This CNCF project provides a unified platform to wrangle Kubernetes and other cloud native tools, so you can focus on building and deploying amazing applications.\n\nBy incorporating these Git aliases into your workflow, you can streamline your development process, reduce errors, and ultimately become a more efficient developer. Experiment with different aliases to find the perfect combination that suits your needs.\n \n**Happy Git-ing!**\n\n</BlogWrapper>","frontmatter":{"title":"Supercharge Your Git Workflow with Powerful Aliases","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADFUlEQVR42h2TT0ybdRjHmw3hfd9CW0YptKXSjvTvKKzt2xfoaJlUxqrAtnRjfxCpBTcw6CiblbKwCUyE6tiG8n9z042IMdPMiycvxuyiS7zt5MmriRdPevj42y7P5Uk++XzzfB/d3lKFPZJMiSJRapJQbDJGbxnWjkrUt4N0Xe/kxHdpetePob0TwdvrwBoxore/hGJRKDPI7JVl9pQpPGfpno8SSUISixqHAbXdycBkH9Obl5h/tETuYZ7l3z6m8HiKDx5cY/bhHJeL5zl9PoU3UI2pWkEqF0JC6gWwpFRGqZCpe9lE/LCfuds5Fu/NkC2O0LPRj7YV59zTDB2POmlf6+b4J2+QuznB6tdLXF64SLI7jNVqQNYLaJmMThK6dpuRlqiTsfE+Fj8aoDWjESjESOwcY/zZHLv//MDyX3c4+fMY4ZVD+Cdj9GXa2dqc4P3CIOFmu4AakWQJ3T6TnlDQSm8qxP1bQ/SfaaHxQhS12MbJn0b59u8nPP3vCb/++zuzfzyg65sTBD9s4cDZZkZHU2zfGKQ3eeAF1GTUo3MIsrvBTEIY7tw6RzrThzYco7EQRdtMMfTLFYp/3mfq2So9P44S+iyBP9eKmmljcDTN3cU0iYiDgK8GW40RXZ0AhoI26u0mrr+boLhyiSP5POqbKgfzYdzTHmI7SXwrYWEdJZgLog1o9FyZYW17ik/zSfxuC9GDddRaDOgsVeXEW+vxeWoIeav5cinN3PpVsqtrdEyM0D6d4fD8cSK5TlrnL5B4b5ixtc9ZvnOVx1tDxFUnDS6zYDipqhSRK8oVPK4qEm0uImEXjW4zs+MdfHVvkuW7s9z8fpuF3Q2u7X7BzMYC6+K6qzeyzF/spKvNid9rpzPhwbvfjKFC1EYS/THvK0cVyt1JPz6fDYe9ksYGI6deC5A93Uxh8nVG3oqTOdXE2ZSPsM+MWSTzemwc7QoS0+qxmCsoEyzRQwVFkbGK/Ic0F6nuJoaz3cQTTaiaD7fHyv4GC3WOShz11bgaalFVD8lXmjnTH+PoqwHsteJz9OJBShX+BzG6kyA+/AgqAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/566411427e09e80368249dd7537f1ba8/77779/hero-image.png","srcSet":"/static/566411427e09e80368249dd7537f1ba8/596c0/hero-image.png 750w,\n/static/566411427e09e80368249dd7537f1ba8/faa1e/hero-image.png 1080w,\n/static/566411427e09e80368249dd7537f1ba8/a9997/hero-image.png 1366w,\n/static/566411427e09e80368249dd7537f1ba8/77779/hero-image.png 1792w","sizes":"100vw"},"sources":[{"srcSet":"/static/566411427e09e80368249dd7537f1ba8/4c8c9/hero-image.webp 750w,\n/static/566411427e09e80368249dd7537f1ba8/faf10/hero-image.webp 1080w,\n/static/566411427e09e80368249dd7537f1ba8/55813/hero-image.webp 1366w,\n/static/566411427e09e80368249dd7537f1ba8/fb23b/hero-image.webp 1792w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5714285714285714}},"extension":"png","publicURL":"/static/566411427e09e80368249dd7537f1ba8/hero-image.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADFUlEQVR42h2TT0ybdRjHmw3hfd9CW0YptKXSjvTvKKzt2xfoaJlUxqrAtnRjfxCpBTcw6CiblbKwCUyE6tiG8n9z042IMdPMiycvxuyiS7zt5MmriRdPevj42y7P5Uk++XzzfB/d3lKFPZJMiSJRapJQbDJGbxnWjkrUt4N0Xe/kxHdpetePob0TwdvrwBoxore/hGJRKDPI7JVl9pQpPGfpno8SSUISixqHAbXdycBkH9Obl5h/tETuYZ7l3z6m8HiKDx5cY/bhHJeL5zl9PoU3UI2pWkEqF0JC6gWwpFRGqZCpe9lE/LCfuds5Fu/NkC2O0LPRj7YV59zTDB2POmlf6+b4J2+QuznB6tdLXF64SLI7jNVqQNYLaJmMThK6dpuRlqiTsfE+Fj8aoDWjESjESOwcY/zZHLv//MDyX3c4+fMY4ZVD+Cdj9GXa2dqc4P3CIOFmu4AakWQJ3T6TnlDQSm8qxP1bQ/SfaaHxQhS12MbJn0b59u8nPP3vCb/++zuzfzyg65sTBD9s4cDZZkZHU2zfGKQ3eeAF1GTUo3MIsrvBTEIY7tw6RzrThzYco7EQRdtMMfTLFYp/3mfq2So9P44S+iyBP9eKmmljcDTN3cU0iYiDgK8GW40RXZ0AhoI26u0mrr+boLhyiSP5POqbKgfzYdzTHmI7SXwrYWEdJZgLog1o9FyZYW17ik/zSfxuC9GDddRaDOgsVeXEW+vxeWoIeav5cinN3PpVsqtrdEyM0D6d4fD8cSK5TlrnL5B4b5ixtc9ZvnOVx1tDxFUnDS6zYDipqhSRK8oVPK4qEm0uImEXjW4zs+MdfHVvkuW7s9z8fpuF3Q2u7X7BzMYC6+K6qzeyzF/spKvNid9rpzPhwbvfjKFC1EYS/THvK0cVyt1JPz6fDYe9ksYGI6deC5A93Uxh8nVG3oqTOdXE2ZSPsM+MWSTzemwc7QoS0+qxmCsoEyzRQwVFkbGK/Ic0F6nuJoaz3cQTTaiaD7fHyv4GC3WOShz11bgaalFVD8lXmjnTH+PoqwHsteJz9OJBShX+BzG6kyA+/AgqAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/566411427e09e80368249dd7537f1ba8/77779/hero-image.png","srcSet":"/static/566411427e09e80368249dd7537f1ba8/596c0/hero-image.png 750w,\n/static/566411427e09e80368249dd7537f1ba8/faa1e/hero-image.png 1080w,\n/static/566411427e09e80368249dd7537f1ba8/a9997/hero-image.png 1366w,\n/static/566411427e09e80368249dd7537f1ba8/77779/hero-image.png 1792w","sizes":"100vw"},"sources":[{"srcSet":"/static/566411427e09e80368249dd7537f1ba8/4c8c9/hero-image.webp 750w,\n/static/566411427e09e80368249dd7537f1ba8/faf10/hero-image.webp 1080w,\n/static/566411427e09e80368249dd7537f1ba8/55813/hero-image.webp 1366w,\n/static/566411427e09e80368249dd7537f1ba8/fb23b/hero-image.webp 1792w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5714285714285714}},"extension":"png","publicURL":"/static/566411427e09e80368249dd7537f1ba8/hero-image.png"}},"fields":{"slug":"/blog/engineering/supercharge-your-git-workflow-with-powerful-aliases"}},{"id":"4cd22efc-b803-50b8-98ba-ff7c6411fed5","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport MesheryVersion from \"./meshery-version.png\";\n\n<BlogWrapper>\n\n  Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.\n  Artifacts of the builds for Meshery and its components are published under two different release channels, so that improved controls may be provided to both  Meshery users and Meshery developers. The two release channels are edge and stable release channels. Relative to stable releases, edge releases occur much more frequently. Edge releases are made with each merge to master, unless that merge to master is for a stable release. Stable releases are made with each\n  merge to master when a GitHub release tag is also present in the workflow.\n<h2> How release channels offer subscription </h2>\n  Release Channels offers a subscription where user can subscribe to a specific  release channel and get notified when a new release is available. This is  useful for users who want to stay up to date with the latest Meshery features, while also also providing flexibility for users who want to stay on a specific version of Meshery.\n  However, this approach can be risky because some updates may introduce bugs or compatibility issues that could break your existing installation. Depending upon your risk aversion and the nature of your deployment environment, having a subscription means that you will automatically receive these updates that you might not be ready incorporate. On the other hand, release channels also offer the ability to pin to a specific release which is a  good thing as it allows users to maintain stability and predictability of their environment by preventing unexpected changes from being introduced into their system. However, doing so cancels out any future subscription-based benefits such as receiving security patches or bug fixes that were added after that version was released.\n\nTherefore, it's important for you to weigh the pros and cons of each option before making decisions on how you want to manage your Meshery deployment. It's recommended you and your organizations have a well-defined upgrade strategy based on testing and validation procedures prior to applying new releases in production environments whether via subscriptions or manual upgrades to ensure that system availability is maintained and risks are minimized.\nTo subscribe to a specific release channel or version using mesheryctl you can use \n<pre><code className=\"language-bash\">mesheryctl system channel set [stable|stable-version|edge|edge-version] </code></pre>\nThis command will update your local Meshery configuration to use the selected channel for future updates. To set the channel to a specific version, replace Version with the desired version number. Example: <code className=\"language-bash\">mesheryctl system channel set stable</code> or <code className=\"language-bash\">mesheryctl system channel set stable-v0.5.56</code>\n<h2> Switching between Release Channels</h2>\nThere are two ways to switch between Meshery release channels: using mesheryctl or by editing your meshconfig file. In this blog post, we'll cover both methods.\n<h3>What is Meshconfig?</h3>\n  Meshconfig is a configuration file that is used to configure Meshery. It is typically located in the <code>~/.meshery/config.yaml</code> directory. It contains information about the current release channel, the version of Meshery that is installed, and other configuration options that are specific to your Meshery installation. \n  Meshconfig is automatically generated when you run Meshery for the first time. It is also automatically updated when you update Meshery\n<ol>\n<h3>Switching between Meshery release channels using meshconfig file.</h3>\nOpen your terminal and confirm that you have mesheryctl installed by running  <code>mesheryctl version</code>. If you don't have mesheryctl installed, you can install it by following the instructions in the  <a href=\"https://docs.meshery.io/installation/mesheryctl\">Meshery documentation</a>.\n<li>Create new Meshery config.yaml file <pre><code className=\"language=bash\">mesheryctl system context create [context-name]</code></pre></li>\nExample: <br/> <code className=\"language-bash\">mesheryctl system context create new-context --components meshery-istio meshery-osm meshery-linkerd --platform docker --url http://localhost:9081 --set --yes </code>\n<li> To view the newly created meshery context use <pre><code className=\"language-bash\">mesheryctl system context view [context-name]</code></pre></li>\n<li>After making these changes, you can switch between different context by using <pre><code className=\"language-bash\">mesheryctl system context switch</code></pre></li>\n</ol>\n\n<h3>Switching between Meshery release channels using mesheryctl.</h3>\nmesheryctl is a command-line tool for managing Meshery. You can use it to switch between different release channels. Here's how:\n<ul>\n  <li>Run the following command to see the current configuration for Meshery: <pre><code className=\"language-bash\">mesheryctl system context view</code></pre><img src={MesheryVersion} className=\"image-center\" style={{ width: \"50%\" }} />This will show you the current release channel (<b>stable</b> or <b>edge</b>), along with the version number and other information.</li>\n  <li>Run the following command to switch to a different release channel:<pre><code className=\"language-bash\">mesheryctl system channel switch</code></pre>This command will update your meshconfig file to switch release channel and version of context in focus. To switch the channel to a specific version, replace <b>Version</b> with the desired version number.</li>\n  <li>To confirm that the channel has been changed, run the following command again: <pre><code className=\"language-bash\">mesheryctl system channel view</code></pre></li>\n</ul>\n\n<h2>Conclusion </h2>\n\n  Switching between Meshery release channels is a simple and straightforward process. You can do it using mesheryctl or by switching between your meshconfig file. Whether you want stable updates or bleeding-edge features, Meshery has a release channel that suits your needs. Just remember to carefully consider your use case and needs before making any changes to ensure that you have the best Meshery experience.\n</BlogWrapper>\n","frontmatter":{"title":"Changing Meshery Release Channels","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACI0lEQVR42kWSS28TMRSFTSqqqilNxh5nXvZ4HhnPZJp5NJlJQiktFApqKAQFpWRbJKQu2AD/gCVSkWDFom0KXYBA4qHyWoD4aziKaKSjI8vy53vvsUGU8sGw1+tvDe73VtdywrDlKsxRTCG7MhGrqpZRwv3r4O8H8Oc9+P0OfDsGpyPgeHrSCMLIFRJrjUg6hTqVCJPHmDWWostqpVzsb80+3Zt7tDv3+OG5j6/B9zfAYIjX2MVLjc7KcquTrF1tX77SEr4UVw0mW0yJ6zaziG3bLqUUQjxfRGWpcLQPfp4AamEvMLvb13aGd7d7N7u3Nm7f2RRT1OrOuLiFswhlqRtHYVCrMUY1VVVMOnP8YgyL3gTPa2YYOdwnXlrlkROE1mRaynArRWnd5B43TZMQalJKHHtmJOC3YHKIUKgGFK83i0920WaHKgvjwJyKQStpmmRZ5nlckiSEEJQkqCqF0VllwROo57XS3hANbujt0KRQbDIBExzHSZ7nhBAIoYyxDBHS1CnMXNW2sNH04YN72mpCItsSIbsas2SDKUkzz/Kc+76m60jAsox0bQp7ARWvnWVhlnjNlDezMG4E3KfUN6SdblY38niJ2458YRGXynhhUUZyYbQ/DUy44xkuN2xPdzmxPJ3heTTszr56ZrY9ut5RV9ql5ajcjMvCW43CyUvw439gkyvOZDKZ+uT84XPw6wR8OgSfD8CXA/D1aCrxvU5H/wCqZH2AqKZNzAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png","srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/0dee1/change-meshery-release-channels.png 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/8beaa/change-meshery-release-channels.png 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/d079a/change-meshery-release-channels.png 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/a66aa/change-meshery-release-channels.webp 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/65dd5/change-meshery-release-channels.webp 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/4fad6/change-meshery-release-channels.webp 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/c512e/change-meshery-release-channels.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACI0lEQVR42kWSS28TMRSFTSqqqilNxh5nXvZ4HhnPZJp5NJlJQiktFApqKAQFpWRbJKQu2AD/gCVSkWDFom0KXYBA4qHyWoD4aziKaKSjI8vy53vvsUGU8sGw1+tvDe73VtdywrDlKsxRTCG7MhGrqpZRwv3r4O8H8Oc9+P0OfDsGpyPgeHrSCMLIFRJrjUg6hTqVCJPHmDWWostqpVzsb80+3Zt7tDv3+OG5j6/B9zfAYIjX2MVLjc7KcquTrF1tX77SEr4UVw0mW0yJ6zaziG3bLqUUQjxfRGWpcLQPfp4AamEvMLvb13aGd7d7N7u3Nm7f2RRT1OrOuLiFswhlqRtHYVCrMUY1VVVMOnP8YgyL3gTPa2YYOdwnXlrlkROE1mRaynArRWnd5B43TZMQalJKHHtmJOC3YHKIUKgGFK83i0920WaHKgvjwJyKQStpmmRZ5nlckiSEEJQkqCqF0VllwROo57XS3hANbujt0KRQbDIBExzHSZ7nhBAIoYyxDBHS1CnMXNW2sNH04YN72mpCItsSIbsas2SDKUkzz/Kc+76m60jAsox0bQp7ARWvnWVhlnjNlDezMG4E3KfUN6SdblY38niJ2458YRGXynhhUUZyYbQ/DUy44xkuN2xPdzmxPJ3heTTszr56ZrY9ut5RV9ql5ajcjMvCW43CyUvw439gkyvOZDKZ+uT84XPw6wR8OgSfD8CXA/D1aCrxvU5H/wCqZH2AqKZNzAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png","srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/0dee1/change-meshery-release-channels.png 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/8beaa/change-meshery-release-channels.png 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/d079a/change-meshery-release-channels.png 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/afa5c/change-meshery-release-channels.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/60fe9ee92d711b8b6d591e00535d18ef/a66aa/change-meshery-release-channels.webp 750w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/65dd5/change-meshery-release-channels.webp 1080w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/4fad6/change-meshery-release-channels.webp 1366w,\n/static/60fe9ee92d711b8b6d591e00535d18ef/c512e/change-meshery-release-channels.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png"}},"fields":{"slug":"/blog/meshery/changing-meshery-release-channels"}},{"id":"0bf099ea-9608-5c18-9882-81c42e07ea75","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport mesheryui from \"./mesheryui.webp\"; \n\n<BlogWrapper>\n\n<div className=\"intro\">\n<a href=\"https://meshery.io/\">Meshery</a>'s goal is to make the operation of cloud native infrastructure and the service mesh layer of cloud simplified. Originally created by Layer5, Meshery is an open source project with hundreds of contributors world-wide and is actively maintained by engineers from Red Hat, VMware, Intel, Layer5 and others.\n</div>\n<h2>Setup and run Meshery on AKS</h2>\nThe following instructions expects you to have an active Azure subscription, and Azure CLI installed on your system.\n<h3> Spin up the AKS Cluster</h3>\nCreate the resource group (a logical group where all our resources will be deployed). The following command creates  a resource group named MesheryGroup in <code>southindia</code> location.\n<pre><code className=\"language-bash\">\naz group create --name MesheryGroup --location southindia\n</code></pre>\n\nCreate AKS cluster using <code>az aks create</code>. The following command creates aks cluster with a single node.\n<pre><code className=\"language-bash\">\naz aks create --resource-group MesheryGroup --name MesheryAKS --node-count 1 --generate-ssh-keys\n</code></pre>\nAfter a few minutes, the command completes and returns a JSON formatted information about the cluster.\nYou can connect with your cluster by using <code>az aks get-credentials</code> ,  which basically downloads credentials and configure the Kubernetes CLI.\n<pre><code>\naz aks get-credentials --resource-group MesheryGroup --name MesheryAKS\n</code></pre>\nVerify the connection to your cluster using the <code>kubectl get command</code>.\n<pre><code>\n$kubectl get nodes\n</code></pre>\n<h3>Install Meshery into your AKS cluster</h3>\n\n```\nhelm repo add meshery https://meshery.io/charts/\n\nhelm install meshery meshery/meshery --namespace meshery --create-namespace\n\n```\nMeshery server supports customizing authentication flow callback URL, which can be configured in the following way.\n<pre><code>\nhelm install meshery meshery/meshery --namespace meshery --set env.MESHERY_SERVER_CALLBACK_URL=https://custom-host --create-namespace\n</code></pre>\nPort forward to Meshery UI\n```\nexport POD_NAME=$(kubectl get pods --namespace meshery -l \"app.kubernetes.io/name=meshery,app.kubernetes.io/instance=meshery\" -o jsonpath=\"{.items[0].metadata.name}\")\n\n$ kubectl --namespace meshery port-forward $POD_NAME 9081:8080\n\n```\nMeshery should now be running in your AKS cluster and the Meshery UI should be accessible at the specified endpoint you‚Äôve exposed to. Navigate to the meshery service endpoint to log into Meshery.\n<div><img src={mesheryui} className=\"image-center\" alt=\"Meshery UI Dashboard\" /></div>\n\nFrom here, your Meshery deployment on AKS is ready to use. In order to login to Meshery, authenticate with your chosen provider from the list.\nThere are different ways to configure a Meshery on AKS. Join the <a href=\"https://layer5.io/community\">community</a> and share your deployment‚Äôs configuration on the <a href=\"https://discuss.layer5.io/\"> discussion forum </a>today!\n</BlogWrapper>\n","frontmatter":{"title":"How to deploy Meshery on AKS","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmYAAABXRUJQVlA4IFoAAADQAwCdASoUAAoAPtFipk0oJiOiMAgBABoJaACw7GYVobqX7FMxDIAA/qX3az11ecS2G7Ywek1haVMFjWlflvPlov5ZOXa13PEkNYdR0wgoGPwU0M3fO53QAAA="},"images":{"fallback":{"src":"/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp","srcSet":"/static/3fe6493b7ebec3694bc03967df3a3a83/ee7ce/Meshery-on-AKS.webp 750w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/819dc/Meshery-on-AKS.webp 1080w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/3fe6493b7ebec3694bc03967df3a3a83/Meshery-on-AKS.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmYAAABXRUJQVlA4IFoAAADQAwCdASoUAAoAPtFipk0oJiOiMAgBABoJaACw7GYVobqX7FMxDIAA/qX3az11ecS2G7Ywek1haVMFjWlflvPlov5ZOXa13PEkNYdR0wgoGPwU0M3fO53QAAA="},"images":{"fallback":{"src":"/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp","srcSet":"/static/3fe6493b7ebec3694bc03967df3a3a83/ee7ce/Meshery-on-AKS.webp 750w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/819dc/Meshery-on-AKS.webp 1080w,\n/static/3fe6493b7ebec3694bc03967df3a3a83/f9756/Meshery-on-AKS.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/3fe6493b7ebec3694bc03967df3a3a83/Meshery-on-AKS.webp"}},"fields":{"slug":"/blog/meshery/how-to-deploy-meshery-on-aks"}},{"id":"a3d9d6ca-504e-51f1-b0d0-d7a2b928f10c","body":"\n\nimport { ResourcesWrapper } from \"../Resources.style.js\";\nimport Button from \"../../../reusecore/Button\";\nimport { Link } from \"gatsby\";\n\n<ResourcesWrapper>\n<p>\nTechStrong TV hosts a variety of live conversations and panel discussions with world‚Äôs leading technology experts and leaders at global tech events and user conferences. In this episode of TechStrong TV, straight out of <Link to=\"/community/events/open-source-summit-north-america-2022\">Open Source Summit NA 2022</Link> , catch guest <Link to=\"https://layer5.io/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and host Alan Shimel discuss the power of <Link to=\"/projects\">Layer5 projects</Link> in managing service meshes, Kubernetes and the rest of your cloud native infrastucture. They also dive into some of the other network-centric CNCF projects like CoreDNS and gRPC. Tune in now! \n</p>\n <Button $primary $url=\"https://digitalanarchist.com/videos/open-source-summit-na-2022/lee-calcote-layer5\" className=\"btn-center\" >\n <h3>Check out the TechStrong TV Interview with Layer5!</h3>\n </Button>\n</ResourcesWrapper>\n","frontmatter":{"title":"TechStrong TV Interview","type":"Interview","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAADQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBUesX6ZASr6rLojbUAA/q2Y4OjbO04hKhCcWYa4hSfBkj5L39LSxqIGpOMe19Y5zEFgVSsDNDPZ8LN767ayRpz7k7XG9zzlYAjzCCt9H6JybGgtwZ/88yp1/dYqEE/HQKxd2wcpSbNcL2/Tg/UxwwAAAA=="},"images":{"fallback":{"src":"/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp","srcSet":"/static/25aeb82dc80044f21493d0295ca3b84b/0b2ce/techstrong.webp 750w,\n/static/25aeb82dc80044f21493d0295ca3b84b/ce61b/techstrong.webp 1080w,\n/static/25aeb82dc80044f21493d0295ca3b84b/9469d/techstrong.webp 1366w,\n/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5166666666666666}},"extension":"webp","publicURL":"/static/25aeb82dc80044f21493d0295ca3b84b/techstrong.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAADQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBUesX6ZASr6rLojbUAA/q2Y4OjbO04hKhCcWYa4hSfBkj5L39LSxqIGpOMe19Y5zEFgVSsDNDPZ8LN767ayRpz7k7XG9zzlYAjzCCt9H6JybGgtwZ/88yp1/dYqEE/HQKxd2wcpSbNcL2/Tg/UxwwAAAA=="},"images":{"fallback":{"src":"/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp","srcSet":"/static/25aeb82dc80044f21493d0295ca3b84b/0b2ce/techstrong.webp 750w,\n/static/25aeb82dc80044f21493d0295ca3b84b/ce61b/techstrong.webp 1080w,\n/static/25aeb82dc80044f21493d0295ca3b84b/9469d/techstrong.webp 1366w,\n/static/25aeb82dc80044f21493d0295ca3b84b/8fecf/techstrong.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5166666666666666}},"extension":"webp","publicURL":"/static/25aeb82dc80044f21493d0295ca3b84b/techstrong.webp"}},"fields":{"slug":"/resources/interview/techstrong-tv-interview"}},{"id":"de0c7552-7a04-5f35-8a06-4b6842d35504","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\n\n<BlogWrapper>\n\nHola folks,\nAs a contributor, each of us is always striving hard in the ocean to open more and more pull-requests, but being a contributor just doesn't mean only raising PRs, it also means reviewing other PRs, pointing out mistakes, helping others in improving the **code-quality/code-reusability/code-readability**, helping in finding missing edge-cases that haven't been tackled yet, giving your opinions, writing LGTM, CITY helps nothing but just improving the confidence and engagement of the PR author.\nSo put on your **Quality Tester** hats because here I'll talk about how to test the PRs with the label `component/mesheryctl` i.e. pull-requests related to `mesheryctl`.\n\nOkay before we start, I'll like to tell you about <a href=\"https://github.com/cli/cli\">GitHub CLI</a>, it helps you checkout PRs very easily in your local system.\n<ol>\n    <li>The very first step is to **review the PR**, suggest changes if you think of any, ask queries, help the author to improve the code quality/readability/reusability, ask questions because asking helps you learn asking more better questions next time.</li>\n    <li>PR authors either attach a video showcasing expected behavior or add written instructions about their fix under **User Acceptance Behavior**.</li>\n    <li>Now it's the time to **checkout PR** in your local system, we can check out any PR like this:<pre><code className=\"language-bash\">gh pr checkout https://github.com/meshery/meshery/pull/4823</code></pre></li>\n    <li>You can check if you're into the same branch as the PR author with:<pre><code className=\"language-bash\">git branch</code></pre></li>\n    <li>Well, if we're testing a PR related to mesheryctl, we need to **build the binary** from the same branch. Change your directory to the `mesheryctl` folder and run:<pre><code className=\"language-bash\">make</code></pre>This will create a **mesheryctl binary** according to your OS in the same directory.</li>\n    <li>Now it's time to **test out this newly built binary** according to what's been tackled in the PR and related issues. For e.g. `system start` has some new functionality, make sure you followed the pull-request/linked-issue instruction for env setup, as sometimes fix/features are tackling an issue with a specific type of environment.<pre><code className=\"language-bash\">./mesheryctl system start</code></pre>the `./` helps us in using the newly built cli-binary present in the current directory which we built in 5th step.</li>\n</ol>\n<ol start=\"7\">\n    <li>Make sure we have a similar experience as mentioned in the Video or the instructions added to the PR. But wait, is it okay to give green flags to the PR? not yet tbh. We as a tester should **turn a little evil** and think of the relevant situations/environments which might not have been tackled but should be (basically we're trying to **break the new feature/fix**).</li>\n    <li>After spending a good amount of time testing the new behaviors, old standard behaviors, new test cases, few edge cases. We can provide new insights to the PR author about the behavior in your system, depending on our experience we can ask the PR author to address our new queries, or we can appreciate the work, or give green flags to the PR.</li>\n</ol>\nWow, that was a ton of work there. Well being a **Tester** is tough but very important before we merge pull requests. Every PR should be marked green with **end-to-end testing** before merging, we as a project are using **GH Workflows** to perform standard golang-testing but manual end-to-end testing completely removes margins of error.\n</BlogWrapper>","frontmatter":{"title":"Validating Meshery CLI Functionality","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uoJKMhsAgBABoJZwCdADBsAAD+8CVGzfndbE6d1gAA"},"images":{"fallback":{"src":"/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp","srcSet":"/static/9156c22b67aedb4c9c71f4951b06f17f/a4fab/thumbnail.webp 750w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16baf/thumbnail.webp 1080w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/5eb4b/thumbnail.webp 1366w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp 1895w","sizes":"100vw"},"sources":[]},"width":1,"height":0.36358839050131925}},"extension":"webp","publicURL":"/static/9156c22b67aedb4c9c71f4951b06f17f/thumbnail.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uoJKMhsAgBABoJZwCdADBsAAD+8CVGzfndbE6d1gAA"},"images":{"fallback":{"src":"/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp","srcSet":"/static/9156c22b67aedb4c9c71f4951b06f17f/a4fab/thumbnail.webp 750w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16baf/thumbnail.webp 1080w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/5eb4b/thumbnail.webp 1366w,\n/static/9156c22b67aedb4c9c71f4951b06f17f/16531/thumbnail.webp 1895w","sizes":"100vw"},"sources":[]},"width":1,"height":0.36358839050131925}},"extension":"webp","publicURL":"/static/9156c22b67aedb4c9c71f4951b06f17f/thumbnail.webp"}},"fields":{"slug":"/blog/meshery/validating-meshery-cli-functionality"}},{"id":"d3755e16-1694-5614-8d5f-5fe6f590fc95","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\nimport oldDesign from \"./initial-design.webp\";\nimport newDesign from \"./mesheryctl-docs.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro\">\nDocumentation plays a major role in any project. Even if the project is small or too big, the creator or the team behind the project needs to curate the documentation very well such that it'll be useful for new end users to refer and learn to use the project, troubleshoot the problems occurred and lot more. Thus, we, Layer5 have curated the documentation for Meshery to meet such purposes. Not to mention, <code>mesheryctl</code>, the CLI client of Meshery needs a curated documentation as well. This blog describes about the evolution of <code>mesheryctl</code> command reference page.\n</div>\n\n<h3>Initial Command Reference Design</h3>\nThe initial design of <code>mesheryctl</code> command reference page is all made using pure markdown and the functionality is handled using Jekyll, the main framework used for Meshery Docs. This handled great at initial stage but had many limitations, such as:\n    <ul>\n        <li>Updation of YAML for data is often required</li>\n        <li>Design was obselete at initial stage</li>\n        <li>No separate pages for each command and subcommand</li>\n    </ul>\n    Thus, the idea for redesigning the <code>mesheryctl</code> reference page was desperately needed.\n    <a href=\"https://docs.meshery.io\" alt=\"Meshery Documentation\" target=\"_parent\">\n    <img src = {oldDesign} className=\"image-center-shadow\" alt=\"Initial design of mesheryctl command reference\" /></a>\n<h3>Updated Command Reference Design</h3>\nTo tackle the shortcomings of the previous design, I was tasked to redesign the <code>mesheryctl</code> command reference page entirely. This was a big task at first glance to me, as I was a new contributor back then. Eventually after manipulating the reference section with help of great folks, I was able to pull off the task and the design was updated.\n    <a href=\"https://docs.meshery.io\" alt=\"Meshery Documentation\">\n<img src={newDesign} className=\"image-center-shadow\" alt=\"Meshery CLI command reference\" /></a>\n\nThe redesign work was done with help of HTML in markdown and with optimization in YAML code. A sample is given below.\n\n```shell\n    <!-- Copy this template to create individual doc pages for each mesheryctl commands -->\n\n    <!-- Name of the command -->\n    # mesheryctl mesh\n\n    <!-- Description of the command. Preferably a paragraph -->\n    ## Description\n\n    {% assign name = site.data.mesheryctlcommands.cmds[page.command] %}\n    {{ name.description }}\n\n    <!-- Basic usage of the command -->\n    <pre className=\"codeblock-pre\">\n    <div className=\"codeblock\">\n    mesheryctl mesh [flags] \n    </div>\n    </pre>\n    ...........\n```\n\n<h3>Adding auto generation feature in reference</h3>\n\nAs time passed, we realized that the command reference missed something for a while, though the design has been changed. Then, we thought the idea of automating the generation of docs such that developers don't need to change the code in docs section while working towards <code>mesheryctl</code>. That's where we got to know that Cobra library (the library for CLI apps made using golang) has a feature to make doc pages automatically. So we decided to incorporate that feature into <code>mesheryctl</code> docs page as well! After making several changes and a PR, I was finally able to introduce the feature in the docs site!\n\n```\nvar startCmd = &cobra.Command {\n\tUse:   \"start\",\n\tShort: \"Start Meshery\",\n\tLong:  `Start Meshery and each of its service mesh components.`,\n\tArgs:  cobra.NoArgs,\n\tExample: `\n// Start meshery\nmesheryctl system start\n// To create a new context for in-cluster Kubernetes deployments and set the new context as your current-context\nmesheryctl system context create k8s -p kubernetes -s\n// (optional) skip checking for new updates available in Meshery.\nmesheryctl system start --skip-update\n// Reset Meshery's configuration file to default settings.\nmesheryctl system start --reset\n// Silently create Meshery's configuration file with default settings\nmesheryctl system start --yes\n.....\n}\n\t`,\n```\n\nUsing this information provided above in each golang file, the markdown page is generated using Cobra CLI library and thus reducing the workload on the developer by automating via <a href=\"https://github.com/meshery/meshery/blob/master/.github/workflows/mesheryctl-ci.yml#L73\">GitHub Actions</a>.\n<br />\nThis is so far on how the <code>mesheryctl</code> command reference is evolved for now. And I hope that it'll continue to evolve in the field of documentation to serve the users to use Meshery in best way possible.\n</BlogWrapper>\n","frontmatter":{"title":"Evolution of the Meshery CLI Command Reference","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABwBACdASoUAA0APtFWpEuoJKOhsAgBABoJbACdMoGvtgJwx880HleA8ofTgAD+2VgctvGN2cFdfAJj4YJ0Ha8AiiMSiWh82G/yk9ZshKIR54QST0HBPk98AjqzxGHfuVZiMjvT9XDm39S3tEJ+oAAA"},"images":{"fallback":{"src":"/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp","srcSet":"/static/8b8429808b6e7381fa812bf1f5d29572/f06bf/mesheryctl.webp 750w,\n/static/8b8429808b6e7381fa812bf1f5d29572/8c7d4/mesheryctl.webp 1080w,\n/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6316666666666667}},"extension":"webp","publicURL":"/static/8b8429808b6e7381fa812bf1f5d29572/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABwBACdASoUAA0APtFWpEuoJKOhsAgBABoJbACdMoGvtgJwx880HleA8ofTgAD+2VgctvGN2cFdfAJj4YJ0Ha8AiiMSiWh82G/yk9ZshKIR54QST0HBPk98AjqzxGHfuVZiMjvT9XDm39S3tEJ+oAAA"},"images":{"fallback":{"src":"/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp","srcSet":"/static/8b8429808b6e7381fa812bf1f5d29572/f06bf/mesheryctl.webp 750w,\n/static/8b8429808b6e7381fa812bf1f5d29572/8c7d4/mesheryctl.webp 1080w,\n/static/8b8429808b6e7381fa812bf1f5d29572/1c0a1/mesheryctl.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6316666666666667}},"extension":"webp","publicURL":"/static/8b8429808b6e7381fa812bf1f5d29572/mesheryctl.webp"}},"fields":{"slug":"/blog/meshery/evolution-of-the-meshery-cli-command-reference"}},{"id":"10d40198-40a0-5d1e-8617-a75e432b771e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport BlockquoteAlt from \"../../../../reusecore/Blockquote/Blockquote-alt-style\";\nimport { Link } from \"gatsby\";\nimport { PerfbytesPodcast } from \"./perfbytesPodcast\";\nimport ConsulDemo from \"./consul-docker-extension-demo.webp\"\n\n<BlogWrapper>\n<PerfbytesPodcast>\n\n<h2>Podcast Insights</h2>\nMany questions were asked, answered, and a variety of topics were discussed. The story just gets better. This podcast goes deep into service meshes, load generators, circuit breaker, service mesh patterns in addition to a live demo of <Link to=\"/cloud-native-management/meshery\">Meshery</Link> and more. Hosted by Henrik from Perfbytes and joined by Mark, <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and Mrittika Ganguli from Intel. Tune in to find out more. Get answers to all community questions as a bonus.\n<h3>What is a service mesh?</h3>\n<div className=\"answer\">\n\nService mesh is one of the solutions that helps you to route traffic within your cluster so as¬†to expose¬†your services outside the cluster. It is a solution to control how different parts of an application share data with one another. Unlike other systems for managing this communication, a service mesh is a dedicated infrastructure layer built right into an app. You have different options like the service type load balancer or using ingress but service mesh makes sense because it will manage a lot of features around your service to service communication.\n\n</div>\n\nIn general, service meshes arose from the concept of proxies such as the NGINX proxy. Then Envoy was introduced by Lyft. Lyft had the architecture, and Google came along and created it. That gave us Istio, which is now part of CNCF. \n<Blockquote\n  quote=\"We were slugging it out in our labs trying to figure out how to do performance benchmarking with a service mesh. Instead of ten tools, if we had just¬†one, it would be nice. Then we see Meshery come into the field\"\n  person=\"Mrittika\"\n/>\n\nService meshes, according to Lee, \"hit a real sweet spot¬†personally\",¬†having been focused on networking for most¬†part of his career.\nHe¬†believes that there are a couple of different ways to speak about the genesis of service meshes, with Linkerd¬†being the first to coin the term.\nWe had Linkerd v1 written in scala and use jvm and then came Linkerd v2 which is something totally different at this point. It's all different code, different languages and  a different service mesh architecture. There's a number of different architectures by which service meshes are deployed. There's a new one that's been softly announced in beta from called Cilium that is helping bring back some of the different architectures of how to run the proxies.\n\n<div className=\"intro\">\n\nThe way I prefer to think about a surface mesh is that it's all about resiliency.\nIf you were to take a three-tiered web or three-tiered app and you think about how you're breaking out those tiers with some amount of\nkind of vertical scaling,  you'd probably, end up putting at least a virtual IP address out in front of the whole web tier and then you've got an app tier and a database tier because you've got multiple instances of those things. Maybe there's a load balancer in between.  This structure makes it simple to boost your resiliency.\n\n</div>\n\nHenrik goes on to elaborate that in service mesh we can do a lot of things to make sure that the communication is reliable. \nWhen you design microservice architecture, there is a need of implementing retry logic. So if a service A needs to introduce another service B, then the service mesh will manage the retry logic such that if we reach at one time and the service B is not responding then the service mesh will try to reach out several times. Therefore a service mesh offers a variety of features like this to manage the certificates within the cluster and and circle them in a regular pace. You can also have traffic splitting if you do canary releases. In your service to service communication, there are a plethora of scenarios that the service mesh can handle.\nHenrik¬†recalled¬†that it's normally difficult to obtain a full view¬†of what rules we've applied in the cluster, and¬†when he¬†first saw Meshery, his immediate¬†thought was, \"Wow, this is exactly what is missing in the market at the moment.\"\n\n\nLets dig deeper into this tool we've been alluding to for a while now: <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n\n<h3>Meshery</h3>\nIf you were on a pager and were¬†managing a large service mesh deployment with a number of rules and configurations around how security is enforced and identities are managed, and¬†things like uniform observability and how metrics and logs are collected and enforced, and then the different traffic writing rules and stuff. You might soil myself if you had to go make a change in that sea of yaml. That's in part what we're working towards. There's a capability within Meshery for solving this challenge. As a cloud native management plane, Meshery presides over top of 10 different types of service meshes and it also presides over kubernetes. You can run it outside of kubernetes or inside of kubernetes.\nMeshery has a number of components to its architecture. There is Meshery UI. It has a Mesheryctl, which is a CLI component. We have a number of service mesh adapters for each service mesh that Meshery supports.\n<h5>What is the need for different adapters?</h5>\n<div className=\"answer\">\n\nMeshery, as the multi-mesh manager, supports couple of different¬†adapters. Adapters are used by Meshery to manage the numerous service meshes. Different service mesh adapters are written to expose the unique value of each service mesh. Consequently, they are not equally capable just as each service mesh is not equally capable as the other. Some of them work in a similar way. Some of the service meshes have their own¬†differentiated¬†value, which is why there are individual adapters. Some of them work slightly differently depending on whether they're running as a managed service or not.\n\n</div>\n\n\nWe have a plug-in for Meshery it's called <Link to=\"/meshmap\">MeshMap</Link>, it is what you might consider a visual topology. It has a lot of use cases for observing in kind of a read-only mode. There's a second mode to this tool: The Designer Mode. It's a visual configurator of not only the specific settings within any of those service meshes that it supports like a circuit breaker and adjusting the sensor video\nbut also end up being a visual designer for your kubernetes deployments. When users drop in, they're able to go over and grab the specific capabilities of any of those service mesh adapters that are loaded for any of the versions of that mesh that they might want to design. The concept here is that they drag and drop these capabilities over and there's a bit of discoverability that's afforded through this ui rather than parsing through yaml, trying to¬†understand what's going on.\n\n<img src={ConsulDemo} alt=\"Consul MeshMap Demo\" className=\"slides-right\"/>\n\nI like to pretend that I know a lot about service meshes, but when it comes to having to keep track of all¬†of them, I don't know what the gateway tls sds config is, and so this¬†type of inline help is quite useful to design your deployments. The deployments may or may not use a mesh; in fact, you can use this to create your Kubernetes configuration and deployment as well.¬† You can even¬†save and recall those designs.\n\nTaking this example of consul, produced by hashicorp, is a little more of an\nintriguing deployment and a simple two-tier deck.  We announced the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> recently. So if you're using docker desktop, Meshery will be a first class app that's available inside of market and part of what it does as it integrates with docker desktop is it will import docker compose apps convert them to kubernetes manifests or kubernetes apps and they'll let you deploy those formerly docker compose apps onto a mesh which is why I'm talking about a two-tiered service.\n\n<h5>Does MeshMap allow you to load the current configuration that is has been applied in the current cluster?</h5>\n<div className=\"answer\">\n\nCurrently, there are two modes: the one we were looking at before was the designer mode, and the one we'll be¬†looking at now is the visualizer mode, which is probably a little more of an it's not entirely read-only¬†to the extent that you could¬†grab a pod and start an interactive session with the containers in that pod or you could you start a logging session. You could also initiate a performance test against¬† that particular service or that particular endpoint.¬†\nMeshery supports three different types of load generators,¬†which is a nighthawk,¬†fortio and wrk2. \n\n</div>\n\n<h5>What are the capabilities of these three load generators? When you speak about service mesh testing or performance testing, what is actually the process behind the scene? What should users think about when they're starting a gig and need to configure and optimize the service mesh?</h5>\n<div className=\"answer\">\n\nLee expounds on that for our benefit. \nIt takes weeks to months that you've got to dedicate for performance engineers to go over and like pull together various tools and scripts around them to then get into a spreadsheet or into some database that you then generate results. \nThe genesis of Meshery part was to help people comprehend what a service mesh is, when to use one and which one to use?  As you go to explain these common questions, the real answer is a totally disappointing, which is, it just depends on what you're asking to do.\nPeople want to measure it in cold hard quantitative metrics but if you're asking to do 100 percent sampling then also consider the distributed tracing implementation you had somewhere else and the fact that you're getting it\nin a uniform way here. Maybe you're likely to consider the overhead that you would have over there. It's frustrating to be trying to explain stuff to folks and get them excited about the tech and and to give them a vague response. Instead we give them a tool that says \"Hey look here's a tool that will deploy any of the service meshes that you want to test out.\"\nThere's a reason why there's ten of them like and actually many more than that.\nThere's a lot of overlap between them but different tools for different purposes for different size orgs, so it would be inappropriate to say well you know here's the one. It's rather hey here's a tool that that lets you deploy any number of them quickly, answer your own question about performance, because we can pump out benchmarks of the various service meshes under various configurations, using different types of workloads but which may or may not match your environment and over time those reports are going to get stale and so rather he's a tool to make you empowered.\n\n</div>\n\n<h5>Do you actually generate traffic that will go through the sidecar proxy of the service and then reach out the actual service?</h5>\n<div className=\"answer\">\n\nThat load is generated on demand or on schedule against one or more endpoints,¬†one or more of your services or something that is¬†not even on¬†your service. You can generate load not only against something running within your infrastructure but something external as well to do statistical analysis based on the configuration that you gave it and so yeah the answer is yes the traffic flows through the sidecar.\n\n</div>\n\n<h5>If I say I have never scripted or built any scenarios for fortio or nighthawk. Let's say I'm a loadrunner, a neoload, or a k6 user, and I want to accomplish the same thing with them. So what is the journey on those load generator? is it the same thing you have to build a workflow of requests that you want to send in that scenario?</h5>\n<div className=\"answer\">\n\nThat leads us to probably talk about one of our other projects which is called <Link to=\"/projects/cloud-native-performance\"> Performance</Link> which is a specification. It's another one of the projects that we've donated to the CNCF. Service Mesh Performance is the spec while Meshery is an implementation of the spec. \nAt a high level, if those other load generators were to adhere to how we standardize and describe the test that you want to run and then hand off that configuration to generate the performance profiles that are created here  you're not gonna down download them but the descriptor is important.\nThis implements a standard for the industry on what is the actual\nservice mesh test and then standardize the format so then anyone can use the same format to design their script or whatever they want and then use it to test. \nSo when I build a script, and I don't know loadrunner today and I want to use neologo tomorrow, then I don't have to rewrite everything. Great!\n\n</div>\n\nMissed the podcast? No worries, we got you covered. Check out the recording below :)\n\n<div className=\"iframe-container\">\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dGMGUocTvOk\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n</div>\n\n\n</PerfbytesPodcast>\n</BlogWrapper>\n","frontmatter":{"title":"Perfbytes Podcast","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsQAAABXRUJQVlA4ILgAAAAwBACdASoUAAoAPtFUo0uoJKMhsAgBABoJbACw7Yt8398roTNsHPm4xAAA/gu6KtGdEQS5MUTKGfcP5Gufx9gXWpRj6G6ds5oqLjt/xyiYITce88gLQWzHHdPM4p6O0dVK0TJ5vwzgFZYqZ8N/fMTcyWQbQwJcnXul4iJS4b4+3WL7wzf7lOxhYVMdx/EI+4De52RgUcZu9ExLRro321dRNawkgTU0AJR/jMHpNlTZZpGuYjgz6HAA"},"images":{"fallback":{"src":"/static/fc15cbdd8a2907439ce513abde29cbca/4d4bd/perfbytes-layer5.webp","srcSet":"/static/fc15cbdd8a2907439ce513abde29cbca/ebb4d/perfbytes-layer5.webp 750w,\n/static/fc15cbdd8a2907439ce513abde29cbca/27e7b/perfbytes-layer5.webp 1080w,\n/static/fc15cbdd8a2907439ce513abde29cbca/7162a/perfbytes-layer5.webp 1366w,\n/static/fc15cbdd8a2907439ce513abde29cbca/4d4bd/perfbytes-layer5.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5125000000000001}},"extension":"webp","publicURL":"/static/fc15cbdd8a2907439ce513abde29cbca/perfbytes-layer5.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsQAAABXRUJQVlA4ILgAAAAwBACdASoUAAoAPtFUo0uoJKMhsAgBABoJbACw7Yt8398roTNsHPm4xAAA/gu6KtGdEQS5MUTKGfcP5Gufx9gXWpRj6G6ds5oqLjt/xyiYITce88gLQWzHHdPM4p6O0dVK0TJ5vwzgFZYqZ8N/fMTcyWQbQwJcnXul4iJS4b4+3WL7wzf7lOxhYVMdx/EI+4De52RgUcZu9ExLRro321dRNawkgTU0AJR/jMHpNlTZZpGuYjgz6HAA"},"images":{"fallback":{"src":"/static/fc15cbdd8a2907439ce513abde29cbca/4d4bd/perfbytes-layer5.webp","srcSet":"/static/fc15cbdd8a2907439ce513abde29cbca/ebb4d/perfbytes-layer5.webp 750w,\n/static/fc15cbdd8a2907439ce513abde29cbca/27e7b/perfbytes-layer5.webp 1080w,\n/static/fc15cbdd8a2907439ce513abde29cbca/7162a/perfbytes-layer5.webp 1366w,\n/static/fc15cbdd8a2907439ce513abde29cbca/4d4bd/perfbytes-layer5.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5125000000000001}},"extension":"webp","publicURL":"/static/fc15cbdd8a2907439ce513abde29cbca/perfbytes-layer5.webp"}},"fields":{"slug":"/blog/events/perfbytes-podcast"}},{"id":"b171f9fc-a31b-5e80-ba6b-cd0f83878e10","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport bugEnvoy from \"./debug-envoy-proxy.svg\";\nimport DockerExtensionCTA from \"../../../../sections/Docker-Meshery/docker-extension-CTA\";\nimport Code from \"../../../../components/CodeBlock\";\n\n<BlogWrapper>\n    Trying to figure out what's happening with your request traffic? Not sure why your Envoy configuration isn't working? If you're using Istio as your gateway and need to troubleshoot your ingress traffic requests, here are a few tips for debugging Envoy proxy.\n<h2>Enable Envoy Debug Logging</h2>\n  By default Envoy system logs are sent to <code>/dev/stderr</code>. This location be overridden using <code>--log-path</code>. Logging to <code>/dev/stderr</code>  for system logs and to <code>/dev/stdout</code> for access logs can be useful when running Envoy inside a container. In this way, these two individual logstreams can be separated, and using this approach, logging requires no additional files or directories to be mounted.\n<div className=\"intro\">\n  We recommend setting the Envoy proxy‚Äôs log level to debug in a pre-production environment. Debug logs can help you identify issues before you graduate the associated configuration to your production environment.\n</div>\n<h3>Using envoy CLI</h3>\n  The envoy command has a <code>--log-level</code> flag that can be useful for debugging. By default, it‚Äôs set to info. To change it to debug, edit the envoy DaemonSet in the istio-system namespace and replace the <code>--log-level info</code> flag with <code>--log-level debug</code>. Setting the Envoy log level to debug can be particilarly useful for debugging TLS connection failures.\n<h3>Using container image</h3>\n  If you‚Äôre using the Envoy image, you can set the log level to debug through the <code>ENVOY_LOG_LEVEL</code> environment variable. The log level for Envoy system logs can be set using the <code>-l</code> or <code>--log-level</code> option.\nThe available log levels are:\n\n<ul>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>trace</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>debug</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>info</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>warning/warn</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>error</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>critical</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>off</li>\n</ul>\n\nThe default is <span className=\"highlight\">info</span>.\n\n<h3>Setting Envoy logs in the Helm configuration</h3>\n\n  The Consul helm chart uses <code>envoyExtraArgs:</code> to leverage Envoy command line options. One of the helpful options is <code>--component-log-level</code>. This provides granular control over setting log levels for Envoy components. In the example below, the components upstream, http, router and config are set to the debug log level. These four components are vital when debugging issues with requests between your services(sidecar proxies).\n<div>\n  <pre>\n    <code>connectInject:\n  enabled: true\n  envoyExtraArgs: \"--component-log-level upstream:debug,http:debug,router:debug,config:debug\"</code>\n  </pre>\n</div>\n\n  If you haven't set envoyExtraArgs: in consul-values.yaml just yet, you can set the log levels on the fly by using the following kubectl command:\n<div>\n  <pre>\n    <code>$ kubectl exec pod/pod-name -c container-name -- curl -X POST http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\nExample:\n<div>\n  <pre>\n    <code>$ kubectl exec pod/static-client-5bf4575d9c-zr2b -c static-client -- curl -X POST  http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\n  You will execute the kubectl command for each component. Make sure to append the correct component at the end of the curl command, i.e. <code>logging? component = debug</code>.\n  If curl is not able to be used in your pod, you can alternatively use <code>kubectl port-forward pod-name 19000</code> to make the Envoy admin accessible. From another terminal window, you can then curl to change the log levels. The output you receive in the terminal will show the modified component log levels.\n<div>\n  <pre>\n    <code>$ curl -X POST http://localhost:19000/logging? component = debug</code>\n  </pre>\n</div>\n<h3>Access Envoy logs in Kubernetes</h3>\n\nAccessing Envoy logs via pods can be done with the following command:\n<div>\n  <pre>\n    <code>$ kubectl logs --follow pod/ pod-name -c envoy-sidecar</code>\n  </pre>\n</div>\n\nThe --follow flag provides a real time observation into Envoy logs.\n<h3>Setting and Accessing Envoy logs when not using Helm.</h3>\n\nThe following command will start an envoy side car proxy, set the log level to debug with -l debug and capture Envoy logs in envoy_logs.txt. The .txt file will need to be created before executing this command.\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- -l debug --log-path envoy_logs.txt</code>\n  </pre>\n</div>\n\nTo have granular control over the Envoy components that is needed to be debugged, use the following command:\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- --log-path envoy_logs.txt --component-log-level upstream:debug,http:debug,router:debug,config:debug</code>\n  </pre>\n</div>\n\n<h2>Find your Istio Ingress Gateway</h2>\n  With Istio as your gateway, you should first look at <code>VirtualService</code> objects. These can show if the hosts are registered to the gateway correctly.\n<div>\n  <pre>\n    <code>$ kubectl get virtualservice -o=yaml</code>\n  </pre>\n</div>\n\n  However, sometimes, the <a  className=\"highlight\" href=\"https://envoyproxy.io\">Envoy</a> inside the gateway container is not properly configured (likely due to a bug). You can dump Envoy configuration to debug this further.\n<div>\n  <pre>\n    <code># find istio ingress gateway pod \\\n      $ kubectl get pods -n istio-system -l app=istio-ingressgateway</code>\n  </pre>\n</div>\n\n  Let's use <code>istio-ingressgateway-a93019f9dfw-l39xd</code> as an example pod name.\n<div>\n  <pre>\n    <code>\n      # enable debugging on envoy \\\n      $ kubectl exec --namespace=istio-system \\\n      istio-ingressgateway-a93019f9dfw-l39xd \\\n      -c istio-proxy -- curl -X POST \\\n      http://localhost:15000/logging?level=debug\n    </code>\n  </pre>\n</div>\n  Then, use <code>istioctl</code> tool to dump route configuration (this will show the output from the <a href=\"https://www.envoyproxy.io/docs/envoy/latest/operations/admin#operations-admin-interface-config-dump\"><code>/config_dump</code> admin endpoint</a> on Envoy):\n<div>\n  <pre>\n    <code>\n    $ istioctl proxy-config routes -n istio-system -o=json \\\n      istio-ingressgateway-a93019f9dfw-l39xd\n    </code>\n  </pre>\n</div>\n  We hope these steps are useful to you. If you're still having trouble configuring Envoy proxy, open up a new thread on the <a href=\"https://discuss.layer5.io\" className=\"highlight\">community discussion forum</a> or subscribe to the <Link to=\"/subscribe\" className=\"highlight\">Layer5 newletter</Link> for tips and tricks.\n</BlogWrapper>","frontmatter":{"title":"Debug Envoy Proxy","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYBAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSMAAAAABgGPb2rHn+W3bsW3btlmlUmfbtu2k+utoAnYyg1SpbLxfhhAREwA/5RzAbDvWNZyIxWorhwixTWieSwvGI3SYUtcXVVUFt2bUezvn5LRMeRUp8LOahjjvhMGQ9NBxXLZdb1HxVsVqDPypGwOE3LK8CkN3ACLUdAoAa6T46jZBH4cUefB4djh8mgKoRg+N2x8v2o9KIYKi9lKW9PG6/9HORQD/e+OWtxftXRsJBTf18nqUHyOn4VAAzNKI8I9CQARWUDggkAAAAHAEAJ0BKhQADwA+0VSjS6gkoyGwCAEAGglsAJ0vj/GAPH2dlBNaf2wZATiAAP7ASS/mP6a2Y+hs5t5eJvQi4+mGcsP07df1gED073L+PvHX6SzjzFJJrgvLrJ/bvxxRU7AjtrkOARQf7D08V4gAE2dUXwgM1otrPffYMi+KwR4hd8IMLnKUWTT00mrORnXAAA=="},"images":{"fallback":{"src":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp","srcSet":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp 553w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7432188065099458}},"extension":"webp","publicURL":"/static/86469654139cd83c10102b4b7340a05b/debug-envoy-proxy.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYBAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSMAAAAABgGPb2rHn+W3bsW3btlmlUmfbtu2k+utoAnYyg1SpbLxfhhAREwA/5RzAbDvWNZyIxWorhwixTWieSwvGI3SYUtcXVVUFt2bUezvn5LRMeRUp8LOahjjvhMGQ9NBxXLZdb1HxVsVqDPypGwOE3LK8CkN3ACLUdAoAa6T46jZBH4cUefB4djh8mgKoRg+N2x8v2o9KIYKi9lKW9PG6/9HORQD/e+OWtxftXRsJBTf18nqUHyOn4VAAzNKI8I9CQARWUDggkAAAAHAEAJ0BKhQADwA+0VSjS6gkoyGwCAEAGglsAJ0vj/GAPH2dlBNaf2wZATiAAP7ASS/mP6a2Y+hs5t5eJvQi4+mGcsP07df1gED073L+PvHX6SzjzFJJrgvLrJ/bvxxRU7AjtrkOARQf7D08V4gAE2dUXwgM1otrPffYMi+KwR4hd8IMLnKUWTT00mrORnXAAA=="},"images":{"fallback":{"src":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp","srcSet":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp 553w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7432188065099458}},"extension":"webp","publicURL":"/static/86469654139cd83c10102b4b7340a05b/debug-envoy-proxy.webp"}},"fields":{"slug":"/blog/service-mesh/debug-envoy-proxy"}},{"id":"44b1509f-0ba1-5ea3-9341-82abe59558cd","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport { Link } from \"gatsby\";\n\nimport meshmark from './meshmark-dark-text-side.svg';\nimport performanceQuestion from './performance-question.webp';\nimport smp from './smp.webp';\nimport meshmarkSlide from './meshmark.webp';\nimport example from './example.webp';\nimport formula from './formula.webp';\nimport MUE from './mue.webp';\nimport MeshMapDemo from './meshmark-score.webp';\n\n<BlogWrapper>\n\n<div className=\"intro\">\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and{\" \"}\n  <Link to=\"#\">Mrittika Ganguli</Link> presented <i>MeshMark: Service Mesh value measurement</i> at ServiceMeshCon Europe 2022.\n</div>\n\n<p>\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.\n</p>\n\n<p>\n  <Link to=\"#\">Mrittika Ganguli</Link> is the Director of Cloud Native Data Plane, Principal Engineer, and Network Architect at Intel.\n</p>\n\n<img src={meshmark} alt=\"MeshMark Graphic\" style={{ display: \"block\", margin: \"0 auto 0.5rem\", width: \"40%\" }} />\n\n---\n\n## What is MeshMark?\n\nMeshMark is a performance index that measures the value and overhead of your cloud native environment. It converts performance measurements into insights about the value of application networking functions, distilling overhead signals and KPIs into a simple index.\n\n<img src={performanceQuestion} alt=\"Performance characteristics question\" style={{ width: \"50%\", float: \"right\" }} />\n\n### Talk started with a question to the audience\n\n<Blockquote\n  className=\"pull-left\"\n  quote=\"We are missing some performance characteristics, as people have many metrics to track environments. It might take a while to articulate the performance characteristics of your environment.\"\n  person=\"Lee Calcote\"\n/>\n\n---\n\n### Lee Calcote explains ‚ÄúBusiness Performance‚Äù\n\n<p>\nWe're frequently overlooking business performance ‚Äî the reason we run the infrastructure in the first place. Rather than only focusing on quantitative speeds and feeds, we should quantify the value the infrastructure provides.\n</p>\n\n<img src={smp} alt=\"Service Mesh Performance\" style={{ width: \"50%\", float: \"right\" }} />\n\n---\n\n## Introduction to Service Mesh Performance (SMP)\n\nThe Service Mesh Performance project (a CNCF project) provides a consistent specification for capturing infrastructure configuration, service mesh configuration, and workload characteristics. This enables:\n\n- Baselines  \n- Benchmark comparisons  \n- System-to-system exchange of performance data  \n\n---\n\n## Mrittika Ganguli introduces MeshMark with an example\n\nMeshMark measures whether the performance of your infrastructure aligns with the value your deployment is intended to provide.\n\n<Blockquote\n  className=\"pull-right\"\n  quote=\"Are my resources utilized as best as possible? Why am I not getting the SLO met with 4 resources when I only needed 1 without the service mesh? Is the network a performance hog? MeshMark intends to help provide an index for many of these areas.\"\n  person=\"Mrittika Ganguli\"\n/>\n\n<p>\nOften when loading a YouTube video, text appears before the video. The load latency of the video traffic determines the experience. MeshMark helps quantify the efficiency of infrastructure functions that impact this latency and ties it directly to resource usage and cost (TCO).\n</p>\n\n<img src={meshmarkSlide} className=\"slides\" style={{ marginLeft: \"30px\" }} alt=\"MeshMark slides\" />\n<img src={example} className=\"slides\" style={{ marginLeft: \"30px\" }} alt=\"MeshMark example\" />\n\n<img src={formula} alt=\"MeshMark formula\" style={{ width: \"50%\", float: \"right\" }} />\n\n---\n\n# MeshMark: The Formula\n\nMeshMark scores from 0‚Äì100 and includes:\n\n- Value vs. overhead calculations  \n- Resource utilization efficiency  \n- Categorized consumption classes  \n\n---\n\n## Mrittika explains MUE (Mesh Utilization Efficiency)\n\n<p>\nMUE represents the ratio of measured platform resources to assigned resources.\n</p>\n\n<img src={MUE} alt=\"MeshMark MUE\" style={{ width: \"50%\", float: \"left\", paddingRight: \"1rem\" }} />\n\n<p>\nCPU performance is an easy example:  \nMUE = 1 ‚Äì (CPU Utilization / 100).  \nHigher latency lowers MUE, indicating reduced efficiency as QPS increases.\n</p>\n\n<p>\nMeshery, a cloud native management plane, helps visualize MUEs and evaluate efficiency of workloads across any service mesh.\n</p>\n\n<img src={MeshMapDemo} alt=\"MeshMap demo\" style={{ width: \"40%\", float: \"right\" }} />\n\n---\n\n## Lee demonstrates MeshMap with an example Consul application\n\n<p>\nIn the demo, a Consul workload is loaded into MeshMap's visual designer to inspect:\n</p>\n\n- Service splitting  \n- Service intentions  \n- Efficiency (MeshMark) calculations  \n\n---\n\n<div style={{ textAlign: \"center\" }}>\n  <iframe\n    width=\"70%\"\n    height=\"450px\"\n    style={{ marginRight: \"1.5rem\", marginLeft: \"1.5rem\" }}\n    src=\"https://www.youtube.com/embed/yvqn6ckO7BI\"\n    title=\"MeshMark demo video\"\n    frameBorder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n    allowFullScreen\n  />\n  <p style={{ fontStyle: \"italic\", fontSize: \"1rem\", marginLeft: \"1rem\" }}>\n    MeshMark in Meshery (excerpt from ServiceMeshCon EU 2022 demo)\n  </p>\n</div>\n\n---\n\n<strong>\n  Lee Calcote and Mrittika Ganguli covered all the concepts of SMP and MeshMark.  \n  Learn more on the <Link to=\"https://meshery.io/service-mesh-interface\">Service Mesh Performance</Link> website.\n</strong>\n\n</BlogWrapper>\n","frontmatter":{"title":"MeshMark: Cloud Native Value Measurement","type":"Blog","technology":null,"product":"MeshMap","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/c8936/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/8d8ff/banner.webp 750w,\n/static/262c08771cc081196228e58152adc495/fc98a/banner.webp 1080w,\n/static/262c08771cc081196228e58152adc495/62268/banner.webp 1366w,\n/static/262c08771cc081196228e58152adc495/c8936/banner.webp 1898w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5600632244467861}},"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/c8936/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/8d8ff/banner.webp 750w,\n/static/262c08771cc081196228e58152adc495/fc98a/banner.webp 1080w,\n/static/262c08771cc081196228e58152adc495/62268/banner.webp 1366w,\n/static/262c08771cc081196228e58152adc495/c8936/banner.webp 1898w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5600632244467861}},"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp"}},"fields":{"slug":"/blog/service-mesh/meshmark-cloud-native-value-measurement"}},{"id":"f2512afd-5871-5b42-9a4d-d8e7e3ed3a8e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport { Link } from \"gatsby\";\nimport DDE from './docker-extension-meshery.webp';\nimport developer from './developers-need.webp';\nimport dashboard from './dashboard.webp';\nimport designer from './designer-1.webp';\nimport visualizer from './viz-1.webp';\n\n<BlogWrapper>\n\n<div className=\"intro \">\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and <Link to=\"/community/members/nic-jackson\">Nic Jackson</Link> gave a presentation entitled <i>Extending the Docker Compose Experience to Service Mesh</i> at DockerCon 2022.\n</div>\n\n    The <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> extends Docker Desktop's position as the cloud native developer's go-to Kubernetes environment with easy access to the next\n    layer of cloud native infrastructure.\n    <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement. \n    <Link to=\"/community/members/nic-jackson\"> Nic Jackson </Link> is a developer advocate at HashiCorp, and the author of ‚ÄúBuilding Microservices in Go‚Äù, a book which examines the best patterns and practices for building microservices with the Go. Nic is also a coauthor of the Service Mesh Patterns book.\n    Nic Jackson has been using Docker Desktop from long time and tells how Docker Desktop provides feasibility to run Kubernetes for his local environment,\n    while Lee Calcote recalls how Docker Desktop has become a staple of his daily routine while building an extension for Meshery.\n<h3>Discussing Developers need to access Kubernetes</h3>\n<img\n    src={developer}\n    alt=\"Developers need to access Kubernetes\"\n    style={{ width: \"50%\", float: \"right\" }}\n/>\nMoving forward with the introduction to Docker Extension for Meshery, Nic says, \"When it comes to Kubernetes, should developers care about Kubernetes? And the answer is \"Yes\" because developers need Kubernetes because of the changing reliability patterns implementation rapidly, it provides a tight feedback loop for developing and deploying workloads onto your Kubernetes and makes the over developer experience smooth. With the help of Kubernetes, developers should be able to create environments without needing to be operational experts.\"\n    <h3>Meshery Extension offers an easy single click button to go from Docker Compose to Kubernetes wih all cloud native infrastructure supported.</h3>\n<img\n    src={DDE}\n    alt=\"Docker Desktop Extension Meshery\"\n    style={{ width: \"50%\", float: \"right\" }}\n/>\n    The Docker Extension for Meshery provides:\n<ul>\n<li>Kubernetes support for your Docker Compose apps - Import your Docker Compose apps. Configure and deploy them to Kubernetes and integrate into your GitOps pipeline.</li>\n<li>Collaborative designer for Docker Compose apps - Early access to the Docker Extension for Meshery that offers a visual topology for designing Docker Compose applications, operating Kubernetes, Kubernetes Operators, and their workloads.</li>\n<li>Single-click deployment of your infrastructure - Support of 250+ different cloud native infrastructure projects (including all the CNCF projects) at the fingertips of developers in connection with Docker Desktop‚Äôs ability to deliver Kubernetes locally.</li>\n</ul>\n        <img\n            src={dashboard}\n            alt=\"Docker Desktop Extension Meshery Dashboard\"\n            style={{ width: \"50%\", float: \"left\", paddingRight: \"30px\" }}\n        />\n    <ul>\n    <li>\n    While giving the demo Meshery Lee explained how with Docker Desktop running and Meshery extension installed we can see that Meshery has discovered\n    the installed Kubernetes cluster automatically and it performs action with the adapter present. \n    </li>\n    <li>\n    Meshery is a Kubernetes multi-cluster manager capable of performing lifecycle management of all CNCF projects, like Flux, Argo, Prometheus, Envoy, Jaeger, and so on.\n     </li>  \n    <li>\n    We can configure different cloud native infrastructure based on their configurations and performs actions such as deploy, design, and explore all of the capabilities of cloud native infrastructure via a rich schema with a live preview.\n    </li> \n    </ul>\n        <h3>Lee Calcote introduces MeshMap</h3>\n                <img\n                    src={designer}\n                    alt=\"MeshMap Designer\"\n                    style={{ width: \"50%\", float: \"right\" }}\n                />\nMeshMap is the world's only visual designer for Kubernetes and all cloud native infrastructure. Collaborate with other engineers in real-time as you use MeshMap to design, deploy, and manage your Kubernetes-based deployments. Save time and use a design template. Take advantage of the best practices embedded in the patterns found in Meshery Catalog. MeshMap not only allows you to create and verify your cloud native application and infrastructure configurations, but to deploy and operate that infrastructure as well.\n\n    Lee demonstrated MeshMap <strong>Designer</strong>  design capabilities using Consul Service Mesh as an eample and configures various Consul-specific features. He designs a service mesh deployment with application and Envoy filter from scratch.\n                            <img\n                                src={visualizer}\n                                alt=\"MeshMap Designer\"\n                                style={{ width: \"50%\", float: \"left\", paddingRight: \"30px\" }}\n                            />\n     MeshMap <strong>Visualizer Mode</strong> allows you to examines a visual topology of Kubernetes cluster and its services. View and search log streams from your pod's containers. Connect an interactive terminal to instances of your containers.\n    To Lee's demo, Nic also added in the context of developer experience that MeshMap also makes it easy to do the job and with Meshery extension it makes it super easy to write and configure code without being worried for the developer environment.\n           These Docker Extensions are so powerful that it allows you to do multiple tasks without leaving Docker Desktop.\n<div className=\"iframe-container\">\n<iframe src=\"https://www.youtube.com/embed/3DPZafR8VWM\" loading=\"lazy\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen ></iframe>\n</div>\n\n<strong>Lee Calcote and Nic Jackson packed a great deal of information in this talk. Find the recording below. The Meshery Extension is now out! Try now, and Share your Experience </strong>\n<Link to=\"/meshmap\">Apply for MeshMap Beta Program</Link>\n</BlogWrapper>\n","frontmatter":{"title":"Extending the Docker Compose Experience to Service Mesh","type":"Blog","technology":"Docker","product":"Docker Extension","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwAB6/pABoj2NUy/koAADL/k2zUZNSDZNP4McvnXa+KZwCUuZErfVazXD/7BG3PNmBDAo+RXP2IQbdHXgMBjCf0RJ75yHgAAA="},"images":{"fallback":{"src":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp","srcSet":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/a66aa/DC22-talk-HashiCorp.webp 750w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/65dd5/DC22-talk-HashiCorp.webp 1080w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/f9724/DC22-talk-HashiCorp.webp 1366w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp 1499w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630420280186791}},"extension":"webp","publicURL":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/DC22-talk-HashiCorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwAB6/pABoj2NUy/koAADL/k2zUZNSDZNP4McvnXa+KZwCUuZErfVazXD/7BG3PNmBDAo+RXP2IQbdHXgMBjCf0RJ75yHgAAA="},"images":{"fallback":{"src":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp","srcSet":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/a66aa/DC22-talk-HashiCorp.webp 750w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/65dd5/DC22-talk-HashiCorp.webp 1080w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/f9724/DC22-talk-HashiCorp.webp 1366w,\n/static/353e6b4dcf99ef4c8b16120ff9e1291e/4cd12/DC22-talk-HashiCorp.webp 1499w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630420280186791}},"extension":"webp","publicURL":"/static/353e6b4dcf99ef4c8b16120ff9e1291e/DC22-talk-HashiCorp.webp"}},"fields":{"slug":"/blog/docker/extending-the-docker-compose-experience-to-service-mesh"}},{"id":"6f70ddf7-740d-5640-b104-fa03b4622855","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport { Link } from \"gatsby\";\nimport CloudNative from './cloud-native-management.webp';\nimport CloudNativeIdentity from './cloud-native-identity.webp';\nimport dde from './dde.webp';\nimport designer from './Designer.webp';\nimport visualizer from './Visualizer.webp';\nimport meshmapInDocker from './meshmap-docker-extension-for-meshery.webp';\n\n<BlogWrapper>\n\n<div className=\"intro\">\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and{\" \"}\n  <Link to=\"/community/members/maximiliano-churichi\">Maximiliano Churichi</Link>{\" \"}\n  gave a presentation entitled <i>Extending Docker with Meshery, SPIRE, and Istio</i> at DockerCon 2022.\n</div>\n\n<p style={{ marginLeft: \"10px\", fontStyle: \"italic\" }}>\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative\n  product and technology leader, passionate about empowering engineers and\n  enabling organizations. As the founder and CEO of Layer5, he is at the\n  forefront of the cloud native movement.\n</p>\n\n<p style={{ marginLeft: \"10px\", fontStyle: \"italic\" }}>\n  <Link to=\"/community/members/maximiliano-churichi\">Maximiliano Churichi</Link>{\" \"}\n  is a Software Engineer at Hewlett Packard Enterprise, working in the Security\n  Engineering team, and fully engaged in open source technologies, passionate\n  about service mesh and cloud-native security.\n</p>\n\n<div>\n  <h3>\n    Cloud Native Management\n    <img\n      src={CloudNative}\n      alt=\"Meshery Docker Extension\"\n      style={{ width: \"50%\", float: \"right\" }}\n    />\n  </h3>\n  <p>\n    Lee Calcote introduces Meshery as a Cloud Native Management Plane, stating:\n    <Blockquote\n      quote=\"Meshery does Lifecycle and Performance Management of 10 different service meshes; more than that, it helps with configuration management with Kubernetes and with the Meshery Docker Extension it does the same for the Docker Compose application.\"\n    />\n  </p>\n</div>\n\n<p>\n  As a{\" \"}\n  <Link to=\"https://www.docker.com/blog/docker-captain-take-5-lee-calcote/\">Docker Captain</Link>, Lee has always been a proponent of Docker, particularly its enablement of developer workflows. Docker Extensions bring an integrated experience with ecosystem tooling like Meshery ‚Äî a critical tool for developers configuring and managing cloud native applications.\n</p>\n\n<div>\n  <h3>Cloud Native Identity</h3>\n\n  <p>\n    Maximiliano Churichi briefly explains Cloud Native Identity and HPE's open\n    source Project Mithril:\n  </p>\n\n  <p>\n    <Link to=\"https://spiffe.io\">SPIFFE</Link> (Secure Production Identity\n    Framework For Everyone) is a{\" \"}\n    <Link to=\"https://www.cncf.io/projects/\">CNCF-incubated</Link> project that\n    defines standards for identifying and securing communications between\n    application services. The{\" \"}\n    <Link to=\"https://spiffe.io/docs/latest/spire-about\">SPIRE</Link> project is\n    a production-ready reference implementation of these principles, offering\n    APIs for attestation policies, certificate issuance, and rotation.\n  </p>\n\n  <img\n    src={CloudNativeIdentity}\n    alt=\"SPIRE and SPIFFE in Cloud Native Identity\"\n    style={{ width: \"50%\", float: \"right\" }}\n  />\n\n  <p>\n    Maximiliano explains how HPE's Project Mithril integrates SPIRE and Istio to\n    strengthen service identity in the data plane.{\" \"}\n    <strong>Project Mithril leverages the service management capabilities of Istio and the strong identity-by-attestation principles of SPIFFE and SPIRE to deliver robust and flexible attestation beyond Kubernetes namespaces and service accounts</strong>. It provides end-to-end secure workload attestation based on zero-trust principles, regardless of workload location.\n  </p>\n\n  <p>\n    Improvements from Project Mithril have been upstreamed into Istio and are\n    expected in Istio 1.14, enabling users to leverage SPIRE for SPIFFE identity\n    management and stronger attestation mechanisms.\n  </p>\n</div>\n\n<h3>How the Docker Extension for Meshery enables single-click deployment</h3>\n\n<img\n  src={dde}\n  alt=\"Docker Extension for Meshery\"\n  style={{ width: \"50%\", float: \"left\", paddingRight: \"2rem\" }}\n/>\n\n<p>\n  The new Meshery Docker Extension brings{\" \"}\n  <Link to=\"/meshmap\">Layer5 MeshMap</Link>, the world's only visual designer\n  for Kubernetes and service mesh deployments, to millions of developers‚Äô\n  desktops. Developers and operators can visually configure and operate cloud\n  native infrastructure using MeshMap‚Äôs low-code visual designer.\n</p>\n\n<p>\n  Maximiliano Churichi of HPE describes how Meshery conveniently integrates\n  multiple services into Docker:\n</p>\n\n<ul>\n  <li>\n    <strong>Kubernetes and service mesh support for your Docker Compose apps</strong>{\" \"}‚Äî Import Docker Compose apps and deploy them to Kubernetes or any service mesh.\n  </li>\n  <li>\n    <strong>Visual design of Kubernetes applications</strong> ‚Äî Use{\" \"}\n    <Link to=\"/meshmap\">MeshMap</Link> as a visual topology designer for Docker\n    Compose, Kubernetes workloads, CRDs, and operators.\n  </li>\n  <li>\n    <strong>Single-click deployment</strong> ‚Äî 250+ Kubernetes operators and\n    60+ cloud services ready to use alongside Docker Desktop‚Äôs local Kubernetes.\n  </li>\n  <li>\n    <strong>Detection of Kubernetes environments</strong> ‚Äî Scan kubeconfigs,\n    switch clusters, or manage them concurrently.\n  </li>\n</ul>\n\n<h3>Maximiliano demonstrates MeshMap</h3>\n\n<img src={meshmapInDocker} alt=\"MeshMap in Meshery Docker Extension\" />\n\n<div\n  style={{\n    display: \"grid\",\n    gridTemplateColumns: \"1fr 1fr\",\n    padding: \"10px\",\n    gap: \"1rem\",\n  }}\n>\n  <div style={{ padding: \"20px\", textAlign: \"center\" }}>\n    <h5>Designer Mode</h5>\n    <p>\n      Design a service mesh deployment with applications and Envoy filters from\n      scratch, or customize deployments from patterns.\n    </p>\n    <img src={designer} alt=\"MeshMap Designer\" />\n  </div>\n\n  <div style={{ padding: \"20px\", textAlign: \"center\" }}>\n    <h5>Visualizer Mode</h5>\n    <p>\n      Examine a visual topology of your Kubernetes cluster and its services. View\n      logs from pods and open interactive terminals to containers.\n    </p>\n    <img src={visualizer} alt=\"MeshMap Visualizer\" />\n  </div>\n</div>\n\n<div className=\"iframe-container\">\n  <iframe\n    src=\"https://www.youtube.com/embed/SazEJizK4xQ\"\n    loading=\"lazy\"\n    title=\"YouTube video player\"\n    frameBorder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n    allowFullScreen\n  ></iframe>\n</div>\n\nLee Calcote and Maximiliano Churichi packed a great deal of information into this talk. Watch the recording above! The Meshery Extension is now out‚Äîtry it and share your experience!\n\n<p>\n  <Link to=\"/meshmap\">Apply for the MeshMap Beta Program</Link>\n</p>\n\n</BlogWrapper>\n","frontmatter":{"title":"Extending Docker with Meshery, SPIRE, and Istio","type":"Blog","technology":"Docker","product":"Docker Extension","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsAAAABXRUJQVlA4ILQAAADwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwIsAKKsXQ3bDU0Sh7xNByx8AA3QTx+NCIdbtlgNUIj8p8TTldQEJK/Onajgz/QWQc/tznhrECMWd6h2YF5Vur29u/3qZIIEF6x1ljtCpku538y8znYOZfzbugSVf57n6bu5fySdDxuSAlPHMO8HeUR+DU0Js9dn/ooTZ5vtV1ZIsjnj3E/a5Rec1TEKlY1hCyDOdAAAA="},"images":{"fallback":{"src":"/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp","srcSet":"/static/6d9aae3d5df3089bd154e53c9d945331/8d8ff/dc22-hpe-talk.webp 750w,\n/static/6d9aae3d5df3089bd154e53c9d945331/eedfa/dc22-hpe-talk.webp 1080w,\n/static/6d9aae3d5df3089bd154e53c9d945331/e048d/dc22-hpe-talk.webp 1366w,\n/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp 1907w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5595175668589407}},"extension":"webp","publicURL":"/static/6d9aae3d5df3089bd154e53c9d945331/dc22-hpe-talk.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsAAAABXRUJQVlA4ILQAAADwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoRwIsAKKsXQ3bDU0Sh7xNByx8AA3QTx+NCIdbtlgNUIj8p8TTldQEJK/Onajgz/QWQc/tznhrECMWd6h2YF5Vur29u/3qZIIEF6x1ljtCpku538y8znYOZfzbugSVf57n6bu5fySdDxuSAlPHMO8HeUR+DU0Js9dn/ooTZ5vtV1ZIsjnj3E/a5Rec1TEKlY1hCyDOdAAAA="},"images":{"fallback":{"src":"/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp","srcSet":"/static/6d9aae3d5df3089bd154e53c9d945331/8d8ff/dc22-hpe-talk.webp 750w,\n/static/6d9aae3d5df3089bd154e53c9d945331/eedfa/dc22-hpe-talk.webp 1080w,\n/static/6d9aae3d5df3089bd154e53c9d945331/e048d/dc22-hpe-talk.webp 1366w,\n/static/6d9aae3d5df3089bd154e53c9d945331/a7268/dc22-hpe-talk.webp 1907w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5595175668589407}},"extension":"webp","publicURL":"/static/6d9aae3d5df3089bd154e53c9d945331/dc22-hpe-talk.webp"}},"fields":{"slug":"/blog/docker/extending-docker-with-meshery-spire-and-istio"}},{"id":"5d6e85c1-a958-51c5-a20e-1308e5fd0237","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\nimport UnitTest from \"./unit-test.webp\";\nimport IntegrationTest from \"./integration-test.webp\";\nimport TreeGraph from \"./tree-graph.webp\";\n\n<BlogWrapper>\n\n<div className=\"intro \">\nDelivering a high quality user experience is our pinnacle goal in the design of Meshery's CLI: <code>mesheryctl</code>. Delivering a high quality user experience means testing both qualitatively and quantatively. As a concept, quality - whether you're talking about software or anything else - can be directly measured by consistency. A quality user experience is consistent and consistency of <code>mesheryctl</code> is reinforced by its many unit tests.\n</div>\n\n<code>mesheryctl</code> is written in Golang. In the Meshery project, we use CodeCov to calculate the code coverage across <code>mesheryctl</code>'s line of code. And there are plenty of lines of code. Achieving high percentages of code coverage in Meshery's CLI with grows in criticality as we bring more features into <code>mesheryctl</code> as a robust and sophisticated command line client of Meshery. Unit and integration tests bolster and roll up into broader end-to-end, functional testing performed across Meshery and the rest of its components.\nHigh levels of code coverage makes it easier for each project contributor to be confident that their code changes aren‚Äôt breaking any preexisting <code>mesheryctl</code> commands, side-swiping their functionality unknowingly, and consequently, unwittingly lowering the quality of Meshery's overall user experience.\n<h3> mesheryctl lines of code</h3>\n\n\n```yaml\n\n    270 text files.\n    106 unique files.\n    166 files ignored.\n\n    cloc v 1.92  T=0.15 s (692.3 files/s, 110063.3 lines/s)\n    ------------------------------------------------------------------\n    Language       files          blank        comment           code\n    ------------------------------------------------------------------\n    Go                88           2128           1330          13045\n    YAML              12              0              0            215\n    JSON               4              0              0             42\n    make               1             10              2             31\n    Markdown           1             23              0             27\n    ------------------------------------------------------------------\n    SUM:             106           2161           1332          13360\n    ------------------------------------------------------------------\n```\n\nUnit Tests can be written in two ways:\n<ol>\n    <li>\n        Test <code>mesheryctl</code> subcommand\n        <ol>\n            <li>Mock Meshery(backend) response if needed</li>\n            <li>Grab console output</li>\n            <li>Store standard/verified mesheryctl output in a golden file(a text file)</li>\n            <li>Match the stored/expected output with what we grab from the console</li>\n            <li>Cover as many scenarios as possible, test the situations where errors must be thrown</li>\n            <li>This is a standard format, changes can be made accordingly</li>\n        </ol>\n    </li>\n    <li>\n        Test <code>mesheryctl</code> functions\n        <ol>\n            <li>This is the standard testing you may have come across in every project</li>\n            <li>You write one test dedicated to one function covering all possible test-cases, matching expected outputs</li>\n        </ol>\n    </li>\n</ol>\n\n<h3>Example tree graph</h3>\nThis example of a tree graph (from <a href=\"https://github.com/meshery/meshery/pull/4823\">meshery/meshery/pull/4823</a>) shows the impact given changes make on the level of code coverage.\n<img src={TreeGraph} />\n\n<h3>Integration Tests</h3>\n\nIntegrations tests come into view when you cannot mock something easily and when a given behavior is cross-functional / cross-component. Integration tests put more, but not all of the focus validating system behavior and that the system completes all the necessary actions. Take <code>mesheryctl system start</code> for example. This command deploys Meshery, its adapters, and Kubernetes Operator; it starts Meshery. So, you run the command to start Meshery in a GitHub workflow and after running the <code>mesheryctl</code> subcommand through the tests and make sure that Meshery actually started. And if the workflow successfully runs the test, then boom!, you aced your integration writing test... errr... test writing.\nThe integration test writing exam can initially be challenging, but... that‚Äôs the fun in it. :) Running tests and making sure a command that is otherwise hard to verify, hard to test, and making it automatic through GH workflows.\n<h3>How you can make an impact</h3>\n\nWriting tests and making them work is in itself a tough task to do, so writing one test for a single function counts and makes a big difference over the long term. Don't hesitate. Start writing tests now. A single, new test is worthy of raising a pull request and will get you well on your way to learning much more about Golang, Docker, Kubernetes, and Clouds.\n<ul>\n    <li><a href=\"https://codecov.io/gh/meshery/meshery/\">Codecov</a> is used to check code coverage in <code>mesheryctl</code> (login with GitHub to get an in-depth idea of lines-of-code being covered in code coverage).</li>\n    <li>You can check the files on CodeCov‚Äôs website to figure out which mesheryctl commands haven‚Äôt been covered by existing tests.</li>\n    <li>Guide: <a href=\"https://docs.google.com/document/d/1xRlFpElRmybJ3WacgPKXgCSiQ2poJl3iCCV1dAalf0k/edit#heading=h.rzpmb66db1sq\">Writing tests for mesheryctl</a>. This guide will briefly introduce how tests are supposed to be written for mesheryctl.</li>\n    <li>Contributing to Tests doesn‚Äôt always mean writing new tests, It also means improving the effectiveness of already written-ones.</li>\n    <li> Search for Issues marked with area/tests in <a href=\"https://github.com/meshery/meshery\">GitHub - meshery/meshery</a>: Meshery, the cloud native management plane.</li>\n</ul>\n\nThe impact that you make with by writing even a single test is quite high. Your tests will be executed and used time-and-time again. I can‚Äôt explain in words (I don‚Äôt have that good of a vocabulary). Your Tests are going to run in each pull request raised against the Meshery project, in each commit someone pushes to a pull request, in every nightly regression test suite, in every release. Just think: if another contributor incidently introduces a defect or doesn't consider for an edge case, and fails to uphold the intended behavior of the code, your tests are going to catch them redhanded. How cool is that?\nSo, what are you waiting for? Jump in and write a few tests today! When you raise your pull request, label it with <code>area/tests</code> and <code>component/mesheryctl</code> and I'll be there to review! Let‚Äôs get <code>mesheryctl</code> 100% code coverage badge.\n</BlogWrapper>","frontmatter":{"title":"How to write unit and integration tests for mesheryctl","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uwJKMhsAgCABoJaQDImC0kAAD+8jqXyPcoCEgyAAAA"},"images":{"fallback":{"src":"/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp","srcSet":"/static/228cadb307e48d8dd59978517c9862a3/0622a/integration-test.webp 750w,\n/static/228cadb307e48d8dd59978517c9862a3/56413/integration-test.webp 1080w,\n/static/228cadb307e48d8dd59978517c9862a3/28a59/integration-test.webp 1366w,\n/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp 1882w","sizes":"100vw"},"sources":[]},"width":1,"height":0.35281615302869285}},"extension":"webp","publicURL":"/static/228cadb307e48d8dd59978517c9862a3/integration-test.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRjoAAABXRUJQVlA4IC4AAADwAgCdASoUAAcAPtFUo0uwJKMhsAgCABoJaQDImC0kAAD+8jqXyPcoCEgyAAAA"},"images":{"fallback":{"src":"/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp","srcSet":"/static/228cadb307e48d8dd59978517c9862a3/0622a/integration-test.webp 750w,\n/static/228cadb307e48d8dd59978517c9862a3/56413/integration-test.webp 1080w,\n/static/228cadb307e48d8dd59978517c9862a3/28a59/integration-test.webp 1366w,\n/static/228cadb307e48d8dd59978517c9862a3/45e9e/integration-test.webp 1882w","sizes":"100vw"},"sources":[]},"width":1,"height":0.35281615302869285}},"extension":"webp","publicURL":"/static/228cadb307e48d8dd59978517c9862a3/integration-test.webp"}},"fields":{"slug":"/blog/meshery/how-to-write-unit-and-integration-tests-for-mesheryctl"}},{"id":"a8f09cde-c9bd-5f47-b328-0d7aea181ac9","body":"\nimport { Link } from \"gatsby\";\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport token from \"./download-token.webp\";\nimport perfdashboard from \"./service-mesh-performance-profile-test-results.webp\"\nimport smidashboard from \"./smi-conformance-result.webp\";\nimport smpLogo from \"../../../../assets/images/service-mesh-performance/horizontal/smp-dark-text-side.svg\";\nimport smiLogo from \"../../../../assets/images/service-mesh-icons/service-mesh-interface/horizontal-stackedtext/color/servicemeshinterface-horizontal-stackedtext-color.svg\";\nimport githubBlack from \"../../../../assets/images/socialIcons/github_black.svg\";\n\n<BlogWrapper>\n  \nWith growing adoption of service meshes in cloud native environments, service mesh abstractions - service mesh-neutral specifications - have emerged. <Link to=\"/projects/cloud-native-performance\">Service Mesh Performance</Link>  and <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface</Link> are two open specifications that address the need for universal interfaces for interacting with and managing any type of service mesh. Let‚Äôs examine what each specification provides.\n<img src={smpLogo} className=\"image-left-no-shadow\" alt=\"service mesh performance logo\"/><a href=\"https://smp-spec.io\">Service Mesh Performance</a> standardizes service mesh value measurement, characterizing any deployment's performance by capturing the details of infrastructure capacity, service mesh configuration and workload metadata.\n<img src={smiLogo} className=\"image-right-no-shadow\" alt=\"service mesh interface logo\"/><a href=\"https://smi-spec.io\">Service Mesh Interface</a> provides a standard interface for service meshes on Kubernetes. These (currently) four specfications offer a common denominator set of interfaces to support most common service mesh use cases and the flexibility to evolve to support new service mesh capabilities over time.\nAs a service mesh agnostic tool that provides lifecycle and performance management of a large number of (10+) service meshes, Kubernetes applications, service mesh patterns and WebAssembly filters, Meshery is the ideal tool for the job when it comes to implementing these specifications.\nMeshery also comes with two new GitHub Actions that do exactly this. The <a href=\"https://github.com/layer5io/meshery-smi-conformance-action\">Meshery SMI Conformance Action</a> which <a href=\"https://meshery.io/blog/validating-smi-conformance-with-meshery\">validates SMI conformance</a> in your pipeline and the <a href=\"https://github.com/layer5io/meshery-smp-action\">Meshery SMP Action</a> which runs <a href=\"https://docs.meshery.io/functionality/performance-management\">SMP compatible performance benchmarks</a>.\nBut how do we use these actions? What do they offer? Let‚Äôs find out!\n<h2>Service Mesh Interface Conformance GitHub Action</h2>\n\nConformance of SMI specifications is defined as a series of test assertions. These test assertions are categorised by SMI specification (of which, there are currently four specifications) and comprise the complete suite of SMI conformance tests. Conformance requirements will change appropriately as each new version of the SMI spec is released. Refer to Meshery's documentation for details of how <a href=\"https://docs.meshery.io/functionality/service-mesh-interface\">Meshery performs SMI conformance</a>.\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth:\"9vw\"}}/>\n\n<h3>Using Meshery's SMI Conformance GitHub Action</h3>\n\nThe <a href=\"https://github.com/marketplace/actions/service-mesh-interface-conformance-with-meshery\">Service Mesh Interface Conformance GitHub Action</a> is available in the GitHub Marketplace. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event.\nAn example of the action configuration which runs on every release is shown below. The action handles setting up a Kubernetes environment, deploying the service mesh (see supported service meshes), running the conformance tests and reporting back the results to the SMI Conformance dashboard in Meshery.\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: false\n```\n\nYou can also bring in their own cluster with specific capabilities and with a service mesh already installed.\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    branches:\n      - 'master'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance tests on master\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Install OSM\n        run: |\n           curl -LO https://github.com/openservicemesh/osm/releases/download/v0.9.1/osm-v0.9.1-linux-amd64.tar.gz\n           tar -xzf osm-v0.9.1-linux-amd64.tar.gz\n           mkdir -p ~/osm/bin\n           mv ./linux-amd64/osm ~/osm/bin/osm-bin\n           PATH=\"$PATH:$HOME/osm/bin/\"\n           osm-bin install --osm-namespace default\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: true\n```\n\nYou can download a token from Meshery and add it as a GitHub secret (in the example above, the secret is <code>MESHERY_PROVIDER_TOKEN</code>). After the test is run, you can view the results from the Service Mesh Interface dashboard in Meshery UI.\n<p style={{ textAlign: \"center\" }}><img src={smidashboard} className=\"image-center-shadow\" style={{width:\"70%\"}} alt=\"smi conformance dashboard\" /></p>\n<i>Meshery's Service Mesh Interface Conformance Results</i>\nParticipating projects can also automatically report their conformance test results to the <a href=\"https://meshery.io/service-mesh-interface\">SMI Conformance dashboard</a>\n\n<h2>Service Mesh Performance GitHub Action</h2>\n\nMeasuring and managing the performance of a service mesh is key to efficient operation of any service mesh. Meshery is the canonical implementation of the Service Mesh Performance specification. You can choose from multiple load generators and use a highly configurable set of load profiles with variable tunable facets to run a performance test. Meshery packages all these features into an easy-to-use GitHub Action.\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth:\"9vw\"}}/>\n\n<h3>Using Meshery's Service Mesh Performance GitHub Action</h3>\n\nThe <a href=\"https://github.com/marketplace/actions/performance-testing-with-meshery\">Service Mesh Performance GitHub Action</a> is available in the GitHub Marketplace.You can create your own performance profiles to run repeatable tests with Meshery. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event. A sample configuration of the action is shown below.\n```yaml\nname: Meshery SMP Action\non:\n  push:\n    branches:\n      'master'\n\njobs:\n  performance-test:\n    name: Performance Test\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v2\n        with:\n          ref: 'perf'\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Run Performance Test\n        uses: layer5io/meshery-smp-action@master\n        with:\n          provider_token: ${{ secrets.PROVIDER_TOKEN }}\n          platform: docker\n          profile_name: soak-test\n```\n\nYou can also define your test configuration in an SMP compatible configuration file as shown below.\n```yaml\nsmp_version: v0.0.1\nid:\nname: Istio Performance Test\nlabels: {}\nclients:\n- internal: false\n  load_generator: fortio\n  protocol: 1\n  connections: 2\n  rps: 10\n  headers: {}\n  cookies: {}\n  body: \"\"\n  content_type: \"\"\n  endpoint_urls:\n  - http://localhost:2323/productpage\nduration: \"30m\"\n```\n\nSee this sample GitHub workflow (<a href=\"https://github.com/layer5io/meshery-smp-action/blob/master/action.yml\">action.yml</a>) for more configuration details.\n<img src={perfdashboard} className=\"image-center\" alt=\"performance management dashboard\"/>\n\nThe results from the tests are updated on the Performance Management dashboard in Meshery. To learn more about interpreting the test results, check out <a href=\"https://docs.meshery.io/guides/interpreting-performance-test-results\">this guide</a>. You can always checkout the <a href=\"https://docs.meshery.io/guides\">Meshery User Guides</a> to dive deep into these features.\nStay meshy!\n</BlogWrapper>\n","frontmatter":{"title":"Pipelining Service Mesh Specifications","type":"Blog","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/a66aa/service-mesh-specifications.webp 750w,\n/static/81aa70f0509f2123d8f460d3633f063c/65dd5/service-mesh-specifications.webp 1080w,\n/static/81aa70f0509f2123d8f460d3633f063c/4fad6/service-mesh-specifications.webp 1366w,\n/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp 1600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/a66aa/service-mesh-specifications.webp 750w,\n/static/81aa70f0509f2123d8f460d3633f063c/65dd5/service-mesh-specifications.webp 1080w,\n/static/81aa70f0509f2123d8f460d3633f063c/4fad6/service-mesh-specifications.webp 1366w,\n/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp 1600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp"}},"fields":{"slug":"/blog/service-mesh/pipelining-service-mesh-specifications"}},{"id":"01336bab-b9d8-5b9a-b18f-6b7a3378e1da","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper>\n<p>\n<Link to=\"/cloud-native-management/meshery\">Meshery</Link> is an open source, vendor-neutral, extensible management plane that enables service mesh users to overcome the challenges of complex virtual networking, empowers them to design and apply patterns containing tried and true best practices, benchmarks the performance of your service mesh deployments and enables developers, operators, and product managers to understand and manage their cloud native services with confidence. \n</p>\n\n<h3>\nLet‚Äôs learn how to manage service meshes with confidence with the extensible service mesh manager, <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n</h3>\n\n<div className=\"iframe-container\">\n<iframe width=\"460\" height=\"215\" src=\"https://www.youtube.com/embed/mU8qHUGYsk8\" loading=\"lazy\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to Meshery (Webinar-on-Demand)","type":"Recorded Webinar","technology":null,"product":"Meshery","mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/meshery/an-introduction-to-meshery-webinar-on-demand"}},{"id":"026b5e97-a286-53d0-b507-8f9ed86d2cae","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\nimport FAQ from \"../../../sections/General/Faq\";\n\n<ResourcesWrapper>\n  <div>\n    <FAQ category={[\"Meshery\"]} />\n  </div>\n</ResourcesWrapper>\n;\n","frontmatter":{"title":"Meshery FAQs","type":"FAQ","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRooAAABXRUJQVlA4IH4AAADwAwCdASoUAA8APtFUo0uoJKMhsAgBABoJbACdMoACZNTMZvLPw/oAAP7ZUrvgQ7hVtNtvV7hXXCZrxWyqJsc8NVTd2E2fcSmqDspjWKr+UXIi716HI+AFGNfb4VwB7WrWScZXrre8zZ9NfQKIvIAt9xgUCAoRlz8B9ZAAAAA="},"images":{"fallback":{"src":"/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp","srcSet":"/static/2db8d89cdff9c95760d3235b380b39ea/ba09c/meshery-logo-dark-text.webp 750w,\n/static/2db8d89cdff9c95760d3235b380b39ea/bc96e/meshery-logo-dark-text.webp 1080w,\n/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp 1113w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7619047619047619}},"extension":"webp","publicURL":"/static/2db8d89cdff9c95760d3235b380b39ea/meshery-logo-dark-text.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRooAAABXRUJQVlA4IH4AAADwAwCdASoUAA8APtFUo0uoJKMhsAgBABoJbACdMoACZNTMZvLPw/oAAP7ZUrvgQ7hVtNtvV7hXXCZrxWyqJsc8NVTd2E2fcSmqDspjWKr+UXIi716HI+AFGNfb4VwB7WrWScZXrre8zZ9NfQKIvIAt9xgUCAoRlz8B9ZAAAAA="},"images":{"fallback":{"src":"/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp","srcSet":"/static/2db8d89cdff9c95760d3235b380b39ea/ba09c/meshery-logo-dark-text.webp 750w,\n/static/2db8d89cdff9c95760d3235b380b39ea/bc96e/meshery-logo-dark-text.webp 1080w,\n/static/2db8d89cdff9c95760d3235b380b39ea/eb896/meshery-logo-dark-text.webp 1113w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7619047619047619}},"extension":"webp","publicURL":"/static/2db8d89cdff9c95760d3235b380b39ea/meshery-logo-dark-text.webp"}},"fields":{"slug":"/resources/faq/meshery-faqs"}},{"id":"14a9d010-447a-5ad3-bd1f-7016887e2f5d","body":"\n\nimport { ResourcesWrapper } from \"../Resources.style.js\";\nimport FAQ from \"../../../sections/General/Faq\";\n\n\n<ResourcesWrapper>\n <div>\n   <FAQ category={[\"Layer5\"]} /> \n </div>\n</ResourcesWrapper>\n","frontmatter":{"title":"Layer5 FAQs","type":"FAQ","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoACtcg53I4/HmZQ4AD+0C/LiaNYp/gAptl+AxIcPxvl67IhZN4oeuHuj0hO+8RPUMPR/JulDon1IZvwiZPOAxPH6F7m/pw+6es+w3zgAAA="},"images":{"fallback":{"src":"/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp","srcSet":"/static/4817b5f110f099c46c7d31dfcab76aeb/a66aa/layer5-gradient.webp 750w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/65dd5/layer5-gradient.webp 1080w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/4fad6/layer5-gradient.webp 1366w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/4817b5f110f099c46c7d31dfcab76aeb/layer5-gradient.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoACtcg53I4/HmZQ4AD+0C/LiaNYp/gAptl+AxIcPxvl67IhZN4oeuHuj0hO+8RPUMPR/JulDon1IZvwiZPOAxPH6F7m/pw+6es+w3zgAAA="},"images":{"fallback":{"src":"/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp","srcSet":"/static/4817b5f110f099c46c7d31dfcab76aeb/a66aa/layer5-gradient.webp 750w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/65dd5/layer5-gradient.webp 1080w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/4fad6/layer5-gradient.webp 1366w,\n/static/4817b5f110f099c46c7d31dfcab76aeb/c512e/layer5-gradient.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/4817b5f110f099c46c7d31dfcab76aeb/layer5-gradient.webp"}},"fields":{"slug":"/resources/faq/layer5-faqs"}},{"id":"c65e2e9b-9b5c-5994-a495-fc14ded2327f","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\nimport FAQ from \"../../../sections/General/Faq\";\n\n<ResourcesWrapper>\n  <div>\n    <FAQ category={[\"careers\"]} />\n  </div>\n</ResourcesWrapper>\n;\n","frontmatter":{"title":"Internship FAQs","type":"FAQ","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpoBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSKwAAAABgLJt2/lX9v23m9LsLdq26hqbVa3EaHurTtYHsK1kpv2evx0REwB7zqv0MMMyeZuWf0A+pu0R4wdEmnC92fPUnX/natzcE+kOGspSucwypPclVo+0qv52hYzsBJJbn+nvM2T/xsCqBKgn3e/v+NJXIma8sAmIvdJDtCiQd20GoaAFw2TkWTqA7OsTf0X/v6GnAgBpB+MOQMCunt8WGYxl5TwSM+0EU6XVoTAaVlA4IMgAAABwBgCdASoUABQAPtFWpk0oJCOiMBgIAQAaCWcABEFPGJ84aiB+qodM63A9zAWf18SPYalFhDgO3HTEJkAA/vd5mgQA2cByfbsxLlZ3azENuxPSupy6lFcmZ5xWXix5UmHhue4m7lhIK9sMlzFCY97FzXrfW+r9vifnpsw50ef9rqzQcHtjNDRqVOvKsgsNfqL0jz3js3QMU0TPOTe+viuahzYjLvKCJLj79c4msbu+XexWJUbckQA2UKJNzpuiUI4QGIlhUjgAAA=="},"images":{"fallback":{"src":"/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp","srcSet":"/static/527d1d45923fb0b266d35b755e1f1879/4f03f/workshops.webp 750w,\n/static/527d1d45923fb0b266d35b755e1f1879/4f506/workshops.webp 1080w,\n/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/527d1d45923fb0b266d35b755e1f1879/workshops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpoBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSKwAAAABgLJt2/lX9v23m9LsLdq26hqbVa3EaHurTtYHsK1kpv2evx0REwB7zqv0MMMyeZuWf0A+pu0R4wdEmnC92fPUnX/natzcE+kOGspSucwypPclVo+0qv52hYzsBJJbn+nvM2T/xsCqBKgn3e/v+NJXIma8sAmIvdJDtCiQd20GoaAFw2TkWTqA7OsTf0X/v6GnAgBpB+MOQMCunt8WGYxl5TwSM+0EU6XVoTAaVlA4IMgAAABwBgCdASoUABQAPtFWpk0oJCOiMBgIAQAaCWcABEFPGJ84aiB+qodM63A9zAWf18SPYalFhDgO3HTEJkAA/vd5mgQA2cByfbsxLlZ3azENuxPSupy6lFcmZ5xWXix5UmHhue4m7lhIK9sMlzFCY97FzXrfW+r9vifnpsw50ef9rqzQcHtjNDRqVOvKsgsNfqL0jz3js3QMU0TPOTe+viuahzYjLvKCJLj79c4msbu+XexWJUbckQA2UKJNzpuiUI4QGIlhUjgAAA=="},"images":{"fallback":{"src":"/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp","srcSet":"/static/527d1d45923fb0b266d35b755e1f1879/4f03f/workshops.webp 750w,\n/static/527d1d45923fb0b266d35b755e1f1879/4f506/workshops.webp 1080w,\n/static/527d1d45923fb0b266d35b755e1f1879/83805/workshops.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/527d1d45923fb0b266d35b755e1f1879/workshops.webp"}},"fields":{"slug":"/resources/faq/internship-faqs"}},{"id":"9e6d6d38-989d-5fb6-8743-b7b4ccc5b9b0","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\nimport MeshManager from \"./mesh-manager.webp\";\nimport MesheryClients from \"./meshery-clients.webp\";\nimport Mesheryfeatures from \"./meshery-features.webp\";\nimport MesheryDeployments from \"./meshery-deployment.webp\";\nimport Nighthawk from \"./nighthawk.webp\";\nimport Patterns from \"./patterns.webp\";\nimport ServiceMeshPatterns from \"./service-mesh-patterns.webp\";\nimport Planes from \"./planes.webp\";\nimport Mesheryoperatoricon from \"../../../../assets/images/meshery-operator/meshery-operator.svg\";\nimport MesheryLogo from \"../../../../assets/images/meshery/icon-only/meshery-logo-light.svg\";\nimport NighthawkIcon from \"../../../../assets/images/nighthawk/icon-only/SVG/nighthawk-logo.svg\";\nimport PatternsLogo from \"./patterns-logo.webp\";\nimport { Link } from \"gatsby\";\n\n<BlogWrapper>\n\n<div className=\"intro \">\n\n      Meshery is the open-source, collaborative cloud native manager that can\n    configure 230+ Kubernetes infrastructure, onboard your applications, manage WebAssembly filters, apply cloud native patterns, validate against best practices, and benchmarks the performance of your cloud native deployments. Let‚Äôs learn how to manage cloud native infrastructure with confidence with Meshery.{\" \"}\n\n</div>\n\n<h3>Network Planes</h3>\n<img src={Planes} className=\"slides-right\" align=\"right\" alt=\"network-planes\"/>\n  As we unfold what a management plane is, it would serve us well to talk about\n  network planes in this regard. Architecturally, a service mesh consists of two\n  planes. One of those is the data plane, while the other one is the control\n  plane. A service mesh data plane is the collection of intelligent proxies that\n  operate in unison under the coordination of the control plane. The control\n  plane performs configuration management of these intelligent proxies.\n  A management plane can do many things. Essentially, a management plane helps\n  you integrate cloud native infrastructure into your backend systems. A robust management\n  plane allows you to take full advantage of the power of the network while\n  integrating your service delivery processes seamlessly. Your management plane\n  might federate different types of infrastructure, help you instigate chaos\n  through controlled experiments, or offer automated traffic splitting in order\n  to execute different styles of canarying of your applications. Your management\n  plane might offer deep insights into the performance of your applications and\n  to the performance of your infrastructure or might deliver a change in\n  management framework.\n<h3>\n  <img\n    src={MesheryLogo}\n    align=\"center\"\n    alt=\"meshery-logo\"\n    height=\"35rem\"\n    width=\"35rem\"\n    style={{paddingBottom:\"5px\", paddingTop:\"auto\"}}/>{\" \"}\n  Meshery\n</h3>\n\n<img\n  src={MeshManager}\n  className=\"slides-left\"\n  align=\"right\"\n  alt=\"mesh-manager\"/>\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> manages the\n  lifecycle of infrastructure. Meshery does workload management, helps you\n  onboard or offboard your applications onto the mesh. It also lets you do\n  performance management.{\" \"}\n  <a href=\"https://docs.meshery.io/concepts/architecture/meshsync\">MeshSync</a>,\n  a custom controller within{\" \"}\n  <Link to=\"/cloud-native-management/meshery/meshery-operator\">Meshery operator</Link>\n  , performs discovery of existing infrastructure and deep fingerprinting of the\n  specific functions that version of your infrastructure is capable of performing.\n  Through MeshSync, Meshery supports brownfield deployments of your infrastructure\n  (Meshery discovers your existing infrastructure deployment that is already running\n  inside your cluster(s) whether those infrastructures were deployed by Meshery or\n  not){\" \"}\n  In order to facilitate such a deep level of understanding of each type of\n  infrastructure, <Link to=\"/cloud-native-management/meshery\">Meshery</Link> has\n  models that are specific to each infrastructure (given that each infrastructure\n  has its own set of features). Consequently, in order to leverage the maximum\n  functionality of each infrastructure, Meshery has separate, dedicated adapter\n  for each of the{\" \"}\n<a href=\"https://docs.meshery.io/getting-started/overview\"> supported models. </a>\n  :{\" \"}\n<table className=\"table-1\" align=\"center\">\n  <thead>\n    <tr>\n      <th align=\"left\">Infrastructure</th>\n      <th className=\"status\">Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/consul\"> Meshery Adapter for Consul </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/istio\"> Meshery Adapter for Istio </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/kuma\"> Meshery Adapter for Kuma </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/linkerd\"> Meshery Adapter for Linkerd </a>{\" \"}\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/nsm\"> Meshery Adapter for Network Service Mesh </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/osm\"> Meshery Adapter for Open Service Mesh </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/traefik-mesh\"> Meshery Adapter for Traefik Mesh </a>\n      </td>\n      <td className=\"status\">stable</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/cpx\"> Meshery Adapter for Citrix Service Mesh </a>\n      </td>\n      <td className=\"status\">beta</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/nginx-sm\"> Meshery Adapter for NGINX Service Mesh </a>\n      </td>\n      <td className=\"status\">beta</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/app-mesh\"> Meshery Adapter for App Mesh </a>\n      </td>\n      <td className=\"status\">alpha</td>\n    </tr>\n    <tr>\n      <td>\n<a href=\"https://docs.meshery.io/service-meshes/adapters/tanzu-sm\"> Meshery Adapter for Tanzu Service Mesh </a>\n      </td>\n      <td className=\"status\">alpha</td>\n    </tr>\n  </tbody>\n</table>\n\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> also lets you\n  integrate your Prometheus and Grafana add-ons so you can import your existing\n  Grafana dashboards to Meshery. When you first start Meshery, we also have a\n  configuration wizard, which basically walks you through the entire setup to\n  get Meshery up and running. By the end of this, it will make sure that you\n  have Meshery running on your cluster.\n<img\n  src={MesheryDeployments}\n  className=\"slides-right\"\n  align=\"right\"\n  alt=\"meshery-deployment\"/>\n  If you want a more finer configuration, you can configure your environment\n  through settings and you can configure infrastructure, and you can configure\n  the metrics, you can define your performance tests to be reused.\n  For configuration management,{\" \"}\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> will analyze your\n  runtime environment for certain infrastructure and tell you if you're doing\n  things right or not. What you can do is you can upload your applications\n  directly into Meshery, edit them in the Meshery UI itself and actually apply\n  these applications or onboard these applications on your infrastructure.\n<h3>\n  <img\n    src={Mesheryoperatoricon}\n    align=\"center\"\n    alt=\"meshery-operator-logo\"\n    height=\"32rem\"\n    width=\"32rem\"\n    style={{paddingBottom:\"5px\", paddingTop:\"auto\"}}/>{\" \"}\n  Meshery Operator\n</h3>\n<img\n  src={Mesheryfeatures}\n  className=\"slides-left\"\n  align=\"right\"\n  alt=\"Meshery-features\"/>\n\n  <Link to=\"/cloud-native-management/meshery/meshery-operator\">Meshery operator</Link>{\" \"}\n  is a custom controller called MeshSync. MeshSync helps keep Meshery apprised\n  of the various changes that are going on to the infrastructure and various\n  changes that are happening within Kubernetes itself. In this way Meshery\n  supports not only greenfield deployments like deploying infrastructure itself,\n  it also supports connecting to existing infrastructure deployments, that is,\n  brownfield deployment. So it will discover your existing deployments as well.\n  There's an extensible concept in Meshery called a{\" \"}\n  <a href=\"https://docs.meshery.io/extensibility/providers\">provider</a>.\n  Providers can typically offer a layer of persistence so to the extent that\n  users are running performance tests intensely or to the extent that users want\n  to have a particular type of directory integrated to bring their own identity\n  to Meshery and have a multi-user experience. The other area of extensibility\n  is the notion that Meshery has a couple of APIs both ‚Äì rest API and graphql\n  API. It comes with a command-line interface as well as a user interface.{\" \"}\n<h3>Layer5 MeshMap</h3>\n  Another capability of Meshery that is going to be released in the upcoming\n  version is visually configuring your infrastructure using MeshMap. You can add\n  filters, applications as well as make other configurations visually here and\n  you can export it as patterns to make it reusable quite easily. It\n  automatically figures out the sample application we have deployed, then\n  generates a visual representation. It provides users the ability to design\n  infrastructure, infrastructure configuration, and the applications that run on\n  it.\n<img src={Patterns} className=\"slides-left\" align=\"right\" alt=\"Patterns\"/>\n<h3>\n  <img\n    src={PatternsLogo}\n    align=\"center\"\n    alt=\"patterns-logo\"\n    height=\"35rem\"\n    width=\"32rem\"\n    style={{paddingBottom:\"5px\", paddingTop:\"auto\"}}/>{\" \"}\n  Patterns\n</h3>\n  {\" \"}\n  A pattern is capable of describing the deployment of any of the meshes that Meshery\n  supports as well as the configuration of the mesh. It also notes ongoing behavior\n  so if you wanted to run a canary you can describe that in a pattern. So, patterns\n  are like a template, they're customizable and ingestible into Meshery itself.\n<img\n  src={ServiceMeshPatterns}\n  className=\"slides-right\"\n  align=\"right\"\n  alt=\"Service-Mesh-Patterns\"/>\n  Meshery will take action based on what you've described in the pattern, things\n  like generating or running a performance test, generating load, and then doing\n  statistical analysis on that set of results. In the future, if you want to\n  deploy a web assembly filter, you can describe that in a pattern as well and\n  have Meshery apply it. The patterns are infrastructure agnostic, they're\n  reusable and the initial set of them is being stored in a public-facing\n  repository. There are almost 60 patterns that have been identified.\n  Ultimately, it will allow you to ingest these and measure then orchestrate and\n  apply them to your infrastructure. You can also use Meshery to visually\n  represent them and to visually design.\n<h3>\n  <img\n    src={NighthawkIcon}\n    align=\"center\"\n    alt=\"nighthawk-logo\"\n    height=\"35rem\"\n    width=\"35rem\"\n    style={{paddingBottom:\"5px\", paddingTop:\"auto\"}}/>{\" \"}\n  Nighthawk\n</h3>\n  There‚Äôs a project called <Link to=\"/projects/nighthawk\">Nighthawk</Link> that\n  helps advance the existing integration of nighthawk and Meshery. Nighthawk is\n  a load generator that is an envoy project. It's written in c plus plus and has\n  a couple of intriguing capabilities that are the ongoing study within\n  Nighthawk. There is an ongoing effort to take advantage of nighthawk‚Äôs\n  adaptive load controllers, add a couple of those in and expose them through\n  Meshery to let people recursively evaluate what is ultimately an optimal\n  configuration in your environment and the infrastructure.\n<img src={Nighthawk} className=\"slides-right\" align=\"right\" alt=\"Nighthawk\"/>\n\n  If you consider that you've got a certain SLO or a certain minimum latency\n  requirement that you need to stick to that but you also want to at the same\n  time maximize resiliency characteristics of your deployment, that can be a\n  difficult thing to figure out particularly if any of your infrastructure\n  changes:\n<ul>\n  <li>if you add another node to your environment, your clusters,</li>\n  <li>if you upgrade your infrastructure,</li>\n  <li>if you change the configuration of your infrastructure,</li>\n  <li>\n    if you add another service to your set of workloads that you're running.\n  </li>\n</ul>\n  If these factors change, so does the ability to run optimization routines. To\n  help you identify the optimal configuration of your infrastructure but in accordance\n  with your own constraints is again the study of{\" \"}\n  <Link to=\"/projects/nighthawk\">Nighthawk</Link>.{\" \"}\n<h3>\n  Check out the CNCF On-Demand Webinar:{\" \"}\n  <Link to=\"/cloud-native-management/meshery\">Meshery</Link> - The Cloud Native\n  Manager to learn more!\n</h3>\n<div className=\"iframe-container\">\n\n  <iframe\n    width=\"460\"\n    height=\"215\"\n    src=\"https://www.youtube.com/embed/mU8qHUGYsk8\"\n    loading=\"lazy\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n    allowfullscreen\n  ></iframe>\n\n</div>\n\n</BlogWrapper>","frontmatter":{"title":"An Introduction to Meshery (Webinar-on-Demand) ","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABQAwCdASoUAAsAPtFipk0oJiOiMAgBABoJZgCw7GlXTbijAAD+0jMMBfop23C2fGXyMOcvtj4R0cAWOYI9rXbL4gq6+9RFfodXXX946n/c7bfC7T9i6EDDw4DwHhsAAAA="},"images":{"fallback":{"src":"/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp","srcSet":"/static/28ae2a6f951a849aa29443d8f5f79f4e/06597/meshery-webinar.webp 750w,\n/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp 810w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5641975308641975}},"extension":"webp","publicURL":"/static/28ae2a6f951a849aa29443d8f5f79f4e/meshery-webinar.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABQAwCdASoUAAsAPtFipk0oJiOiMAgBABoJZgCw7GlXTbijAAD+0jMMBfop23C2fGXyMOcvtj4R0cAWOYI9rXbL4gq6+9RFfodXXX946n/c7bfC7T9i6EDDw4DwHhsAAAA="},"images":{"fallback":{"src":"/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp","srcSet":"/static/28ae2a6f951a849aa29443d8f5f79f4e/06597/meshery-webinar.webp 750w,\n/static/28ae2a6f951a849aa29443d8f5f79f4e/847c8/meshery-webinar.webp 810w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5641975308641975}},"extension":"webp","publicURL":"/static/28ae2a6f951a849aa29443d8f5f79f4e/meshery-webinar.webp"}},"fields":{"slug":"/blog/meshery/an-introduction-to-meshery-webinar-on-demand"}},{"id":"c0ba14fc-089b-5939-abc8-083252a26606","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\nimport Hamlet from \"./Hamlet.webp\";\nimport Graph from \"./Graph1.webp\";\nimport Bucket from \"./Graph2.webp\";\nimport SMI from \"./SMI-demo.webp\";\nimport SMP from \"./SMP.webp\";\nimport Abstractions from \"./abstractions.webp\";\nimport Journey from \"./cloud-native-journey.webp\";\nimport Flowchart from \"./flowchart.webp\";\nimport { Link } from \"gatsby\";\n\n\n<BlogWrapper>\n\n<div className=\"intro \">\n\n     <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovator, product and technology leader, active in the community as a Docker Captain, Cloud Native Ambassador and GSoC, GSoD, and Community Bridge Mentor. In this talk, he walked through service mesh specifications and why they matter in your deployment.\n   How many service mesh specifications do you know? He went through all of them. So, no worries if you're unfamiliar.\n\n</div>   \n\n### Service Mesh Specifications:\n<img src={Abstractions} className=\"slides-left\" align=\"left\" alt=\"abstractions\"/>\n\nAs the ubiquity of service meshes unfolds and they become a commonplace for any cloud native or edge environment, so does the need for vendor and technology-agnostic interfaces to interact with them. The Service Mesh Interface (SMI), the Service Mesh Performance (SMP), and Multi-Vendor Service Mesh Interoperation (Hamlet) are three open specifications solving the challenge of interoperability, workload and performance management between service meshes. \n\nLearn what makes each of them unique and why they are much needed. See each of these three specifications in action as we use Meshery, the open-source service mesh management plane to demonstrate the value and functionality of each service mesh abstraction, and the adherence of these specifications by Istio, Linkerd, Consul and other popular service meshes.\n\n### Cloud native Journey to service meshes:\n\n<img src={Journey} className=\"slides-right\" align=\"right\" alt=\"journey-image\"/>\n\nThe advent of cloud native was the popularization of containers. Thank you Docker! From there, containers took off like wildfire. Turns out you need an orchestrator to wrangle that sprawl. We saw a number of orchestrators come and we still have a number of orchestrators around.\n\nService meshes have become a hot topic in the last few years. They still continue to be, rightfully so, a very powerful piece of technology. ‚ÄúA lot of the power is yet to come from my perspective. For my part, I believe that there is a tomorrow in which data plane intelligence really matters. And matters about how people write cloud native applications.‚Äù, Lee emphasized. Not everyone quite understands the capabilities of meshes as they are promoted and spoken about today. So come along into the journey of service mesh.\n\nThere are a number of service meshes out there. One of the community projects is to track the landscape of all of the meshes there are. There‚Äôs a lot to say about each of them, their architecture, and their working. Why are they made? Who are they focused on? What do they do? When did they come about? Why are some of them not here anymore? Why are we still seeing new ones? A lot of things to go through. You might be interested in any number of the details that the landscape tracks.\n <div className=\"note\">Be Aware, It's Meshy Out There!</div>\n\n### Service Mesh Interface\n<img src={SMI} className=\"slides-left\" align=\"left\" alt=\"smi-image\"/>\n- Its goal and genesis were born inside of Kubernetes.\n- Being a specification that is native to Kubernetes, its focus is on lowest common denominator functionality.\n- The focus on bringing forth APIs that highlight and reinforce the most common use cases that service meshes are being used for currently\n- Leaves space and provides extensibility room for additional APIs to address other service mesh functionality as more people adopt and make use cases well known.\n- There are seven service meshes that claim compatibility with SMI. There's been a community effort, open-source effort to create service mesh conformance tests to assert whether or not a given service mesh is compatible with SMI\n- In order to facilitate those types of tests, you need to have a tool to provision a sample application on those services which will generate load and test whether traffic splitting behaves as expected or works with that service mesh implementation properly.\n- Then you need to be able to collect the results, guarantee the provenance of those results and publish them.\n- As a community, we turned to Meshery as the tool to implement <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link> and we have been working with the individual service meshes to validate their conformance.\n<b>Meshery</b>\n- We work on an open-source project called <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n- Meshery, the cloud native management plane, is the canonical implementation of the service mesh performance.\n- The management planes can do a number of things to help bridge the divide between other back-end systems and service meshes. They also help performance management, configuration management, making sure you are following best practices in your implementations by taking common patterns and applying them to your environment\nLet's take a moment to demo what it looks like to validate conformance in SMI using Meshery.\n\n<img src={Graph} className=\"slides-left\" align=\"left\" alt=\"graph\"/>\n- We need to spin up Meshery locally\n- We use mesheryctl as the command line interface to work with Meshery.\n- We can interact with a number of different service mesh. The service mesh we‚Äôre going to work with today is an Open service mesh (one of those 7 that is compatible with SMI). Let‚Äôs put it to the test.\n- We'll initiate <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link>\n- These tests go and do assertions across these different specifications. We‚Äôre looking at traffic access, traffic splitting, traffic specification. Meshery then collects these results and will eventually be publishing them in combination with the SMI project.\n\n### Service Mesh Performance\n<img src={SMP} className=\"slides-right\" align=\"right\" alt=\"smp-image\"/>\n- Focused on describing and capturing the performance of a service mesh.\n- The overhead of the value is another way of looking at it and characterizing it.\n- Trying to characterize the performance of the infrastructure of a service mesh can be really difficult.\n- Considering the number of variables that you would have to track, how difficult it can be to have repeatable tests, and benchmark your environment, to track your history based on your environment, compare performance between other meshes people need.\n- SMP creates a standard way of capturing the performance of the mesh to help with these issues.\n- It's also the way in which you're configuring your control plan of your service mesh.\n\nYou might be using a client library to do some service mesh functionality. Maybe you're using those in combination with the service mesh. What costs more? What's more efficient? What's more powerful? Maybe you're using web assembly and filters there.\nThese are all open questions that <Link to=\"/projects/cloud-native-performance\">SMP</Link> assists in answering in your environment. You‚Äôd be surprised by some of the results of some tests that we have done and that the community has done in combination with a couple of universities and graduate students.\n\n<b>Performance Test</b>\n\nDemonstration of the implementation of service mesh Performance:\n\n<img src={Flowchart} className=\"slides-left\" align=\"left\" alt=\"flowchart\"/>\n- On the terminal, we have a local deployment of Meshery running. You can also deploy on Kubernetes as well as the vendor Kubernetes platforms like AKS, EKS and GCP or you can use a dockerized container to run Meshery. You can also have your Kubernetes on Docker desktop.\n- We have the Open service mesh deployed.\n- The Meshery UI is exposed at 9081 port. This is the UI which is used to instantiate a Load test.\n- Over here you can see we have 3 load generators fortio, wrk2, nighthawk.\n- All of these load generators have their own set of attributes which they record correctly and each of its attributes have their own significance. We begin with fortio.\n- <img src={Bucket} className=\"slides-right\" align=\"right\" alt=\"graph\"/>\n\n- You can actually download the test results or you can just browse into the Results Tab and see all of the tests which you have run until now.\n- Next, we used nighthawk to generate the load and benchmark the service for the same. Nighthawk is a load generator which is maintained by the Envoy community and is relatively new. It still hasn't got its 1.0 release but right now Nighthawk has sufficient features to compete with different generators which are still in the play. It can generate a gRPC service on its own and it has some more attributes which you can expose using their CLI tools.\n- You can also see that Meshery has the capability to search your environment, see what specifications are being used and what's the load on your Kubernetes.\n- Jump into the results Tab and see how we compare with these results.\n- You can click on the download. You will see that a yaml gets downloaded in which you can browse and see that the start time, load time, the performance latencies, the metrics are being captured.\n\n### Hamlet or Multi-vendor Service Mesh Interoperation\n<img src={Hamlet} className=\"slides-left\" align=\"left\" alt=\"hamlet-image\"/>\n- Focus on service mesh federation\n- Specifies a set of API standards for enabling service mesh federation\n- Hamlet takes on a client-server architecture in which resources and services of one service mesh are discovered, registered and using a common format, information about them is exchanged between different service mesh.\n- Rules around authentication and authorization rules around which Services get exposed and to whom and who can communicate with them and whether or not they can do it securely. These are things that Hamlet addresses.\n- The specification currently consists of two APIs:\n    - **The Federated Resource Discovery API**: API to authenticate and securely distribute resources between federated service meshes.\n    - The **Federated Service Discovery API**: API to discover, reach, authenticate and securely communicate with federated services.\n- Part of the real power is the ability to overcome what are likely to be separate administrative domains. The intention here is to marry up connect two disparate service mesh deployments, those deployments might be of the same type, they might be of two different types.\n\nIn addition to SMI, SMP and Hamlet there has been an emergence of service mesh patterns, by which people are running and operating service meshes. There is a service mesh working group under CNCFs network that is helping identify those patterns of which there's a list right now unbeknownst to you. Reach out, join it, help us work through the 60 patterns that are defined right now. 30 of those are going into an <Link to=\"/learn/service-mesh-books\">O‚ÄôReilly</Link> book called <Link to=\"/learn/service-mesh-books/service-mesh-patterns\">Service Mesh Patterns</Link>.\n\nSomething that isn‚Äôt always obvious to folks is this piece of value that people get from a service mesh and actually from the specifications that we were just mentioning. It is the fact that teams are decoupled when you‚Äôre running a mesh. Developers get to iterate a bit independently of operators, and so do operators get to make changes to implement infrastructure to the way that applications behave independent of developers in the presence of a mesh.  Both of these teams are significantly empowered. Everybody gets a piece of power when they deploy a mesh.\n\n\n_**P.S.: If these topics excite  come and say \"Hi\" on our [Slack Channel](http://slack.layer5.io) and one of us will reach out to you!**_\n\n</BlogWrapper>","frontmatter":{"title":"Service Mesh Specifications and Why They Matter","type":"Blog","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/a66aa/Cover-image.webp 750w,\n/static/f9e70b0d102359852501532eaf88c857/65dd5/Cover-image.webp 1080w,\n/static/f9e70b0d102359852501532eaf88c857/f9724/Cover-image.webp 1366w,\n/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630208333333334}},"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/a66aa/Cover-image.webp 750w,\n/static/f9e70b0d102359852501532eaf88c857/65dd5/Cover-image.webp 1080w,\n/static/f9e70b0d102359852501532eaf88c857/f9724/Cover-image.webp 1366w,\n/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630208333333334}},"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp"}},"fields":{"slug":"/blog/service-mesh/service-mesh-specifications-and-why-they-matter"}},{"id":"2d0498d1-9781-5c5b-a187-6dc25d7c9588","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1GhJH3YF5mBeYX7I7ItEd-EbUmk1cnn3BdK1X230kwII/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\t\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/PBq7mIPnPhM\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n\n</ResourcesWrapper>","frontmatter":{"title":"Working with Meshery Docs and Jekyll","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBYdhghiDMAAAP7qjeX4S8vnJOZ2O8YIJf5D92SY4mvIWq2H5SPwQnrqSs3UrBXFX9Us5D3+HeJD94XG05JPNODc5lErF5oAAA=="},"images":{"fallback":{"src":"/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp","srcSet":"/static/300d26a25901973293e1afa1d7163fd6/06597/docs-jekyll.webp 750w,\n/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5635148042024833}},"extension":"webp","publicURL":"/static/300d26a25901973293e1afa1d7163fd6/docs-jekyll.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBYdhghiDMAAAP7qjeX4S8vnJOZ2O8YIJf5D92SY4mvIWq2H5SPwQnrqSs3UrBXFX9Us5D3+HeJD94XG05JPNODc5lErF5oAAA=="},"images":{"fallback":{"src":"/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp","srcSet":"/static/300d26a25901973293e1afa1d7163fd6/06597/docs-jekyll.webp 750w,\n/static/300d26a25901973293e1afa1d7163fd6/9c287/docs-jekyll.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5635148042024833}},"extension":"webp","publicURL":"/static/300d26a25901973293e1afa1d7163fd6/docs-jekyll.webp"}},"fields":{"slug":"/resources/service-mesh/working-with-meshery-docs-and-jekyll"}},{"id":"f41cb63f-c339-58db-973e-da30450bb41d","body":"import { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/ug6yaYC-Kkw\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"A tutorial on Gatsby","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJQBOgBERqlqFce6cAAP7o3Ul65eSgLy7Q2ysf3QFvMd5MVKk1URuZ5T99a5W2gIXHlxaKa0V27sJ1hwpgAA=="},"images":{"fallback":{"src":"/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp","srcSet":"/static/f33532c7d406b7420907a601674bbd29/a66aa/intro-to-gatsby.webp 750w,\n/static/f33532c7d406b7420907a601674bbd29/65dd5/intro-to-gatsby.webp 1080w,\n/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/f33532c7d406b7420907a601674bbd29/intro-to-gatsby.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIAAABXRUJQVlA4IFYAAACQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJQBOgBERqlqFce6cAAP7o3Ul65eSgLy7Q2ysf3QFvMd5MVKk1URuZ5T99a5W2gIXHlxaKa0V27sJ1hwpgAA=="},"images":{"fallback":{"src":"/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp","srcSet":"/static/f33532c7d406b7420907a601674bbd29/a66aa/intro-to-gatsby.webp 750w,\n/static/f33532c7d406b7420907a601674bbd29/65dd5/intro-to-gatsby.webp 1080w,\n/static/f33532c7d406b7420907a601674bbd29/71d4d/intro-to-gatsby.webp 1280w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/f33532c7d406b7420907a601674bbd29/intro-to-gatsby.webp"}},"fields":{"slug":"/resources/service-mesh/a-tutorial-on-gatsby"}},{"id":"5caef945-2e9e-5ee0-b825-7469d162ed54","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1UOlwFtZ-VJhW4RgQoSI_QOGUQ7OBG8NZDWrFUor7eyY/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/O9UZO5g9BvI\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"A tutorial on contributing to Layer5 and working with Git","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJYwCdMoADCoez2MwSD8qu6AD+v8Ru5d7zz+5taxp3ZMdQ8llnTq1XNwe1lipyKC+76r0IDAiqUgfquExjejLHTZqjZ3BMnjMPVA+EI+6sAA=="},"images":{"fallback":{"src":"/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp","srcSet":"/static/ab5d02560ab6edddd3b05e5b68200986/a66aa/layer5-walkthrough.webp 750w,\n/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5628571428571428}},"extension":"webp","publicURL":"/static/ab5d02560ab6edddd3b05e5b68200986/layer5-walkthrough.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJYwCdMoADCoez2MwSD8qu6AD+v8Ru5d7zz+5taxp3ZMdQ8llnTq1XNwe1lipyKC+76r0IDAiqUgfquExjejLHTZqjZ3BMnjMPVA+EI+6sAA=="},"images":{"fallback":{"src":"/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp","srcSet":"/static/ab5d02560ab6edddd3b05e5b68200986/a66aa/layer5-walkthrough.webp 750w,\n/static/ab5d02560ab6edddd3b05e5b68200986/3ffd3/layer5-walkthrough.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5628571428571428}},"extension":"webp","publicURL":"/static/ab5d02560ab6edddd3b05e5b68200986/layer5-walkthrough.webp"}},"fields":{"slug":"/resources/service-mesh/a-tutorial-on-contributing-to-layer5-and-working-with-git"}},{"id":"d31448ed-6fc6-5cc9-93b8-b594a85596f9","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1LxhzJhUs9-Hc9mwlKVUMlDAVdH-QWLvU1KWxVuRbSHg/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/wK7Q-zbJ3gQ\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to mesheryctl","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJZQCdAC0H3gN1AAD+61LGcyksda4fQX+hcW28PKI7CGviUbngvM3IveJsmXZPBAo3MZ4e3LLHqIAA"},"images":{"fallback":{"src":"/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp","srcSet":"/static/1945732eb52073c7fc259c43a0c566db/a66aa/golang-meshery-ctl.webp 750w,\n/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp 1048w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5620229007633588}},"extension":"webp","publicURL":"/static/1945732eb52073c7fc259c43a0c566db/golang-meshery-ctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJZQCdAC0H3gN1AAD+61LGcyksda4fQX+hcW28PKI7CGviUbngvM3IveJsmXZPBAo3MZ4e3LLHqIAA"},"images":{"fallback":{"src":"/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp","srcSet":"/static/1945732eb52073c7fc259c43a0c566db/a66aa/golang-meshery-ctl.webp 750w,\n/static/1945732eb52073c7fc259c43a0c566db/691d8/golang-meshery-ctl.webp 1048w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5620229007633588}},"extension":"webp","publicURL":"/static/1945732eb52073c7fc259c43a0c566db/golang-meshery-ctl.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-mesheryctl"}},{"id":"4777de98-5714-58fd-abd4-c083b634a2c1","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n      <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1Wc5ALdn-G3fADJ8I6nJlyOGhV2XHVprYPqDvkZ1MEqY/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n      <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/67iy2JEp4Ss\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"An Introduction to Contributing to Meshery","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC06CG/jydzPs5oAAD+wD9oJE6Ds2QpzakR61Sp/u8yD0QGv6XIODSgXUC7xMLpwAAA"},"images":{"fallback":{"src":"/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp","srcSet":"/static/432b107d65e54188f665be55b8b337a6/06597/intro-to-meshery.webp 750w,\n/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp 1077w","sizes":"100vw"},"sources":[]},"width":1,"height":0.564531104921077}},"extension":"webp","publicURL":"/static/432b107d65e54188f665be55b8b337a6/intro-to-meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC06CG/jydzPs5oAAD+wD9oJE6Ds2QpzakR61Sp/u8yD0QGv6XIODSgXUC7xMLpwAAA"},"images":{"fallback":{"src":"/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp","srcSet":"/static/432b107d65e54188f665be55b8b337a6/06597/intro-to-meshery.webp 750w,\n/static/432b107d65e54188f665be55b8b337a6/662e4/intro-to-meshery.webp 1077w","sizes":"100vw"},"sources":[]},"width":1,"height":0.564531104921077}},"extension":"webp","publicURL":"/static/432b107d65e54188f665be55b8b337a6/intro-to-meshery.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-contributing-to-meshery"}},{"id":"c6c57869-97d1-5f78-be36-41f667cce46e","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\nimport  Button  from  \"../../../reusecore/Button\";\n\n<ResourcesWrapper> \n\n<h3> Tutorial Recording </h3>\n<iframe className=\"iframe\" src=\"https://www.youtube.com/embed/Yu03slXrdS0\" loading=\"lazy\"\nframeBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n</iframe>\n<div className=\"Tutorial-btn\"> \n<Button $primary $url=\"/community/handbook/repository-overview\"> Check out the Layer5 Repository Overview </Button>\n</div>\n     \n</ResourcesWrapper>","frontmatter":{"title":"An introduction to all Layer5 repositories","type":"Tutorial","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCw7CDPyd2ZWd1AAAD+2OvxSMgUO+0MRh6/2bKOqsB8FxmVvDD/qBbE5KbzSZT7gAAA"},"images":{"fallback":{"src":"/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp","srcSet":"/static/98ef543ae405ef027a56c28ec8427b54/06597/all-repos-layer5.webp 750w,\n/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp 869w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5638665132336018}},"extension":"webp","publicURL":"/static/98ef543ae405ef027a56c28ec8427b54/all-repos-layer5.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlgAAABXRUJQVlA4IEwAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCw7CDPyd2ZWd1AAAD+2OvxSMgUO+0MRh6/2bKOqsB8FxmVvDD/qBbE5KbzSZT7gAAA"},"images":{"fallback":{"src":"/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp","srcSet":"/static/98ef543ae405ef027a56c28ec8427b54/06597/all-repos-layer5.webp 750w,\n/static/98ef543ae405ef027a56c28ec8427b54/6b02a/all-repos-layer5.webp 869w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5638665132336018}},"extension":"webp","publicURL":"/static/98ef543ae405ef027a56c28ec8427b54/all-repos-layer5.webp"}},"fields":{"slug":"/resources/service-mesh/an-introduction-to-all-layer5-repositories"}},{"id":"a95eeac7-cff2-5552-9cfb-6022352a5104","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n  <h3> Tutorial Recording </h3>\n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/PBq7mIPnPhM\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"Contributing to Meshery API Swagger Documentation","type":"Tutorial","technology":"API","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJYgCdG1/AR9xGRrF+XLDQAADfxWTJdzHtgR8N683kc2UdZ6vV/0sOQq+WHV9n4K+L13fp8HYPjJsleFUPx/qv99ZbNgykEeoAAA=="},"images":{"fallback":{"src":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp","srcSet":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.375}},"extension":"webp","publicURL":"/static/c8545d2914fb7562526089838dae61f7/swagger-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRm4AAABXRUJQVlA4IGIAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJYgCdG1/AR9xGRrF+XLDQAADfxWTJdzHtgR8N683kc2UdZ6vV/0sOQq+WHV9n4K+L13fp8HYPjJsleFUPx/qv99ZbNgykEeoAAA=="},"images":{"fallback":{"src":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp","srcSet":"/static/c8545d2914fb7562526089838dae61f7/3ec5c/swagger-logo.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.375}},"extension":"webp","publicURL":"/static/c8545d2914fb7562526089838dae61f7/swagger-logo.webp"}},"fields":{"slug":"/resources/service-mesh/contributing-to-meshery-api-swagger-documentation"}},{"id":"d75ad6d8-6aa9-583d-ad25-0b5257a08e44","body":"\nimport { ResourcesWrapper } from \"../Resources.style.js\";\n\n<ResourcesWrapper> \n   <h3> Tutorial Slides </h3>\n        <iframe\t src=\"https://docs.google.com/presentation/d/1oUzWQpFeFbpIs_sejtOPbF9J4nigj9ziEAzoWxmm6ig/embed?start=false&loop=false&delayms=3000\" loading=\"lazy\"\n              frameBorder=\"0\" allowFullScreen width=\"100%\" height=\"500\">\t\n        </iframe>\n   <h3> Tutorial Recording </h3>   \n        <iframe className=\"iframe\" src=\"https://www.youtube.com/embed/hh_kFLZx3G4\" loading=\"lazy\"\n              frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowFullScreen width=\"100%\" height=\"500\">\n        </iframe>\n</ResourcesWrapper>","frontmatter":{"title":"Beginner's guide to contributing to Meshery and mesheryctl","type":"Tutorial","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCdAC0H3spAAP7rq+An2RQM+dpPwh6NSaGNe898ZYovCl1/zVRMex7R7x0znKTQAA=="},"images":{"fallback":{"src":"/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp","srcSet":"/static/57826452d610ee6c68a56e9dcfccdef2/b9516/intro-meshery-ctl.webp 750w,\n/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5616045845272206}},"extension":"webp","publicURL":"/static/57826452d610ee6c68a56e9dcfccdef2/intro-meshery-ctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZQCdAC0H3spAAP7rq+An2RQM+dpPwh6NSaGNe898ZYovCl1/zVRMex7R7x0znKTQAA=="},"images":{"fallback":{"src":"/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp","srcSet":"/static/57826452d610ee6c68a56e9dcfccdef2/b9516/intro-meshery-ctl.webp 750w,\n/static/57826452d610ee6c68a56e9dcfccdef2/ae92c/intro-meshery-ctl.webp 1047w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5616045845272206}},"extension":"webp","publicURL":"/static/57826452d610ee6c68a56e9dcfccdef2/intro-meshery-ctl.webp"}},"fields":{"slug":"/resources/service-mesh/beginners-guide-to-contributing-to-meshery-and-mesheryctl"}},{"id":"f3698102-848c-561d-bb18-e29be1e80e1f","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport MesheryOperatorShot from \"./meshery-operator-v0.5.0.webp\";\nimport MesheryOperator from \"./meshery-operator-dark.svg\";\nimport MeshSync from \"./meshsync.svg\";\nimport MesheryDB from \"./meshery-database.svg\";\nimport MesheryAdapterLibrary from \"./meshery-adapter-library.svg\";\nimport Traefik from \"./traefik-mesh.svg\";\nimport MesheryExtensibility from \"./meshery-extensibility.svg\";\nimport NGINXSM from \"./nginx-service-mesh.svg\";\nimport layer5Logo from \"../../../../assets/images/layer5/layer5-only/svg/layer5-no-trim.svg\";\n\n<BlogWrapper>\n\n<strong>We're pleased to announce the release of Meshery 0.5.0!</strong>  \nConsisting of several significant architectural enhancements ‚Äî with eight new capabilities entering alpha ‚Äî Meshery v0.5.0 delivers an impressive amount of functionality.\n\nPreviewed in the <i>Using Istio</i> workshop delivered at the  \n<Link to=\"/community/events/istiocon-2021\">inaugural IstioCon 2021</Link>, Meshery v0.5.0 lays a strong foundational architecture for cloud-native application and service mesh management.\n\n## Feature Highlights\n\n- New GraphQL API  \n- Meshery Operator with MeshSync inside  \n- Meshery Adapter for Traefik Mesh (beta)  \n- MeshKit and the Meshery Adapter Library  \n- Meshery Adapter for NGINX Service Mesh (alpha)  \n- Meshery Remote Provider extensions with dynamic injection  \n- New Meshery CLI commands to manage multiple Meshery deployments  \n\n<div\n  className=\"intro\"\n  style={{\n    textAlign: \"center\",\n    display: \"flex\",\n    flexDirection: \"row\",\n    flexWrap: \"wrap\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: \"2rem\"\n  }}\n>\n  <img\n    src={layer5Logo}\n    alt=\"Layer5 logo\"\n    style={{ maxHeight: \"55px\", margin: \"auto\", padding: \".5rem\" }}\n  />\n  <p style={{ flexBasis: \"50%\", width: \"100%\", margin: 0 }}>\n    Thank you to the wonderful Layer5 community of open source contributors for\n    making this significant release possible.\n  </p>\n</div>\n\n## New Service Mesh Support\n\n<span className=\"bigfirstletter\">2</span> new Meshery service mesh adapters are bundled in this release:  \nThe Meshery Adapter for Traefik Mesh and the Meshery Adapter for NGINX Service Mesh.\n\n---\n\n### Meshery Adapter for Traefik Mesh (beta)\n\n<img\n  src={Traefik}\n  alt=\"Traefik Mesh logo\"\n  style={{ float: \"left\", maxWidth: \"300px\", width: \"80%\", padding: \"1.25rem\" }}\n/>\n\nTraefik Mesh is a lightweight, non-invasive service mesh offering visibility and traffic management inside Kubernetes clusters.\n\nMeshery supports the lifecycle and performance management of Traefik Mesh, including multiple versions and bundled operations for Book Info and HttpBin sample applications.\n\nReview the  \n<a href=\"https://docs.meshery.io/guides/sample-apps\">sample application guides</a>  \nand learn more about the beta adapter for  \n<a href=\"https://docs.meshery.io/service-meshes\">Traefik Mesh</a>.\n\n---\n\n### Meshery Adapter for NGINX Service Mesh (alpha)\n\n<img\n  src={NGINXSM}\n  alt=\"NGINX Service Mesh logo\"\n  style={{ float: \"left\", maxWidth: \"200px\", padding: \"1.25rem\", marginRight: \"1.5rem\" }}\n/>\n\nNGINX Service Mesh (NSM) is powered by NGINX Plus and provides lightweight traffic management in Kubernetes.\n\nMeshery supports NSM lifecycle and performance management with bundled sample applications:\n\n<ul>\n  <li>Book Info</li>\n  <li>HTTPBin</li>\n  <li>Emojivoto</li>\n</ul>\n\nLearn more in the  \n<a href=\"https://docs.meshery.io/guides/sample-apps\">sample application guides</a>  \nand review the  \n<a href=\"https://docs.meshery.io/service-meshes\">NGINX Service Mesh adapter</a>.\n\n---\n\n## Integrating with Meshery: Using Extension Points\n\nMeshery is an extensible cloud-native management platform offering a variety of extension points that let integrators augment or modify its behavior.\n\n<div className=\"img-center\">\n  <a href={MesheryExtensibility} style={{ backgroundColor: \"transparent\" }}>\n    <img src={MesheryExtensibility} alt=\"Meshery extensibility diagram\" />\n  </a>\n</div>\n\n### Types of Extension Points\n\n- **Extensible Service Mesh Adapters** ‚Äî bring your own service mesh  \n- **Extensible APIs** ‚Äî plug in custom GraphQL resolvers  \n- **Extensible Load Generators** ‚Äî or bring your own  \n- **Extensible Providers** ‚Äî dynamic injection of remote extensions  \n\nProviders (local and remote) support:\n\n- Pluggable UI  \n- Pluggable backend  \n- Custom authN/authZ  \n- Long-term persistence  \n- Enhanced visualization  \n- Historical reporting  \n\nExplore Meshery extensibility at:  \n<a href=\"https://docs.meshery.io/extensibility\">docs.meshery.io/extensibility</a>\n\n---\n\n## MeshKit and Meshery Adapter Library\n\nMeshKit provides common models, abstractions, error handling, and utilities for Meshery and its components.\n\n### Meshery Adapter Library\n\n<div className=\"img-center\">\n  <a href={MesheryAdapterLibrary}>\n    <img src={MesheryAdapterLibrary} alt=\"Meshery Adapter Library diagram\" />\n  </a>\n</div>\n\n- Supplies common interfaces and default implementations  \n- Includes a mini-framework for building gRPC adapter servers  \n- Uses Viper-based configuration providers, which users may override  \n\nRead  \n<Link to=\"/community/members/michael-gfeller\">Michael Gfeller</Link>'s intro post:  \n<Link to=\"/blog/meshery/introducing-meshkit-and-the-meshery-adapter-library\">\n  Introducing MeshKit and the Meshery Adapter Library\n</Link>\n\n---\n\n## Meshery Operator\n\n<img\n  src={MesheryOperator}\n  alt=\"Meshery Operator diagram\"\n  style={{ float: \"left\", maxWidth: \"300px\", width: \"20%\", padding: \"1.25rem\" }}\n/>\n\nMeshery Operator is a Kubernetes-native controller providing cluster discovery, service catalog discovery, and NATS-based data streaming.\n\n<div style={{ display: \"flex\", width: \"100%\" }}>\n  <div style={{ textAlign: \"center\", flex: \"50%\" }}>\n    <a href={MesheryOperatorShot} style={{ backgroundColor: \"transparent\" }}>\n      <img src={MesheryOperatorShot} alt=\"Meshery Operator UI\" style={{ width: \"100%\" }} />\n    </a>\n  </div>\n\n  <ul style={{ flex: \"50%\" }}>\n    <li>Defines the MeshSync and Meshery Broker (NATS) custom resources</li>\n    <li>Provides cluster discovery and service catalog synchronization</li>\n    <li>Streams data throughout Meshery's components</li>\n  </ul>\n</div>\n\n---\n\n## MeshSync\n\n<div style={{ display: \"flex\" }}>\n  <img\n    src={MeshSync}\n    alt=\"MeshSync diagram\"\n    style={{ maxWidth: \"300px\", width: \"20%\", padding: \"1.25rem\" }}\n  />\n\n  <ul>\n    <li>\n      <a href=\"https://docs.meshery.io/concepts/architecture/meshsync\">\n        MeshSync is the heartbeat of Meshery\n      </a>\n      , synchronizing cluster and cloud state.\n    </li>\n    <li>Enables cloud-agnostic object modeling</li>\n    <li>Detects existing services and workloads and maintains an in-memory snapshot</li>\n    <li>Improves resilience across Meshery operations</li>\n  </ul>\n</div>\n\n---\n\n## Relational Database\n\nMeshery‚Äôs  \n<a href=\"https://docs.meshery.io/concepts/architecture/database\">relational database</a>  \nstores MeshSync data, preferences, and system settings. It serves as an ephemeral cache.\n\n<div className=\"img-center\">\n  <a href={MesheryDB}>\n    <img src={MesheryDB} alt=\"Meshery database diagram\" />\n  </a>\n</div>\n\nLearn more or contribute at  \n<a href=\"https://github.com/layer5io/meshsync\">github.com/layer5io/meshsync</a>.\n\n---\n\n## GraphQL Support\n\nMeshery now exposes GraphQL between the UI and Meshery Server, enabling clients to request exactly the data they need. Extension points allow custom resolvers and schema additions.\n\n---\n\n## Meshery CLI Enhancements\n\nThe beloved `mesheryctl` introduces:\n\n- `context` ‚Äî manage multiple Meshery deployments  \n- `channel` ‚Äî subscribe deployments to stable or edge release channels  \n\n### Managing Multiple Deployments\n\nMeshery now uses a `meshconfig` file describing multiple contexts across Docker hosts and Kubernetes clusters. Use:\n\n- `mesheryctl system context`\n\n\nto switch deployments instantly.\n\n### Subscribing to Release Channels\n\n`mesheryctl system channel` lets you choose the release channel for each deployment, enable or disable auto-updates, or pin versions manually.\n\nReview all commands at the  \n<a href=\"https://docs.meshery.io/reference/mesheryctl\">mesheryctl Command Reference</a>.\n\n---\n\n## On to v0.6.0\n\nReview the full list of enhancements in the  \n[Meshery Documentation](https://docs.meshery.io/).\n\nPlanning for v0.6.0 is complete, and the community's innovation cycle shows no sign of slowing down.\n\nSee the  \n<a href=\"https://github.com/layer5io/meshery/blob/master/ROADMAP.md\">Meshery roadmap</a>.\n\n---\n\n<div className=\"intro\">\n  If these topics excite you, come say ‚ÄúHi‚Äù in the community\n  <a href=\"http://slack.layer5.io\"> Slack</a> ‚Äî you‚Äôll be warmly welcomed. üòÄ\n</div>\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing Meshery v0.5.0","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwC7AB6PNYoAAP7ZPPBqgHk9L8Rq4LOZeWzq4QQEHi3NCBc96JkEWIAAAA=="},"images":{"fallback":{"src":"/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp","srcSet":"/static/8817162db307ec6582ad1a1f5aa71201/ee7ce/v0.5.0.webp 750w,\n/static/8817162db307ec6582ad1a1f5aa71201/819dc/v0.5.0.webp 1080w,\n/static/8817162db307ec6582ad1a1f5aa71201/7b8ce/v0.5.0.webp 1366w,\n/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/8817162db307ec6582ad1a1f5aa71201/v0.5.0.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwC7AB6PNYoAAP7ZPPBqgHk9L8Rq4LOZeWzq4QQEHi3NCBc96JkEWIAAAA=="},"images":{"fallback":{"src":"/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp","srcSet":"/static/8817162db307ec6582ad1a1f5aa71201/ee7ce/v0.5.0.webp 750w,\n/static/8817162db307ec6582ad1a1f5aa71201/819dc/v0.5.0.webp 1080w,\n/static/8817162db307ec6582ad1a1f5aa71201/7b8ce/v0.5.0.webp 1366w,\n/static/8817162db307ec6582ad1a1f5aa71201/1ff2c/v0.5.0.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5}},"extension":"webp","publicURL":"/static/8817162db307ec6582ad1a1f5aa71201/v0.5.0.webp"}},"fields":{"slug":"/blog/announcements/announcing-meshery-v050"}},{"id":"6d660fe4-6dc6-5b5a-80b1-ea41cc92dfff","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { MeshkitMesheryAdapterLib } from \"./MeshkitMesheryAdapterLib.style\";\nimport { Link } from \"gatsby\";\n\nimport mesheryAdapterLibrary from \"./meshery-adapter-library.svg\";\nimport malOverview from \"./meshery-adapter-library-overview.webp\";\n\n<BlogWrapper>\n<MeshkitMesheryAdapterLib>\n\n<div className=\"intro\">The Meshery v0.5.0 release includes two new libraries: <span>MeshKit</span> and <span>Meshery Adapter Library</span>.</div>\n\nThese two libraries improve contributor experience and development speed by reducing the burden of sustaining the plethora of Meshery adapters, allowing contributors to focus on exposing any given infrastructure component's differentiated value,\ninstead of having to redundantly implement plumbing for managing cloud native infrastructure.\n\n\n## MeshKit\n\nMeshKit was formerly named `gokit` and was renamed recently to align with the other Meshery components' names (and avoid confusion with the `go-kit` project). MeshKit can be considered a derivative of `go-kit` with specific focus on cloud native management.\n\nIn the Meshery v0.5.0 release, MeshKit has been enhanced and expanded substantially. Considering that the MeshKit library provides broadly useful functionality, it is used in a growing number of Meshery components. It is intended to be one of the top level libraries in the Meshery ecosystem. <div className=\"fact\">Meshkit provides functionality useful across all Meshery components.</div>\n\nMeshKit is a toolkit for Layer5‚Äôs microservices, and is positioned to become Layer5‚Äôs middleware component for Layer5‚Äôs microservices, leveraging other libraries like `go-kit/kit`. In complement to functionality provided by any given cloud native infrastructure component, its purpose is to provide implementations for common cross-cutting concerns like error handling, logging, and tracing. Uniform error handling and logging across all Meshery components helps to implement efficient tooling for observability, monitoring and troubleshooting. The library provides some common data models for Meshery and Meshery's <a href=\"https://meshery.io/extensions\">ecosystem of extensions</a>.\n\nAnother central component in Meshkit is the `utils` package.\n\nThis package provides a Kubernetes and a Helm client that implements functionality based on the Go libraries of these tools. The API exposed by these libraries is quite low-level, and the higher-level functions of the `utils` package simplifies usage of Kubernetes and Helm clients significantly.\nAnother advantage MeshKit that it is not necessary to use the command line versions of these tools, providing a more tailored experience for developers,\nand better logging and error handling integration.\n\n<Link to=\"https://github.com/layer5io/meshkit\">MeshKit</Link> is simple and straight\nforward to use, as the following code example illustrates.{\" \"}\n\n```go\npackage main\n\nimport (\n\t\"os\"\n\n\tmeshkitlogger \"github.com/layer5io/meshkit/logger\"\n\tmeshkitkubernetes \"github.com/layer5io/meshkit/utils/kubernetes\"\n\t\"k8s.io/client-go/kubernetes\"\n)\n\nfunc main() {\n\t// nginx contains the deployment manifest for nginx.\n\tnginx := `apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2 # tells deployment to run 2 pods matching the template\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n`\n\n\t// Create an instance of the meshkit logger handler.\n\tlog, err := meshkitlogger.New(\"ExampleApp\",\n\t\tmeshkitlogger.Options{Format: meshkitlogger.JsonLogFormat, DebugLevel: false})\n\tif err != nil {\n\t\tos.Exit(1)\n\t}\n\tlog.Info(\"successfully instantiated meshkit logger\")\n\n\t// Detect kubeconfig on the local system.\n\tconfig, err := meshkitkubernetes.DetectKubeConfig()\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\tlog.Info(config.Host)\n\n\t// Create Kubernetes client set for the detected kubeconfig using the Kubernetes Go client library.\n\tclientset, err := kubernetes.NewForConfig(config)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\n\t// Create an instance of the meshkit Kubernetes client ...\n\tclient, err := meshkitkubernetes.New(clientset, *config)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\tos.Exit(1)\n\t}\n\n\t// ... and use it to deploy nginx to the cluster.\n\terr2 := client.ApplyManifest([]byte(nginx), meshkitkubernetes.ApplyOptions{\n\t\tNamespace: \"default\",\n\t\tUpdate:    true,\n\t\tDelete:    false,\n\t})\n\tif err2 != nil {\n\t\tlog.Error(err2)\n\t\tos.Exit(1)\n\t}\n\tlog.Info(\"successfully applied the manifest\")\n}\n```\n\n## Meshery Adapters\n\nMeshery adapters are management plane components and manage the lifecycle of cloud native infra. This includes installation and deletion, configuration, and verification that an installation follows recommended practices. As example use of Meshery adapters is for purposes of compliance verification, actively attesting whether whether infrastructure complies to an open standard, like that of <Link to=\"/blog/announcements/a-standard-interface-for-service-meshes\">Service Mesh Interface</Link>. Meshery adapters support management of multiple versions of their respective capabilites and also come bundled with sample applications that can be deployed for easy and quick exploration of infrastructure (or other) capabilities. <div className=\"fact\">Meshery adapters extend Meshery's core functionality housed within Meshery Server, often deepening Meshery's ability to manage the lifecycle infratructure, but not limited to those use cases. Adapters have been known to act as engineering workflow facilititors, providing gate reviews, sending emails, and so on.</div>\n\nA Meshery adapter is a gRPC server that exposes the `MeshServiceServer` interface:\n\n```go\n// MeshServiceServer is the server API for MeshService service.\ntype MeshServiceServer interface {\n\tCreateMeshInstance(context.Context, *CreateMeshInstanceRequest) (*CreateMeshInstanceResponse, error)\n\tMeshName(context.Context, *MeshNameRequest) (*MeshNameResponse, error)\n\tApplyOperation(context.Context, *ApplyRuleRequest) (*ApplyRuleResponse, error)\n\tSupportedOperations(context.Context, *SupportedOperationsRequest) (*SupportedOperationsResponse, error)\n\tStreamEvents(*EventsRequest, MeshService_StreamEventsServer) error\n}\n```\n\n- `CreateInstance` sets up the Kubernetes client. It does not, as the name might imply, create an instance of an infrastructure component.\n- `Name` returns the name of the infrastructure component, configured in the adapter.\n- `SupportedOperations` returns all supported operations, configured in the adapter. An operation is e.g. the installation of any given cloud native infrastructure component or service.\n- `ApplyOperation` executes the operation specified in the request. It is one of the supported operations.\n- `StreamEvents` allows sending events from the server to the client.\n\nThis API is one of the extension points of Meshery, making it easy to add support for new cloud native technologies to Meshery. Meshery adapters abstract away differences in installation and configuration of the various technologies. Various cloud native technologies are installed and configured in their own way. For instance, some projects have their own installer, like `istioctl` for Istio, while others use Helm charts, like Consul. One of the purposes of Meshery adapters is to abstract these differences away. <div className=\"fact\">It's important to note, however, that Meshery Adapters allow Meshery to interface with each managed system uniquely, and not treat those systems uniformly by only offering the lowest common denominator of functionality, but instead by exposing that system's differentiated value to users.</div>\n\n\n\n## Meshery Adapter Library\n\nAs can be expected, adapters for the various meshes have a lot of code in common. Initially, this common code was copied from one adapter implementation to the next. The question arose whether common code should be factored out to one or several libraries. After some discussion, the community decided to move some of the more general code to Meshkit, and adapter specific code to a new library.\n\nThus, the Meshery Adapter Library was born.\n\nIt reduces the amount of boilerplate code in the adapters substantially, making adapter code easier to follow. This is especially valuable in an open source community where typically many developers contribute, for varying amounts of time. For the same reasons, it is important such libraries are easily understandable.\n\nAlso, it means new adapters can be implemented quickly, as only configuration and operations that differ between services meshes need to be implemented.\n\n<div className=\"fact\">\n  The Meshery Adapter Library provides a common and consistent set of\n  functionality that Meshery adapters use for managing the lifecycle of\n  cloud infrastructure and their workloads.\n</div>\n\nThe initial commit was submitted on October 6th, 2020 based on a refactoring effort in the adapter for the Kuma service mesh. Within a few months, several adapters have been refactored or implemented from scratch based on the Meshery Adapter Library.\n\nThe main purpose of the Meshery Adapter Library is to:\n\n- provide a set of interfaces, some with default implementations, to be used and extended by adapters.\n- implement cross-cutting concerns like logging, error handling, and tracing.\n- provide a mini framework implementing the gRPC server that allows plugging in the mesh specific configuration and operations implemented in the adapters.\n\nThe core interface in the library is the adapter `Handler` interface:\n\n```go\n// Interface Handler is extended by adapters, and used in package api/grpc that implements the MeshServiceServer.\ntype Handler interface {\n\t// GetName returns the name of the adapter.\n\tGetName() string\n\t// CreateInstance instantiates clients used in deploying and managing mesh instances, e.g. Kubernetes clients.\n\tCreateInstance([]byte, string, *chan interface{}) error\n\t// ApplyOperation applies an adapter operation. This is adapter specific and needs to be implemented by each adapter.\n\tApplyOperation(context.Context, OperationRequest) error\n\t// ListOperations list all operations an adapter supports.\n\tListOperations() (Operations, error)\n\n\t// Need not implement this method and can be reused\n\tStreamErr(*Event, error) // Streams an error event, e.g. to a channel\n\tStreamInfo(*Event)       // Streams an informational event, e.g. to a channel\n}\n```\n\nIt corresponds closely to the gRPC API discussed above, and indeed these methods are called in the implementation of the `MeshServiceServer` interface. This implementation is also part of the Meshery Adapter Library.\n\nUsing `struct` embedding, an adapter extends the default implementation `Adapter` of the interface `Handler` from the library.\nUsually, it is sufficient that this adapter handler overrides only the `ApplyOperation` function from the default implementation.\n(There, it is a no-op implementation.)\n\nThe figure below illustrates this and the usage of the library in an adapter.\n\n<img\n  src={mesheryAdapterLibrary}\n  className=\"image-center\"\n  alt=\"meshery adapter library\"\n/>\n\nIn the `main` package of the adapter, the default configuration provider `Viper` from the library is instantiated, and reads the adapter specific configuration. This includes a specification of all available operations. As configuration providers are implementations of an interface, you can choose any of the providers from the library, or implement your own.\n\nNext, an instance of the adapter handler is created. Other components, for instance a logger, may be created depending on needs and requirements, which is symbolize by the three dots in the figure.\n\nThe `service` is a struct that holds all the parameters that specify an adapter service, like the port the gRPC server is running on, and the instance of the adapter handler created in a previous step. This struct is passed to the `Start` function from the library. This `Start` function wraps the gRPC server, wiring up all necessary components, and starts the service. The developer does not need to touch any gRPC code.\n\n### Conclusion\n\nExtracting common code from adapters to the two new libraries has proven to be a worthwhile investment. It led to cleaner code as well as cleaner application architecture, shortened implementation time for new adapters considerably, and upleveled the quality of Meshery's adapters through consistency of implementation.\n\n\n<div className=\"intro\">P.S. If these topics excite you and you want to explore the beautiful realm of cloud native infrastructure, come and say \"Hi\" on the community <Link to=\"http://slack.layer5.io\">Slack</Link> and you are sure to be warmly welcomed. <span>üòÄ</span></div>\n\n</MeshkitMesheryAdapterLib>\n</BlogWrapper>\n","frontmatter":{"title":"Introducing Meshkit and the Meshery Adapter Library","type":"Blog","technology":"API","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIAAABXRUJQVlA4IEYAAABQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZwC06BuZNpYBQAD+y8x8Y+HSd5zjXtkB1x+V98O5YQD2dH+igeMC9cNeLgAA"},"images":{"fallback":{"src":"/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp","srcSet":"/static/f6d05b0291faa22eb65720f319dae9e8/b9516/meshery-adapter-library-overview.webp 750w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a327/meshery-adapter-library-overview.webp 1080w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a401/meshery-adapter-library-overview.webp 1366w,\n/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5614583333333334}},"extension":"webp","publicURL":"/static/f6d05b0291faa22eb65720f319dae9e8/meshery-adapter-library-overview.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIAAABXRUJQVlA4IEYAAABQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZwC06BuZNpYBQAD+y8x8Y+HSd5zjXtkB1x+V98O5YQD2dH+igeMC9cNeLgAA"},"images":{"fallback":{"src":"/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp","srcSet":"/static/f6d05b0291faa22eb65720f319dae9e8/b9516/meshery-adapter-library-overview.webp 750w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a327/meshery-adapter-library-overview.webp 1080w,\n/static/f6d05b0291faa22eb65720f319dae9e8/2a401/meshery-adapter-library-overview.webp 1366w,\n/static/f6d05b0291faa22eb65720f319dae9e8/3a03f/meshery-adapter-library-overview.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5614583333333334}},"extension":"webp","publicURL":"/static/f6d05b0291faa22eb65720f319dae9e8/meshery-adapter-library-overview.webp"}},"fields":{"slug":"/blog/meshery/introducing-meshkit-and-the-meshery-adapter-library"}},{"id":"f0be9d0b-f557-56b6-9f99-b2d28864d4ab","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport bestPracticesSelectingElementsImg from './best-practices-selecting-elements.webp';\nimport cypressTestRunnerImg from './cypress-test-runner.webp';\n\n<BlogWrapper>\n\n<a href=\"https://www.cypress.io\" rel=\"nofollow\">Cypress</a> is the functional test tool used in development of Meshery UI. As a reliably test tool, Cypress  works with <i>ReactJS</i>, <i>VueJS</i>, <i>AngularJS</i> and so on; it is agnostic of the framework you use. You can write all types of tests: <i>end-to-end</i>, <i>integration</i>, and <i>unit tests</i>.\n\nTests allow you to ensure that the new code do not break the current one. They help you to develop and integrate new features faster and ensure everything will work after including your changes. The more tests you have, the more coverage you will have (and less likelihood of issues in production).\n\n### UI tests in Meshery\n\nMeshery has two web projects:\n\n- <b>provider-ui:</b> A <i>ReactJS</i> app that allows you to select the Provider to be used for Meshery\n- <b>ui:</b> Also a <i>ReactJS</i> app where you can do everything related with Meshery. It is the cloud native management plane.\n\nWe create UI tests for both projects using Cypress. Also, we write two types of UI tests at the moment:\n- <b>Integration:</b> Test a specific functionality without backend communication (mocking requests and responses)\n- <b>End-to-end:</b> Test a whole flow like setting up Linkerd Service Mesh or running a SMI Performance Test sending requests and validating the responses from the back-end\n\n### How to write UI tests for Meshery\n\nIf you are writting your first test, you can read and watch the <b><u><a href=\"https://docs.cypress.io/guides/getting-started/writing-your-first-test.html\">great getting started</a></u></b> from Cypress blog.\n\nThen, you have to add your test below `\"provider-ui/cypress/integration\"` or `\"ui/cypress/integration\"` folders (do not forget adding <i>_spec</i> in the filename).\n\nHere is a basic example of a test validating that <b>Provider UI component</b> exists:\n\n```javascript\ndescribe('Provider UI', () => {\n  it('renders provider component', () => {\n    cy\n      .get('[data-cy=root]')\n      .should('exist')\n  })\n})\n```\n\nPlease follow the <b><u><a href=\"https://docs.cypress.io/guides/references/best-practices.html\">best practices recommended</a></u></b> by Cypress.\nOne of the most important is to use or add the `\"data-cy\"` attribute to the element you want to interact to:\n\n<img src={bestPracticesSelectingElementsImg} className=\"image-center\" alt=\"Best Practices selecting elements with Cypress\" />\n<div style={{ textAlign: \"center\" }}>Best Practices Selecting Elements</div>\n### Run your test!\n\nOnce you have written your test, it is time to execute it locally:\n\n1. First, you have to run the back-end executing this command at the root project folder:\n\n```bash\n$ make run-local\n```\n\n2. Then, run the front-end project (i.e. provider-ui)\n\n```bash\n$ make run-provider-ui-dev\n```\n\n3. Finally, in `\"provider-ui\"` folder, run all the tests with:\n\n```bash\n$ npm run cy:run\n```\n\nIf everything went well, you will see <b>\"All specs passed!\"</b> message. Congrats!\n\nYou can also execute, debug and see in real time your test by executing:\n\n```bash\n$ npm run cy:open\n```\n\nthis will open the <b>Cypress Test Runner:</b>\n\n<img src={cypressTestRunnerImg} className=\"image-center\" alt=\"Cypress Test Runner\" />\n<div style={{ textAlign: \"center\" }}>Cypress Test Runner</div>\njust double-click on your test and a window browser will be opened and you will see your testing running!\n\n#### What‚Äôs next?\n\nTo improve writting better tests, I recommend that you watch:\n\n- Watch the <a href=\"https://www.youtube.com/watch?v=pIFSI7xtwFs\" target=\"_blank\" rel=\"nofollow noreferrer\">Meshery Development Meeting (Nov 4th, 2020)</a> where I gave a demo running UI tests on the Meshery project (<a href=\"https://docs.google.com/presentation/d/1QbMEyQgbXMLvvSheAIDruzCFe8SmBrKXUjqP0Hxfqjw\" target=\"_blank\" rel=\"noreferrer\">slides</a>)\n- <a href=\"https://docs.cypress.io/examples/examples/tutorials.html\" rel=\"nofollow noreferrer\" target=\"_blank\">Tutorial Videos</a> from Cypress blog.\n- The <a href=\"https://www.youtube.com/watch?v=5XQOK0v_YRE\" target=\"_blank\" rel=\"nofollow noreferrer\">Brian Mann ‚Äì I see your point, but‚Ä¶ (Part 1)</a> YouTube video where he gives pro tips writting tests in Cypress.\n\nIf you have questions, do not hesitate to ask to the Meshery community on Slack :)\n\nHappy testing!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Functional Testing with Cypress in Meshery UI","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRvwAAABXRUJQVlA4WAoAAAAQAAAAEwAABQAAQUxQSHkAAAAAAEuqoDAAAAAAAAAAAAAAAAAxEQBQ/v//9CkpLBwlJx4dLxU3AD0VObf/////kbOvpWm3t69rnHwCd4Rvtf////+PtK+lFbxsUslLv2CHg3ZK/f//8TCiIhoBICAgIhkpGxcHMgBDoZcqAhAAAAAAAAAAAAAAAAAAAFZQOCBcAAAAEAMAnQEqFAAGAD7RVKNLqCSjIbAIAQAaCWkAAEmNZx2QAP5J9cl7VPwN7XJEL49/xxssqNFXLSgNmwkZGlgr/sTSa2WP3E3Um5txG6RuWRpO/b5FgZ5pqOnIgAA="},"images":{"fallback":{"src":"/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp","srcSet":"/static/b239a146858aacbc01f39092bd992e6e/2b7d2/cypress-logo.webp 750w,\n/static/b239a146858aacbc01f39092bd992e6e/ab31e/cypress-logo.webp 1080w,\n/static/b239a146858aacbc01f39092bd992e6e/53ea9/cypress-logo.webp 1366w,\n/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.2833333333333333}},"extension":"webp","publicURL":"/static/b239a146858aacbc01f39092bd992e6e/cypress-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRvwAAABXRUJQVlA4WAoAAAAQAAAAEwAABQAAQUxQSHkAAAAAAEuqoDAAAAAAAAAAAAAAAAAxEQBQ/v//9CkpLBwlJx4dLxU3AD0VObf/////kbOvpWm3t69rnHwCd4Rvtf////+PtK+lFbxsUslLv2CHg3ZK/f//8TCiIhoBICAgIhkpGxcHMgBDoZcqAhAAAAAAAAAAAAAAAAAAAFZQOCBcAAAAEAMAnQEqFAAGAD7RVKNLqCSjIbAIAQAaCWkAAEmNZx2QAP5J9cl7VPwN7XJEL49/xxssqNFXLSgNmwkZGlgr/sTSa2WP3E3Um5txG6RuWRpO/b5FgZ5pqOnIgAA="},"images":{"fallback":{"src":"/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp","srcSet":"/static/b239a146858aacbc01f39092bd992e6e/2b7d2/cypress-logo.webp 750w,\n/static/b239a146858aacbc01f39092bd992e6e/ab31e/cypress-logo.webp 1080w,\n/static/b239a146858aacbc01f39092bd992e6e/53ea9/cypress-logo.webp 1366w,\n/static/b239a146858aacbc01f39092bd992e6e/35438/cypress-logo.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.2833333333333333}},"extension":"webp","publicURL":"/static/b239a146858aacbc01f39092bd992e6e/cypress-logo.webp"}},"fields":{"slug":"/blog/meshery/functional-testing-with-cypress-in-meshery-ui"}},{"id":"7802e907-ecf2-5e60-93ed-04551ee7687f","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport smpImg from \"./smp.webp\";\n\n<BlogWrapper>\n\n### What is performance benchmarking and why should you care?\n\nMany of you may remember that the HBO streaming service crashed when the final season of the popular sitcom, Game of Thrones went live on the service. Unable to engage all the user requests, the streaming service and the website broke down and ultimately resulted in DoS (Denial of Service). There are numerous examples of service crashes across different platforms, which has forced developers to take a closer look at performance benchmarking and pre-launch performance checks.\n\nThere are several advantages of preliminary service benchmarking, which may extensively enhance the response time, resolve glitches, enhance the application's robustness, and bring together several other commendable factors, including but not limited to stability and dependability within an application.\n\nThere are several tools for performance benchmarking. A major one is the interconnected relationship between load generators and benchmarks. Some of the well-known load generators in the cloud native realm are:\n\n<ul>\n    <li>Fortio</li>\n    <li>Wrk2/Wrk</li>\n    <li><a href=\"/projects/nighthawk\">Nighthawk</a></li>\n</ul>\n\nThe conclusion can be encapsulated as following, Meshery, the cloud native management plane possesses the ability to generate load and benchmark services in/out of your service mesh using Fortio, Wrk2 and now, Nighthawk too.\n\n### Meshery + Nighthawk = Robust Distributed and Scalable Services\n\nNighthawk, written and maintained by the Envoy Community, is a L7 (HTTP/HTTPS/HTTP2) performance characterization tool that supports performance benchmarking using HTTP or gRPC services.\n\nNighthawk is built using open-source builds and test tool Bazel and supports output formatting to well-known formats, allowing integration with other systems and dashboards. To add more to the list, it will soon support distributed performance benchmarking which is currently under an active development stage.\n\nOn the other hand, Meshery, written and maintainer by Layer5 Community is the multi-service mesh management plane offering lifecycle, configuration and performance management of service meshes and their workloads. With Meshery, you can both, manage your service mesh's lifecycle, and benchmark them with industry-grade tools to let you know how much under or over-utilized your services are.\n\n<img src={smpImg} alt=\"smp-image\" className=\"image-left smp-image\"/>\n\nSoon, Meshery is going to be a canonical implementation for [Service Mesh Performance](https://github.com/layer5io/service-mesh-performance) which is a common and standardised format to describe : - Performance test configuration - Service mesh configuration - Environment configuration - Workload configuration - Performance test results.\n\n### How did we achieve it ?\nThe following project was proposed as a Google Summer of Code Idea, I was selected as a student mentee to draft the design, architecture and code my way from scratch. On my journey, I received guidance from some amazing mentors, colleagues and open-source stake holders. I discussed the design proposal with Envoy Team as well as Layer5 Team and from suggestions from both, I was able to complete my project.\n\nIn the course of the project, I came up with the idea of invoking Nighthawk as a separate container with which Meshery will communicate using a go-lang based middleware.\n\nTo my elation, the project was a huge success and Nighthawk is now invoked as a load-generator in Meshery. Soon, the public release for the new version will be made and users will be able to utilize Nighthawk as a performance-benchamark tool alongside with Fortio and Wrk2.\n\n### What's next?\nThis is just the first relay, in the long run, there are many more milestones to come. The following is a list of projects which will be completed in upcoming months:\n\n- Invoke Nighthawk as an gRPC Service and support gRPC connection between Nighthawk & Meshery.\n- Implement user-profiles for performance benchmarking which may store some preset preferred values according to users.\n- Enhance Nighthawk to support distributed load generation and performance benchmarking.\n- NATS & gRPC Performance Benchmarking for gRPC and NATS services invoked in Meshery.\n\nand many more awesome and bleeding-edge ideas.\n\n### How can I get involved?\nIf any of this sounds remotely exciting, I implore you to give this a chance. You won‚Äôt regret it. Head over to our [Slack Channel](http://slack.layer5.io) and join the #performance channel where everything related to performance testing is discussed. We would love to hear your feedback. Stay tuned for more blogs related to Performance Benchmarking, SMI Conformance and all things meshy!!!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Performance benchmarking using Meshery and Nighthawk","type":"Blog","technology":null,"product":"Nighthawk","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp","srcSet":"/static/093f9cfbcb5c36ac072615fe97352342/4a552/mesheryctl.webp 750w,\n/static/093f9cfbcb5c36ac072615fe97352342/571ff/mesheryctl.webp 1080w,\n/static/093f9cfbcb5c36ac072615fe97352342/1866d/mesheryctl.webp 1366w,\n/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/093f9cfbcb5c36ac072615fe97352342/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp","srcSet":"/static/093f9cfbcb5c36ac072615fe97352342/4a552/mesheryctl.webp 750w,\n/static/093f9cfbcb5c36ac072615fe97352342/571ff/mesheryctl.webp 1080w,\n/static/093f9cfbcb5c36ac072615fe97352342/1866d/mesheryctl.webp 1366w,\n/static/093f9cfbcb5c36ac072615fe97352342/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/093f9cfbcb5c36ac072615fe97352342/mesheryctl.webp"}},"fields":{"slug":"/blog/performance/performance-benchmarking-using-meshery-and-nighthawk"}},{"id":"41186fe5-9702-5f79-9115-7013aba6492e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport conformance from \"./conformance-results.webp\";\n\n<BlogWrapper>\n\nReleased on August 5th, 2020 by Microsoft, [Open Service Mesh](https://openservicemesh.io/) (OSM) is a lightweight and [Service Mesh Interace conformant](https://layer5.io/smi) (SMI). Open Service Mesh is a contemporary addition to the [service mesh landscape](/service-mesh-landscape). Using Envoy as its data plane proxy component and SMI specifications as it's control plane APIs, OSM draws lessons and code from existing service mesh projects, like Linkerd. The Open Service Mesh project has some miles to go as it is one of a growing list of choices available in the service mesh landscape.\n\nFirst pronounced to be SMI compliant by [Meshery](https://meshery.io/), the cloud native management plane, the first release of OSM supports a myriad of basic\n\n<ul>\n    <li>Securing service to service links</li>\n    <li>Supporting traffic shifting</li>\n    <li>Managing observability for your services</li>\n    <li>Validating and Implementing access control policies</li>\n    <li>Auto addition of applications and services</li>\n</ul>\n\n### Get started with OSM using Meshery\nIn Layer5's effort to support our multi-mesh world, our Meshery project provides an effortless way for Kubernetes operators to install, maintain and run service meshes. [Meshery v0.4.3](https://github.com/layer5io/meshery/releases/tag/v0.4.3) includes the [Meshery Adapter for Open Service Mesh](https://github.com/layer5io/meshery-osm), enabling you to quickly provision OSM, run any number of sample applications, manage its performance using [Service Mesh Performance](https://smp-spec.io/) (SMP), validate OSM's compliance to SMI using a suite of conformance tests. Meshery offers configuraiton management with builtin best practice configuration analysis giving you confidence in applying custom configuration to OSM. Meshery's documenation on the [Open Service Mesh integation](https://docs.meshery.io/service-meshes/adapters/osm) provides a complete walkthrough on how to get set up, install, deploy and configure OSM according to your needs.\n\n<img src={conformance} className=\"\" alt=\"meshery-smi-conformance-results-image\" />\n\nTry Open Service Mesh now, by [getting started with Meshery](/cloud-native-management/meshery/getting-started).\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing the Meshery Adapter for Open Service Mesh","type":"Blog","technology":null,"product":"Meshery","mesh":"Open Service Mesh","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/280d5/meshery-open-service.webp 750w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/5b49f/meshery-open-service.webp 1080w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f8bdf/meshery-open-service.webp 1366w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5010416666666666}},"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/280d5/meshery-open-service.webp 750w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/5b49f/meshery-open-service.webp 1080w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f8bdf/meshery-open-service.webp 1366w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5010416666666666}},"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp"}},"fields":{"slug":"/blog/service-mesh/announcing-the-meshery-adapter-for-open-service-mesh"}},{"id":"ea2400da-2d3b-59c7-be79-7831ba9fc7fc","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport operator from \"./meshery-operator-dark.svg\";\nimport MesheryArchitecture from \"./meshery-architecture.webp\";\n\n<BlogWrapper>\n\n[Meshery](https://meshery.io) is the cloud native management plane offering lifecycle, configuration and performance management of cloud native infrastructure and their workloads.\n\nLayer5 community members are hard at work providing our users with easy access to any cloud native infrastructureand myriad management features. New releases for Meshery are published on a frequent cadence with new features and bug fixes. Today, we are announcing version 0.4.0 of Meshery. This summary highlights Meshery's latest developments and elucidates new features.\n\n## What's New?\n\nThe v0.4.0 release of Meshery introduces a plethora of new features and bug fixes across cloud native infrastructure environments spanning Meshery and it's various adapters.\n\n### Meshery's CLI: `mesheryctl`\n**New Command Structure**<br/>\n`mesheryctl` commands and subcommands have been restructured in v0.4.0 into the categories:\n- Global Commands and Flags\n- Meshery Lifecycle Management\n- Performance Management\n- Infrastructure Lifecycle Management\n- Workload Lifecycle Management\n\nOrganizing commnands [under these categories](https://docs.meshery.io/reference/mesheryctl) is done with both the intention to make `mesheryctl` functions intuitively at your fingertips, but also to make room for forthcoming functionality.\n\n**Exposing Performance Management in the CLI**<br/>\n`perf:` a new `mesheryctl`command. Introduction of new performance sub-commands, now benchmark your cloud native infrastructure at the tip of your fingers using our new CLI command `perf`.\n\n**Support for Scoop** <br/>\nSupport extended to Scoop Bucket. You can now install mesheryctl on your Windows machine with Scoop Bucket. Visit the [Meshery Scoop Bucket](https://github.com/layer5io/scoop-bucket) to install Meshery on Windows.\n\n**Rename `cleanup` to `reset`**<br/>\nThe `cleanup` is used to reset your Meshery deployment configuration back to its default settings. This command has been renamed to `reset` to more appropriately reflect its purpose.\n\n### MeshSync<br/>\n<img src={operator} className=\"image-right\" alt=\"meshery-operator-dark\" />\n\n-  A component of the [Meshery Operator](https://github.com/layer5io/meshery-operator), MeshSync can scan the environment to get the deployment details of specific types of cloud native infrastructure and the connected Kubernetes cluster.\n-  MeshSync is a new component addition to Meshery. Meshery needs to be constantly updated given that cloud native infrastructure and their underlying infrastructure are dynamic, constantly changing.  Meshery operations should be resilient in the face of this change.\n-  MeshSync brings a infrastructure agnostic object model that defines relationships between all objects under management.\n\n### Meshery Adapter for Citrix Service Mesh (beta)<br/>\n\n<img src={MesheryArchitecture} className=\"image-right\" alt=\"meshery-architecture\" />\n\n- [Citrix Service Mesh](https://github.com/layer5io/meshery-cpx) is now a supported integration. Meshery incorporates support for the Citrix ADC CPX, which is a cloud-ready, container-based application delivery controller that can be provisioned on a Docker host.\n- CPX runs as the Istio Data Plane component, displacing Envoy as the default data plane service proxy.<br/>\n\n### Security & Authentication\n\n- Meshery has moved from using session authentication to JWT authentication. Meshery's JWT authentication is powered by Hydra Auth.\n- You can now opt to authenticate yourself on mesheryctl while performing performance tests using `mesheryctl`, you can authenticate yourself by getting the JWT Token from Meshery UI.\n\n### Meshery Server\n\n- Support provided for [wrk2 as an alternative load generator](https://docs.meshery.io/functionality/performance-management#load-generators).\n- [Providers](https://docs.meshery.io/extensibility) - A new project construct that allows users to select authentication, long-term storage etc.\n- Ad-hoc [connectivity tests for Prometheus and Grafana](https://docs.meshery.io/functionality/performance-management#grafana-and-meshery) are now supported.\n- Extraneous information beyond IP address and port in Grafana and Prometheus endpoints have been stripped off.\n\n### Meshery UI\n\n- ES-Lint has been added to the client side to ensure the quality of code and increase maintainaiblity of code.\n- Cypress has been set-up to enable end-to-end tests and integration tests for Meshery UI.\n\n<center><iframe frameBorder=\"0\" width=\"100%\" height=\"300\" allowfullscreen={true} mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"frameBorder=\"0\" width=\"100%\" height=\"300\" allowfullscreen={true} mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\" src=\"https://www.youtube.com/embed/ds9D2KgZKxo\" loading=\"lazy\"></iframe></center>\n\n\n### Other notable changes\n\n- From within the [Meshery Continuous Integration Working Group](https://www.youtube.com/watch?v=ds9D2KgZKxo&list=PL3A-A6hPO2IM7rYiKxG4l3eQNc6X3IUex), we have strengthened our continuous integration (CI) actions & tests by introducing new workflows like `static check`, `vet check`, `security check` for our server code.\n- ReleaseDrafter & WelcomeBot has been added to the repository to enable automation of release notes and for welcoming new contributors, respectively.\n\nTo get a more comprehensive list of the bug fixes and enhancements packaged in the v0.4.0 release, see the [Meshery Documentation](https://docs.meshery.io/project/releases)\n\n\n_**P.S.: If these topics excite you and you want to explore the beautiful realm of cloud native infrastructure, come and say \"Hi\" on our [Slack Channel](http://slack.layer5.io) and one of us will reach out to you!**_\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing Meshery v0.4.0","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsoAAABXRUJQVlA4WAoAAAAQAAAAEwAADAAAQUxQSGYAAAABgCsAgIHqqtHm5JrcZNvWxqvd2GwbYz1u7yf5ARGR4N+JIZRCqIZQBSQ+aIdJPY+dC3seH6nRZlTtfN27zv5n8B0Vs5jm+2qmdSqD7LBa0lUQRfBdDgvPIlGJVCQJR0JTiTjw/wBWUDggPgAAADADAJ0BKhQADQA+0VakS6gko6GwCAEAGglpAAB60b/b/AAA/vAi9+Ax+ANYXYVXicTSFmjmW1J3l211gAAA"},"images":{"fallback":{"src":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp","srcSet":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp 500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.666}},"extension":"webp","publicURL":"/static/af2d9c15a09697b2ad48556b58102cd8/meshery-v040.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRsoAAABXRUJQVlA4WAoAAAAQAAAAEwAADAAAQUxQSGYAAAABgCsAgIHqqtHm5JrcZNvWxqvd2GwbYz1u7yf5ARGR4N+JIZRCqIZQBSQ+aIdJPY+dC3seH6nRZlTtfN27zv5n8B0Vs5jm+2qmdSqD7LBa0lUQRfBdDgvPIlGJVCQJR0JTiTjw/wBWUDggPgAAADADAJ0BKhQADQA+0VakS6gko6GwCAEAGglpAAB60b/b/AAA/vAi9+Ax+ANYXYVXicTSFmjmW1J3l211gAAA"},"images":{"fallback":{"src":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp","srcSet":"/static/af2d9c15a09697b2ad48556b58102cd8/921bf/meshery-v040.webp 500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.666}},"extension":"webp","publicURL":"/static/af2d9c15a09697b2ad48556b58102cd8/meshery-v040.webp"}},"fields":{"slug":"/blog/announcements/announcing-meshery-v040"}},{"id":"47a58ab5-c67e-52d4-ae1d-1623eeab8aed","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport listioLayer5 from \"./layer5-and-istio.webp\";\nimport img1 from \"./image1.webp\";\nimport img2 from \"./image2.webp\";\nimport img3 from \"./image3.webp\";\nimport img4 from \"./image4.webp\";\n\n<BlogWrapper>\n\n<img src={listioLayer5} className=\"image-left\" alt=\"Layer5 and Istio\"/>\n\nRecently, I started learning on Service Mesh and it was a very interesting journey as I explored the Service Mesh\nlandscape starting with [Layer5 tutorials](https://github.com/layer5io/istio-service-mesh-workshop) and by exploring\nthe blogs at [Istio.io](https://istio.io/).\n\nOur organization decided to use the features of Istio for securing, managing and automating microservices. However, we have to support a multi-tenant environment and that became a challenge due to lack of sufficient documentation and clarity. To give a little bit of background on the problem, we have a single cluster with multiple tenants in different namespaces sharing the same cluster . We do not want to provide each tenant their own separate Kubernetes Cluster because that would be additional provisioning overhead, management overhead and also additional resource overhead on the platform.\n\nIn this blog, I will go over the concepts and visual representation as well as the steps to learn and build your setup.\nNow there are different combinations possible depending on the requirements. These could be :\n\n1. Single Istio Control Plane with its own Ingress-Gateway to ensure traffic for the control plane is coming via the same control plane Ingress-Gateway.\n1. One or more Workspace namespaces for the workload applications and each with its own instance of the ingress gateway\n1. More advanced scenario would be multiple Control Plane and its associated Data Plane or essentially Multiple Service Mesh within a single Kubernetes Cluster. This is presently feasible using the Maistra Istio Operator, but its not fully supported using the upstream Istio at present. I intend to go over this use case in a later article.\n\nHere by Ingress Gateway we mean the Istio Ingress Gateway and not the Kubernetes Ingress Gateway.\nNow, before we get into the steps for building an Istio Multi-tenant setup, lets quickly review the prerequisite :\n\n- Kubernetes setup (in the steps below I am using v1.18 on ubuntu 18.04)\n\n  ```sh\n  $ sudo apt-get install -y docker.io\n  $ sudo sh -c ‚Äúecho ‚Äòdeb http://apt.kubernetes.io/ kubernetes-xenial main‚Äô >> /etc/apt/sources.list.d/kubernetes.list‚Äù\n  $ sudo sh -c ‚Äúcurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -‚Äù\n  $ sudo apt-get update\n  $ sudo apt-get install -y kubeadm=1.18.1‚Äì00 kubelet=1.18.1‚Äì00 kubectl=1.18.1‚Äì00\n  $ sudo kubeadm init ‚Äî kubernetes-version 1.18.1 ‚Äî pod-network-cidr 192.168.0.0/16\n  $ mkdir -p $HOME/.kube\n  $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n  $ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n  ```\n\n- Get the latest istioctl binary\n\n  ```sh\n  $ curl -L https://git.io/getLatestIstio | sh -\n  cd istio-*\n  export PATH=$PWD/bin:$PATH\n  istioctl version\n  ```\n\n- Initialize the Istio Operator\n  ```sh\n  $ istioctl operator init\n  Using operator Deployment image: docker.io/istio/operator:1.6.3\n  ‚úî Istio operator installed\n  ‚úî Installation complete\n  $ kubectl get all -n istio-operator\n  NAME READY STATUS RESTARTS AGE\n  pod/istio-operator-5998f6c744-vrkbk 1/1 Running 1 78m\n  NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n  service/istio-operator ClusterIP 10.107.183.94 <none> 8383/TCP 78m\n  NAME READY UP-TO-DATE AVAILABLE AGE\n  deployment.apps/istio-operator 1/1 1 1 78m\n  NAME DESIRED CURRENT READY AGE\n  replicaset.apps/istio-operator-5998f6c744 1 1 1 78m\n  ```\n\nNext we will look into the details of the multitenancy scenarios; but before that a few word on the Istio operator would be nice. The Istio Operator follows the Kubernetes Controller and Custom Resource Definition mechanism and basically the above steps create an Istio operator controller in the istio-operator namespace and also registers the CRDs in the Kubernetes Registry. Basically, it extends the API for Kubernetes and allows management of a Custom Resource(CR). A word of caution, the existing upstream Istio Operator does not follow any Operator Framework like kubebuilder or Operator SDK. Hence, many of the expected behavior fail like trying to create two Istio Operator Custom Resource(the community mentions it as `iop` instances) in different namespaces or multiple `iop` instances and are under heavy development.\n\nOk, so now lets jump into action. We will build our Istio Setup for the scenario 1 &2 above shown in the diagram below. There are three different instances of Ingress Gateway(and it could be egress gateway as well) :\n\na. Ingress Gateway in Control Plane for traffic entry point to the Control plane Observability Components like `Kiali`(for the Service Mesh Graph), `Prometheus`(for metrics),Grafana(for visual charts of the metrics)and `Jaeger` (for distributed tracing between the services)\nb. Ingress Gateway in the Worskpace 1 namespace for traffic entry point to the workspace 1 microservices.\nc. Ingress Gateway in the Worskpace 2 namespace for traffic entry point to the workspace 2 microservices.\n\n<img src={img1} alt=\"kubernetes-cluster\"/>\n<div style={{ textAlign: \"center\" }}>\n\n  Single Control Plane with Multiple Data Plane each with separate Ingress\n  Gateway\n\n</div>\n- Creation of Control Plane CR and Data Plane CR\n  A sample CR for creation of the Control plane and Data Plane CR can be referred below :\n  ```sh\n  $ cat iop-platform.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: platform-istiocontrolplane\n  spec:\n  profile: demo\n  $ cat iop-wk1-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk1-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  - name: wk1-ingressgw\n  namespace: workspace-1\n  enabled: true\n  label:\n  istio: ingressgateway-1\n  app: istio-ingressgateway-1\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  $ cat iop-wk2-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk2-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  - name: wk2-ingressgw\n  namespace: workspace-2\n  enabled: true\n  label:\n  istio: ingressgateway-2\n  app: istio-ingressgateway-2\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  ```\n\nIt is important to make sure the indentation is correct ,otherwise it would lead to errors.\nReference: [Istio Website](https://istio.io/latest/docs/setup/install/)\n\nDeploy the CRs using kubectl:\n\n```sh\n$ kubectl create ns istio-system\n$ kubectl create ns workspace-1\n$ kubectl create ns workspace-2\n$ kubectl apply -f ../iop-platform.yaml\nistiooperator.install.istio.io/platform-istiocontrolplane created\n$ kubectl apply -f ../iop-wk1-gw.yaml\nistiooperator.install.istio.io/wk1-gwconfig configured\n$ kubectl apply -f ../iop-wk2-gw.yaml\nistiooperator.install.istio.io/wk2-gwconfig configured\n```\n\n- Troubleshooting the Istio Operator Controller.\n  Its a good idea to run another window and execute the below command to observe the running logs on the controller pod.\n  ```sh\n  $ kubectl logs -f -n istio-operator\n  $(kubectl get pods -n istio-operator -lname=istio-operator -o jsonpath=‚Äô{.items[0].metadata.name}‚Äô)\n  ```\n\n<img src={img2} alt=\"image\"/>\n\n- Observe the created objects in istio-system and the workspace namespaces for all pods to be in running state.\n\n  ```sh\n  $ kubectl get all -n istio-system\n  NAME READY STATUS RESTARTS AGE\n  pod/grafana-b54bb57b9-k84xf 1/1 Running 0 79s\n  pod/istio-egressgateway-77c7d594c5-fr79j 1/1 Running 0 83s\n  pod/istio-ingressgateway-766c84dfdc-p6g6t 1/1 Running 0 83s\n  pod/istio-tracing-9dd6c4f7c-ndjvn 1/1 Running 0 79s\n  pod/istiod-7b69ff6f8c-9gwp8 1/1 Running 0 94s\n  pod/kiali-d45468dc4‚Äì4sww2 1/1 Running 0 79s\n  pod/prometheus-5fdfc44fb7‚Äì67khx 2/2 Running 0 78s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-1\n  NAME READY STATUS RESTARTS AGE\n  pod/wk1-ingressgw-5674488c8b-fg2w5 1/1 Running 0 21s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-2\n  ```\n\n- Now we will label the namespaces for istio-injection\n\n  ```sh\n  $kubectl label namespace workspace-1 istio-injection=enabled\n  $kubectl label namespace workspace-2 istio-injection=enabled\n  ```\n\n- Now we will deploy the bookinfo sample application in both namespaces but before that we need to make sure that the Gateway resource is updated with the correct label selector as below :\n\n  ```sh\n  $ cat istio/bookinfo-gateway-1.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-1 # use istio gateway-1 controller in workspace-1\n  servers:\n  - port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  - ‚Äú*‚Äù\n  $ cat istio/bookinfo-gateway-2.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-2 # use istio gateway-2 controller in workspace-1\n  servers:\n  - port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  - ‚Äú*‚Äù\n  ```\n\n\nDeploy the applications in workspace-1 and workspace-2 and deploy the Gateway, VirtualService and DestinationRules.\n\n{/* */}\n\n```sh\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-2\n```\n\nEssentially what is happening is the Gateway CR is configuring the traffic to come via the ingress-gateway, it specifies the label selector based on which the ingress-gateway is selected and the host from where the traffic is allowed and port on which the traffic is allowed. It is important to ensure the label maps the label on the ingress-gateway.\nOnce this is done the traffic will start flowing the intended gateway and it could be observed on the Kiali dashboard.\nPlease note that in this scenario the Kiali is also accessed via the default control plane ingress-gateway running in the istio-system control plane namespace.\n\n<img src={img3} alt=\"image\" />\n<div style={{ textAlign: \"center\" }}>Kiali view for Workspace-1</div>\n<img src={img4} alt=\"image\" />\n<div style={{ textAlign: \"center\" }}>Kiali view for Workspace-2</div>\nShortly, we will go over the 3rd scenario which is to run multiple Istio Control Planes (Multiple Service Meshes) within the same Kubernetes Cluster. For that, we will need to build an open-shift setup and deploy the Maistra Istio Operator.\nSpecial thanks to the [Istio Community](https://istio.slack.com/) for helping me understand the concepts and also answering my queries and of course to [Lee Calcote](https://calcotestudios.com/talks/), who helped me embark on my Istio journey.\n\n<div>\n\n  <b>\n    Connect with Sudeep Batra on\n    <a href=\"https://www.linkedin.com/in/sudeep-batra\"> LinkedIn</a>, <a href=\"https://github.com/sb1975\">GitHub</a>, or <a href=\"https://twitter.com/sudeepbatra\"> Twitter</a>.\n  </b>\n\n</div>\n\n</BlogWrapper>\n","frontmatter":{"title":"Service Mesh (Istio) patterns for Multitenancy","type":"Blog","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/1f1d0/image2.webp 750w,\n/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.638095238095238}},"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/1f1d0/image2.webp 750w,\n/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.638095238095238}},"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp"}},"fields":{"slug":"/blog/service-mesh/service-mesh-istio-patterns-for-multitenancy"}},{"id":"933fdd2b-b2a4-5371-bb9a-f047b72e3e23","body":"import { Link } from \"gatsby\";\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport smilogo from \"./smi-logo.webp\";\nimport checklist from \"./checklist.svg\"\n\n<BlogWrapper>\n\n<img\n\tsrc={smilogo}\n\talign=\"right\"\n\talt=\"smilogo\"\n\twidth=\"200px\"\n\tstyle={{ margin: \"1rem 2rem\" }}\n/>\n\n### About SMI\n\nThe Service Mesh Interface (SMI) is a specification for service meshes that run on Kubernetes. It utilizes CRDs to modify the behavior of service meshes. The project is under development at [SMI Github Repository](https://github.com/servicemeshinterface/smi-spec). Please visit the github repository page to know the latest advancements in the characteristics. The complete spec can be found [here](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md).\n\n### APIs in SMI\n\nCurrently SMI supports 4 set of APIs:\n\n- [Traffic Specs](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-specs) - Used to define traffic, currently only supports TCP, HTTP traffic.\n- [Traffic Access Control](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-access-control) - Used to specify whether a particular form of traffic is allowed or not\n- [Traffic Split](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-split) - Used to redirect/divide a request for a resource between 2 or more resources. Useful in canary testing\n- [Traffic Metrics](https://github.com/servicemeshinterface/smi-spec/blob/master/SPEC.md#traffic-metrics) - Used to expose common traffic metrics like p99 in a specific format that can be utilized by single dashboard for all the service meshes.\n\n### About SMI Conformance Tests\n\n**SMI Conformance Tests** check whether the service mesh that is installed in the kubernetes cluster, conforms to SMI specs or not. This involves asking some major questions. Does it have the required CRDs? Do these CRDs perform as they should when applied or not applied? Are we able to get metrics in a proper format?\n\nAll these questions will be answered by SMI conformance tests. The biggest benefit of your service mesh conforming to SMI is that it makes building tools an easier process.Also, one time development of any tool would in turn support all the meshes that conform to SMI.\n\nSounds fun, right? Let's dig deeper into the SMI conformance project and find out.\n\n### Meshery'ing with Conformance Tests\n\n<img src={checklist} align=\"left\" alt=\"checklist\" width=\"250px\"/>\n\n<Link to=\"/cloud-native-management/meshery\">Meshery</Link>  is _the cloud native management plane__. It supports all the popular meshes, teaches you how to manage them, assists you in applying custom or recommended configurations, tests for  compatibility, performs performance tests for meshes and a lot more. The SMI conformance testing requires performance testing capabilities, load generation (Meshery is about to support distributed load generation as well), and other functionalities such that these conformance tests can be easily used in the pipelines of all the popular service meshes. mesheryctl does have a perf command that can be used in the pipelines of service meshes. I aim at making such capabilities for SMI conformance as well.\n\nAs you have made your way halfway through the post (thank you for your patience), you should now be aware of SMI, its conformance practices and how Meshery‚Äôs incredible engineering can be utilized for conformance tests. We can now tackle the larger questions and hope to see the bigger picture.\n\n### The Bigger Picture\n\nDo you know that almost all of the test cases that we would write in this project would be  raw YAML files? To those doing traditional unit and integration tests, we might sound unhinged at this point. We assure you that we are completely sober and serious (if you don‚Äôt count the temporary euphoria from geeky jokes).\n\n#### Forking [kuttl](https://kuttl.dev/)\n\n`kuttl` is a tool for writing tests against Kubernetes operators and controllers. It can ascertain whether any kind of resources exist or not in the Kubernetes cluster, spring up a kind cluster and do other convenient things. Another plus is that It's entirely declarative. Consider a scenario in which we have a special use case where we wanted to run some go code  after each individual step in the test case was executed. To accomplish this, we forked `kuttl` and modified it a little. You can see our modified version [here](https://github.com/kanishkarj/kuttl).\n\n\nWe are planning to use `kuttl` for all the APIs in SMI. We are also planning to use the Meshery load generator with the modified version of `kuttl`.\n\n#### [Learn Layer5](https://github.com/layer5io/learn-layer5/)\n\nLearn Layer5 is a sample app which is very lightweight and simple to deploy. It is a simple sample app for learning about service meshes. We are planning to use the same app for testing for SMI conformance. The app is deployed when we test for SMI conformance and traffic is generated from one service/deployment/pod to another. This is a great tool for playing around with service meshes and the tools provided by Layer5 and its projects without investing any personal resources.\n\nThis is where all the test cases along with the code will be placed. Currently, there is a large overlap in the learn-layer5 and `smi-conformance` testing files. All those changes will be transferred here.\n\nIf any of this sounds remotely exciting, I implore you to give this a chance. You won‚Äôt regret it.\nHead over to our [Slack Channel](http://slack.layer5.io) and join the #smi channel where everything related to conformance testing is discussed. We would love to hear your feedback. Stay tuned for more blogs related to SMI Conformance and all things meshy!!!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Starting SMI Conformance Testing with Meshery","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAADQAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJZgCdMoRwABouJpxndAAA/rk5FTx5IAPyy7bwayFHbqZeUwT5kp/jZAeb6AaWX0+j97v2lRg8t8fOoRyxzRsu40wcUtoNkON2o0AA"},"images":{"fallback":{"src":"/static/1b5c57550ae99467aa7b1f4f632274dc/d0012/smi-conformance.webp","srcSet":"/static/1b5c57550ae99467aa7b1f4f632274dc/1cb46/smi-conformance.webp 750w,\n/static/1b5c57550ae99467aa7b1f4f632274dc/d0012/smi-conformance.webp 1036w","sizes":"100vw"},"sources":[]},"width":1,"height":0.4343629343629343}},"extension":"webp","publicURL":"/static/1b5c57550ae99467aa7b1f4f632274dc/smi-conformance.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAADQAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJZgCdMoRwABouJpxndAAA/rk5FTx5IAPyy7bwayFHbqZeUwT5kp/jZAeb6AaWX0+j97v2lRg8t8fOoRyxzRsu40wcUtoNkON2o0AA"},"images":{"fallback":{"src":"/static/1b5c57550ae99467aa7b1f4f632274dc/d0012/smi-conformance.webp","srcSet":"/static/1b5c57550ae99467aa7b1f4f632274dc/1cb46/smi-conformance.webp 750w,\n/static/1b5c57550ae99467aa7b1f4f632274dc/d0012/smi-conformance.webp 1036w","sizes":"100vw"},"sources":[]},"width":1,"height":0.4343629343629343}},"extension":"webp","publicURL":"/static/1b5c57550ae99467aa7b1f4f632274dc/smi-conformance.webp"}},"fields":{"slug":"/blog/programs/starting-smi-conformance-testing-with-meshery"}},{"id":"fbdb0105-a11c-58b8-b99e-f59449dd09f9","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport cncf from \"./cncf-landscape-stacked-color.svg\"\nimport cncfmeshery from \"./cncf-meshery-landscape.webp\"\n\n<BlogWrapper>\n\n<img src={cncf} className=\"image-right\" alt=\"cncf-landscape-stacked-color\" />\n\n### Digging into Service Meshes\n\nAbout a year and a half ago I got interested in service mesh technology. A customer needed some advanced routing capabilities and we started looking at Envoy and Istio. Then - invitations to talk about Istio at meetups and conferences started flowing in. That's when I got excited about progressive delivery capabilities that service meshes enable. I even wrote a Kubernetes Istio canary controller - BirdWatch.\n\n### Finding Meshery\n\nDigging deeper into what service meshes had to offer I discovered Meshery - the universal service mesh management plane. And immediately joined Layer5 - the great, welcoming open-source community that created it.\n\n### Community Matters\n\nBeing a member of Layer5 was one of the nicest community experiences I've ever had. Mainly thanks to community's founder and captain - Lee Calcote. He always makes sure everybody feels significant, included and motivated to participate. And this spirit spreads out to all community activities.\n\nIn no time, I had my first commits approved and merged and started joining weekly community and development video calls.\n\n### We're on CNCF Landscape!\n\nNow - I won't be reviewing Meshery in this post. I've spoken about it in this video and some great introductory articles by community members can be found here and here. This post is more of a celebration, because last week...\n\n<h5 style={{ textAlign: \"center\" }}><i>Meshery now featured in the CNCF Landscape!</i></h5>\n\n<img src={cncfmeshery} className=\"image-center\" alt=\"cncf-meshery-landscape\" />\n\nAnd this is only the first step - there's already an application filed for Meshery to become a full-fledged CNCF sandbox project. I had a chance to collaborate on the sandbox proposal and am so eager for this to happen.\n\n### Getting Meshy\n\nThis is also an invitation to participate - Meshery is a young, ambitious project - it requires a ton of work to make it what it aims to become. Integrating with all of the leading service mesh solutions asks for extensive expertise. In many areas Meshery's functionality is still young. But these are normal growth stages, aren't they? To put it simple - the community and the project need more hands! And these should be your hands!\n\n<div style={{ textAlign: \"center\" }}><i>As already mentioned - Layer5 is a very welcoming bunch!</i></div>\nOpen source contributions are a must-do for becoming a true cloud native hero. Cloud native is all about the community and one can't be a part of a community by only taking and never giving back. So if you were looking for a promising and welcoming project to join - look no further! Hop on to Layer5 Slack and we'll happily embrace you and help you get started.\n\nAnd it's not only coding! Documentation, testing, UI design, logos, blogs, videos - you decide where to apply your talent.\n\nFor example - I sometimes wish I had more time and motivation to code new Meshery features or fix existing bugs. But instead I'm writing this post. Because lately I enjoy writing texts more than coding. Coding for longer than a couple of days at a time throws me into a coding fatigue‚Ä¶ Actually also many other activities do. I'm just not very good at keeping a routine. But I'm sure many of you out there aren't like me. So why not join forces?\n\n### Join the cloud native community!\n\n* Meshery is an exciting opportunity to learn more about service meshes.\n* We're already on CNCF Landscape and are headed for the sandbox.\n* Now is a great time to hop on board. Are you ready? Get into the mesh pit!\n\n\n</BlogWrapper>\n\n","frontmatter":{"title":"Meshery lands in the CNCF Landscape","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQBACdASoUAAoAPtFUo0uoJKMhsAgBABoJZACdMoADgO9k6qEL53yk2sYAAP7Abw4XvX2jHGD89BNjRpE70cE2XMKPwIVX+4lLfd3o20v5GElRvyyyUrRwSFT2h/RDZdLxUwq/W4DautwG0qJ1AAAA"},"images":{"fallback":{"src":"/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp","srcSet":"/static/c201715de532db5e6e35ab46bb613fee/678bf/cncf-meshery.webp 750w,\n/static/c201715de532db5e6e35ab46bb613fee/00510/cncf-meshery.webp 1080w,\n/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp 1250w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504}},"extension":"webp","publicURL":"/static/c201715de532db5e6e35ab46bb613fee/cncf-meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQBACdASoUAAoAPtFUo0uoJKMhsAgBABoJZACdMoADgO9k6qEL53yk2sYAAP7Abw4XvX2jHGD89BNjRpE70cE2XMKPwIVX+4lLfd3o20v5GElRvyyyUrRwSFT2h/RDZdLxUwq/W4DautwG0qJ1AAAA"},"images":{"fallback":{"src":"/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp","srcSet":"/static/c201715de532db5e6e35ab46bb613fee/678bf/cncf-meshery.webp 750w,\n/static/c201715de532db5e6e35ab46bb613fee/00510/cncf-meshery.webp 1080w,\n/static/c201715de532db5e6e35ab46bb613fee/82c33/cncf-meshery.webp 1250w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504}},"extension":"webp","publicURL":"/static/c201715de532db5e6e35ab46bb613fee/cncf-meshery.webp"}},"fields":{"slug":"/blog/announcements/meshery-lands-in-the-cncf-landscape"}},{"id":"58ae43e0-f0b0-5c61-ab4f-b71e722508cc","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\n\n<BlogWrapper>\n\n### Introduction to Meshery\n\nFor all those who are unaware of <a href=\"/meshery\">Meshery</a>, Meshery is a cloud native management plane which provides users with operational best practices, lifecycle and configuration management, but also interoperates between various infrastructure, while enabling you with the tools and knowledge to glean the most of out your infrastructure performance, while keeping your overhead to a minimum.\n\nMeshery's vision is to make the operating of any cloud infrastructure simplified. Meshery is created by the <Link to=\"/community\">Layer5</Link>.\n\nLayer5 is a community-first, Cloud Native company which has technology <Link to=\"/partners\">partnerships</Link> with various tech giants like Microsoft, CNCF, RedHat and many more to enlist. The community consists of open source leaders like maintainers of trending open-source projects, Google SoCers, Docker Captains, Cloud Native Ambassadors and many more (<a href=\"http://slack.layer5.io\">join in!</a>).\n\n\n### What is mesheryctl?\n\nMeshery provides you with a clean, robust, streamlined command-line interface to manage and benchmark your infrastructure, `mesheryctl`. With `mesheryctl`, not only you can manage your adapters & containers but you can also benchmark your mesh using the command line. `mesheryctl` provides support to a number of platforms so that we never miss out users. `mesheryctl` can be installed with a single bash command by simply executing:\n\n```bash\n$ curl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n````\n\nin your terminal. You will see Meshery getting installed & fired up on port: 9081.\nYou will see the output as\n\n\n```\nExtracting mesheryctl-v0.3.14...\nArchive:  /Users/user/meshery.zip\n  inflating: LICENSE\n  inflating: README.md\n  inflating: mesheryctl\n\nInstalling mesheryctl in /usr/local/bin.\nmesheryctl installed.\npermissions moved to user\nRemoving installation files and opening Meshery...Updating Meshery now...\nPulling meshery          ... download complete\nPulling meshery-istio    ... done\nPulling meshery-linkerd  ... done\nPulling meshery-consul   ... done\nPulling meshery-octarine ... done\nPulling meshery-nsm      ... done\nPulling meshery-cpx      ... done\nPulling watchtower       ... done\n```\n\nand you will be able to see the Meshery UI on `https://localhost:9081`.\n\nIf you are wondering if bash is only way to get `mesheryctl`, then here is the list of platforms which you can get `mesheryctl` describing all the different ways to get it.\n\n<table className=\"table-1\" align=\"center\">\n<thead>\n    <tr>\n    <th align=\"left\">Platform</th>\n    <th >Supported?</th>\n    </tr>\n</thead>\n<tbody>\n    <tr>\n    <td ><a href=\"https://docs.meshery.io/installation/platforms/docker\">Docker</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/docker\">Docker - Docker App</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/platforms/kubernetes\">Kubernetes</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/aks\">Kubernetes - AKS</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/quick-start\">Kubernetes - Docker Desktop</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/eks\">Kubernetes - EKS</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/gke\">Kubernetes - GKE</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/kubernetes#helm\">Kubernetes - Helm</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/minikube\">Kubernetes - Minikube</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - Kubernetes - OpenShift</td>\n    <td className=\"text-centre\">In Progress</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/quick-start\">Linux</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/quick-start\">Mac</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/mesheryctl#homebrew\">Mac - Homebrew</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td><a href=\"https://docs.meshery.io/installation/platforms/windows\">Windows</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/mesheryctl#scoop\">Scoop</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td> - <a href=\"https://docs.meshery.io/installation/platforms/windows#wsl\">WSL2</a></td>\n    <td className=\"text-centre\">‚úîÔ∏è</td>\n    </tr>\n    <tr>\n    <td>Raspberry Pi</td>\n    <td className=\"text-centre\">In Progress</td>\n    </tr>\n</tbody>\n</table>\n\n<br/>\nWe believe we have not missed any of the popular platforms for what it‚Äôs worth, we will be rolling out support for RaspberryPi and OpenShift soon üéâüéâüéâ.\n\nIf you are thinking about the requirements you would have to run `mesheryctl`, so to your surprise, to successfully run `mesheryctl` you will only need :\n\n<table style={{ textAlign: \"center\" }} className=\"table-box\"><tbody><tr><td className=\"text-centre\">a running Docker daemon</td></tr></tbody></table>\n\n### Into the MesheryCTL\n\nOnce you have successfully installed, you will be having the power of a new CLI Command MesheryCTL. As you type `mesheryctl` into your terminal, you will be shown with the various sub-commands and flags `mesheryctl` can support.\n\n```\nMeshery is the cloud native management plane, providing lifecycle, performance, and configuration management of cloud infrastructure and their workloads.\n\nUsage:\n  mesheryctl [command]\n\nAvailable Commands:\n  help        Help about any command\n  perf        Performance Management\n  system      Meshery Lifecyle Management\n  version     Print mesheryctl version\n\n\nFlags:\n      --config string    config file (default location is: $HOME/.meshery//meshery.yaml)\n  -h, --help            help for mesheryctl\n  -v, --version         Version of mesheryctl\n\nUse \"mesheryctl [command] --help\" for more information about a command.\n```\n\nOnce you do `mesheryctl system start`, Meshery will pull its adapters and latest docker images. Meshery will also detect your Kubernetes configuration and will let you know if Kubernetes is running. Meshery will run it‚Äôs web-based user interface on localhost port `9081` and will let you select your choice of <a href=\"https://docs.meshery.io/extensibility#providers\">Provider</a> before you can start managing your infrastructure with this powerful utility.\n\n<table style={{ textAlign: \"center\" }} className=\"table-box\"><tbody><tr><td className=\"text-centre\">One of the most interesting sub-commands of <code>mesheryctl</code> is <strong><code>perf</code></strong>.</td></tr></tbody></table>\n\nThe `perf` subcommand enables you to being managing the performance of your cloud native deployment and your workloads running atop of them. It lets you benchmark your infrastructure without using the Meshery UI from the command line interface itself. Once you type `mesheryctl perf`, it will present you with all the powerful flags you can control with CLI, including providing it with a `--file` flag that points to any of a number of performance test profiles that you may have saved.\n\n```\nPerformance Management and Benchmarking using Meshery CLI.\n\nUsage:\n  mesheryctl perf --[flags]\n\nAvailable Flags for Performance Command:\n  name[string]                  (optional) A short descriptor to serve as reference for this test. If not provided, a random name will be generate.\n  url[string]                   (required) URL endpoint to send requests.\n  duration[string]              (required) Length of time to perform test (e.g 30s, 15m, 1hr). See standard notation https://golang.org/pkg/time/#ParseDuration\n  load-generator[string]        (optional) Name of load generator to be used to perform test (default: \"fortio\")\n  provider[string]              (required) Choice of Provider (default: \"Meshery\")\n  concurrent-requests[string]   (optional) Number of parallel requests to be sent (default: \"1\")\n  qps[string]                   (required) Queries per second (default: \"0\")\n  file[string]                  (optional) file containing SMPS-compatible test configuration. \n  help                          Help for perf subcommand\n\nurl, duration, concurrent-requests, and qps can be considered optional flags if specified through an SMPS compatible yaml file using --file\n```\n\nAn example usage of `mesheryctl perf --[flags]` can be\n\n```bash\n mesheryctl perf --name \"a quick stress test\" --url http://192.168.1.15/productpage --qps 300 --concurrent-requests 2 --duration 30s --token \"provider=Meshery\"\n```\n\nYou can also provide a SMPS Configuration file with `perf` subcommand, with this file provided you will not have to specify url, duration, concurrent-requests & qps. However, if specified the value provided through file will be over-rided by value through CLI. For more info about file configuration, see [here](https://github.com/service-mesh-performance/service-mesh-performance/blob/master/docs/assets/spec/readme/service%20mesh%20performance%20specification%20result.yaml).\n\n```bash\n mesheryctl perf --name \"a quick stress test\" --file {path}/smps.yaml --token \"provider=Meshery\"\n```\n\n### What's next?\n\nMeshery is an ever-growing community with attracting contributors from across the globe. We always have a role for everyone whether to be a code-writer, a community manager or a marketer. Layer5 community is always open to welcome you warmly.\n\nIf this makes you excited, [join the Layer5 community](http://slack.layer5.io) with just a click & someone will be there to make sure you do not get missed.\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Getting started with mesheryctl","type":"Blog","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp","srcSet":"/static/9cfe96da1edeb15d9314d201d6f225a0/4a552/mesheryctl.webp 750w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/571ff/mesheryctl.webp 1080w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/1866d/mesheryctl.webp 1366w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/9cfe96da1edeb15d9314d201d6f225a0/mesheryctl.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADwAgCdASoUAAkAPtFUo0uoJKMhsAgBABoJYwCdAC0kAAD+8Ft1agncm7Dve5aKGf5sAA=="},"images":{"fallback":{"src":"/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp","srcSet":"/static/9cfe96da1edeb15d9314d201d6f225a0/4a552/mesheryctl.webp 750w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/571ff/mesheryctl.webp 1080w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/1866d/mesheryctl.webp 1366w,\n/static/9cfe96da1edeb15d9314d201d6f225a0/5711e/mesheryctl.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42552083333333335}},"extension":"webp","publicURL":"/static/9cfe96da1edeb15d9314d201d6f225a0/mesheryctl.webp"}},"fields":{"slug":"/blog/meshery/getting-started-with-mesheryctl"}},{"id":"ee99e5c3-8e43-5eed-b3e0-a64947d39a71","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport awsappmesh from '../../../../assets/images/service-mesh-icons/aws-app-mesh.webp';\nimport consul from '../../../../assets/images/service-mesh-icons/consul.svg';\nimport istio from '../../../../assets/images/service-mesh-icons/istio.svg';\nimport linkerd from '../../../../assets/images/service-mesh-icons/linkerd.svg';\nimport maesh from '../../../../assets/images/service-mesh-icons/maesh.webp';\nimport nsm from '../../../../assets/images/service-mesh-icons/nsm.svg';\nimport octarine from '../../../../assets/images/service-mesh-icons/octarine.svg';\nimport kuma from '../../../../assets/images/service-mesh-icons/kuma.svg';\nimport {Link} from \"gatsby\"\n\n<BlogWrapper>\n\n<span className=\"starting-letter\">I</span>t‚Äôs no secret that service mesh tech is boiling hot. Microservice architectures brought on as many challenges as they have advantages. With operational complexity being one of the most acute pains. Service meshes do offer solutions to a number of these operational concerns. Including but not limited to: resilience, improved observability, security and advanced service discovery.\n\n<div>\n<iframe width=\"100%\" alt=\"Deploying Linkerd with Meshery\" title=\"Deploying Linkerd with Meshery\" src=\"https://www.youtube.com/embed/MXQV-i-Hkf8\" allowFullScreen loading=\"lazy\" frameBorder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" style={{minHeight: \"315px\", minWidth: \"280px\"}}></iframe>\n</div>\n\nBut with so many mesh options around - how do we choose, evaluate and compare them? And once we‚Äôve chosen a solution - how do we make it accessible to all our engineers? It is to provide an answer to these questions that the Layer5 community has created <Link to=\"/cloud-native-management/meshery\">Meshery</Link>, the open-source, service mesh management plane. Meshery already supports a number of leading mesh providers with adapters for additional meshes on the way. In today‚Äôs video, I‚Äôll show how to use Meshery for rolling out and evaluating Linkerd.\n\n Linkerd is a system that comes from the service mesh pioneers - the company called Buoyant. They were the first to realise the need for a distributed network of smart, centrally configured proxies and coin the term ‚Äúservice mesh‚Äù back in 2016. Today, we‚Äôll be looking at Linkerd 2.x - the second generation of this now CNCF project.\n\n<h5>Meshery Adapters</h5>\n\n<table className=\"table-adapters\">\n    <thead className=\"hidden\">\n        <th>Status</th>\n        <th>Adapter</th>\n    </thead>\n    <tbody>\n    <tr>\n        <td rowspan=\"7\" className=\"stable-adapters\">stable</td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-istio\"><img src={istio} alt='Istio Service Mesh adapter' className=\"adapter-logo\" />Meshery adapter for Istio</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-linkerd\"><img src={linkerd} alt='Linkerd' className=\"adapter-logo\" />Meshery adapter for Linkerd</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-consul\"><img src={consul} alt='Consul Connect' className=\"adapter-logo\" />Meshery adapter for Consul</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-octarine\"><img src={octarine} alt='Octarine Service Mesh' className=\"adapter-logo\" />Meshery adapter for Octarine</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-nsm\"><img src={nsm} alt='Network Mesh' className=\"adapter-logo\" />Meshery adapter for Network Service Mesh</a></td>\n    </tr>\n    <tr><td className=\"stable-adapters\"></td></tr>\n    <tr>\n        <td rowspan=\"2\" className=\"beta-adapters\">beta</td><td><a href=\"https://github.com/layer5io/meshery-cpx\">\nMeshery adapter for Citrix CPX</a></td>\n    </tr>\n    <tr><td className=\"beta-adapters\"></td></tr>\n    <tr>\n        <td rowspan=\"6\" className=\"alpha-adapters\">alpha</td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-maesh\"><img src={maesh} alt='Maesh Service Mesh' className=\"adapter-logo\" />Meshery adapter for Maesh</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-app-mesh\"><img src={awsappmesh} alt='AWS App Mesh Service Mesh' className=\"adapter-logo\" />Meshery adapter for App Mesh </a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://github.com/layer5io/meshery-kuma\"><img src={kuma} alt='Kuma Service Mesh' className=\"adapter-logo\" />Meshery adapter for Kuma</a></td>\n    </tr>\n    <tr><td></td></tr>\n    <tr><td className=\"alpha-adapters\"></td></tr>\n    </tbody>\n</table>\n\nSome things that Linkerd is known for:\n\n- Purpose-built for Kubernetes\n- Featuring custom-built, highly performant proxies written in Rust\n- Zero-config option (works out-of-the-box)\n- Network telemetry built-in (includes a pre-configured, optimised Prometheus instance)\n- Low-overhead control-plane\n- Operational simplicity (when compared to Istio, for example, even though Istio is getting better in this regard)\n\nSo what is covered in the video? More or less the following:\n\n- What service mesh tech allows us to do\n- What a typical service mesh architecture looks like\n- What Layer5 is about (<i>Lookout - it may surprise you!</i>)\n- What Meshery is. What Linkerd is.\n- How easy it is to install Meshery on your PC (be it Linux, Mac or Windows)\n- All it takes is:\n```sh\n$ curl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n```\n- How Meshery connects to your Kubernetes cluster (nothing to be done if it‚Äôs in your <code>kubectl config current-context</code>)\n- How to correctly install and remove Linkerd on your Kubernetes cluster using Meshery\n- How to install one of included Linkerd sample applications and verify the installation\n\nThat‚Äôs quite a lot of content for a 20 minute clip. In the follow-up videos, we‚Äôll dive deeper into many of these concepts. And also show how to use Meshery with other service mesh providers.\n\nThis video is also the opening shot of Layer5's [Learn to Service Mesh](https://www.youtube.com/playlist?list=PL3A-A6hPO2IN_HSU0pSfijBboiHggs5mC) playlist, which is specifically dedicated to tutorials and webinars. If service mesh tech interests you and you‚Äôre willing to learn more about it, then make sure to [subscribe to the channel](https://www.youtube.com/channel/UCFL1af7_wdnhHXL1InzaMvA?sub_confirmation=1) and watch for updates.\n\nAnd let us know if there‚Äôs any specific content you want us to create. Or maybe anything you‚Äôve created yourself and would like to share? Layer5 is all about knowledge sharing and we want to talk to you, so please [join the cloud native community](http://slack.layer5.io)!\n\nHappy meshing!\n\n</BlogWrapper>\n","frontmatter":{"title":"Deploying Linkerd with Meshery","type":"Blog","technology":null,"product":"Meshery","mesh":"Linkerd","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgAAW41+EMeuRS5kAAD+zRR30B7IZkwg5DLpIC/9Ldd+oO3jEdv9tbLd+qeOIGpIzE1i+iJaKAAA"},"images":{"fallback":{"src":"/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp","srcSet":"/static/af48ad5b31a3b12f8d571eea1a4f863f/a66aa/Linkerd-with-Meshery.webp 750w,\n/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/af48ad5b31a3b12f8d571eea1a4f863f/Linkerd-with-Meshery.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAACwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgAAW41+EMeuRS5kAAD+zRR30B7IZkwg5DLpIC/9Ldd+oO3jEdv9tbLd+qeOIGpIzE1i+iJaKAAA"},"images":{"fallback":{"src":"/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp","srcSet":"/static/af48ad5b31a3b12f8d571eea1a4f863f/a66aa/Linkerd-with-Meshery.webp 750w,\n/static/af48ad5b31a3b12f8d571eea1a4f863f/bde8a/Linkerd-with-Meshery.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/af48ad5b31a3b12f8d571eea1a4f863f/Linkerd-with-Meshery.webp"}},"fields":{"slug":"/blog/meshery/deploying-linkerd-with-meshery"}},{"id":"c95858c2-6e7f-5a8e-a41e-c069bc89b90b","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport issueImage from \"./issue.webp\";\n\n<BlogWrapper>\n\nSeveral weeks ago, I wrote [a blog post](https://raungar.wordpress.com/2019/11/15/introducing-comparative-spectrums-to-the-layer5-landscape/) about introducing \"comparative spectrum\" tools to [the Layer5 landscape](https://layer5.io/landscape)‚Äîa webpage which I have transformed multiple times, now!\n\nUp until now, the contents of each blog post I have written were centered upon a freshly-opened pull request. Shortly before writing my last post, I did open [one such pull request (layer5#238)](https://github.com/layer5io/layer5/pull/238). However, since my PR remains open, and since I am still working on the same issue my PR addresses, I have opted to instead push [a new commit](https://github.com/layer5io/layer5/pull/238/commits/4d396aaa6d3ca46add71531daedc8c0e2a5d2495) to the aformentioned (but, now, renamed) PR instead of creating a whole new one. This newest commit introduces a major step towards resolving the issue at hand, and will be the subject of this blog post!\n\n<img src={issueImage} alt=\"Issue\"/>\n\nThe issue at hand: [layer5#211](https://github.com/layer5io/layer5/issues/211) - add comparative spectrums to the Landscape page\n\n* * *\n\n_**Note:** this blog post will frequently reference [the update and documentation comment that I made](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644) to accompany my last commit to my PR. I consider this hefty comment to be an extension of this blog post, so I strongly recommend giving it a read!_\n\n* * *\n\nMy initial commit towards introducing comparative spectrum tooling did not represent a full solution. Thinking about what might constitute a full solution for the issue at hand, I came up with three criteria:\n\n## What was still needed:\n\n#### 1\\. A complete toolset\n\nWithin [Issue #211](https://github.com/layer5io/layer5/issues/211), Layer5 lead developer Lee indicates [four slides](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6) upon which comparative spectrum graphics may be based upon. During my initial commit, I created graphics that emulated those found within the first three of those four slides, but I had yet to implement the graphic found in [the fourth](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p12): a table. I was also less-than-satisfied with the 'grid' design I had implemented in response to [slide 7](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p10).\n\n#### 2\\. A modular design\n\nThe designs I am implementing are meant to be used to present opinionated information. As I am not nearly knowledgeable to form opinionated comparisons between DevOps tools and related technologies, I have instead made my goal to make it as easy as possible for other Layer5 contributors to utilize the graphics (\"\\[comparative\\] spectrums\") that I am designing. Doing so would require encapsulating (templating) the spectrums I design (new and old), within their own HTML files, and providing a means to easily invoke (and customize) instances of those templates into the Landscape page.\n\n#### 3\\. Documentation\n\nBecause the templates I design are intended to be implemented and customized by other contributors, it is _especially_ critical that those contributors have access to complete and thorough documentation detailing the intended use of each templated design.\n\n* * *\n\n## What I delivered:\n\n#### 1\\. A complete toolset\n\nAs documented in my [update comment](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644), I designed a table that very closely resembles that of Lee's slides. Implementing the table was interesting, as it ended up requiring [quite a few nested Liquid for-loops](https://github.com/layer5io/layer5/blob/4d396aaa6d3ca46add71531daedc8c0e2a5d2495/_includes/partials/spectrum/table.html#L23). Also as documented, I revamped the grid-based tooling and am quite pleased with the improvements made. The end result of these efforts is a complete set of comparative spectrums.\n\n#### 2, 3. A modular design and documentation\n\nThe bulk of the documentation I wrote details how to deal with the modular solution that I designed and implemented to enable comparative spectrums to be included into the Landscape page (through the use of Liquid `include` tags). The documentation speaks for itself; [check it out!](https://github.com/layer5io/layer5/pull/238#issuecomment-561613644)\n\n## What's next?\n\nI would not have considered the documentation I delivered to be complete if I did not report on the issues still present in the work I delivered. I denoted these as 'Current issues' in the documentation, and they represent work that still remains to be done. I know that I can count on the Layer5 community to assist me with small issues like these, and, once this pull request receives some forward motion, I hope to start zeroing in on its smaller issues. Fortunately, I have made plans to continue working with open source well into the new year!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Layer5: Landscape Spectrums Revisited","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSJgAAAABcGPbtpr8WI1TJaGj1tYdWifWsjIF3K10eyUynD+oeEYQERNA9dYbi+s+pWIb1Q8WKhYF/PljFllk8d8U0xgUCEul+XwetyTM5/Oqpdh8Po1YQtEij8wwzRAyNPIMYR+wEjkCwM6HULrNGKSuoN2EFYBxWId7gf4bAODE6bwNdN+u+mBBMhQFUZIkAX9UbKNK9dYbi+s+BVZQOCCkAAAAMAUAnQEqFAAUAD7RXqZOqCUjIigKqQAaCWoAtPYgDeQAGMhLc1H/DL6oPzFChTu32AAA/jFFGJ8niSBnVreaWpa4nP1x1X+3nWWO4WVOC1xl9aML2H9tl9Df3+iYKwGacMsOsKsp0kuYqqfmS1VHbiUUqYm3IfxzOaPVeqOolkWIQKT4Stet4gyBZKd/Y1ANHBrDhHIu/CoOY2il6CMuIQxYAAA="},"images":{"fallback":{"src":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp","srcSet":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp 206w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9805825242718447}},"extension":"webp","publicURL":"/static/5cf346a8332e49fcac54d6c02a4119cc/landscape_green.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSJgAAAABcGPbtpr8WI1TJaGj1tYdWifWsjIF3K10eyUynD+oeEYQERNA9dYbi+s+pWIb1Q8WKhYF/PljFllk8d8U0xgUCEul+XwetyTM5/Oqpdh8Po1YQtEij8wwzRAyNPIMYR+wEjkCwM6HULrNGKSuoN2EFYBxWId7gf4bAODE6bwNdN+u+mBBMhQFUZIkAX9UbKNK9dYbi+s+BVZQOCCkAAAAMAUAnQEqFAAUAD7RXqZOqCUjIigKqQAaCWoAtPYgDeQAGMhLc1H/DL6oPzFChTu32AAA/jFFGJ8niSBnVreaWpa4nP1x1X+3nWWO4WVOC1xl9aML2H9tl9Df3+iYKwGacMsOsKsp0kuYqqfmS1VHbiUUqYm3IfxzOaPVeqOolkWIQKT4Stet4gyBZKd/Y1ANHBrDhHIu/CoOY2il6CMuIQxYAAA="},"images":{"fallback":{"src":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp","srcSet":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp 206w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9805825242718447}},"extension":"webp","publicURL":"/static/5cf346a8332e49fcac54d6c02a4119cc/landscape_green.webp"}},"fields":{"slug":"/blog/internship-programs/layer5-landscape-spectrums-revisited"}},{"id":"94ec3b54-c4c3-53cd-ad1b-e5a628ad968e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport pr211 from \"./PR-211.webp\";\nimport pr2112 from \"./PR-211-2.webp\";\nimport card1 from \"./card1.webp\";\nimport card2 from \"./card2.webp\";\nimport arrow from \"./arrow.webp\";\nimport gtable from \"./graphical-table.webp\";\nimport gcomp from \"./graph-compare.webp\";\nimport image21 from \"./image.webp\";\nimport comment from \"./comment.webp\";\n\n<BlogWrapper>\n\nDuring [Hacktoberfest 2019](https://raungar.wordpress.com/tag/layer5/), I worked on the website of [Layer5](https://layer5.io/), open source community. More specifically, my contributions concerned one specific page of that website: its [Service Mesh Landscape page](https://layer5.io/landscape).\n\nShortly after making these contributions, I was graciously welcomed into the Layer5 community by its lead developer [Lee Calcote](https://twitter.com/lcalcote?lang=en), who later directly approached me to assist him in furthering his vision for the Landscape page by implementing \"comparative spectrums\". Wishing to focus on my remaining two Hacktoberfest contributions at the time, I suggested surveying the interest of other potential contributors for this project. As such, an informative issue was opened:\n\n<img src={pr211} alt=\"PR 211\"/>\n\nIssue [layer5#211](https://github.com/layer5io/layer5/issues/211): add comparative spectrums to the Landscape page\n\nA month later, I fortunately found time enough to make some major progress into this issue.\n\n* * *\n\nThis issue is quite highly conceptual, much moreso than any other issue I have thus far worked on. I decided that the best way to approach this issue would be to focus on establishing a set of tools that could be used by more-knowledgeable contributors to later construct comparative spectrums‚Äîopinionated data visualizations. As such, my first step was to build a set of responsive graphical elements that resembled [those provided as examples](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6). These include:\n\n#### (1) _Sleek information cards:_\n\n<table>\n    <tbody>\n    <tr>\n    <td><img src={card1} alt=\"Card\"/></td>\n    <td> or this </td>\n    <td><img src={card2} alt=\"Card\"/></td>\n    </tr>\n    </tbody>\n</table>\n\n_(Source: [ONIF Container Networking Panel, slides 5 and 6](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n#### (2) _Gradiented, labelable double-arrow banners:_\n\n<img src={arrow} alt=\"Arrow\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 5](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n#### (3) _Graphically-augmented tables:_\n\n<img src={gtable} alt=\"Table\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 8](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p12))_\n\n#### (4) _Spectrum-like graphical comparisons:_\n\n<img src={gcomp} alt=\"Comparison\"/>\n\n_(Source: [ONIF Container Networking Panel, slide 7](https://docs.google.com/presentation/d/1P6LzzG0_alAxshpdfLnix53S9WU4vjbpSCrHJQoWPqc/edit#slide=id.p6))_\n\n* * *\n\n(1) Although there may exist libraries that may help construct such graphical elements, I did not want to introduce additional libraries to accomplish my work. Instead, I wanted to make good use of Layer5io's preexisting [Materialize](https://materializecss.com/) library. Fortunately, Materialize strongly supports the design of card-like structures, allowing me to more easily [implement some](https://github.com/layer5io/layer5/pull/238/files#diff-20fc098534d6aab31ad8e5c9db51bde0R10).\n\n(2) Unfortunately, it does not seem that Materialize supports the creation of graphical arrows, so I just ended up [styling my own](https://github.com/layer5io/layer5/pull/238/files#diff-1d5fe92e61759723c94b009b32e9e1b7R2).\n\n(3) These tables can be quite easily implemented and styled with or without the use of `<table>` tags. I anticipate these will be given a proper fleshing out after the other graphical elements are further developed.\n\n(4) These unique spectrum graphics present the most challenging, of all the comparison tools, to implement. Snaking spectrum bar aside, I needed to develop a _responsive_ solution that (a) allowed contributors to programmatically place image thumbnails at preset horizontal positions, while (b) ensuring those thumbnails placed at the same position do not overlap with one another (and instead align vertically atop each other).\n\nThis presented a problem to solve: I required a means to 'float' elements toward a horizontal line; to 'stack' thumbnails atop one another, without overlap, if they are given the same horizontal position. After researching quite deeply into potential solutions to this problem, I ended up stumbling across some CSS property-value pairings that I had never heard of before: [`display: grid`](https://www.w3schools.com/css/css_grid.asp) and [`grid-auto-flow: row dense`](https://www.w3schools.com/cssref/pr_grid-auto-flow.asp). Miraculously, I discovered that these could actually function as [a basis for a solution](https://github.com/layer5io/layer5/pull/238/files#diff-1d5fe92e61759723c94b009b32e9e1b7R76).\n\n* * *\n\nAfter styling the graphical elements, I continued the website's trend of using [Liquid](https://help.shopify.com/en/themes/liquid) tags (e.g. [`for`](https://help.shopify.com/en/themes/liquid/tags/iteration-tags#for)) and [YAML lists](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html) to help modularize my solutions, which should aid future contributors in generalizing them.\n\n* * *\n\nI opened [a pull request](https://github.com/layer5io/layer5/pull/238) to share my work as well as invite collaboration:\n\n<img src={pr2112} alt=\"PR 211-2\"/>\n\nPull request [layer5#238](https://github.com/layer5io/layer5/pull/238): description of tooling introduced\n\n<img src={image21} alt=\"Image\"/>\n\nPull request [layer5#238](https://github.com/layer5io/layer5/pull/238): example images of tooling introduced\n\nThe pull request was quite well-recieved:\n\n<img src={comment} alt=\"Comment\"/>\n\n[Comment](https://github.com/layer5io/layer5/pull/238#issuecomment-554181763) by Layer5 team lead on pull request [layer5#238](https://github.com/layer5io/layer5/pull/238)\n\nAs I mentioned in a recent Layer5 community meeting, I am very excited to continue working with Layer5; to refine and expand upon this set of new, visionary tooling for their landscape!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Introducing Comparative Spectrums to the Layer5 Landscape","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSJgAAAABcGPbtpr8WI1TJaGj1tYdWifWsjIF3K10eyUynD+oeEYQERNA9dYbi+s+pWIb1Q8WKhYF/PljFllk8d8U0xgUCEul+XwetyTM5/Oqpdh8Po1YQtEij8wwzRAyNPIMYR+wEjkCwM6HULrNGKSuoN2EFYBxWId7gf4bAODE6bwNdN+u+mBBMhQFUZIkAX9UbKNK9dYbi+s+BVZQOCCkAAAAMAUAnQEqFAAUAD7RXqZOqCUjIigKqQAaCWoAtPYgDeQAGMhLc1H/DL6oPzFChTu32AAA/jFFGJ8niSBnVreaWpa4nP1x1X+3nWWO4WVOC1xl9aML2H9tl9Df3+iYKwGacMsOsKsp0kuYqqfmS1VHbiUUqYm3IfxzOaPVeqOolkWIQKT4Stet4gyBZKd/Y1ANHBrDhHIu/CoOY2il6CMuIQxYAAA="},"images":{"fallback":{"src":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp","srcSet":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp 206w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9805825242718447}},"extension":"webp","publicURL":"/static/5cf346a8332e49fcac54d6c02a4119cc/landscape_green.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSJgAAAABcGPbtpr8WI1TJaGj1tYdWifWsjIF3K10eyUynD+oeEYQERNA9dYbi+s+pWIb1Q8WKhYF/PljFllk8d8U0xgUCEul+XwetyTM5/Oqpdh8Po1YQtEij8wwzRAyNPIMYR+wEjkCwM6HULrNGKSuoN2EFYBxWId7gf4bAODE6bwNdN+u+mBBMhQFUZIkAX9UbKNK9dYbi+s+BVZQOCCkAAAAMAUAnQEqFAAUAD7RXqZOqCUjIigKqQAaCWoAtPYgDeQAGMhLc1H/DL6oPzFChTu32AAA/jFFGJ8niSBnVreaWpa4nP1x1X+3nWWO4WVOC1xl9aML2H9tl9Df3+iYKwGacMsOsKsp0kuYqqfmS1VHbiUUqYm3IfxzOaPVeqOolkWIQKT4Stet4gyBZKd/Y1ANHBrDhHIu/CoOY2il6CMuIQxYAAA="},"images":{"fallback":{"src":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp","srcSet":"/static/5cf346a8332e49fcac54d6c02a4119cc/89f24/landscape_green.webp 206w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9805825242718447}},"extension":"webp","publicURL":"/static/5cf346a8332e49fcac54d6c02a4119cc/landscape_green.webp"}},"fields":{"slug":"/blog/internship-programs/introducing-comparative-spectrums-to-the-layer5-landscape"}},{"id":"cac9ddb8-17d6-5815-b6a0-3a849328003b","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport wsldockerstart from \"./wsl-docker-start.webp\";\nimport wslgrafanalogin from \"./wsl-grafana-login.webp\";\nimport wslgrafanaloginsuccess from \"./wsl-grafana-login-success.webp\";\nimport wslgrafanastart from \"./wsl-grafana-start.webp\";\nimport wslk3dstart from \"./wsl-k3d-start.webp\";\nimport wslmesherycomplete from \"./wsl-meshery-complete.webp\";\nimport wslmesherylogin from \"./wsl-meshery-login.webp\";\nimport wslmesheryloginsuccess from \"./wsl-meshery-login-success.webp\";\nimport wslmesherystart from \"./wsl-meshery-start.webp\";\n\n<BlogWrapper>\n\nDuring KubeCon EU 2019, I had the chance to discover two new softwares that simply amazed me:\n1. [Meshery](https://layer5.io/cloud-native-management/meshery), which is the multi-cluster Kubernetes management plane.\n2. [k3d](https://github.com/rancher/k3d), which is used to create a dockerized [k3s](https://k3s.io) server.\n\nAnd, what really appealed to me about both of them is that everything from the installation to the usage was just *simple!*\nAnd cream on the top, both softwares are used with or inside containers, making each ideal for a create/try/delete workflow.\n\n<h4>Environment Setup</h4>\n\nBefore we start having *real* fun with Meshery, I will quickly list the different components I used for this blog post and ensure I define what could be optional for your own setup:\n1. [Meshery](https://layer5.io/cloud-native-management/meshery)\n2. [Docker](https://docs.docker.com/install/)\n    - Docker is of course mandatory and as Meshery is based on a Compose file, which means that [docker-compose](https://docs.docker.com/compose/install/) is also mandatory.\n3. [k3d](https://github.com/rancher/k3d)\n    - k3d or any k3s/K8s cluster that you might have already configured.\n4. [WSL2](https://devblogs.microsoft.com/commandline/wsl-2-is-now-available-in-windows-insiders/)\n    - For the (few) ones who know me, my \"OS base\" is WSL2, which means that without much/any change, it should run fine for any Linux/MacOS setup.\n5. [Grafana](https://grafana.com/) *(optional)*\n    - Grafana is not mandatory however is strongly recommend. We will setup a dockerized instance, but feel free to plug Meshery with your existing instance.\n\n<h4> Nothing is taken for granted </h4>\n\nFor the sake of making the blog post around Meshery, I won't explain how to install each component and will focus only on getting k3d and Meshery working.\n\nThat said, I do not take anything for granted and as Scott Hanselman once taught me: there is no \"just have to ...\" or \"by simply doing ...\".\n\nIf you face any issue with your setup (hopefully WSL2), just let me know on [Twitter](https://twitter.com/nunixtech) or on the [Layer5 Slack channel](http://slack.layer5.io).\n\n<h4>Meshery Installation</h4>\n\nFor the following steps, I will use the Ubuntu 18.04 WSL2 distro:\n\n- Start docker and confirm it's running:\n\n```bash\nsudo service docker start\ndocker version\n```\n\n- Using Docker, install Meshery on your local machine by running the following:\n\n```bash\ncurl -L https://meshery.io/install | PLATFORM=kubernetes bash -\n```\n<a href={wsldockerstart}>\n    <img src={wsldockerstart} className=\"thumbnail\" alt=\"wsl-docker-start\" />\n</a>\n\n- Create a new k3d cluster with the <code> WSL2 IP </code>\n\n```bash\nexport mainIP=`hostname -I | awk '{ print $1 }'`\nk3d list\nk3d create --workers 3 --api-port ${mainIP}:6443\nexport KUBECONFIG=\"$(k3d get-kubeconfig --name='k3s-default')\"\nkubectl cluster-info\n```\n\n<a href={wslk3dstart}>\n    <img src={wslk3dstart} className=\"thumbnail\" alt=\"wslk3dstart\" />\n</a>\n<br/>\n- Start Meshery on the newly created cluster\n\n```bash\nmesheryctl system start\n```\n\n<a href={wslmesherystart}>\n    <img src={wslmesherystart} className=\"thumbnail\" alt=\"wslmesherystart\" />\n</a>\n- Once Meshery is fully started, login in your preferred browser using the <code>WSL2 IP</code> instead of <code>localhost</code>\n\n```bash\nexport BROWSER=/mnt/c/Firefox/firefox.exe\n$BROWSER $mainIP:9081 &\n```\n\n<a href={wslmesherylogin}>\n        <img src={wslmesherylogin} alt=\"wslmesherylogin\" />\n</a>\n<a href={wslmesheryloginsuccess}>\n    <img src={wslmesheryloginsuccess} alt=\"wslmesheryloginsuccess\" />\n</a>\n\n\n#### [Optional] More analytics with Grafana\nAs stated above, Meshery can leverage the analytics provided by Grafana. For this blog post, as everything is built from scratch. Here is the setup for a new Grafana dockerized instance.\n\nStart a new Grafana on docker instance\n\n```bash\ndocker run \\\n-d \\\n-p 3000:3000 \\\n--name=grafana \\\n-e \"GF_SERVER_ROOT_URL=http://$mainIP\" \\\n-e \"GF_SECURITY_ADMIN_PASSWORD=MesheryInstance\" \\\ngrafana/grafana\n```\n\n<a href={wslgrafanastart}>\n    <img src={wslgrafanastart} className=\"thumbnail\" alt=\"wslgrafanastart\" />\n</a>\n\n- Access the new instance with the admin password that you set in the docker environment variable\n```bash\n$BROWSER $mainIP:3000 &\n```\n\n<a href={wslgrafanalogin}>\n    <img src={wslgrafanalogin} className=\"thumbnail\" alt=\"wslgrafanalogin\" />\n</a>\n<br />\n<a href={wslgrafanaloginsuccess}>\n    <img src={wslgrafanaloginsuccess} className=\"thumbnail\" alt=\"wslgrafanaloginsuccess\" />\n</a>\n\n### An inside look\nWhile everything should run fine, it's always good to have a look at what has been deployed.\n\nIn this case, we are almost exclusively working with Docker and the \"inside look\" should look something like this:\n\n<a href={wslmesherycomplete}>\n    <img src={wslmesherycomplete} className=\"thumbnail\" alt=\"wslmesherycomplete\" />\n</a>\n\n#### Conclusion\nAs [Lee Calcote](https://twitter.com/lcalcote) put it, this is a lot of buzz words: Meshery > k3s (deployed via k3d) > Docker > WSL2 > Windows 10. And he's totally right, still the \"beauty\" here, is that it \"simply works\".\n\nSince the begin of the Docker era, new tooling has appeard for simplifying complex workflows.\nEven Kubernetes (K8s) as a much lighter version with k3s by Rancher.\n\nAnd of course, Meshery which integrates and simplifies the installation and benchmarking of different Kubernetes configurations. Hope you had fun assembling all these pieces and stay tunned for the \"Bonuses\", more fun to come!\n\n<span> > > > <i>Nunix out</i></span>\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Getting started with Meshery, WSL2 and k3d","type":"Blog","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrgAAABXRUJQVlA4IKwAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJagDHMywTmwXkh8XuWw62pPgeLa6iGOkYAAD+9R4SKH1oL6udrBkwr5rrkLRIeudVijKFQQi4NBpAgn1GqiLKGll7/coQQQ8X2m4ARFICZ1eH4EKwlMH79KOgYAEP9qeZU1fXG+Jmj3mSYoA/SF+9X/WI4UZXzEZSPBXefiBldNQhjxeWdjq9FujdEnATM/mAAAAA"},"images":{"fallback":{"src":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp","srcSet":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp 400w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/4c732e28e50f90fde2ff41201d6d0743/cnab-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrgAAABXRUJQVlA4IKwAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJagDHMywTmwXkh8XuWw62pPgeLa6iGOkYAAD+9R4SKH1oL6udrBkwr5rrkLRIeudVijKFQQi4NBpAgn1GqiLKGll7/coQQQ8X2m4ARFICZ1eH4EKwlMH79KOgYAEP9qeZU1fXG+Jmj3mSYoA/SF+9X/WI4UZXzEZSPBXefiBldNQhjxeWdjq9FujdEnATM/mAAAAA"},"images":{"fallback":{"src":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp","srcSet":"/static/4c732e28e50f90fde2ff41201d6d0743/416c3/cnab-logo.webp 400w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/4c732e28e50f90fde2ff41201d6d0743/cnab-logo.webp"}},"fields":{"slug":"/blog/meshery/getting-started-with-meshery-wsl2-and-k3d"}},{"id":"fbc0a4e6-e2df-5139-835a-843d390eaa13","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport SmiLogo from \"./smi-logo.webp\";\n\n<BlogWrapper>\n\n<img className=\"image-left\" src={SmiLogo} alt=\"SMI Logo\"/>\n\nMost began their cloud native journey with their first step being use of containers, and taking a second step, moved into container orchestration as their workloads grew. Now, waves and waves of organizations are considering service meshes as their third significant step in their cloud native journey. As they invest into service meshes as their next layer of key infrastructure, users will continue to look for the same assurances sought from other commonly accepted (standard) interfaces for container runtimes (e.g. CRI), container storage (e.g. CSI), container networking (e.g. CNI) and they will look for a commonly accepted service mesh interface.\n\nAs a prominent supporter of management software for multiple service meshes, Layer5 is pleased to partner with Microsoft in support of the [Service Mesh Interface](https://smi-spec.io) (SMI). The Service Mesh Interface is a specification for service meshes that run on Kubernetes. As such, SMI defines a common standard that can be implemented by a variety of service mesh projects and vendors.\n\nLike standards before SMI, consistent APIs inspire confidence in infrastructure stability, community-managed APIs assuage technology and vendor lock-in concerns, and steward the resounding of core use cases, resulting in streamlining the smaller, but critical-to-users, subset of capabilities offered across the [service mesh landscape](https://layer5.io/landscape).\n\nMeshery and SMI are aligned on common goals of getting users started quickly, understanding that users want service mesh technology, but have questions as to which service mesh use, how, and when to get started through a common interface. Meshery‚Äôs playground capabilities quick provision a variety of service meshes and reduce time to value and time to understanding for those adopting a service mesh.\n\nAs a multi-mesh manager, Meshery, understands that each service mesh has it own strengths. SMI intends to allow for differentiation by service mesh providers, at the same time providing interoperability between service meshes and their surrounding tooling. As a management plane, Meshery enhances networking intelligence in a multi-mesh way, encouraging users to expect more from their infrastructure. Meshery exposes each service mesh‚Äôs differentiated capabilities.\n\nSMI‚Äôs aim for consistent APIs facilitates Meshery‚Äôs same goals, allowing for users and tools to flourish. As SMI unveils today, so does Meshery‚Äôs compatibility. Try out [Meshery and SMI](https://layer5.io/meshery) today!\n\n\n</BlogWrapper>\n","frontmatter":{"title":"A Standard Interface for Service Meshes","type":"Blog","technology":null,"product":"Service Mesh Landscape","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRigCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSPAAAAABkCvbtmlb/VqxbSOyrejWjWwbL7Nt27Zt27Zt+81g6xciYgIwWHbj780KDFaIsqqqSMWibwxwU+XOx0cq/WQ58Evlb3iQoq9sdADOqJxHOVjWWACWexS/sxQjZLk5YLVZJq6/siEOMBkri8wA6+3/e6FuMknmmgK2u/93oG46Q2aaAnb7/zejeUwmmwAuz//VAeS/yYV9MlHhdKs3QPT7zxlgOkummaAZ//GxH4DJVJltqpb0+YEPqiYTZIGZIu3rXU+0R8mD69evX/9xyw29p0U1DfWoSOCQWgLYFNrApycGmqUNigoM2PdxQF2PXkNWUDggEgEAALAGAJ0BKhQAFgA+0VikTSglI6IoDVEAGglsALsvsXoFytSAuzn9ZiQA9nb1UH773JB1ZQmv/+DfOndma9wAAPWKbXfbscu7ED8PNnaio58XsbOOx256LmPVRADnEPF+551VhKdW8r+iWIf2dL6oQLxgUOFBuAuFZfQ14oFo5CDsfZzHKMRan9atM8e5a09UzuBGXaFacdxsJ+X+HLb5fQSlSqpgKCtxzljACQCnWgckQVt863w//zUWqAi28GMv+MPKRx/YyAKGyI/UbWDadMOGwB1bHShhhupziJrW1skC4BbbgSmFR+9b9tjvTQwxiwWMLGwyPKtnui1LQUa/DziIq9WLCOvg++O9V9Uk1OsQAAA="},"images":{"fallback":{"src":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp","srcSet":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp 515w","sizes":"100vw"},"sources":[]},"width":1,"height":1.1242718446601943}},"extension":"webp","publicURL":"/static/8b3b9d5daf662a9f37debc294ba46cf2/smi-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRigCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSPAAAAABkCvbtmlb/VqxbSOyrejWjWwbL7Nt27Zt27Zt+81g6xciYgIwWHbj780KDFaIsqqqSMWibwxwU+XOx0cq/WQ58Evlb3iQoq9sdADOqJxHOVjWWACWexS/sxQjZLk5YLVZJq6/siEOMBkri8wA6+3/e6FuMknmmgK2u/93oG46Q2aaAnb7/zejeUwmmwAuz//VAeS/yYV9MlHhdKs3QPT7zxlgOkummaAZ//GxH4DJVJltqpb0+YEPqiYTZIGZIu3rXU+0R8mD69evX/9xyw29p0U1DfWoSOCQWgLYFNrApycGmqUNigoM2PdxQF2PXkNWUDggEgEAALAGAJ0BKhQAFgA+0VikTSglI6IoDVEAGglsALsvsXoFytSAuzn9ZiQA9nb1UH773JB1ZQmv/+DfOndma9wAAPWKbXfbscu7ED8PNnaio58XsbOOx256LmPVRADnEPF+551VhKdW8r+iWIf2dL6oQLxgUOFBuAuFZfQ14oFo5CDsfZzHKMRan9atM8e5a09UzuBGXaFacdxsJ+X+HLb5fQSlSqpgKCtxzljACQCnWgckQVt863w//zUWqAi28GMv+MPKRx/YyAKGyI/UbWDadMOGwB1bHShhhupziJrW1skC4BbbgSmFR+9b9tjvTQwxiwWMLGwyPKtnui1LQUa/DziIq9WLCOvg++O9V9Uk1OsQAAA="},"images":{"fallback":{"src":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp","srcSet":"/static/8b3b9d5daf662a9f37debc294ba46cf2/c84b8/smi-logo.webp 515w","sizes":"100vw"},"sources":[]},"width":1,"height":1.1242718446601943}},"extension":"webp","publicURL":"/static/8b3b9d5daf662a9f37debc294ba46cf2/smi-logo.webp"}},"fields":{"slug":"/blog/announcements/a-standard-interface-for-service-meshes"}},{"id":"6fadac46-717e-5a00-bc1a-2f93bba892c9","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\n\nimport quickActionsPNG from \"./quick-actions-designs.png\";\nimport importDesignButtonPNG from \"./import-button.png\";\nimport importDesignPanelPNG from \"./import-designs-panel.png\";\nimport renderedDesignPNG from \"../../../../assets/images/kanvas/gifs/rendered-design.webp\";\nimport designPannelOpener from \"./designs-panel-opener.png\";\nimport designerDockPNG from \"./designer-dock.png\";\nimport catalogGIF from \"../../../../assets/images/kanvas/gifs/catalog.gif\";\nimport publishToCatalogGIF from \"./publish-to-catalog.gif\";\nimport getStartedWithDesignerGIF from \"../../../../assets/images/kanvas/gifs/start-from-scratch.gif\";\n\n<BlogWrapper>\n\n### What is the Kanvas Catalog?\n\n<Link to=\"/cloud-native-management/catalog\">Kanvas Catalog</Link> is a hub for sharing and discovering best practices, reusable templates, and operational patterns for Kubernetes and cloud-native infrastructure. It's like a marketplace where you can find and contribute pre-built infrastructure configurations and operational views. The Catalog is a part of the Kanvas platform, which is a comprehensive suite of tools for managing cloud-native infrastructure.\n\n<div className=\"note\"> <a href=\"https://cloud.layer5.io/catalog\">Explore the catalog</a></div>\n\n### What can you find in the Catalog?\n\n- Design Patterns: Ready-made blueprints for common infrastructure and application architectures. These patterns can save you significant time and effort in designing your deployments.  \n- Filters and Applications: Pre-configured filters for Envoy proxies, WebAssembly filters, and complete application deployments.\n- Meshery Designs: Share and reuse your own Meshery configurations, making it easier to collaborate and standardize your deployments.  \n- Meshery Models: Share and reuse your own Meshery models, making it easier to collaborate and standardize your component library.\n\n#### Why is the Catalog useful?\n\n- Accelerated Development: Leverage existing patterns to jumpstart your projects and avoid reinventing the wheel.\n- Community Knowledge: Benefit from the collective experience of the Layer5 community and industry best practices.  \n- Standardization: Promote consistency and reduce errors by using predefined configurations.\n- Collaboration: Share your own designs and contribute to the growing collection of patterns.\n\n### How can you contribute to the Catalog?\n\nYou can contribute to the Catalog by creating high-quality starter templates and publishing designs for the community to use in various ways. You can also climb the leaderboard by having your designs cloned, downloaded, or viewed the most. Follow the instructions below to get started with your designs.\n\n#### Create or Import a Design\nBegin by creating a new design from scratch, using existing design patterns and templates from catalog:\n\n**From Scratch**:\n\n- Open the Designs panel, Select and arrange components from the Designer Dock on the Kanvas, and customize with connections, labels, and properties.\n  <img src={getStartedWithDesignerGIF} />\n\n**From a Template**:\n\n- Start from a pre-built template or clone an existing design from the Catalog. This allows you to build on established designs for a quicker start.\n  <img src={catalogGIF} />\n\n**Import a Design**: \n\n\n-   Access the Kanvas Designer and select the \"Import\" button in the left Designs panel. Import your own designs from local filesystem or from a remote URL directly into the Catalog. Upload a file or provide a URL for Docker Compose, Helm Charts, Meshery Designs or Kubernetes Manifests. Choose to either import as new or merge into current design that you have open in Kanvas.\n    <img src=\"/blog/2024/11-05-what-is-the-kanvas-catalog/import-design-gif.gif\" />\n\nKanvas will convert these into a usable design based on their configurations.\n   \n<img src={renderedDesignPNG} />\n\n\n#### Publish a Design\nMake your designs accessible to others by publishing them in the Catalog:\n\n- In the designs panel, locate your design and hover over it to access quick actions. Select the info button (marked with an \"i\") and add any necessary details for the review process, such as relevant technologies, descriptions, and considerations and click Publish button. Once approved by the Maintainers, your design becomes available to the broader community in Kanvas catalog.\n<img src={publishToCatalogGIF} />\n\n\n#### Share your designs\nShare your designs with your team members and effortlessly collaborate on designing and operating multi-cloud and Kubernetes native infrastrcutre with a seamless, built-in review mechanism.\n\n</BlogWrapper>\n\n","frontmatter":{"title":"What is the Kanvas Catalog?","type":"Blog","technology":null,"product":"Kanvas","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRhIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEQAAQUxQSKkAAAABgGJt27LowaNbssahwRrcEtGdSOSQIEkjORvwcfem0WcF7u4+v60gIiYA6C0uEF4uA1B1TRHCmjk+kPIZiamzdmBMPb20TLStb0E6ovN4PB6Xy/6vaEEQSJrSJNU58/Dm0m8DABhWfm+1bj7/PFpdXV09/Pzz4pPhp2+/Po4IXQmrv+a4u0SGEK1UKpUM8kRK+NdL5PVg/+9bIqSfqXgpvhD7eHt7eywAAFZQOCBCAAAA0AMAnQEqFAASAD7RWKRLqCUjobAIAQAaCWkAyNQeY38FvWo8CqcAAP7MMmcL5IJfZ+BDUHwdL9Sr1z+PKMl+sAAA"},"images":{"fallback":{"src":"/static/c8a87ce46229ada52dd6d0e230a6a2fa/d8672/catalog2.webp","srcSet":"/static/c8a87ce46229ada52dd6d0e230a6a2fa/d8672/catalog2.webp 131w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8931297709923663}},"extension":"webp","publicURL":"/static/c8a87ce46229ada52dd6d0e230a6a2fa/catalog2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkQBAABXRUJQVlA4WAoAAAAQAAAAEwAAEQAAQUxQSKkAAAABgGJt27LowaNbssahwRrcEtGdSOSQIEkjORvwcfem0WcF7u4+v60gIiYA6C0uEF4uA1B1TRHCmjk+kPIZiamzdmBMPb20TLStb0E6ovN4PB6Xy/6vaEEQSJrSJNU58/Dm0m8DABhWfm+1bj7/PFpdXV09/Pzz4pPhp2+/Po4IXQmrv+a4u0SGEK1UKpUM8kRK+NdL5PVg/+9bIqSfqXgpvhD7eHt7eywAAFZQOCB0AAAA0AMAnQEqFAASAD7RWqVNKCUjojAYCAEAGglmALT5/+AeevckfuvAAP51XEgucmKvHZGWEWs8Mb3u1efswP1F3/eU59Fb1D/vRIf5KiZ80HmT1+tHi54a9ZG43yJDbkNHEbBww+erZSTO8RNDq1SNvgXAwAA="},"images":{"fallback":{"src":"/static/90d5ea7372a7acb320174abbb6fd7dc6/d8672/catalog.webp","srcSet":"/static/90d5ea7372a7acb320174abbb6fd7dc6/d8672/catalog.webp 131w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8931297709923663}},"extension":"webp","publicURL":"/static/90d5ea7372a7acb320174abbb6fd7dc6/catalog.webp"}},"fields":{"slug":"/blog/kanvas/what-is-the-kanvas-catalog"}},{"id":"89dcc3da-3c78-58ea-bd12-4386b28da209","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport { BlockquoteAlt } from \"../../../../reusecore/Blockquote/Blockquote-alt-style\";\n\n<BlogWrapper>\nWhile building a Docker image for one of <Link to=\"/projects\">Layer5's open source projects</Link>, I ran into a build warning in one of the multi-stage Dockerfiles. Up to this point, while creating container images, I hadn't paid attention to a particular feature of `docker build`: <i><a href=\"https://docs.docker.com/reference/build-checks/\">build checks</a></i>. I had otherwise overlooked warnings and informational notices that were lost among the fray of docker build log lines. I've stopped ignoring them, however. In this post, I'll touch upon a handful of the more common build warnings, delve into the importance of these checks, and explore how and why to address each. But, first...\n\n<BlockquoteAlt\n  style={{ width: \"100%\" }} person=\"Lee Calcote\" quote=\"Build checks are your Dockerfile linter.\" />\n\n###  Why Use Docker Build Checks?\n\nNow, of course we're aware that `docker build` is a bread and butter command (very commonplace), however, if you're like me, you might have overlooked the `--check` flag. Think of build checks as a linter for your Dockerfile, and as it turns out, build checks are a valuable tool for validating your Dockerfile and build options (flags) against established best practices. Build checks help you identify potential issues early on, too, which I've come to appreciate. In fact, whereas am occassionally annoyed by overzealous linting rules, in general, I've turned the corner with lint checks as when you're maintaining large codebases with a couple thousand contributors, it becomes essential to enforce some uniformity and idiomatic coding. \n\nThey analyze your build configuration and provide feedback on potential problems, such as:\n\n* **Inefficiencies:**  Checks can identify unnecessary layers or overly large images, helping you optimize for size and performance.\n* **Security risks:**  They can flag potential security vulnerabilities, like using outdated base images or insecure commands.\n* **Maintainability issues:** Checks can highlight inconsistencies and deviations from best practices, improving the readability and maintainability of your Dockerfiles.\n\n### Under the Hood of Build Checks\n\nIntroduced in Dockerfile 1.8, build checks are integrated into the build process itself. When you invoke a build with the `--check` flag, Docker analyzes your Dockerfile and build options *before* executing any build steps. This pre-emptive analysis allows for early detection of potential issues, saving you time and resources.\n\nDocker employs a rule-based system to perform these checks. Each rule targets a specific aspect of your Dockerfile, such as image size, security practices, or Dockerfile syntax. These rules are continuously updated to reflect evolving best practices and address new vulnerabilities.\n\nAs you familiarize yourself with build checks, you'll notice that they are categorized into three levels, which are pretty self-evident, but worth noting, so that you can prioritize your remediation efforts. These levels are:\n\n* **Errors:**  These are critical issues that prevent the build from completing successfully. Errors must be resolved before you can proceed with the build.\n* **Warnings:**  Warnings indicate potential problems that don't halt the build but should be addressed to ensure best practices.\n* **Info:**  Informational messages provide additional context or suggestions for improving your Dockerfile. While not critical, acting on these messages can enhance your Dockerfile's quality.\n\n## Common Warnings and Remediation\n\nBefore we dive into some common warnings and how to address them, let's review how to run build checks on a Dockerfile.\n#### Running Build Checks\n\nTo run build checks, simply use the `--check` flag with your `docker build` command:\n\n```bash\ndocker build --check .\n```\n\nYes, quite straightforward. This command triggers build checks for the Dockerfile in the current directory. If any issues are detected, Docker will display the corresponding warnings or errors.\n\nNow, we're ready to explore some frequently encountered warnings and how to address them. Here are some of the warnings that I've run into, what they mean, and how to fix them:\n\n### 1. FromAsCasing\n\n\n- **Warning:** `WARN: FromAsCasing: 'as' and 'FROM' keywords' casing do not match`\n- **Explanation:** This warning occurs when the `FROM` and `AS` keywords in a multi-stage build have different casing (e.g., `FROM` and `as`). While Docker allows both uppercase and lowercase, mixing casing can hinder readability. Consistency in casing enhances readability and maintainability, making your Dockerfile easier to understand for both yourself and collaborators.\n- **Remediation:**  Ensure consistent casing for `FROM` and `AS` keywords throughout your Dockerfile.\n\n```docker\n# Incorrect\nFROM ubuntu:latest as builder\n\n# Correct\nFROM ubuntu:latest AS builder\n```\n\n### 2. LatestType\n\n* **Warning:** `WARN: LatestType: 'latest' tag used for base image`\n* **Explanation:** Using the `latest` tag can lead to unpredictable builds since the base image may change unexpectedly. Pinning to specific tags ensures reproducible builds, preventing unexpected behavior due to changes in the base image. This is crucial for production environments where stability is paramount.\n* **Remediation:**  Specify a specific tag for your base image to ensure consistency and reproducibility.\n\n```dockerfile\n# Incorrect\nFROM ubuntu:latest\n\n# Correct\nFROM ubuntu:22.04\n```\n\n### 3. AptGetNoInstallRecommends\n\n* **Warning:** `WARN: AptGetNoInstallRecommends: 'apt-get install' with no ' --no-install-recommends' flag`\n* **Explanation:**  Installing recommended packages can increase image size and potentially introduce unnecessary dependencies. Recommended packages often include extra dependencies that bloat your image size. This can lead to increased storage costs, slower downloads, and potentially longer build times.\n* **Remediation:**  Use the `--no-install-recommends` flag with `apt-get install` to avoid installing recommended packages.\n\n```dockerfile\n# Incorrect\nRUN apt-get update && apt-get install -y package-name\n\n# Correct\nRUN apt-get update && apt-get install -y --no-install-recommends package-name\n```\n\n### 4. RunCommandWithNoExecForm\n\n* **Warning:** `WARN: RunCommandWithNoExecForm: 'RUN' command with no 'exec' form`\n* **Explanation:** Using the exec form (`RUN [\"executable\", \"param1\", \"param2\"]`) for RUN commands is generally more efficient and avoids potential issues with shell interpretation. The exec form provides better performance and avoids potential shell injection vulnerabilities by directly executing the command without shell processing.\n* **Remediation:** Use the exec form for `RUN` commands whenever possible.\n\n```dockerfile\n# Incorrect\nRUN apt-get update && apt-get install -y package-name\n\n# Correct\nRUN [\"apt-get\", \"update\"]\nRUN [\"apt-get\", \"install\", \"-y\", \"--no-install-recommends\", \"package-name\"]\n```\n\n### 5. RedunantAptUpdate\n\n* **Warning:** `WARN: RedundantAptUpdate: 'apt-get update' found in multiple RUN instructions`\n* **Explanation:** Running `apt-get update` multiple times within a Dockerfile is inefficient. Each `apt-get update` fetches package information from repositories. Repeating this unnecessarily consumes bandwidth and increases build time.\n* **Remediation:**  Combine `apt-get update` with the subsequent `apt-get install` command in a single `RUN` instruction.\n\n```dockerfile\n# Incorrect\nRUN apt-get update\nRUN apt-get install -y package-name\n\n# Correct\nRUN apt-get update && apt-get install -y package-name\n```\n\nThese are just the checks that I ran into. See the full list of available checks by running `docker build --help` or visiting the [official documentation](https://docs.docker.com/reference/build-checks/).\n\n## Beyond the Build Check Basics\n\nNow, that you've gotten started with Dockerfile optimatization, you can further customize build checks to suit your needs. Know that you're not limited to just enabling or disabling all checks, but that Docker offers granular control, allowing you to:\n\n* **Skip specific checks:**  If a particular check isn't relevant to your use case, you can skip it using the `--check=rule1,rule2,!rule3` syntax. This enables `rule1` and `rule2` while skipping `rule3`.\n* **Fail on warnings:** By default, warnings don't halt the build process. However, you can enforce stricter compliance by using the `--fail-on=warn` flag, ensuring any warning triggers a build failure.\n* **Explore experimental checks:**  Push the boundaries with experimental checks by using the `--check=experimental` flag. These checks offer a glimpse into future best practices and can help you stay ahead of the curve.\n\nBuild checks are not just about fixing warnings; they are about proactively adopting best practices. Up your Dockerfile game with these additional tips:\n\n* **Embrace multi-stage builds:**  Leverage multi-stage builds to create smaller, more efficient images by separating build-time dependencies from runtime essentials.\n* **Utilize a `.dockerignore` file:** Exclude unnecessary files from your build context to reduce image size and speed up builds.\n* **Order your instructions strategically:** Place frequently changing instructions towards the end of your Dockerfile to take advantage of Docker's layer caching.\n\nBy understanding the mechanics of build checks and actively addressing the warnings, you can unlock the full potential of Docker and build robust, efficient, and secure containerized applications.\n</BlogWrapper>","frontmatter":{"title":"Docker Build Check Failures","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRiwCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSAMBAAABgGvbtrHn/LHt5Alc2a4yUtl2OrW2bVe2+dtWFTuljd/f9woRMQGg1K1bvB0KKM152EYezgtFGnb4CDfchSKFtzLGW+mOqSwxReDMX5jhLjxuDXK2bFVB0c4Gd4/US8T1NiIIoJ73ZHCJDWxys6oIAb6JdXPYysU296jabqKTm2jXh61sWk40RkEDFrCkPiw5Infp/Vsi6QAAv2Or/lH26pjAqfNNohipZtEkaXZY4c7jL54lyg8OJU+SBdBL50kQvsX8SSQHBS13EsTgXo6VoH0HgApUJACIQlUMAOafKB4MAADqEP3NOYKiJg6JJBuUG86oukoBhAHT57//t0uJWgAAAFZQOCACAQAAEAYAnQEqFAAWAD7RXKZOqCUjIigKqQAaCWwAnTMYL0EzOEYzCUcfGIl3ENai4eFZQu+1MxBrwrAAAP6e2afMPBN+4pGaascUU4u+Q/nINgyrLk2RBNA9vvzhOtWcx2DZE3iPefuoTrIDZcltVH/7R/zVPJLZmhHo6jeqvnraJOwL3nhwxW7mjyuSMBjfIgtbZ8WFXngRTltsvvsMDS5JA9On6QWnBP68Li0bPT0OAJxnEmf3+/qYxHOP+O9KSAEJU2QUNkHP7rG0w9LJx+xRksEQryQ4/yFpjym1b6KAux8wiHfr/5hPUR1pCZgUMmu3K3M4BHbdGETzGS3gItK+SwAA"},"images":{"fallback":{"src":"/static/2a7dde65e579f386ecbed3f2fc4606ac/ad7cd/docker-extension-meshery-logo.webp","srcSet":"/static/2a7dde65e579f386ecbed3f2fc4606ac/ad7cd/docker-extension-meshery-logo.webp 363w","sizes":"100vw"},"sources":[]},"width":1,"height":1.0853994490358125}},"extension":"webp","publicURL":"/static/2a7dde65e579f386ecbed3f2fc4606ac/docker-extension-meshery-logo.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRiwCAABXRUJQVlA4WAoAAAAQAAAAEwAAFQAAQUxQSAMBAAABgGvbtrHn/LHt5Alc2a4yUtl2OrW2bVe2+dtWFTuljd/f9woRMQGg1K1bvB0KKM152EYezgtFGnb4CDfchSKFtzLGW+mOqSwxReDMX5jhLjxuDXK2bFVB0c4Gd4/US8T1NiIIoJ73ZHCJDWxys6oIAb6JdXPYysU296jabqKTm2jXh61sWk40RkEDFrCkPiw5Infp/Vsi6QAAv2Or/lH26pjAqfNNohipZtEkaXZY4c7jL54lyg8OJU+SBdBL50kQvsX8SSQHBS13EsTgXo6VoH0HgApUJACIQlUMAOafKB4MAADqEP3NOYKiJg6JJBuUG86oukoBhAHT57//t0uJWgAAAFZQOCACAQAAEAYAnQEqFAAWAD7RXKZOqCUjIigKqQAaCWwAnTMYL0EzOEYzCUcfGIl3ENai4eFZQu+1MxBrwrAAAP6e2afMPBN+4pGaascUU4u+Q/nINgyrLk2RBNA9vvzhOtWcx2DZE3iPefuoTrIDZcltVH/7R/zVPJLZmhHo6jeqvnraJOwL3nhwxW7mjyuSMBjfIgtbZ8WFXngRTltsvvsMDS5JA9On6QWnBP68Li0bPT0OAJxnEmf3+/qYxHOP+O9KSAEJU2QUNkHP7rG0w9LJx+xRksEQryQ4/yFpjym1b6KAux8wiHfr/5hPUR1pCZgUMmu3K3M4BHbdGETzGS3gItK+SwAA"},"images":{"fallback":{"src":"/static/2a7dde65e579f386ecbed3f2fc4606ac/ad7cd/docker-extension-meshery-logo.webp","srcSet":"/static/2a7dde65e579f386ecbed3f2fc4606ac/ad7cd/docker-extension-meshery-logo.webp 363w","sizes":"100vw"},"sources":[]},"width":1,"height":1.0853994490358125}},"extension":"webp","publicURL":"/static/2a7dde65e579f386ecbed3f2fc4606ac/docker-extension-meshery-logo.webp"}},"fields":{"slug":"/blog/docker/docker-build-check-failures"}},{"id":"748ec643-815e-5e49-8df6-58e257e9bdc5","body":"Join the Meshery project office hours at KubeCon North America 2023 from 6th to 9th November, 2023 and get introduced to the cloud native management plane and to its open source maintainers.\n\n","frontmatter":{"title":"KubeCon + CloudNativeCon North America Chicago 2023","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmoAAABXRUJQVlA4IF4AAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQAAKVUVi2o0E/RBAAAD+6OwHbusRM21Xmi3Wvp1u+KBhKwaJ72MhQ8JdpkdPj/natj5Lrx3vKRjldF9kuVsEqLvPgAAA"},"images":{"fallback":{"src":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp","srcSet":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/7513b/kubeconNA2023.webp 750w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/317ed/kubeconNA2023.webp 1080w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/kubeconNA2023.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmoAAABXRUJQVlA4IF4AAACwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQAAKVUVi2o0E/RBAAAD+6OwHbusRM21Xmi3Wvp1u+KBhKwaJ72MhQ8JdpkdPj/natj5Lrx3vKRjldF9kuVsEqLvPgAAA"},"images":{"fallback":{"src":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp","srcSet":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/7513b/kubeconNA2023.webp 750w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/317ed/kubeconNA2023.webp 1080w,\n/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/31cc3/kubeconNA2023.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5233333333333333}},"extension":"webp","publicURL":"/static/ab738b5d2dc3e9d6abb6c38a1e15d10b/kubeconNA2023.webp"}},"fields":{"slug":"/community/events/kubecon-cloudnativecon-north-america-chicago-2023"}},{"id":"38980f7f-ff6a-5fc1-85a3-1270d326537f","body":"\n<h3>Multiplayer Istio: Collaborative WASM Plugins with Intel and Layer5</h3>\n<br/>\nJoin Layer5 and Intel at the Istio conference on Monday, Sept. 25th to Tuesday, Sep. 26th. IstioCon is a 100% virtual event that is designed to connect community members across the globe with Istio and the Istio ecosystem.\n<a href=\"https://cvent.me/LnMXkN\"> Register Here </a> \n","frontmatter":{"title":"IstioCon Virtual 2023","type":"Event","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB6UlEQVR42mWQ60/TYBTG+5+ZkADDSCJiFFGcFyDICo44p4BM7ohKIvjBxBAlfiMhrLvJtg4YC5h4nZBtzTArILCZQcc60o12beezlRkT3jzvyXNOzu+cvC9RKB9eEE9EWfOKqhal/BfVgqoWyl7V2ghctZT8YJKB4L5GFs4cYGfLxD/3Zm7j0dQazHFW+hk9ELL56M5RmOUOUlkunfN92Y3tptPHIsefJFPCKaztCUaTLcOLlQbqO5MUJfntfOj17Pqsd/ODk5mmQjMOxr7Cfg79QX3aGn5vj2BBCVaK8GowPj7zbeTd108bcaS/fh9FWG4nkWH3eGYrtRXnwzEutsdH2NT2fmY7kcGCIpwTZSgvK+HYYeJQgBFykpRXZEWFh0EUyymiJCkaAhH6p/RNC339iad5aNH0atX4MkA+9yO2Di/pLXT7M79xIoC6Ydx/b2y588VK10TAPLnWNrrcZPES51rmdCRVZ3LVdjnuDPhaR5Zu9dN4f53JifrV7oW7gz6kGN3U57094LvR52nodutIG0CimqRqOm0XjI5ao+PSQ9dl80cAVx4vYNzFB856s0vfTzf2uht63Nd63GirMlAVbfNVBitAAglU2W7FV1eTNoys6TjV+ft28I29HsAwug4bGkptlEb9BRHLxTg09CrhAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/24c181b970a98d05761e711cb086f08f/0ccb9/IstioCon2023.png","srcSet":"/static/24c181b970a98d05761e711cb086f08f/9e217/IstioCon2023.png 750w,\n/static/24c181b970a98d05761e711cb086f08f/e4953/IstioCon2023.png 1080w,\n/static/24c181b970a98d05761e711cb086f08f/0ccb9/IstioCon2023.png 1200w","sizes":"100vw"},"sources":[{"srcSet":"/static/24c181b970a98d05761e711cb086f08f/7513b/IstioCon2023.webp 750w,\n/static/24c181b970a98d05761e711cb086f08f/317ed/IstioCon2023.webp 1080w,\n/static/24c181b970a98d05761e711cb086f08f/31cc3/IstioCon2023.webp 1200w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5233333333333333}},"extension":"png","publicURL":"/static/24c181b970a98d05761e711cb086f08f/IstioCon2023.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB6UlEQVR42mWQ60/TYBTG+5+ZkADDSCJiFFGcFyDICo44p4BM7ohKIvjBxBAlfiMhrLvJtg4YC5h4nZBtzTArILCZQcc60o12beezlRkT3jzvyXNOzu+cvC9RKB9eEE9EWfOKqhal/BfVgqoWyl7V2ghctZT8YJKB4L5GFs4cYGfLxD/3Zm7j0dQazHFW+hk9ELL56M5RmOUOUlkunfN92Y3tptPHIsefJFPCKaztCUaTLcOLlQbqO5MUJfntfOj17Pqsd/ODk5mmQjMOxr7Cfg79QX3aGn5vj2BBCVaK8GowPj7zbeTd108bcaS/fh9FWG4nkWH3eGYrtRXnwzEutsdH2NT2fmY7kcGCIpwTZSgvK+HYYeJQgBFykpRXZEWFh0EUyymiJCkaAhH6p/RNC339iad5aNH0atX4MkA+9yO2Di/pLXT7M79xIoC6Ydx/b2y588VK10TAPLnWNrrcZPES51rmdCRVZ3LVdjnuDPhaR5Zu9dN4f53JifrV7oW7gz6kGN3U57094LvR52nodutIG0CimqRqOm0XjI5ao+PSQ9dl80cAVx4vYNzFB856s0vfTzf2uht63Nd63GirMlAVbfNVBitAAglU2W7FV1eTNoys6TjV+ft28I29HsAwug4bGkptlEb9BRHLxTg09CrhAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/24c181b970a98d05761e711cb086f08f/0ccb9/IstioCon2023.png","srcSet":"/static/24c181b970a98d05761e711cb086f08f/9e217/IstioCon2023.png 750w,\n/static/24c181b970a98d05761e711cb086f08f/e4953/IstioCon2023.png 1080w,\n/static/24c181b970a98d05761e711cb086f08f/0ccb9/IstioCon2023.png 1200w","sizes":"100vw"},"sources":[{"srcSet":"/static/24c181b970a98d05761e711cb086f08f/7513b/IstioCon2023.webp 750w,\n/static/24c181b970a98d05761e711cb086f08f/317ed/IstioCon2023.webp 1080w,\n/static/24c181b970a98d05761e711cb086f08f/31cc3/IstioCon2023.webp 1200w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5233333333333333}},"extension":"png","publicURL":"/static/24c181b970a98d05761e711cb086f08f/IstioCon2023.png"}},"fields":{"slug":"/community/events/istiocon-virtual-2023"}},{"id":"793e68f1-347d-50cd-8b2d-1bbe47cee53f","body":"\n\n<h2>Kickstarting Open Source with Layer5</h2>\nEmbark on your Open Source journey with an insightful session led by Layer5's community member Samyak . Joining him is  Yash, our Intern, MeshMate and a valued member of the community. This dynamic duo will guide you through the realms of open-source, while providing valuable insights about Layer5's projects. Don't let this opportunity pass you by ‚Äì seize the chance to embark on your open source adventure with us and explore the world of Layer5.\n<a href=\" https://lu.ma/z5sjbqws\">Register</a> for the event and join us in a live session on August 19th at 7 PM IST on  <a href=\"https://discord.gg/newton-school-862937560359108609\"> Newton's school  discord</a> channel","frontmatter":{"title":"Kickstarting Open Source with Layer5","type":"Event","technology":null,"product":"Kanvas, Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrwAAABXRUJQVlA4ILAAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJQBdgZYJ0UL0dJPQ55GVV61e6sNkMjSQ0AAD+9JWNPseYUFdVro4E2dXDukrpVLHLnhPHmHEsQ8lM3LPq45c3MmtyAr53nEQd2Copaz1nlF33HBIRq765IgBLoGEQFH+qzeWebh+ju1FV5gFDQ31pwzggVF/pu/aTYErPqGKvSXvK2uvScvqsoOTHaVWzGi4IIEfTgwAAAA=="},"images":{"fallback":{"src":"/static/612139d55e7911e2e80f48a6c66530f5/4f506/kickstarting_your_open_source_with_layer5.webp","srcSet":"/static/612139d55e7911e2e80f48a6c66530f5/4f03f/kickstarting_your_open_source_with_layer5.webp 750w,\n/static/612139d55e7911e2e80f48a6c66530f5/4f506/kickstarting_your_open_source_with_layer5.webp 1080w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/612139d55e7911e2e80f48a6c66530f5/kickstarting_your_open_source_with_layer5.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRrwAAABXRUJQVlA4ILAAAAAwBQCdASoUABQAPtFgqU+oJSOiKAgBABoJQBdgZYJ0UL0dJPQ55GVV61e6sNkMjSQ0AAD+9JWNPseYUFdVro4E2dXDukrpVLHLnhPHmHEsQ8lM3LPq45c3MmtyAr53nEQd2Copaz1nlF33HBIRq765IgBLoGEQFH+qzeWebh+ju1FV5gFDQ31pwzggVF/pu/aTYErPqGKvSXvK2uvScvqsoOTHaVWzGi4IIEfTgwAAAA=="},"images":{"fallback":{"src":"/static/612139d55e7911e2e80f48a6c66530f5/4f506/kickstarting_your_open_source_with_layer5.webp","srcSet":"/static/612139d55e7911e2e80f48a6c66530f5/4f03f/kickstarting_your_open_source_with_layer5.webp 750w,\n/static/612139d55e7911e2e80f48a6c66530f5/4f506/kickstarting_your_open_source_with_layer5.webp 1080w","sizes":"100vw"},"sources":[]},"width":1,"height":1}},"extension":"webp","publicURL":"/static/612139d55e7911e2e80f48a6c66530f5/kickstarting_your_open_source_with_layer5.webp"}},"fields":{"slug":"/community/events/kickstarting-open-source-with-layer5"}},{"id":"02f9128f-4f23-5463-a389-60b4f69d7185","body":"\n\n<h2>Multiplayer Kubernetes: GitOps with Friends</h2>\nJoin Pranav Singh at KCD Chennai 2023 to witness firsthand how Meshery revolutionizes Kubernetes operations, enabling seamless orchestration across multiple environments made possible by GitOps principles and multi-user collaboration..","frontmatter":{"title":"KCD Chennai 2023","type":"Event","technology":null,"product":"Kanvas, Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABwAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJYgCdMoAEu0JkhAAA/vB1Y3qYd35+zf3TWIbZX2tP1sLiqtdtdz1BNFKNkO98MmVdc+hdz6lQLNnKb9UHD4AA"},"images":{"fallback":{"src":"/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png","srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/89ef0/kcd_chennai.png 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png 962w","sizes":"100vw"},"sources":[{"srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/4cace/kcd_chennai.webp 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/dc547/kcd_chennai.webp 962w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4563409563409564}},"extension":"webp","publicURL":"/static/f2a4ec0abd2656caffece99a892e808a/kcd_chennai.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABwAwCdASoUAAkAPtFUo0uoJKMhsAgBABoJYgCdMoAEu0JkhAAA/vB1Y3qYd35+zf3TWIbZX2tP1sLiqtdtdz1BNFKNkO98MmVdc+hdz6lQLNnKb9UHD4AA"},"images":{"fallback":{"src":"/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png","srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/89ef0/kcd_chennai.png 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/9c3e0/kcd_chennai.png 962w","sizes":"100vw"},"sources":[{"srcSet":"/static/f2a4ec0abd2656caffece99a892e808a/4cace/kcd_chennai.webp 750w,\n/static/f2a4ec0abd2656caffece99a892e808a/dc547/kcd_chennai.webp 962w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4563409563409564}},"extension":"webp","publicURL":"/static/f2a4ec0abd2656caffece99a892e808a/kcd_chennai.webp"}},"fields":{"slug":"/community/events/kcd-chennai-2023"}},{"id":"daac5707-325b-5bbb-bc64-edea287ef9dc","body":"\nJoin Lee Calcote and Nate Waddington in the upcoming Maintainer‚Äôs Circle special session and explore their insights, and experiences from their mentorship journey within the CNCF.","frontmatter":{"title":"May Maintainer's Circle 2023","type":"Event","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACvklEQVR42jWT208TURDG13cSSWmB7na7l5aWUqAshbIt0EJvQAEVCYaKCgFDFBU1Bi8JwWi864MaExWjCcZLojE+GWPiP6YvP2dreJicOTsz33zznVnF/f3pj/n9JcmPTxl5skNuxKVQyJHLDYkv57CLm80w5GYYlvtoPkc25zIieaNiwyNZycsyNVXl+FL9j+L8eI/y5ja+d/dR67O0+pvpTiWZqk1QmSgze6jG9EyVycliA6xSLYlfobMrRlBtQ9WDaLqKprU1Ykru9xda3j0ivL2JaYexLR1DzIoY6IZOV9xg0ImS7o8Q7ZCYKTlRA9PLsQ0xU+4WqtZOqVJEcW9cJNiXwJKPlhUWkBB9/Q5z83MsHlsgMzdNIGbRm0xQnigxOjZKdaKCk3YImzp2xGzUBkNBYVhGqRbyaMG2RsAUQMMMEYtFGBx0mJ+dxHHT6LZOh8TTAw550SvV10M0asokYSGhExFf8wArMrKnk4fu0fZGjlgaerITR4r3ttYougNoloGR6iae6GCtmiHZkyAc+T+uKc08hpq2Dyg01VB7A8zwNBRxW2Q098plXt95xNjSEs2iWWBhjv7DNe5m4nTms7RIU1um8eosIRTUApRr1X1AVRhKN+lqy8v5j0zh232G+/ge/itnaU4lCKzUMd++oLCzRWBjhRanG9vQCHsyHS4TuHSSwWc3UbyXCWqtDR1MYWJ73abL+J7exX/1PE0by/h7E7Qdncb3/B6+6+fwbZyifaCXqKxLT1YkkZU7+OEhxa+v5FFEw1BYbZg3uiqAmqxAa3eMpu3zqDsX0C8uY26cwNraxNq8Tns83ti7rnQK37XTHNh7gPL2Fv0/91Dq9cW/M7M1CrIOhfExOfPyp4hfGie7vkz+jNjaEoWVRYqry5RW18mXSpTH80wuzpN484Cub7vExIZ/ff77D6qzc9P/LlrQAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png","srcSet":"/static/2a4da6359a86759259487a68a8831202/0dee1/Maintainer-Circle.png 750w,\n/static/2a4da6359a86759259487a68a8831202/8beaa/Maintainer-Circle.png 1080w,\n/static/2a4da6359a86759259487a68a8831202/d079a/Maintainer-Circle.png 1366w,\n/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/2a4da6359a86759259487a68a8831202/a66aa/Maintainer-Circle.webp 750w,\n/static/2a4da6359a86759259487a68a8831202/65dd5/Maintainer-Circle.webp 1080w,\n/static/2a4da6359a86759259487a68a8831202/4fad6/Maintainer-Circle.webp 1366w,\n/static/2a4da6359a86759259487a68a8831202/c512e/Maintainer-Circle.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/2a4da6359a86759259487a68a8831202/Maintainer-Circle.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACvklEQVR42jWT208TURDG13cSSWmB7na7l5aWUqAshbIt0EJvQAEVCYaKCgFDFBU1Bi8JwWi864MaExWjCcZLojE+GWPiP6YvP2dreJicOTsz33zznVnF/f3pj/n9JcmPTxl5skNuxKVQyJHLDYkv57CLm80w5GYYlvtoPkc25zIieaNiwyNZycsyNVXl+FL9j+L8eI/y5ja+d/dR67O0+pvpTiWZqk1QmSgze6jG9EyVycliA6xSLYlfobMrRlBtQ9WDaLqKprU1Ykru9xda3j0ivL2JaYexLR1DzIoY6IZOV9xg0ImS7o8Q7ZCYKTlRA9PLsQ0xU+4WqtZOqVJEcW9cJNiXwJKPlhUWkBB9/Q5z83MsHlsgMzdNIGbRm0xQnigxOjZKdaKCk3YImzp2xGzUBkNBYVhGqRbyaMG2RsAUQMMMEYtFGBx0mJ+dxHHT6LZOh8TTAw550SvV10M0asokYSGhExFf8wArMrKnk4fu0fZGjlgaerITR4r3ttYougNoloGR6iae6GCtmiHZkyAc+T+uKc08hpq2Dyg01VB7A8zwNBRxW2Q098plXt95xNjSEs2iWWBhjv7DNe5m4nTms7RIU1um8eosIRTUApRr1X1AVRhKN+lqy8v5j0zh232G+/ge/itnaU4lCKzUMd++oLCzRWBjhRanG9vQCHsyHS4TuHSSwWc3UbyXCWqtDR1MYWJ73abL+J7exX/1PE0by/h7E7Qdncb3/B6+6+fwbZyifaCXqKxLT1YkkZU7+OEhxa+v5FFEw1BYbZg3uiqAmqxAa3eMpu3zqDsX0C8uY26cwNraxNq8Tns83ti7rnQK37XTHNh7gPL2Fv0/91Dq9cW/M7M1CrIOhfExOfPyp4hfGie7vkz+jNjaEoWVRYqry5RW18mXSpTH80wuzpN484Cub7vExIZ/ff77D6qzc9P/LlrQAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png","srcSet":"/static/2a4da6359a86759259487a68a8831202/0dee1/Maintainer-Circle.png 750w,\n/static/2a4da6359a86759259487a68a8831202/8beaa/Maintainer-Circle.png 1080w,\n/static/2a4da6359a86759259487a68a8831202/d079a/Maintainer-Circle.png 1366w,\n/static/2a4da6359a86759259487a68a8831202/afa5c/Maintainer-Circle.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/2a4da6359a86759259487a68a8831202/a66aa/Maintainer-Circle.webp 750w,\n/static/2a4da6359a86759259487a68a8831202/65dd5/Maintainer-Circle.webp 1080w,\n/static/2a4da6359a86759259487a68a8831202/4fad6/Maintainer-Circle.webp 1366w,\n/static/2a4da6359a86759259487a68a8831202/c512e/Maintainer-Circle.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/2a4da6359a86759259487a68a8831202/Maintainer-Circle.png"}},"fields":{"slug":"/community/events/may-maintainers-circle-2023"}},{"id":"4ab0cb85-e71e-5949-bae5-751a880027b3","body":"\nimport { Link } from \"gatsby\";\n\n  Join Layer5 in-person at <a href=\"https://www.meetup.com/docker-bangalore/events/288597531/\">Docker Community Meetup - Bengaluru</a> as\n  we share on the Meshery Docker Extension and how you can manage your cloud native applications using it.\n<h2>Take the Blinders off with Meshery Docker Extension</h2>\n\n\nManaging cloud native infrastructure becomes a nightmare with hundreds of distributed systems. Vectors like performance, and metrics are game changers but not precisely interpreted. <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> is here to empower engineers so they can extract more value from their infrastructure.\nWhat will you learn?\n<ul>\n<li>An introduction to basic concepts, architecture diagrams, and general ideas about the functioning of different components of <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link></li>\n<li>Performance Management and Metrics Intro, how to run performance tests, interpret the results, and metrics from Grafana and Prometheus.</li>\n<li>An introduction to service meshes, the concept of meshery adapters, provisioning of service meshes, sample applications and <Link to=\"/projects/service-mesh-interface-conformance\">SMI</Link> conformance tests.</li>\n<li><Link to=\"/cloud-native-management/meshery\">Meshery</Link> Configurations: Application, Patterns, Filters, Pattern configurator, ingestion of K8s YAMLs, Docker-Compose apps, helm charts.</li>\n<li>Introduction to <Link to=\"/cloud-native-management/kanvas\">Kanvas</Link>, the visual topology for your cloud native infrastructure.</li>\n<li><Link to=\"/programs/hacktoberfest\">Hacktoberfest</Link> participation for newcomers in the community, how to get started, open issues and how to engage in the community.</li>\n</ul>\n\n<b>Speakers:</b>\n\n<ul>\n  <li>\n    <Link to=\"/community/members/pranav-singh\">Pranav Singh</Link>\n  </li>\n</ul>\n\n<br />\n","frontmatter":{"title":"Hacktoberfest 2022: Docker Extensions Show-n-Tell","type":"Meetups","technology":null,"product":"Meshery Extensions","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZACsAB7HDon77geC0gAA/rPm3sGheniZTrUvmVzONKE9xhunSUPDjDF4UXsgsZpwmE0xL0R3lr138jrEu5bGEHDhQ9f7pqXCDz97Op2WX3py0n+n3N5aM7wSOsbepml7aIzIqrUGkivmMfIAAA=="},"images":{"fallback":{"src":"/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp","srcSet":"/static/208954253f8b2b5c47ccbe13a4d98acc/fdac4/dockerBengaluru.webp 750w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/0f929/dockerBengaluru.webp 1080w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/fc20e/dockerBengaluru.webp 1366w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5567708333333333}},"extension":"webp","publicURL":"/static/208954253f8b2b5c47ccbe13a4d98acc/dockerBengaluru.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJZACsAB7HDon77geC0gAA/rPm3sGheniZTrUvmVzONKE9xhunSUPDjDF4UXsgsZpwmE0xL0R3lr138jrEu5bGEHDhQ9f7pqXCDz97Op2WX3py0n+n3N5aM7wSOsbepml7aIzIqrUGkivmMfIAAA=="},"images":{"fallback":{"src":"/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp","srcSet":"/static/208954253f8b2b5c47ccbe13a4d98acc/fdac4/dockerBengaluru.webp 750w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/0f929/dockerBengaluru.webp 1080w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/fc20e/dockerBengaluru.webp 1366w,\n/static/208954253f8b2b5c47ccbe13a4d98acc/1d4e5/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5567708333333333}},"extension":"webp","publicURL":"/static/208954253f8b2b5c47ccbe13a4d98acc/dockerBengaluru.webp"}},"fields":{"slug":"/community/events/hacktoberfest-2022-docker-extensions-show-n-tell"}},{"id":"78276d2a-ad9d-5dbc-b7a2-17372e7e3866","body":"\nimport { Link } from \"gatsby\" ;\n\nJoin host Bret Fisher and guests <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> from Layer5 and <Link to=\"/community/members/nic-jackson\">Nic Jackson</Link> from HashiCorp at <a href=\"https://www.linkedin.com/events/servicemeshfordocker-withmesher6977705316406730752/about/\">DevOps and Docker Live Show</a> to see the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> in-action! Design and deploy your Docker Compose and Kubernetes apps on Docker Desktop or any remote cluster.\n\nThe Meshery extension transforms Docker Desktop into powerful cloud native infrastructure development environment in a box with Kubernetes and service mesh. Learn how to discover and model your cloud native deployments with <Link to=\"/cloud-native-management/kanvas\">Kanvas</Link>. Kanvas enables GitOps integrated, visual composition of your cloud native infrastructure. \n\nCan‚Äôt wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up and learn all about the <Link to=\"/docker-extension-meshery\">Meshery Docker Extension</Link> to make the most out of it.\n","frontmatter":{"title":"DevOps and Docker Live Show","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoAAAABXRUJQVlA4IHQAAABwAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJbAC7ABDQ3t6Pi0AA/rp9YKc2gqcg9rSeyinFhrntul+JsT2ClPzd5n1yupRrp4H+db6W3NB/OTUCcgNqiKE6hBlzd7cDJLFpP5N4KJvn6F5PC5cx+o7jogAAAA=="},"images":{"fallback":{"src":"/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp","srcSet":"/static/7cb9216652c98031d9a83ec6805fbec8/a66aa/docker-and-meshery-live-show.webp 750w,\n/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/7cb9216652c98031d9a83ec6805fbec8/docker-and-meshery-live-show.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoAAAABXRUJQVlA4IHQAAABwAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJbAC7ABDQ3t6Pi0AA/rp9YKc2gqcg9rSeyinFhrntul+JsT2ClPzd5n1yupRrp4H+db6W3NB/OTUCcgNqiKE6hBlzd7cDJLFpP5N4KJvn6F5PC5cx+o7jogAAAA=="},"images":{"fallback":{"src":"/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp","srcSet":"/static/7cb9216652c98031d9a83ec6805fbec8/a66aa/docker-and-meshery-live-show.webp 750w,\n/static/7cb9216652c98031d9a83ec6805fbec8/bde8a/docker-and-meshery-live-show.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/7cb9216652c98031d9a83ec6805fbec8/docker-and-meshery-live-show.webp"}},"fields":{"slug":"/community/events/devops-and-docker-live-show"}},{"id":"906e4f8a-1e43-5495-8947-d77d96f030b9","body":"\nimport { Link } from \"gatsby\";\n\nJoin Layer5 in-person at <a href=\"https://www.meetup.com/Docker-Bangalore/events/285342797/\">Docker Developer Community Meetup - Bengaluru</a> as we share on the Meshery Docker Extension and how you can manage your cloud native applications using it.\n\n<h2>Composing Cloud Native Infrastructure with Docker Desktop and Meshery</h2>\n\n\nThe Meshery Docker Extension‚Äôs ability to import Docker Compose apps, convert them to Kubernetes applications, and deploy them on any visually and collaboratively is a powerful enabler for microservices developers, who need to develop, test, and deploy their modern applications in the context of and compatibility with any Kubernetes cluster. Along with this, the extension can help you to:\n\n<ul>\n<li>Get Kubernetes support for your Docker Compose apps: Import your Docker Compose apps. Configure and deploy them to Kubernetes and any infrastructure with a Kubernetes Operator.</li>\n<li>Help you with single-click deployment of your infrastructure - Support of 250+ different cloud native infrastructure projects (including all the CNCF projects) at the fingertips of developers in connection with Docker Desktop‚Äôs ability to deliver Kubernetes locally.: Supports 10 different service meshes to the fingertips of developers in connection with Docker Desktop‚Äôs ability to deliver Kubernetes locally.</li>\n<li>Detection of Kubernetes environments: Scan your kubeconfigs and select your current Kubernetes environment. Switch from one environment to another.</li>\n</ul>\n\nThis talk can help the attendees to improve upon their K8s or Docker deployments as well as help them in managing different service meshes simultaneously. I have a pretty basic knowledge of cloud native stuff having worked with Kubernetes, Docker, Helm, and using some of the service meshes, trying them out for different stuff or applications. I have been using Docker Desktop for the past year and a half. I‚Äôm also a maintainer of Meshery and have contributed to several other open source projects.\nSpeakers:\n\n<ul>\n  <li>\n    <Link to=\"/community/members/adithya-krishna\">Aditya Krishna Sharma</Link>\n  </li>\n  <li>Karthik Ravishankar</li>\n</ul>\n","frontmatter":{"title":"Composing Cloud Native Infrastructure with Docker Desktop and Meshery","type":"Meetups","technology":null,"product":"Meshery Extensions","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRowAAABXRUJQVlA4IIAAAACwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBOgBCdX0ZZKDRXGgAD+kVVK+cYYGtSI2eVCoXTN6L8uXdp3bjwue79NZyzTm55fEyGTpK2kP7BTnsGl/E/IBPURHWhjV7gq3rMFHQKd6+wjuuDGhioNhvLyKngQcQg853NbgAAAAA=="},"images":{"fallback":{"src":"/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp","srcSet":"/static/b7199140cfc400f93faf5c264b9dbcb4/45f0d/dockerBengaluru.webp 750w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/3c63c/dockerBengaluru.webp 1080w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/04e2f/dockerBengaluru.webp 1366w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5583333333333333}},"extension":"webp","publicURL":"/static/b7199140cfc400f93faf5c264b9dbcb4/dockerBengaluru.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRowAAABXRUJQVlA4IIAAAACwAwCdASoUAAsAPtFWo0uoJKMhsAgBABoJQBOgBCdX0ZZKDRXGgAD+kVVK+cYYGtSI2eVCoXTN6L8uXdp3bjwue79NZyzTm55fEyGTpK2kP7BTnsGl/E/IBPURHWhjV7gq3rMFHQKd6+wjuuDGhioNhvLyKngQcQg853NbgAAAAA=="},"images":{"fallback":{"src":"/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp","srcSet":"/static/b7199140cfc400f93faf5c264b9dbcb4/45f0d/dockerBengaluru.webp 750w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/3c63c/dockerBengaluru.webp 1080w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/04e2f/dockerBengaluru.webp 1366w,\n/static/b7199140cfc400f93faf5c264b9dbcb4/82e13/dockerBengaluru.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5583333333333333}},"extension":"webp","publicURL":"/static/b7199140cfc400f93faf5c264b9dbcb4/dockerBengaluru.webp"}},"fields":{"slug":"/community/events/composing-cloud-native-infrastructure-with-docker-desktop-and-meshery"}},{"id":"7a338fb3-bc92-55f6-9da9-3c8a3d6817ec","body":"\nimport { Link } from \"gatsby\" ;\n\nWith a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Docker Desktop Extension for Meshery to deploy their service mesh of choice and test the performance of their SPIFFE and SPIRE-based identity solution.\n\nThe Meshery extension transforms Docker Desktop into powerful load generation utility, conveniently enables HPE engineers with the ability to deploy and configure any service mesh with a click of the button and invoke and control load-based performance tests from their desktop.\n\nCan‚Äôt wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up for our <Link to=\"/docker-extension-meshery\">beta program</Link> to get early access!\n\nRead the recap <Link to=\"/blog/docker/extending-docker-with-meshery-spire-and-istio\">blog</Link> post and find out more about <a href=\"https://layer5.io/docker-extension-meshery\">Docker Extension for Meshery</a>.","frontmatter":{"title":"DockerCon 2022: Lighting Talk in a dedicated community room","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnoAAABXRUJQVlA4IG4AAADQBACdASoUAAsAPtFWo0uoJKMhsAgBABoJaACdMoMYPX+z/4DzP8uhaTjalamYAAD+39z6kXh4RPs5dqtegOv3ZmBs7PK8A9ZCXZg/9Xqtx03qAbZmNZB1J3JyoGi/Gv/WFe+f4Vmcup7378AAAA=="},"images":{"fallback":{"src":"/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp","srcSet":"/static/2ca6501625e8174ab27c9f55d9c0cd08/8d8ff/HPE.webp 750w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/fc98a/HPE.webp 1080w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/1ab6d/HPE.webp 1366w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5604166666666667}},"extension":"webp","publicURL":"/static/2ca6501625e8174ab27c9f55d9c0cd08/HPE.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnoAAABXRUJQVlA4IG4AAADQBACdASoUAAsAPtFWo0uoJKMhsAgBABoJaACdMoMYPX+z/4DzP8uhaTjalamYAAD+39z6kXh4RPs5dqtegOv3ZmBs7PK8A9ZCXZg/9Xqtx03qAbZmNZB1J3JyoGi/Gv/WFe+f4Vmcup7378AAAA=="},"images":{"fallback":{"src":"/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp","srcSet":"/static/2ca6501625e8174ab27c9f55d9c0cd08/8d8ff/HPE.webp 750w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/fc98a/HPE.webp 1080w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/1ab6d/HPE.webp 1366w,\n/static/2ca6501625e8174ab27c9f55d9c0cd08/e2aba/HPE.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5604166666666667}},"extension":"webp","publicURL":"/static/2ca6501625e8174ab27c9f55d9c0cd08/HPE.webp"}},"fields":{"slug":"/community/events/dockercon-2022-lighting-talk-in-a-dedicated-community-room"}},{"id":"86f7ec68-6646-59ec-88e1-46ba1d1069ad","body":"\nimport { Link } from \"gatsby\" ;\n\nHashiCorp‚Äôs Consul service mesh offers unique functionality offered to its users. Using its visual designer, Kanvas, Meshery facilitates the developers full understanding of Consul‚Äôs differientiated capabilities, allowing developer‚Äôs to visually configure and deploy Consul-based deployments and their workloads.\n\nThe Meshery extension‚Äôs ability to import Docker Compose apps, convert them to Kubernetes applications, and deploy them on Consult service meshes is a powerful enabler for microservices developers, who need to dev, test, and deploy their modern applications in context of and compatibility with Consul service mesh.\n\nCan‚Äôt wait to get your hands on Docker Desktop for Meshery in the meantime? Sign up for our <Link to=\"/docker-extension-meshery\">beta program</Link> to get early access!\n\nRead the recap <Link to=\"/blog/docker/extending-the-docker-compose-experience-to-service-mesh\">blog</Link> post and find out more about <a href=\"https://layer5.io/docker-extension-meshery\">Docker Extension for Meshery</a>.","frontmatter":{"title":"DockerCon 2022: Lighting Talk on the main stage","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJaACdMoGv/gPM//6mqk4rNoAA/t/c+pF4gihmJJjlXBAZp3OCNsjjwXe6L1Kqtd5U9nHotvGQPEXE2M6ZjjMqBgRk4K3H2CE06QlcORybs1mjQAA="},"images":{"fallback":{"src":"/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp","srcSet":"/static/bd9364ba124a438c72a181924156cb71/b9516/Hashicorp.webp 750w,\n/static/bd9364ba124a438c72a181924156cb71/c4814/Hashicorp.webp 1080w,\n/static/bd9364ba124a438c72a181924156cb71/1ab6d/Hashicorp.webp 1366w,\n/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5609375}},"extension":"webp","publicURL":"/static/bd9364ba124a438c72a181924156cb71/Hashicorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRngAAABXRUJQVlA4IGwAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJaACdMoGv/gPM//6mqk4rNoAA/t/c+pF4gihmJJjlXBAZp3OCNsjjwXe6L1Kqtd5U9nHotvGQPEXE2M6ZjjMqBgRk4K3H2CE06QlcORybs1mjQAA="},"images":{"fallback":{"src":"/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp","srcSet":"/static/bd9364ba124a438c72a181924156cb71/b9516/Hashicorp.webp 750w,\n/static/bd9364ba124a438c72a181924156cb71/c4814/Hashicorp.webp 1080w,\n/static/bd9364ba124a438c72a181924156cb71/1ab6d/Hashicorp.webp 1366w,\n/static/bd9364ba124a438c72a181924156cb71/65058/Hashicorp.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5609375}},"extension":"webp","publicURL":"/static/bd9364ba124a438c72a181924156cb71/Hashicorp.webp"}},"fields":{"slug":"/community/events/dockercon-2022-lighting-talk-on-the-main-stage"}},{"id":"4c7f254a-a258-5915-9f19-4da5f6087650","body":"\nimport { Link } from \"gatsby\";\n\n  Join Layer5 at <a href=\"https://www.devconf.info/cz/\">DevConf.cz 2022</a> as\n  we share on our CNCF projects Meshery and Service Mesh Performance. Bring\n  your questions. We have answers. Engage with us in our talks!\n<br />\n\n<h2>\n  Talk:{\" \"}\n  <a href=\"https://sched.co/siKF\">Measuring Service Mesh Performance 101</a>\n</h2>\n\n<br />\n\nBenchmarking a service mesh and your workload‚Äôs performance is no simple task. Questions arise like:\n\n<ul>\n<li>Which load generator should you use and what signals should you measure?</li>\n<li>How long should I run a test?</li>\n<li>How has the performance of service meshes evolved over time?</li>\n<li>Should I run tests from outside or within my cluster?</li>\n<li>How does the configuration of my service mesh affect performance?</li>\n\n</ul>\n\nThis talk answers these questions by empowering attendees with at-hand tooling for continual evaluation of their service mesh environment and a reflection of how service mesh deployment models affect performance.\nSpeakers:\n\n<ul>\n  <li>\n    Navendu Pottekkat\n  </li>\n</ul>\n\n<br />\n<hr />\n<br />\n\n<h2>\n  Talk:{\" \"}\n  <a href=\"https://sched.co/siEs\">\n    {\" \"}\n    Journey Into the World of Service Meshes and Meshery\n  </a>\n</h2>\n\n<br />\n\nEngineers adopting microservice architectures are quickly faced with distributed systems challenges and in need of implementing rate limiting, circuit breaking, timeouts, retries, and implementing metrics, logging and tracing into each service is no simple task. Enter the service mesh.\n<h3>Let‚Äôs talk about:</h3>\n\nWhat is a service mesh? Why do you need one?\nWhat types of service meshes are available? How do they contrast?\n\nLearn how Meshery, a CNCF Project, multi-service mesh management plane implements the service mesh specifications, Service Mesh Performance (SMP) and Service Mesh Interface (SMI), to empower users to manage more than 10 service meshes simultaneously.\n\nUnderstand how Meshery uses a catalog of Cloud Native Patterns to provide templates for best practice configurations and how you can design new patterns with the visual topology designer, Kanvas\n<h3>Benefits to the ecosystem:</h3>\n\n  Attendees will be empowered with the ability to quickly deploy different\n  service meshes in which they may learn how service meshes function and how\n  each differs from the next, so that they may select the best-fit-for-purpose\n  service mesh for their workloads and their environment. It will be very\n  helpful for experienced service mesh operators seeking to learn best practices\n  through service mesh design patterns.\nSpeakers:\n\n<ul>\n  <li>\n    <Link to=\"/community/members/adithya-krishna\">Aditya Krishna Sharma</Link>\n  </li>\n  <li>\n    <Link to=\"/community/members/nithish-karthik\">Nithish Karthik</Link>\n  </li>\n</ul>\n","frontmatter":{"title":"DEVCONF 2022","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAADQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJYgAD5GoN60GsAsrRAAAA9mjfMimnxwQT5/XIr5WhMTx1nL1rFzbw4qgN/FpH/xIFT02JUgs/3+TvSpoNGcwIrASVmhV5B05AxI+qwAA="},"images":{"fallback":{"src":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp","srcSet":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp 551w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5862068965517242}},"extension":"webp","publicURL":"/static/9902d5f121e1bb06352939e21ee50f90/devConf22.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnIAAABXRUJQVlA4IGYAAADQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJYgAD5GoN60GsAsrRAAAA9mjfMimnxwQT5/XIr5WhMTx1nL1rFzbw4qgN/FpH/xIFT02JUgs/3+TvSpoNGcwIrASVmhV5B05AxI+qwAA="},"images":{"fallback":{"src":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp","srcSet":"/static/9902d5f121e1bb06352939e21ee50f90/0a32c/devConf22.webp 551w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5862068965517242}},"extension":"webp","publicURL":"/static/9902d5f121e1bb06352939e21ee50f90/devConf22.webp"}},"fields":{"slug":"/community/events/devconf-2022"}},{"id":"6f29a40e-4592-5cb6-afbd-07003c19b6af","body":"import {Link} from \"gatsby\";\n\n<div style={{ backgroundColor: \"#E6E6E6\", borderTop: \"1px #D3D3D3 solid\", borderBottom: \"1px #D3D3D3 solid\", padding: \"1rem\", align: \"center\", color: \"#666\", marginBottom: \"1rem\" }}>ENGLISH</div>\n\n<h2>\n  <a href=\"https://kccncosschn21.sched.com/event/pcbq/ji-jie-zhi-ke-zha-mu-solving-the-service-mesh-adopters-dilemma-anita-ihuman-layer5?iframe=no\">\n    Solving the Service Mesh Adopter‚Äôs Dilemma\n  </a>\n</h2>\n\n  Which service mesh should I use and how do I get started? What are the\n  different service meshes, and how do they contrast? Learn about the\n  functionality of different service meshes and visually manipulate mesh\n  configuration.{\" \"}\n  This talk introduces Meshery, an open source, multi-service mesh management\n  plane that provisions (ten and counting) different service meshes, their\n  sample applications and how it benchmarks the performance of service mesh\n  deployments. Meshery facilitates benchmarking various configuration scenarios\n  of any service mesh, comparison of performance of services (applications) on\n  and off the mesh and across different meshes. It vets mesh and service\n  configurations against deployment best practices. Some of the service mesh\n  projects use Meshery as their performance benchmark tool for each release.\nSpeakers:\n\n<ul>\n  <li>\n    MeshMate <Link to=\"/community/members/anita-ihuman\">Anita Ihuman</Link>\n  </li>\n</ul>\n\n- <a href=\"/events/2021/kubecon-china-2021/solving-the-service-mesh-adopters-dilemma-anita-ihuman-kubecon-china-2021.pdf\">Presentation Slides</a>\n\n<h2>\n  <a href=\"https://kccncosschn21.sched.com/event/pcYk/cncf-tag-jie-zhang-re-jie-yuan-cncf-tag-network-and-service-mesh-working-group-lee-calcote-layer5-ed-warnicke-cisco-ken-owens-fiserv?iframe=no\">\n    CNCF TAG Network and Service Mesh Working Group\n  </a>\n</h2>\n\n  With the increasing prevalence of microservice-based distributed systems, this\n  is true: the network, as a discipline, has never been so critical in the\n  efficient operation of cloud-native deployments. Network primitives including\n  load balancing, observability, authentication, authorization, policies, rate\n  limiting, QoS, mesh networks, traditional infrastructure bridging, and so on\n  are now being developed and invested by the entire industry, and are the focus\n  of the Service Mesh Working Group withing the CNCF TAG Network.{\" \"}\n  Listen to our introduction and get an in-depth understanding of the cloud native projects being managed within the working group.\n<ul>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Ed Warnicke</li>\n<li>Ken Owens</li>\n</ul>\n\n- <a href=\"/events/2021/kubecon-china-2021/cncf-tag-network-and-service-mesh-working-group-kubecon-china-2021-lee-calcote-ken-owens.pdf\">Presentation Slides</a>\n\n<h2>Meshery Project Office Hours</h2>\n\nJoin the Meshery Project Office Hours at KubeCon China 2021 to learn more about this CNCF project and its maintainers.\nCome and discover why Meshery is the easiest way to get started with cloud native technologies!\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/aisuko-li\">Aisuko Lee</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Navendu Pottekkat</li>\n<li>All Meshery project maintainers</li>\n</ul>\n\n<iframe width=\"50%\" height=\"360px\" style={{ marginBottom: \"3rem\" }} loading=\"lazy\" src=\"https://www.youtube.com/embed/GTZamP6r74A\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n\n<h2>Cloud Native Performance Project Office Hours</h2>\n\nJoin the Cloud Native Project Office Hours at KubeCon China 2021 and get introduced to the new standard of cloud native performance characterisation and to its open source maintainers.\nLearn what Service Mesh Performance is and how Meshery's implementation uses it to measure the performance of any service mesh available.\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/sunku-ranganath\">Sunku Ranganath</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li><Link to=\"/community/members/otto-van-der-schaaf\">Otto Van der Schaaf</Link></li>\n<li><Link to=\"/community/members/nic-jackson\">Nic Jackson</Link></li>\n<li>Xin Huang</li>\n<li>Mrittika Ganguli</li>\n<li>All SMP project maintainers</li>\n</ul>\n\n<iframe width=\"50%\" height=\"360px\" style={{ marginBottom: \"3rem\" }} loading=\"lazy\" src=\"https://www.youtube.com/embed/WEu6MorFtM0\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n</iframe>\n\n<div style={{ backgroundColor: \"#E6E6E6\", borderTop: \"1px #D3D3D3 solid\", borderBottom: \"1px #D3D3D3 solid\", padding: \"1rem\", align: \"center\", color: \"#666\", marginBottom: \"1rem\" }}>CHINESE</div>\n\n<h2><a href=\"https://kccncosschn21.sched.com/event/pcbq/ji-jie-zhi-ke-zha-mu-solving-the-service-mesh-adopters-dilemma-anita-ihuman-layer5?iframe=no\">Ëá¥Âäõ‰∫éËß£ÂÜ≥ÊúçÂä°ÁΩëÊ†º‰ΩøÁî®‰∏≠Á¢∞Âà∞ÁöÑÊ£òÊâãÈóÆÈ¢ò</a></h2>\n\n‰æãÂ¶ÇÔºöÊàë‰ª¨Â∫îËØ•Â¶Ç‰ΩïÈÄâÊã©Âπ∂‰ΩøÁî®ÊúçÂä°ÁΩëÊ†ºÊäÄÊúØ‰ª•ÂèäÂ¶Ç‰Ωï‰∏äÊâãÔºüÁõÆÂâçÂ≠òÂú®Âì™‰∫õ‰∏çÂêåÁöÑÊúçÂä°ÁΩëÊ†º‰∫ßÂìÅÔºå‰∫íÁõ∏‰πãÈó¥Â¶Ç‰ΩïËøõË°åÂØπÊØîÔºü‰∫ÜËß£‰∏çÂêåÁöÑÊúçÂä°ÁΩëÊ†º‰∫ßÂìÅÁöÑÂäüËÉΩÂπ∂‰∏îÂèØ‰ª•Áõ¥ËßÇÂú∞ÂØπÊúçÂä°ÁΩëÊ†ºËøõË°åÈÖçÁΩÆ„ÄÇ\nÊú¨Ê¨°ÊºîËÆ≤Êó®Âú®‰ªãÁªç MesheryÔºå ‰∏ÄÊ¨æÂºÄÊ∫êÁöÑÂ§öÊúçÂä°ÁΩëÊ†ºÁÆ°ÁêÜÂπ≥Èù¢ÔºåÂÆÉÊèê‰æõ‰∫ÜÂ∏ÇÈù¢‰∏äÔºàËá≥Â∞ë10‰∏™Ôºâ‰∏çÂêåÁöÑÊúçÂä°ÁΩëÊ†º‰∫ßÂìÅÁöÑÁîüÂëΩÂë®ÊúüÁÆ°ÁêÜÔºåÁ§∫‰æãÂ∫îÁî®Á®ãÂ∫è‰ª•ÂèäÂºÄÁÆ±Âç≥Áî®ÁöÑÊúçÂä°ÁΩëÊ†ºÁöÑÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂäüËÉΩ„ÄÇ MesheryÊúâËÉΩÂäõÂú®ÂêÑÁßç‰∏çÂêåÁöÑÂú∫ÊôØ‰∏ãÂØπ‰ªªÊÑèÁöÑÊúçÂä°ÁΩëÊ†ºËøõË°åÊÄßËÉΩÂü∫ÂáÜÊµãËØïÁöÑËÉΩÂäõÔºåÊØîËæÉ‰∏çÂêåÂ∫îÁî®Á®ãÂ∫èÂú®ÊúçÂä°ÁΩëÊ†ºÂÜÖÂ§ñ‰ª•Âèä‰∏çÂêåÊúçÂä°ÁΩëÊ†º‰πãÈó¥ÁöÑÊÄßËÉΩ„ÄÇÂÆÉÂèØ‰ª•Ê†πÊçÆÊúçÂä°ÁΩëÊ†ºÁöÑÊúÄ‰Ω≥ÂÆûË∑µÊù•ÂÆ°Êü•ÁΩëÁªúÂíåÊúçÂä°ÈÖçÁΩÆ„ÄÇË∂äÊù•Ë∂äÂ§öÁöÑÊúçÂä°ÁΩëÊ†ºÈ°πÁõÆ‰ΩøÁî®Meshery‰Ωú‰∏∫ÊØè‰∏™ÁâàÊú¨ÁöÑÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂ∑•ÂÖ∑„ÄÇ\nÊºîËÆ≤ËÄÖÔºö\n<ul>\n<li>MeshMate <Link to=\"/community/members/anita-ihuman\">Anita Ihuman</Link></li>\n</ul>\n\n- <a href=\"/events/2021/kubecon-china-2021/solving-the-service-mesh-adopters-dilemma-anita-ihuman-kubecon-china-2021.pdf\">Presentation Slides</a>\n\n\n<h2><a href=\"https://kccncosschn21.sched.com/event/pcYk/cncf-tag-jie-zhang-re-jie-yuan-cncf-tag-network-and-service-mesh-working-group-lee-calcote-layer5-ed-warnicke-cisco-ken-owens-fiserv?iframe=no\">CNCF TAG Network and Service Mesh Working Group</a></h2>\n\nÈöèÁùÄÂü∫‰∫éÂæÆÊúçÂä°ÁöÑÂàÜÂ∏ÉÂºèÁ≥ªÁªüË∂äÊù•Ë∂äÊµÅË°åÔºåÁΩëÁªú‰Ωú‰∏∫‰∏ÄÈó®Â≠¶ÁßëÔºåÂú®‰∫ëÂéüÁîüÁöÑÈ´òÊïàÈÉ®ÁΩ≤ÂíåËøêË°å‰∏≠ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶ÅÂ∑≤ÁÑ∂Êàê‰∏∫‰∫Ü‰∏çÂèØÂä®ÊëáÁöÑ‰∫ãÂÆû„ÄÇÂåÖÊã¨Ë¥üËΩΩÂùáË°°ÔºåÂèØËßÇÂØüÊÄßÔºåÈâ¥ÊùÉÔºåÊéàÊùÉÔºåÁ≠ñÁï•ÔºåÈôêÈÄüÔºåQoSÔºåMeshÁΩëÁªúÔºå‰º†ÁªüÂü∫Á°ÄËÆæÊñΩÊ°•Êé•Á≠âÔºåÊ≠£Âú®Ë¢´Êï¥‰∏™Ë°å‰∏öÂ§ßÂäõÂèëÂ±ïÂíåÊäïËµÑÔºåËøô‰∫õ‰πüÊòØCNCF TAG NetworkÁöÑService Mesh Working GroupÁöÑÈáçÁÇπ„ÄÇ\nÊ¨¢ËøéÂèÇÂä†Êàë‰ª¨ÁöÑ‰ªãÁªçÊù•Ê∑±ÂÖ•ÁöÑ‰∫ÜËß£Â∑•‰ΩúÁªÑÂÜÖÁÆ°ÁêÜÁöÑÊúçÂä°ÁΩëÊ†ºÈ°πÁõÆ„ÄÇ\nÊºîËÆ≤ËÄÖ:\n<ul>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Ed Warnicke</li>\n<li>Ken Owens</li>\n</ul>\n\n- <a href=\"/events/2021/kubecon-china-2021/cncf-tag-network-and-service-mesh-working-group-kubecon-china-2021-lee-calcote-ken-owens.pdf\">Presentation Slides</a>\n\n\n<h2>Meshery Project Office Hours</h2>\n\nÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•Âà∞KubeCon 2021 ‰∏≠ÂõΩÁ´ô Meshery office hoursÔºåÊù•‰∫ÜËß£CNCFÊúçÂä°ÁΩëÊ†ºÈ°πÁõÆÁöÑÊúÄÊñ∞ËøõÂ±ïÔºå‰ª•Âèä‰∏éÈ°πÁõÆÁª¥Êä§ËÄÖËøõË°åÂú®Á∫ø‰∫íÂä®„ÄÇ\nÂø´Êù•‰∫ÜËß£‰∏∫‰ªÄ‰πàMesheryÊòØÂºÄÂßã‰ΩøÁî®10+‰∏™ÊúçÂä°ÁΩëÊ†ºÁöÑÊúÄÁÆÄÂçïÊñπÊ≥ïÔºÅ\nÊºîËÆ≤ËÄÖ:\n<ul>\n<li><Link to=\"/community/members/aisuko-li\">Aisuko Lee</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li>Navendu Pottekkat</li>\n<li>All Meshery project maintainers</li>\n</ul>\n\n<h2>Service Mesh Performance Project Office Hours</h2>\n\nÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•Âà∞KubeCon 2021 ‰∏≠ÂõΩÁ´ô Service Mesh Performance Project Office HoursÔºåÊù•‰∫ÜËß£‰∫ëÂéüÁîüÊÄßËÉΩË°®ÂæÅÁöÑÊñ∞Ê†áÂáÜÁöÑËµÑËÆØÔºå‰ª•Âèä‰∏éÈ°πÁõÆÁª¥Êä§ËÄÖËøõË°åÂú®Á∫ø‰∫íÂä®„ÄÇ\nÊ¨¢ËøéÂ§ßÂÆ∂Êù•‰∫ÜËß£‰ªÄ‰πàÊòØÊúçÂä°ÁΩëÊ†ºÊÄßËÉΩ‰ª•ÂèäMesheryÂ¶Ç‰ΩïÂÆûÁé∞Ë°°Èáè‰ªª‰ΩïÂèØÁî®ÊúçÂä°ÁΩëÊ†ºÁöÑÊÄßËÉΩ„ÄÇ\nSpeakers:\n<ul>\n<li><Link to=\"/community/members/sunku-ranganath\">Sunku Ranganath</Link></li>\n<li><Link to=\"/community/members/lee-calcote\">Lee Calcote</Link></li>\n<li><Link to=\"/community/members/otto-van-der-schaaf\">Otto Van der Schaaf</Link></li>\n<li><Link to=\"/community/members/nic-jackson\">Nic Jackson</Link></li>\n<li>Xin Huang</li>\n<li>Mrittika Ganguli</li>\n<li>All SMP project maintainers</li>\n</ul>\n<br />\n","frontmatter":{"title":"KubeCon China 2021","type":"Event","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAACQAwCdASoUAAcAPtFUo0uoJKMhsAgBABoJQBdgA6Z8ZYa79/cAAP6g7l8sttdWABhvdu7bcIgenjoppWS3AkrVm23k1zOAokP6eFgz3VFPHAWsoo9qAAAA"},"images":{"fallback":{"src":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp","srcSet":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/1aa35/kubeconchina2021.webp 750w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/f13f2/kubeconchina2021.webp 1080w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/146ff/kubeconchina2021.webp 1366w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.33854166666666663}},"extension":"webp","publicURL":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/kubeconchina2021.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAACQAwCdASoUAAcAPtFUo0uoJKMhsAgBABoJQBdgA6Z8ZYa79/cAAP6g7l8sttdWABhvdu7bcIgenjoppWS3AkrVm23k1zOAokP6eFgz3VFPHAWsoo9qAAAA"},"images":{"fallback":{"src":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp","srcSet":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/1aa35/kubeconchina2021.webp 750w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/f13f2/kubeconchina2021.webp 1080w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/146ff/kubeconchina2021.webp 1366w,\n/static/cffabc0c76f1988dcd97cb6a90dc6fde/291de/kubeconchina2021.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.33854166666666663}},"extension":"webp","publicURL":"/static/cffabc0c76f1988dcd97cb6a90dc6fde/kubeconchina2021.webp"}},"fields":{"slug":"/community/events/kubecon-china-2021"}},{"id":"aa530849-23eb-5265-8ebb-3d754056dad9","body":"In this workshop an introduction to Meshery and what a Service Mesh is will be addressed. Then the entire flow will be shown to contribute to various Meshery repositories such as CI workflows, e2e Testing with Cypress, Documentation, Translations, among others.","frontmatter":{"title":"CCOSS Meshery Workshop 2021","type":"Workshop","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAe3G7RGAZ//EABoQAAICAwAAAAAAAAAAAAAAAAABAhEDEzH/2gAIAQEAAQUCtRITKQuGVvZ//8QAGBEAAgMAAAAAAAAAAAAAAAAAAAEREyH/2gAIAQMBAT8Ba0sg/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAECAQE/AWY//8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEgISL/2gAIAQEABj8CNQdn/8QAHBABAAEEAwAAAAAAAAAAAAAAAQAQESExQWGR/9oACAEBAAE/IUIaOLETNz1iLN0mqggF7P/aAAwDAQACAAMAAAAQFM//xAAYEQADAQEAAAAAAAAAAAAAAAAAARExwf/aAAgBAwEBPxClXBu06f/EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8QTqLbD//EABwQAQACAgMBAAAAAAAAAAAAAAEAETFRIUGR0f/aAAgBAQABPxBrjgCIeRiEX0fzEqRXcSuvNS3cKBCqBaJ//9k="},"images":{"fallback":{"src":"/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg","srcSet":"/static/efaab4bb63b1958f85345953b12601b4/5f965/ccoss.jpg 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg 800w","sizes":"100vw"},"sources":[{"srcSet":"/static/efaab4bb63b1958f85345953b12601b4/ee7ce/ccoss.webp 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e7773/ccoss.webp 800w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}},"extension":"jpeg","publicURL":"/static/efaab4bb63b1958f85345953b12601b4/ccoss.jpeg"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAe3G7RGAZ//EABoQAAICAwAAAAAAAAAAAAAAAAABAhEDEzH/2gAIAQEAAQUCtRITKQuGVvZ//8QAGBEAAgMAAAAAAAAAAAAAAAAAAAEREyH/2gAIAQMBAT8Ba0sg/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAES/9oACAECAQE/AWY//8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEgISL/2gAIAQEABj8CNQdn/8QAHBABAAEEAwAAAAAAAAAAAAAAAQAQESExQWGR/9oACAEBAAE/IUIaOLETNz1iLN0mqggF7P/aAAwDAQACAAMAAAAQFM//xAAYEQADAQEAAAAAAAAAAAAAAAAAARExwf/aAAgBAwEBPxClXBu06f/EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8QTqLbD//EABwQAQACAgMBAAAAAAAAAAAAAAEAETFRIUGR0f/aAAgBAQABPxBrjgCIeRiEX0fzEqRXcSuvNS3cKBCqBaJ//9k="},"images":{"fallback":{"src":"/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg","srcSet":"/static/efaab4bb63b1958f85345953b12601b4/5f965/ccoss.jpg 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e737e/ccoss.jpg 800w","sizes":"100vw"},"sources":[{"srcSet":"/static/efaab4bb63b1958f85345953b12601b4/ee7ce/ccoss.webp 750w,\n/static/efaab4bb63b1958f85345953b12601b4/e7773/ccoss.webp 800w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}},"extension":"jpeg","publicURL":"/static/efaab4bb63b1958f85345953b12601b4/ccoss.jpeg"}},"fields":{"slug":"/community/events/ccoss-meshery-workshop-2021"}},{"id":"4c56628f-1269-5240-b562-8abc0bdabe53","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { BufProtocol } from \"./BufProtocol.style\";\nimport { Link } from \"gatsby\";\nimport Problems from \"./problems.webp\";\n\n<BlogWrapper>\n<BufProtocol>\n\n<div className=\"intro\" style={{ textAlign: \"center\", margin: \"2rem 4rem\" }}>\n\tAt Layer5, we are continuously evaluating new technologies and incorporating\n\tthem into our open source projects. Buf is one of those projects. This post\n\tpresents an overview of Buf.\n</div>\n\n## What is Buf?\n\nA tool to make Protobuf reliable and easy to use for service owners and clients, while keeping it the obvious choice on the technical merits.\nOur organization should not have to reinvent the wheel to create, maintain, and consume Protobuf APIs efficiently and effectively. It will handle our Protobuf management strategy for us, so we can focus on what matters.\n\n<div className=\"fact\">\n\tLearn more about Buf Protocol, visit\n\t<a href=\"https://buf.build\" rel=\"nofollow\">\n\t\t{\" \"}\n\t\tBuf Protocol{\" \"}\n\t</a>\n\tor their documentation at\n\t<a href=\"https://docs.buf.build/\" rel=\"nofollow\">\n\t\t{\" \"}\n\t\tBuf Protocol Docs{\" \"}\n\t</a>\n</div>\n\n<img className=\"problem-image\" src={Problems} />\n\n## Features\n\n- Automatic file discovery.\n- Selectable configuration - 40 lint checkers and 54 breaking checkers\n- Selectable error output - `file:line:col:message`\n- Check anything from anywhere - proto files, tar, git, pre-built images or file descriptors.\n- [Speed](https://docs.buf.build/tour-8/) - Its internal compiler is super fast (approx. 4x then Protoc)\n- Can use buf as a protoc plugin instead of using it as a standalone tool.\n\n## Buf CLI\n\nBuf attempts to simplify your Protocol Buffers workflow using the Buf CLI and protoc plugins. The Buf CLI currently provides:\n\n- A linter that enforces good API design choices and structure.\n- A breaking change detector that enforces compatibility at the source code level or wire level.\n- A generator that invokes your protoc plugins based on a configurable template. A protoc replacement that uses Buf's newly-developed high performance Protobuf compiler.\n- A configurable file builder that produces Images, our extension of FileDescriptorSets.\n\n## Comparison Between Protobuf and Buf\n\nLayer5 projects currently use protoc as the tool for building their protobuf defintions. The following are some considerations made while determining whether to use Buf.\n\n- Protobuf is not as widely adopted as JSON.\n- API Structure\n  - No standards enforcement\n  - Inconsistency can arise across an organization's Protobuf APIs,\n  - Design decisions can be made that can affect your API's future iterability.\n- Backward Compatibility\n- Stub distribution\n- Tooling\n\nBuf aims to solve the above problems and it's long-term goal is to enable schema-driven development: A future where APIs are defined consistently, in a way that service owners and us can depend on\n\n## Roadmap to Adopting Buf\n\nIn consideration of the use of Buf, we would adopt it in phases, starting with the following ares of integration.\n\n- **API Structure Enforcements**\n\n  - Linter solves this issue by enforcing standards.\n  - Also, we don‚Äôt need to use Buf as a standalone tool we can just use linter as plugins.\n\n- **Backward Compatibility**\n  - It will check for different things that can cause breaking change.\n  - For example, type change.\n\n<div className=\"intro\">\n\tIf these topics excite you and you want to explore more\n\t<a href=\"/resources\"> cloud native technolgies </a>, come and say \"Hi\" on the community{\" \"}\n\t<a href=\"http://slack.layer5.io\"> Slack </a> and you are sure to be warmly welcomed.{\" \"}\n\t<span>üòÄ</span>\n</div>\n\n</BufProtocol>\n</BlogWrapper>\n","frontmatter":{"title":"Rethinking Protocol Buffers with Buf","type":"Blog","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAACQAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJQBOgA+Tk8aehcycAAP7ATvlxq/O19EhA9XrL+2Tj+Q03SbYzgyfckaPxQws5+ikk5FoYgfquExjejLHTZGOL/rxz2A413CEfQgAA"},"images":{"fallback":{"src":"/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp","srcSet":"/static/f9bfdf0ed6d91ee82471bb9f41472183/b9516/buf-protocol.webp 750w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a327/buf-protocol.webp 1080w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a401/buf-protocol.webp 1366w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5619791666666667}},"extension":"webp","publicURL":"/static/f9bfdf0ed6d91ee82471bb9f41472183/buf-protocol.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnAAAABXRUJQVlA4IGQAAACQAwCdASoUAAsAPtFUpEuoJKOhsAgBABoJQBOgA+Tk8aehcycAAP7ATvlxq/O19EhA9XrL+2Tj+Q03SbYzgyfckaPxQws5+ikk5FoYgfquExjejLHTZGOL/rxz2A413CEfQgAA"},"images":{"fallback":{"src":"/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp","srcSet":"/static/f9bfdf0ed6d91ee82471bb9f41472183/b9516/buf-protocol.webp 750w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a327/buf-protocol.webp 1080w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/2a401/buf-protocol.webp 1366w,\n/static/f9bfdf0ed6d91ee82471bb9f41472183/467a8/buf-protocol.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5619791666666667}},"extension":"webp","publicURL":"/static/f9bfdf0ed6d91ee82471bb9f41472183/buf-protocol.webp"}},"fields":{"slug":"/blog/cloud-native/rethinking-protocol-buffers-with-buf"}},{"id":"e803ead4-61ce-5d36-be43-9c9414ec99b7","body":"Join Layer5 at the inaugural Istio conference on Monday, Feb. 22nd to Friday, Feb. 26th. <a href=\"https://events.istio.io/istiocon-2021/about/\">IstioCon</a> is a 100% virtual event that is designed to connect community members across the globe with Istio and the Istio ecosystem.\n\nLayer5 will kickoff the event with our renowned service mesh workshop, featuring <a href=\"/cloud-native-management/meshery\">Meshery</a>, the service mesh manager. Attend our workshop to help you get started with managing your own service mesh!\n\n<h4>Using Istio</h4>\n<br />\nAs the third phase in your microservices journey, service meshes provide a substrate of secure connectivity, uniform visibility and granular control over service requests. Service meshes have quickly entered the cloud native landscape filling unmet service-level needs. Organizations that have adopted containers and who are running a handful or more of microservices find tools to provide observability, control and security lacking. Operating at layer 5, service meshes promise much value. This live training walks you through a series of hands-on labs, introducing you to each and every aspect of the popular service mesh - Istio. During this workshop you will gain hands-on experience as we walk through deploying Istio alongside microservices running in Kubernetes.\nYou will learn to:\n\n<ul>\n<li>Configure and operate Istio in context of an example workloads and their common use cases</li>\n<li>Manage traffic through load balancing and resilient communications</li>\n<li>Enforce policies and rate limiting</li>\n<li>Be confident with ongoing management of Istio</li>\n<li>Understand WebAssembly filters for Envoy and deploy a custom filter</li>\n</ul>\n<h4 style={{ marginBottom: \"1.25rem\" }}><a href=\"https://github.com/layer5io/advanced-istio-service-mesh-workshop\">Workshop Labs</a></h4>\n\nSee link for self-paced study.\n\n<h4 style={{ marginBottom: \"1.25rem\" }}><a href=\"https://calcotestudios.com/talks/decks/slides-istiocon-2021-using-istio.html\">Workshop Slides</a></h4>\n\n<iframe width=\"50%\" height=\"400px;\" src=\"https://calcotestudios.com/talks/decks/slides-istiocon-2021-using-istio.html\"></iframe>\n<br />\n<br />\n<h4 style={{ marginBottom: \"1.25rem\" }}>Workshop Recording</h4>\n\n<iframe width=\"50%\" src=\"https://www.youtube.com/embed/T1Kwh3SRAXQ\" loading=\"lazy\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" style={{ minHeight: \"315px\", minWidth: \"280px\", margin: \"auto\", textAlign: \"center\" }} allowfullscreen></iframe>\n<br />\n<br />","frontmatter":{"title":"IstioCon 2021","type":"Event","technology":"WebAssembly","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/community/events/istiocon-2021"}},{"id":"20f2f64e-c6e1-5396-82ba-09d3a00f0208","body":"Organizations that have adopted containers and are running a handful (or more) of microservices often find tools to provide observability, control, and security lacking. Service meshes‚Äîthe third phase in the microservices journey‚Äîhave quickly entered the cloud native landscape, filling unmet service-level needs and providing a substrate of secure connectivity, uniform visibility, and granular control over service requests. Operating at layer 5, service meshes offer great value.\n\nLee Calcote walks you through advanced service mesh concepts and each and every aspect of the open source service mesh Istio. Over three hours, you‚Äôll gain hands-on experience with this popular tool as you learn how to deploy Istio alongside microservices running in Kubernetes.\n\n### What you'll learn-and how you can apply it\n\n#### By the end of this live online course, you‚Äôll understand:\n\n- How to manage traffic through load balancing and resilient communications\n- How to enforce policies and rate limiting\n- Istio's methods for managing telemetry, monitoring, and reporting\n- Approaches to canary deployments and securing communication with Istio\n\n### And you‚Äôll be able to:\n\n- Configure and operate Istio in context of an example workloads and their common use cases\n- Take the third step in your cloud native journey with an initial deployment of a service mesh\n\n### This training course is for you because...\n\n- You‚Äôre an operator who wants uniform observability irrespective of the different languages and libraries that run your services.\n- You‚Äôre a developer who wants to affect application behavior without code changes.\n- You want to become a cloud native architect or level up as one.\n\n#### Prerequisites\n\n- Working knowledge of Docker, Kubernetes, and kubectl.\n\n#### A locally running instance of:\n\n- Docker (Docker Desktop for Mac or Windows, or Docker for Linux)\n- Kubernetes (using Docker Desktop or Minikube for Mac, Windows, or Linux)\n- [Meshery](/cloud-native-management/meshery) (Mac, Windows or Linux)\n\n#### Recommended preparation:\n\n- Take Introduction to Kubernetes (live online training course with S√©bastien Goasguen)\n- If you need help installing Kubernetes, read ‚ÄúInstalling Kubernetes Locally Using Minikube‚Äù (short section in ‚ÄúChapter 3: Deploying a Kubernetes Cluster‚Äù in Kubernetes: Up and Running)\n\n#### Recommended follow-up:\n\n- Read [The Enterprise Path to Service Mesh Architectures](/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures) (report)\n- Read [Istio: Up and Running](/learn/service-mesh-books/istio-up-and-running)\n","frontmatter":{"title":"Introduction to Istio","type":"Workshop","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABwAwCdASoUAAUAPtFUpEuoJKOhsAgBABoJYwCdABXtBUsf90QA9r4yXDIkZSS4/98YaUNRVuJ1ibcvxJnpUM9NKvQmXrHHCXnv/ERTtZ/U8JmEi7E0yC0qUWTh3cNkYAA="},"images":{"fallback":{"src":"/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp","srcSet":"/static/57f2e0891f16e4a8c3d4cb537c154452/5f043/istio-intro.webp 750w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/d488d/istio-intro.webp 1080w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/57f2e0891f16e4a8c3d4cb537c154452/istio-intro.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmwAAABXRUJQVlA4IGAAAABwAwCdASoUAAUAPtFUpEuoJKOhsAgBABoJYwCdABXtBUsf90QA9r4yXDIkZSS4/98YaUNRVuJ1ibcvxJnpUM9NKvQmXrHHCXnv/ERTtZ/U8JmEi7E0yC0qUWTh3cNkYAA="},"images":{"fallback":{"src":"/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp","srcSet":"/static/57f2e0891f16e4a8c3d4cb537c154452/5f043/istio-intro.webp 750w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/d488d/istio-intro.webp 1080w,\n/static/57f2e0891f16e4a8c3d4cb537c154452/ac7e5/istio-intro.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/57f2e0891f16e4a8c3d4cb537c154452/istio-intro.webp"}},"fields":{"slug":"/community/events/introduction-to-istio"}},{"id":"4756fb86-631f-51b1-b180-0e97c217a1d0","body":"Organizations that have adopted containers and are running a handful (or more) of microservices often find tools to provide observability, control, and security lacking. Service meshes‚Äîthe third phase in the microservices journey‚Äîhave quickly entered the cloud native landscape, filling unmet service-level needs and providing a substrate of secure connectivity, uniform visibility, and granular control over service requests. Operating at layer 5, service meshes offer great value.\n\nLee Calcote walks you through advanced service mesh concepts and each and every aspect of the open source service mesh Istio. Over three hours, you‚Äôll gain hands-on experience with this popular tool as you learn how to deploy Istio alongside microservices running in Kubernetes.\n\n### What you'll learn-and how you can apply it\n\n#### By the end of this live online course, you‚Äôll understand:\n\n- Istio's methods for managing telemetry, monitoring, and reporting\n- Advanced traffic management scenarios\n- Approaches to canary deployments and securing communication with Istio\n\n#### And you‚Äôll be able to:\n\n- Configure and operate Istio in context of an example workloads and their common use cases\n- Manage traffic through load balancing and resilient communications\n- Enforce policies and rate limiting\n- Be confident in the third step of your cloud native journey with ongoing management of your service mesh\n\n### This training course is for you because...\n\n- You‚Äôre an operator who wants uniform observability irrespective of the different languages and libraries that run your services.\n- You‚Äôre a developer who wants to affect application behavior without code changes.\n- You want to become a cloud native architect or level up as one.\n\n#### Prerequisites\n\n- A working knowledge of Istio and Kubernetes\n- Familiarity with Docker Desktop, Minikube, or kind\n- A computer with Docker and Meshery installed locally\n- Access to local or remote Kubernetes cluster of any size, with cluster admin privileges (Either of these two local single-node clusters will work: Docker Desktop or Minikube.)\n\n#### Recommended preparation\n\n- Take Introduction to Istio (live online training course with Lee Calcote)\n- If you need to brush up on Kubernetes, take Introduction to Kubernetes (live online training course with S√©bastien Goasguen) or read Kubernetes Cookbook (book) or Kubernetes: Up and Running (book)\n\n#### Recommended follow-up\n\n- Read The Enterprise Path to Service Mesh Architectures (report)\n- Read Istio: Up and Running (early release book)\n","frontmatter":{"title":"Advanced Istio","type":"Workshop","technology":null,"product":null,"mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmgAAABXRUJQVlA4IFwAAADQAwCdASoUAAUAPtFUo0uoJKMhsAgBABoJZACdMoADTFB/LrchbKgA/tuDjRifiEyjK7blIB54Z22YjegTggP9B94px3symZbFfM+eWLNXXz01P+gnrmrZsIAAAA=="},"images":{"fallback":{"src":"/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp","srcSet":"/static/0b49520092152a93c81799540f1a1dd8/5f043/istio.webp 750w,\n/static/0b49520092152a93c81799540f1a1dd8/d488d/istio.webp 1080w,\n/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/0b49520092152a93c81799540f1a1dd8/istio.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmgAAABXRUJQVlA4IFwAAADQAwCdASoUAAUAPtFUo0uoJKMhsAgBABoJZACdMoADTFB/LrchbKgA/tuDjRifiEyjK7blIB54Z22YjegTggP9B94px3symZbFfM+eWLNXXz01P+gnrmrZsIAAAA=="},"images":{"fallback":{"src":"/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp","srcSet":"/static/0b49520092152a93c81799540f1a1dd8/5f043/istio.webp 750w,\n/static/0b49520092152a93c81799540f1a1dd8/d488d/istio.webp 1080w,\n/static/0b49520092152a93c81799540f1a1dd8/ac7e5/istio.webp 1121w","sizes":"100vw"},"sources":[]},"width":1,"height":0.23193577163247103}},"extension":"webp","publicURL":"/static/0b49520092152a93c81799540f1a1dd8/istio.webp"}},"fields":{"slug":"/community/events/advanced-istio"}},{"id":"ff86da1d-9efd-569f-98aa-f2c225f8c8bc","body":"","frontmatter":{"title":"CCOSS 2020","type":"Workshop","technology":null,"product":"Meshery","mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/community/events/ccoss-2020"}},{"id":"a43e3d97-2e4e-5079-bfc7-dc5bbb59ff2f","body":"","frontmatter":{"title":"O'Reilly OSCON 2020","type":"Workshop","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRqgAAABXRUJQVlA4IJwAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoADQn9+voPUk/5eAAD+n0Lrn1eo/SOFlETnXHT8EM8ECIsMVg/ZpgyvP3zhijTAvsAQhf7L3/COxUwKDNv/yW32Gia9CSw/4bMi5cnt/dpZ/ob+qp5VK6U/VQWpbaS0odt9AQiJNZGUIR+DE/JKoNOG4rcwZ4HT8TVhtFQAAAA="},"images":{"fallback":{"src":"/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp","srcSet":"/static/eb1bb6900c1b8d30dd4f66c821c31500/06f57/oscon.webp 750w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b5fe1/oscon.webp 1080w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/8cf68/oscon.webp 1366w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.37604166666666666}},"extension":"webp","publicURL":"/static/eb1bb6900c1b8d30dd4f66c821c31500/oscon.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRqgAAABXRUJQVlA4IJwAAAAQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoADQn9+voPUk/5eAAD+n0Lrn1eo/SOFlETnXHT8EM8ECIsMVg/ZpgyvP3zhijTAvsAQhf7L3/COxUwKDNv/yW32Gia9CSw/4bMi5cnt/dpZ/ob+qp5VK6U/VQWpbaS0odt9AQiJNZGUIR+DE/JKoNOG4rcwZ4HT8TVhtFQAAAA="},"images":{"fallback":{"src":"/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp","srcSet":"/static/eb1bb6900c1b8d30dd4f66c821c31500/06f57/oscon.webp 750w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b5fe1/oscon.webp 1080w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/8cf68/oscon.webp 1366w,\n/static/eb1bb6900c1b8d30dd4f66c821c31500/b3bf0/oscon.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.37604166666666666}},"extension":"webp","publicURL":"/static/eb1bb6900c1b8d30dd4f66c821c31500/oscon.webp"}},"fields":{"slug":"/community/events/oreilly-oscon-2020"}},{"id":"abeeb5ed-d88e-56ea-8d68-5da66360c781","body":"","frontmatter":{"title":"O'Reilly Infrastructure & Ops","type":"Workshop","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAABQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoRwGQAAblgzKfUnzAnAAP7j0LFfp+Dxs1Fkmx6VbWq5XYGM85oRqhXgtUJ7d+4hf2tMgUgqu8nuk2e7a0cbIH68Lgj+Kp1AzQif21wKFpUZmIQCYLUliqATtiP1Dc29JHogAAAA"},"images":{"fallback":{"src":"/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp","srcSet":"/static/168951be11a3367dbe384088996f4c66/93b8c/infra-ops.webp 750w,\n/static/168951be11a3367dbe384088996f4c66/58fe6/infra-ops.webp 1080w,\n/static/168951be11a3367dbe384088996f4c66/da0ea/infra-ops.webp 1366w,\n/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3776041666666667}},"extension":"webp","publicURL":"/static/168951be11a3367dbe384088996f4c66/infra-ops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAABQBACdASoUAAgAPtFUo0uoJKMhsAgBABoJbACdMoRwGQAAblgzKfUnzAnAAP7j0LFfp+Dxs1Fkmx6VbWq5XYGM85oRqhXgtUJ7d+4hf2tMgUgqu8nuk2e7a0cbIH68Lgj+Kp1AzQif21wKFpUZmIQCYLUliqATtiP1Dc29JHogAAAA"},"images":{"fallback":{"src":"/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp","srcSet":"/static/168951be11a3367dbe384088996f4c66/93b8c/infra-ops.webp 750w,\n/static/168951be11a3367dbe384088996f4c66/58fe6/infra-ops.webp 1080w,\n/static/168951be11a3367dbe384088996f4c66/da0ea/infra-ops.webp 1366w,\n/static/168951be11a3367dbe384088996f4c66/5e230/infra-ops.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3776041666666667}},"extension":"webp","publicURL":"/static/168951be11a3367dbe384088996f4c66/infra-ops.webp"}},"fields":{"slug":"/community/events/oreilly-infrastructure-ops"}},{"id":"38b44af0-f7a6-509d-87b6-b37893386d16","body":"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n\n<ResourcesWrapper>\n<div className=\"comparison\">\n\nThe [Layer5 Academy](https://cloud.layer5.io/academy) provides a structured platform for cloud native learning, combining core educational content with practical, hands-on experiences. Learners can enroll in guided paths, complete interactive labs, and take assessments that reinforce understanding at every stage.\n\nThe Academy supports progression through quizzes, tests, and certification exams, offering grades, retake options, and recognition through badges and certificates. For organizations, administrators can monitor learner performance, create new content, and send customized communications, ensuring both individual growth and collective visibility.\n\n## Detailed Comparison\n\nThe following details highlight the key differences between Layer5 Academy and Moocit across various dimensions. Be sure to read the [Layer5 Academy documentation](https://docs.layer5.io/cloud/academy) for more in-depth information.\n\n### Course Creation & Management\n\nIt is the backbone of the platform, enabling instructors to easily design, structure, and deliver courses. This includes tools for creating multimedia lessons, managing modules, setting prerequisites, and organizing assessments to ensure a seamless teaching process.\n\n\n| Feature | Moocit | Layer5 | Notes |\n|---------|--------|--------|-------|\n| Content Variety | ‚úÖ | ‚úÖ | Both: Support text, images, videos, PDFs |\n| Interactive Learning | ‚úÖ | ‚úÖ | Both: Quizzes, tests, self-assessment |\n| Learning Paths/Tracks | ‚úÖ | ‚úÖ | Both: Support sequential paths and prerequisites |\n| Course Publishing | ‚úÖ | ‚úÖ | Moocit: Web-based approach to content creation and publishing with incremental instant and scheduled releases. Layer5: Gitflow based approach to content creation and publishing is gitflow based with version-controlled publishing.  |\n| Course Management | ‚úÖ | ‚úÖ | Both: Tools to organize, assign, and manage |\n| Course Tracking | ‚úÖ | ‚úÖ | Both: Track learner progress and completion |\n| Course Authoring | ‚ö†Ô∏è | ‚úÖ | Moocit: uses the Open edX platform with XML-based authoring. Layer5: uses a modern Hugo static site generator with Markdown-based authoring. |\n| Public Catalog | ‚ùå | ‚úÖ | Moocit: Lacks browsable, public catalog. Layer5: Provides comprehensive discoverability with browsable, public catalog. |\n\n### Learner Experience\n\nLearner experience emphasizes intuitive design, collaboration, and flexibility. Both platforms enable personalized learning, progress tracking, and interactive engagement, with Layer5 extending into real-time collaboration via [Kanvas](/cloud-native-management/kanvas).\n\n| Feature | Moocit | Layer5 | Notes |\n|---------|--------|--------|-------|\n| Learner Portal | ‚úÖ | ‚úÖ | |\n| Self-paced Learning | ‚úÖ | ‚úÖ | |\n| Instructor-led Learning | ‚úÖ | ‚úÖ | | \n| Mobile Learning | ‚úÖ | ‚úÖ | |\n| Certificate Generation | ‚úÖ | ‚úÖ | Both: Shareable certifications |\n| Social Learning | ‚úÖ | ‚úÖ | Both: Forums, discussions. Layer5: Kanvas and Slack. |\n| Learner Profile | ‚ö†Ô∏è | ‚úÖ| Moocit: Limited support for interactive profiles. Layer5: Comprehensive learner profiles with progress tracking and social features. |\n| Group / Synchronous Learning | ‚ùå | ‚úÖ | Layer5: Real-time, collaborative learning. |\n| Hands-on Labs | ‚ùå | ‚úÖ | Layer5:  through Kanvas |\n\n### Administration & Analytics\n\nBoth platforms deliver robust administration capabilities with user management, analytics, and compliance tools. Layer5 extends customization through its cloud-native ecosystem integration.\n\n| Feature | Moocit | Layer5 | Notes |\n|---------|--------|--------|-------|\n| Assessment Management | ‚úÖ | ‚úÖ | Both: Build and evaluate assessments. |\n| Gradebook | ‚úÖ | ‚úÖ | Both: Track grades and scores. |\n| Reporting & Statistics | ‚úÖ | ‚úÖ | Both: Insights into learner engagement and performance. |\n| User Management | ‚ö†Ô∏è | ‚úÖ | Moocit: Manage user accounts. Layer5: Manage user accounts with granular and customizable permissions and roles. |\n| Group Creation and Management |  ‚úÖ | ‚úÖ | Both: Allow instructors to organize students and content into different groups. |\n| Single Sign-On (SSO) | ‚ùå | ‚úÖ | Layer5: Enhanced identity and granular access control. |\n| Branded Academy Invitations | ‚ùå | ‚úÖ | Layer5: Approval queues, domain-based allowances. |\n| Branded Content Announcements | ‚ùå | ‚úÖ | Layer5: New content announcements |\n| Public Clouds | ‚ùå | ‚úÖ | Layer5: AWS, Azure, GCP, DigitalOcean, and an Kubernetes service |\n| Orchestration Support | ‚ùå | ‚úÖ | Layer5: Hundreds of CNCF ecosystem integrations |\n\n### Additional Features\n\nExtra functionalities make the platforms more engaging. While both cover gamification and eCommerce, Layer5 distinguishes itself with advanced white-labeling and community-driven Slack support.\n\n| Feature | Moocit | Layer5 | Notes |\n|---------|--------|--------|-------|\n| Gamification | ‚úÖ | ‚úÖ | Layer5: badges and learning leaderboards. |\n| eCommerce Management | ‚úÖ | ‚úÖ | Both: Support Stripe as a built-in integration. |\n| White-labeling | ‚úÖ | ‚úÖ | Layer5: Superior branding flexibility. |\n| Chatbot Support | ‚ö†Ô∏è | ‚úÖ | Moocit: website chat. Layer5: community-centric Slack. |\n| Cloud Native Focused | ‚ùå | ‚úÖ  | Layer5 is a cloud native ecosystem stalwart, tightly aligned with the CNCF. |\n\n## Summary\n\nWhile Moocit lacks content attribution and seamless orchestration with hands-on labs, Layer5 Academy stands out by enabling true learning through interactive, hands-on labs powered by Kanvas‚Äîwhere real learning happens. Layer5 Academy's labs drive students to utilize third-party public cloud providers' infrastructure, meaning more time spent on hands-on activities can increase costs for users paying for their chosen provider's resources. However, public cloud providers featuring Academy content and labs can incentivize adoption by offering credits and discount codes, presented to learners after enrolling in a Challenge, Learning Path, or Certification. Furthermore, Layer5 enhances administrative efficiency with support for bulk invitations for new learners and email announcements for new academy content, underscoring its superior strengths in content creation, learner experience, and administrative capabilities compared to Moocit.\n\n</div>\n</ResourcesWrapper>\n","frontmatter":{"title":"Layer5 Academy vs Moocit","type":"Comparison","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACd0lEQVR42rWUPUxTURTHT2nLh4uTcXLRwcnEwbi4q4MrTviRODo4Opn6EcUoxkQpUOT1SSkgpUBf21eohT4HI0RCooQYv2BwMBrQQSVo+949/u/tLXQghiie5Jd77z/3/N+5X49IBrOPnFCAEs1+qkYhsZMss5kyRooy0R+UMZco+7CNMg8OUyQS1LMqeRLZVxEK1a2byH7WPEiWcZvS0SV63M80OShgxDTeJ2jqEVOut0RW9BnZ5nkaC++hjfCpwlTkjF0wOgeTIuViazBBYkxQ2iyjMokAnh67lI+zmpM1V5AzSLZxgtKRHRWzjNmPJS1TYYAVMtEykBh10edNwIeiZYXdK2gSVef7XFS9jJwzMIy+pIn4N1TEwXy/aHISXC+XNt4nq+RAYZCbniS4oTjEvom40vzYikbMa5wa4jo7JjWP7NgXmF6sVGn1tOLLn2k0MkvD7dM02jmH5b2F9p5S3S+Ulux4TmnjDfZzkVI9C5QMzygs45U6sDHsfTWYWR2My3zBY06hvbTAXK+1FmgjoP07826plZiPYDzgCRH/xXyg1kOF4zgBLVpciRnQqLV7WlsB+7R2mjfimNb8tRX6dTuiJz0VQjRo7a7WPoG9WmupMTz6J8PUFis8tdUKt83wX/bw+GaGwW0wDPy/Q1nzyjdKnvcO9+qrnIE7toq7Ng9tzvW8FaUJ4WL8+qfrzpU970PVDf1F6PMfS6uHais8C8LgKgiBa6AN3AHXtXYF3NLaTa1dBq3gPtivn53ZhSfn0HBHmka6cuiPqzbZmVVUNcmGZq9rsp/stPAsp/EsT+JHOuD5iwkOOMN/TzFR9s3a8pfW/RuwHjxytwDQOAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/8b9d60ffbc1248a6f3e26b3b57d0df0f/3dc2b/academy-layer5-light.png","srcSet":"/static/8b9d60ffbc1248a6f3e26b3b57d0df0f/3dc2b/academy-layer5-light.png 300w","sizes":"100vw"},"sources":[{"srcSet":"/static/8b9d60ffbc1248a6f3e26b3b57d0df0f/de47d/academy-layer5-light.webp 300w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9133333333333333}},"extension":"png","publicURL":"/static/8b9d60ffbc1248a6f3e26b3b57d0df0f/academy-layer5-light.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC10lEQVR42r2UTUwTQRTH/wio8eLJePIiB08mHowX7+LBK54QTTx68OjJ1I8oRjEmKIkouwuUtrvLR3e73ZYCsgcNEKEJ3bZ8U4RoBKkeDIZESse3s1uqERPl4CQvu/Pbef/3n3mZBZzBWAUsXxXUukqUxqB6GLpUB0PQYIgbMKQcou1NMF6eQWtrtbfKzXPCeefD59u3I+K8R6VT0IVHiIg5DAQYhkJFEmKI+4t4JTPEOr5DF0dgStcQbjmG8qjgxviICUdI6CqJDCPWuUkilNhZRETaImdOFCm2vXkBiS7G10SlPOWEYAoXEGk95IoZUoC2tI7BIOPhJOoCJYoFeme7BBUSt3iYHUUMkeuEv0Cu1ynnMgmKKfR3fSVHDP3etpzqcT/jzClSYv0eSwQ8Rt/MDodtw+z8TKI3XJd6WyNVXqOq4wgLo9CEJCLtc8QWqDGTNHfYW/o+S9teJBMZhNvGeOjiFG9YmM5+ZzCvMWn1OmxZQ0a5iYy6nzNbqafoJf4MdvCou04+S/Mg0koXUurJXzT4cNsOLEV0bI4wvDPGYEkHOVs2mrHx2mF5LPfVcJYzGvBpkOFjgmHFqHUF1cqfHHqTDDl5H2P0fIO52AGPPcFylJGbVdg9x13XwXrM9DBMdRMPnfuzYFrRsDrAaDtlh2mlGR/iDstTco13NJcwrzHM9pGgXPsfBEtnaMs6VhOu4JK1i6B3hmm5AfNhVzCjnv9dcGKies+Ck56gZVX9Y1NkakrgL5uSDt1HKjSPhfAX7mZR+0YCNuxQEnO9eV4kFynQ9mYwGUxiumcFKybjhaa7F2mdjWTwdFlwWr2CrNKCrHwHGdlHru7SvAlZ9TGJ3OMsq97GlPqQs7T8gDgx5RbNGymeIuU/4V076Tn9DCy6WhFoUgyaGCcWoysV5aGJLuO8xASzzCSTmE7XchR6+0X6kQa3MUwX3VL2HsPyFsajzg/kxQ8naGUrm1+lGgAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a2279b22a5df22fc2a85c06a400ce9d4/3dc2b/academy-layer5.png","srcSet":"/static/a2279b22a5df22fc2a85c06a400ce9d4/3dc2b/academy-layer5.png 300w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2279b22a5df22fc2a85c06a400ce9d4/de47d/academy-layer5.webp 300w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9133333333333333}},"extension":"png","publicURL":"/static/a2279b22a5df22fc2a85c06a400ce9d4/academy-layer5.png"}},"fields":{"slug":"/resources/academy/layer5-academy-vs-moocit"}},{"id":"37517025-668e-582d-89ed-7978a482a716","body":"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport { HPEfacts, HPEintro, HPEbenefits } from \"./hpe.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport { Link } from \"gatsby\";\nimport Button from \"../../../../reusecore/Button\";\nimport GlobeIcon from \"./globe.svg\";\nimport UsersIcon from \"./users.svg\";\nimport NetworkIcon from \"./network.svg\";\nimport LayersIcon from \"./layers.svg\";\nimport InlineQuotes from \"../../../../components/Inline-quotes\";\nimport MesheryIntegration from \"./meshery-integrations.svg\";\nimport Maxi from \"../../../../collections/members/maximiliano-churichi/Maximiliano-Churichi.webp\";\nimport Yogi from \"./yogi.webp\"\n\n<ResourcesWrapper>\n\n<HPEintro>\nHPE's adoption of Meshery was driven by the need to simplify Kubernetes cluster management and monitoring. Meshery is an open source cloud native management tool that provides a self-service platform for designing, visualizing, deploying, testing, and operating cloud native infrastructure.\n</HPEintro>\n\n<div style={{display: \"flex\", justifyContent: \"center\", padding: \"2%\"}}>\n\n   <Button $secondary title=\"Download Case Study\" alt=\"Download HPE's Adoption of Layer5 Meshery and Kanvas\" $url=\"/case-studies/hpe-adoption-of-layer5-meshery-and-kanvas.pdf\" />\n\n</div>\n\n<p>\n   HPE, a leading technology company specializing in enterprise infrastructure, adopted Meshery Extension to enhance their Kubernetes deployments. HPE uses Kubernetes as a primary platform to build and deploy their containerized applications. The company has a large and complex Kubernetes environment, which requires robust networking solutions for efficient communication between services.\n</p>\n\n\n\n<HPEfacts>\n   <tr><td colspan=\"2\"><h4>HPE FAST FACTS</h4></td></tr>\n   <tr>\n      <td>\n      <img src={UsersIcon} />\n      Full Time Employees: 60,000+\n      </td>\n      <td>\n      <img src={GlobeIcon} />\n      Market Presence: HPE is one of the largest technology companies globally, serving customers in over 150 countries.\n      </td>\n   </tr>\n   <tr>\n      <td>\n      <img src={LayersIcon} />\n      HPE GreenLake: HPE GreenLake is a key offering by the company, providing a flexible and scalable IT infrastructure model known as \"everything-as-a-service.\"\n      </td>\n      <td>\n      <img src={NetworkIcon} />\n      Research and Development: HPE invests significantly in research and development to drive innovation. It operates HPE Labs, which focuses on developing cutting-edge technologies and solutions for the future.\n      </td>\n   </tr>\n</HPEfacts>\n\n<p>\nSPIRE is a toolchain of APIs for establishing trust between software systems across a wide variety of hosting platforms. SPIRE exposes the SPIFFE Workload API, which can attest running software systems and issue SPIFFE IDs and SVIDs to them. <br/><br/>\n</p>\n\n<HPEbenefits>\n    <b>Meshery offers several benefits to HPE, including:</b>\n    <br/>\n    ‚úîÔ∏è Consistent service mesh management: HPE can now manage all their service meshes consistently, regardless of the underlying infrastructure or cloud provider.\n    <br/>\n    ‚úîÔ∏è Improved observability: With Meshery's built-in visualization and observability tools, HPE can gain insights into the behavior of their service meshes, detect anomalies, and troubleshoot issues in real-time.\n    <br/>\n    ‚úîÔ∏è Simplified testing and validation: Meshery's service mesh validation capabilities enable HPE to easily test and validate their service meshes, ensuring that they meet their performance, security, and compliance requirements.\n    <br/>\n    ‚úîÔ∏è Enhanced security: With Meshery's security features, HPE can ensure that their service meshes are secure and compliant with their organization's security policies.\n</HPEbenefits>\n<br/>\n\n<p>\n    Overall, Meshery has helped HPE to streamline their integration of the identity management control plane to reduce complexity, and improve the overall reliability and performance of their Kubernetes environment. SPIFFE is a set of open-source specifications for a framework capable of bootstrapping and issuing identity to services across heterogeneous environments and organizational boundaries. The lifecycle of SPIFFE identities, SVIDs, is managed by SPIRE, a production-ready implementation of the SPIFFE APIs that performs node and workload attestation in order to securely issue SVIDs to workloads, and verify the SVIDs of other workloads, based on a predefined set of conditions.\n</p>\n\n<p>\n    <b>HPE's adoption of Meshery has also been enhanced by the platform's ability to integrate with other popular technologies, such as SPIRE and Istio</b>\n</p>\n<p style={{display: \"flex\", justifyContent: \"center\", alignItem: \"center\", padding: \"2%\"}}>\n<img src={MesheryIntegration}></img>\n</p>\n<p>\n   SPIRE is an open-source project that provides a secure and scalable solution for service identity and authentication in distributed systems. HPE uses SPIRE to authenticate and authorize services in their Kubernetes environment, which ensures that only authorized services can communicate with each other.\n</p>\n\n<p>\n   Meshery's integration with SPIRE enables HPE to manage SPIRE instances, issue and revoke service certificates, and automate the management of SPIRE agents across their Kubernetes clusters. This integration ensures that HPE's service meshes are secure, and only authorized services can communicate with each other.\n</p>\n  <InlineQuotes\n          quote=\"With a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Meshery's Extension to deploy their cloud native infrastructure of choice and test the performance of our SPIFFE and SPIRE-based identity solution.\"\n          person=\"Maximiliano Churichi\"\n          title=\"Software Engineer at HPE\"\n          image={Maxi} />\n\n<p>\n   In addition, HPE's use of Meshery has been enhanced by its integration with Istio, an open-source service mesh that provides a comprehensive solution for traffic management, security, and observability in Kubernetes environments.\n</p>\n\n<p>\n   Meshery's integration with Istio enables HPE to manage Istio service meshes and configurations, automate the deployment of Istio components, and monitor and visualize Istio metrics and traces. This integration enables HPE to simplify the management of their Istio service meshes, ensure their security and compliance, and gain insights into their behavior for better decision-making.\n</p>\n\n<p>\n   Overall, HPE's adoption of Meshery, along with its integration with SPIRE and Istio, has enabled the company to streamline their service mesh management, ensure the security and compliance of their Kubernetes environment, and gain valuable insights into the behavior of their service meshes for improved performance and reliability.\n</p>\n\n<p>\n   <b>Meshery also implements the Service Mesh Performance (SMP) specification</b>\n</p>\n\n<p>\n   SMP is a community-driven effort that provides a standard for measuring and comparing the performance of different service meshes. It is designed to help users select the best service mesh for their needs by providing a common framework for benchmarking.\n</p>\n <InlineQuotes\n          quote=\"The Layer5 team has been amazing. Our project wouldn‚Äôt have been successful with out Meshery.\"\n          person=\"Yogi Porla\"\n          title=\"Engineering Manager, HPE\"\n          image={Yogi} />\n<p>\n   Meshery implements SMP by providing a simple and easy-to-use interface for running performance tests against different service meshes. Users can select the service mesh they want to test, configure the test parameters (such as the number of requests per second and the number of concurrent clients), and run the test. Meshery will then generate a report that shows the performance metrics for each service mesh, such as latency, throughput, and error rates.\n</p>\n\n<p>\n   By implementing SMP, Meshery provides a valuable tool for developers and operators who are evaluating different service meshes. Instead of having to create their own benchmarks, they can use SMP to get an objective and standardized view of each service mesh's performance characteristics. This can save a significant amount of time and effort, and help users make more informed decisions when choosing a service mesh.\n</p>\n\n<p>\nOverall, HPE's use of Meshery and the Docker Extension for Meshery demonstrates the power of cloud native technologies and the importance of open source collaboration. By leveraging these tools, HPE has been able to streamline its development and deployment processes, improve performance and security, and stay at the forefront of the cloud native movement.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"HPE's Adoption of Layer5 Meshery and Kanvas","type":"Case Study","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/case-study/hpes-adoption-of-meshery-and-kanvas"}},{"id":"322a9220-3d64-5c7e-bc41-c0021e2cba60","body":"\nimport {ResourcesWrapper} from \"../../Resources.style.js\";\nimport {Link} from \"gatsby\"\nimport DockerExtensionCTA from \"../../../../sections/Docker-Meshery/docker-extension-CTA.js\"\nimport PlaygroundCTA from \"../../../../sections/Playground/playground-CTA.js\"\n\n<ResourcesWrapper>\n\nDocker Swarm is a <Link to=\"../../articles/kubernetes/management-of-kubernetes\">container orchestration</Link> tool that makes it easy to manage and scale your existing Docker infrastructure. It consists of a pool of Docker hosts that run in Swarm mode with some nodes acting as managers, workers, or both. Using Docker Swarm mode to manage your Docker containers brings the following benefits:\n\n- It allows you to incrementally apply updates with zero downtime.\n- It increases application resilience to outages by reconciling any differences between the actual state and your expressed desired state.\n- It eases the process of scaling your applications since you only need to define the desired number of replicas in the cluster.\n- It is built into the `docker` CLI, so you don't need additional software to get up and running.\n- It enables multi-host networking such that containers deployed on different nodes can communicate with each other easily.\n\nIn this tutorial, you will learn key concepts in Docker Swarm and set up a highly available Swarm cluster that is resilient to failures. You will also learn some best practices and recommendations to ensure that your Swarm setup is fault tolerant.\n\n## Prerequisites\n\nBefore proceeding with this tutorial, ensure that you have access to five Ubuntu 22.04 servers. This is necessary to demonstrate a highly available set up, although it is also possible to run Docker Swarm on a single machine. You also need to configure each server with a user that has administrative privileges.\n\nThe following ports must also be available on each server for communication purposes between the nodes. On Ubuntu 22.04, they are open by default:\n\n- TCP port 2377 for cluster management communications,\n- TCP and UDP port 7946 for communication among nodes,\n- TCP and UDP port 4789 for overlay network traffic.\n\n## Explaining Docker Swarm terminology\n\nBefore proceeding with this tutorial, let's examine some terms and definitions in Docker Swarm so that you have enough understanding of what each one means when they are used in this article and in other Docker Swarm resources.\n\n- **Node**: refers to an instance of the Docker engine in the Swarm cluster.\n- **Manager nodes**: they are tasked with handling orchestration and cluster management functions, and dispatching incoming tasks to worker nodes. They can also act as worker nodes unless placed in Drain mode (recommended).\n- **Leader**: this is a specific manager node that is elected to perform orchestration tasks and management/maintenance operations by all the manager nodes in the cluster using the <a rel=\"noreferrer\" target=\"_blank\" className=\"whitespace-nowrap\" href=\"https://raft.github.io/\">Raft Consensus Algorithm</a>.\n- **Worker nodes**: are Docker instances whose sole purpose is to receive and execute Swarm tasks from manager nodes.\n- **Swarm task**: refers to a Docker container and the commands that run inside the container. Once a task is assigned to a node, it can run or fail but it cannot be transferred to a different node.\n- **Swarm service**: this is the mechanism for defining tasks that should be executed on a node. It involves specifying the container image and commands that should run inside the container.\n- **Drain**: means that new tasks are no longer assigned to a node, and existing tasks are reassigned to other available nodes.\n\n## Docker Swarm requirements for high availability\n\nA highly available Docker Swarm setup ensures that if a node fails, services on the failed node are re-provisioned and assigned to other available nodes in the cluster. A Docker Swarm setup that consists of one or two manager nodes is not considered highly available because any incident will cause operations on the cluster to be interrupted. Therefore the minimum number of manager nodes in a highly available Swarm cluster should be three.\n\nThe table below shows the number of failures a Swarm cluster can tolerate depending on the number of manager nodes in the cluster:\n\n| Manager Nodes | Failures tolerated |\n| :--- | :--- |\n| 1 | 0 |\n| 2 | 0 |\n| 3 | 1 |\n| 4 | 1 |\n| 5 | 2 |\n| 6 | 2 |\n| 7 | 3 |\n\nAs you can see, having an even number of manager nodes does not help with failure tolerance, so you should always maintain an odd number of manager nodes. Fault tolerance improves as you add more manager nodes, but Docker recommends no more than seven managers so that performance is not negatively impacted since each node must acknowledge proposals to update the state of the cluster.\n\nYou should also distribute your manager nodes in separate locations so they are not affected by the same outage. If they run on the same server, a hardware problem could cause them all to go down. The high availability Swarm cluster that you will be set up in this tutorial will therefore exhibit the following characteristics:\n\n- 5 total nodes (2 workers and 3 managers) with each one running on a separate server.\n- 2 worker nodes (`worker-1` and `worker-2`).\n- 3 manager nodes (`manager-1`, `manager-2`, and `manager-3`).\n\n<PlaygroundCTA/>\n<DockerExtensionCTA/>\n\n## Step 1 ‚Äî Installing Docker\n\nIn this step, you will install Docker on all five Ubuntu servers. Therefore, execute all the commands below (and in step 2) on all five servers. If your host offers a snapshot feature, you may be able to run the commands on a single server and use that server as a base for the other four instances.\n\nLet's start by installing the latest version of the Docker Engine (20.10.18 at the time of writing). Go ahead and update the package information list from all configured sources on your system:\n\n```bash\nsudo apt update\n```\n\nAfterward, install the following packages to allow `apt` to use packages over HTTPS:\n\n```bash\nsudo apt install apt-transport-https ca-certificates curl software-properties-common\n```\n\nNext, add the GPG key for the official Docker repository to the server:\n\n```bash\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n```\n\nOnce the GPG key is added, include the official Docker repository in the server's apt sources list:\n\n```bash\necho \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\nFinally, update apt once again and install the Docker Engine:\n\n```bash\nsudo apt update\n```\n\n```bash\nsudo apt install docker-ce\n```\n\nOnce the relevant packages are installed, you can check the status of the `docker` service using the command below:\n\n```bash\nsudo systemctl status docker\n```\n\nIf everything goes well, you should observe that the container engine is active and running on your server.\n\n## Step 2 ‚Äî Executing the Docker command without sudo\n\nBy default, the `docker` command can only be executed by the root user or any user in the `docker` group (auto created on installation). If you execute a `docker` command without prefixing it with `sudo` or running it through a user that belongs to the `docker` group, you will get a permission error that looks like this:\n\n```bash\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \"http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json\": dial unix /var/run/docker.sock: connect: permission denied\n```\n\nAs mentioned earlier, using `sudo` with `docker` is a security risk, so the solution to the above error is to add the relevant user to the `docker` group. This can be achieved through the command below:\n\n```bash\nsudo usermod -aG docker $USER\n```\n\nNext, run the following command and enter the user's password when prompted for the changes to take effect:\n\n```bash\nsu - $USER\n```\n\nYou should now be able to run `docker` commands without prefixing them with `sudo`. For example, when you run the command `docker ps`, you should observe the output.\n\nBefore proceeding to the next step, ensure that all the commands in step 1 and step 2 have been executed on all five servers.\n\n## Step 3 ‚Äî Initializing the Swarm Cluster\n\nAt this point, each of your five Docker instances are acting as separate hosts and not as part of a Swarm cluster. Therefore, in this step, we will initialize the Swarm cluster on the `manager-1` server and add the hosts to the cluster accordingly.\n\nStart by logging into one of the Ubuntu servers (`manager-1`) and retrieve the private IP address of the machine using the following command:\n\n```bash\nhostname -I | awk '{print $1}'\n```\n\nCopy the IP address to your clipboard and replace the `<manager_1_server_ip>` placeholder in the command below to initialize Swarm mode:\n\n```bash\ndocker swarm init --advertise-addr <manager_1_server_ip>\n```\n\nIf the command is successful, you will see output indicating that the Swarm has been initialized and that the current node is now a manager. It will also provide a command to join worker nodes to the cluster. Copy the command for later use.\n\nNext, SSH into each of the other four Ubuntu servers (manager-2, manager-3, worker-1, and worker-2) and run the command you copied earlier to join them to the Swarm cluster. The command should look like this:\n\n```bash\ndocker swarm join --token <token> <manager_1_server_ip>:<port>\n```\n\nAfter running the command on each server, you should see output indicating that the node has joined the Swarm as either a manager or a worker. To verify the status of the Swarm cluster, you can run the command `docker node ls` on the manager node:\n\n```bash\ndocker node ls\n```\n\nYou should see a list of all the nodes in the Swarm cluster, including their IDs, hostname, status, availability, and whether they are a manager or a worker.\n\n## Step 4 ‚Äî Deploying the Application Stack\n\nNow that you have a functioning Docker Swarm cluster, you can deploy your application stack. In this tutorial, we will use a simple example of a web application stack consisting of a front-end service and a back-end service.\n\nStart by creating a new directory for your application stack on the manager node:\n\n```bash\nmkdir app-stack\ncd app-stack\n```\n\nNext, create a file called `docker-compose.yml` in the `app-stack` directory and open it in a text editor:\n\n```bash\nnano docker-compose.yml\n```\n\nCopy and paste the following YAML code into the `docker-compose.yml` file:\n\n```yaml\nversion: '3.8'\n\nservices:\n  frontend:\n    image: nginx:latest\n    ports:\n      - 80:80\n    deploy:\n      replicas: 2\n      restart_policy:\n        condition: on-failure\n\n  backend:\n    image: httpd:latest\n    ports:\n      - 8080:80\n    deploy:\n      replicas: 2\n      restart_policy:\n        condition: on-failure\n```\n\nThis Docker Compose file defines two services: `frontend` and `backend`. The `frontend` service uses the `nginx:latest` image and maps port 80 of the host to port 80 of the container. It is configured to have 2 replicas and to restart on failure. The `backend` service uses the `httpd:latest` image and maps port 8080 of the host to port 80 of the container. It is also configured to have 2 replicas and to restart on failure.\n\nSave and close the `docker-compose.yml` file.\n\nTo deploy the application stack, run the following command:\n\n```bash\ndocker stack deploy -c docker-compose.yml app-stack\n```\n\nIf the command is successful, you should see output indicating that the services are being deployed. You can check the status of the services by running the command `docker service ls`:\n\n```bash\ndocker service ls\n```\n\nYou should see a list of the services in the stack, including their names, mode, replicas, and ports.\n\n## Conclusion\n\nIn this tutorial, you learned how to set up a highly available Docker Swarm cluster and deploy a simple application stack. This setup provides fault tolerance and load balancing for your applications, allowing you to scale them easily as your needs grow.\n\nNext steps:\n\n- Explore more Docker Swarm features, such as service updates and rolling updates.\n- Deploy your own application stack using Docker Compose.\n- Learn about Docker networking and how to create overlay networks.\n\n</ResourcesWrapper>","frontmatter":{"title":"Configuring Highly Available Docker Swarm","type":"Tutorial","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEAAAQUxQSJQAAAABgGJt2zLlGU+eXav7TJqBSPTOYQW6BDqHaIkN2BogujtEd30f7NcVRMQEwOyTr893V5ebBTW1rmX+m1FzQMXoYPq/4PS90tnCRPZPcJxqr1Z7AQxQ6zGAIU1rAFqk/FWaA+B9IUWEf0XIPgCYJ4WKwm3Xn/Q9VcpHJ/5tXqq474ZiYHjljeTnxVQMai3uVLUUdMJIVlA4IJgAAACQAwCdASoUABEAPtFgqE+oJSOiKAgBABoJbACxG68ARBlm6uAAANS2tWZeMGxmi1qLnh5LjlIo4xIsTbq4p4hCKxJzxrDHwZu1xhyZ41Gz3YoQA/G0bZzOYnmzs7xPjdFxkzyc7a2RtoIDHkb+G1LvgYf//E+1Wr8D10Xopi//C4s/72CdFz/pXwPt+CHUPPeTizNi0zgAAA=="},"images":{"fallback":{"src":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp","srcSet":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp 512w","sizes":"100vw"},"sources":[]},"width":1,"height":0.83203125}},"extension":"webp","publicURL":"/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlIBAABXRUJQVlA4WAoAAAAQAAAAEwAAEAAAQUxQSJQAAAABgGJt2zLlGU+eXav7TJqBSPTOYQW6BDqHaIkN2BogujtEd30f7NcVRMQEwOyTr893V5ebBTW1rmX+m1FzQMXoYPq/4PS90tnCRPZPcJxqr1Z7AQxQ6zGAIU1rAFqk/FWaA+B9IUWEf0XIPgCYJ4WKwm3Xn/Q9VcpHJ/5tXqq474ZiYHjljeTnxVQMai3uVLUUdMJIVlA4IJgAAACQAwCdASoUABEAPtFgqE+oJSOiKAgBABoJbACxG68ARBlm6uAAANS2tWZeMGxmi1qLnh5LjlIo4xIsTbq4p4hCKxJzxrDHwZu1xhyZ41Gz3YoQA/G0bZzOYnmzs7xPjdFxkzyc7a2RtoIDHkb+G1LvgYf//E+1Wr8D10Xopi//C4s/72CdFz/pXwPt+CHUPPeTizNi0zgAAA=="},"images":{"fallback":{"src":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp","srcSet":"/static/5b72df1802df0608ac6ee6e6bff70c9d/7079b/docker-swarm.webp 512w","sizes":"100vw"},"sources":[]},"width":1,"height":0.83203125}},"extension":"webp","publicURL":"/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp"}},"fields":{"slug":"/resources/docker/configuring-highly-available-docker-swarm"}},{"id":"ea7f10cc-a66d-5ebe-9167-6bf3e9bc136b","body":"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport { Link } from \"gatsby\";\nimport Button from \"../../../../reusecore/Button\";\n\n<ResourcesWrapper>\n<p>\n    Terraform is a powerful tool that helps users manage and provision infrastructure resources in a consistent and efficient manner. With Terraform, you can define your infrastructure as code, using human-readable configuration files that can be versioned, shared, and reused. This makes it easy to create, modify, and manage your infrastructure resources, whether they are cloud-based or on-premises.\n</p>\n<div className=\"intro\">\n  <p>\n     It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.\n  </p>\n</div>\n\n<p>\n  One way to further enhance your use of Terraform is by integrating it with Meshery. Meshery is a cloud-native management platform that provides a unified interface for managing and monitoring your infrastructure resources, including those managed by Terraform. By integrating Terraform with Meshery, you can leverage the power and flexibility of both tools to streamline your infrastructure management process.\n</p>\n\n<p>\n  One of the key benefits of using Terraform with Meshery is the ability to manage and monitor infrastructure resources in a consistent and centralized manner. With Meshery, you can view and manage all of your infrastructure resources, whether they are managed by Terraform or other tools, from a single dashboard. This allows you to quickly identify any issues or potential problems with your infrastructure, and take action to resolve them in a timely manner.\n</p>\n\n<p>\n  Another benefit of using Terraform with Meshery is the ability to automate your infrastructure management process. With Meshery, you can create and manage automated pipelines for provisioning and managing your infrastructure resources. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks.\n</p>\n\n<p>\n  In addition to these benefits, using Terraform with Meshery also provides a number of other advantages. For example, Meshery integrates with a wide range of tools and platforms, allowing you to easily incorporate your existing infrastructure resources into your management process. This can help to reduce the complexity of managing your infrastructure, and make it easier to keep everything running smoothly.\n</p>\n\n<p>\n  Overall, the use of Terraform with Meshery can help to streamline and improve your infrastructure management process. By integrating these two powerful tools, you can gain greater visibility and control over your infrastructure resources, and automate many of the tasks involved in managing them. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks. So, it is a good idea to use Terraform with Meshery to improve the efficiency and effectiveness of your infrastructure management process.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Terraform with Meshery","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/cloud-native/terraform-with-meshery"}},{"id":"d28378ea-03c7-5dc2-99a3-95a1b827966a","body":"import { ResourcesWrapper } from \"../../../Resources.style.js\";\nimport picture1 from \"./meshery-core-architecture.webp\"; \nimport picture2 from \"./settings.webp\"; \nimport picture3 from \"./context-switcher.webp\"; \nimport ClusterImg from \"./multi-cluster-kubernetes-management-with-meshery.webp\";\nimport CTA_FullWidth from \"../../../../../components/Call-To-Actions/CTA_FullWidth\";\n\n<ResourcesWrapper>\n  \n### What is Kubernetes Management, and Why Should You Care?\n\nIt is easy to understand why Kubernetes has become one of the most popular tools on the market today. Primarily, it allows you to easily manage Docker containers across your entire infrastructure with very little overhead, making it easier than ever to manage massive amounts of information in a timely manner. But what are you supposed to do with all this information? That‚Äôs where Kubernetes management comes into play‚Äîthe process of using that information in an effective manner can make or break your efforts, so it‚Äôs essential that you choose the right solutions from the get-go.\n\n### Defining Kubernetes management\n\nKubernetes management is the process of managing your containers on a Kubernetes cluster. This can include things like adding or removing clusters, scaling clusters up or down, balancing workloads across nodes in a cluster, and restarting failed containers or nodes in a cluster. These tasks are complicated and involve many different types of actions. Figuring out how to do them all manually would be extremely time-consuming. Fortunately, there are tools like Meshery that automate these tasks for you, making it easier to see what‚Äôs going on within your cluster so you can make informed decisions about what needs to happen next. Staying on top of Kubernetes management will not only keep your cluster running smoothly but also help prevent problems before they occur. Automating this process will save you time and money, leaving more time to focus on other aspects of the business. When things go wrong, automated Kubernetes management allows you to have a plan and know exactly what steps need to be taken to recover from an incident. With these benefits in mind, it‚Äôs important that companies with containerized infrastructure use some type of automation for their Kubernetes management.\n\n### The benefits of Kubernetes management\n\nKubernetes management can seem like a daunting task. In the past, IT teams had to worry about maintaining large clusters of machines that required constant tweaking and monitoring. Kubernetes simplifies this process by automating tasks such as: \n\n- Monitoring cluster health\n- Deploying apps across nodes\n- Running rolling updates\n- Scaling up or down resources on demand\n- Auto-recover from failures\n- Application deployment consistency\n- Managing container upgrades\n\nAfter reading through these benefits, you may be asking yourself, \"Why should I care? Here are two reasons why you should care about Kubernetes management: - Kubernetes management has been shown to improve software development efficiency because it reduces time spent waiting for containers to restart and redeploy. A recent study showed that developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution.\n\nKubernetes management has also been shown to reduce operational costs because it eliminates the need for manual intervention in scaling applications, updating running containers with new versions, etc. If your IT team was spending 10 hours per week on manual operations before adopting Kubernetes, they'll spend only 2 hours after switching over!\n\n<CTA_FullWidth \n  image={ClusterImg}\n  alt=\"Multi-Cluster Kubernetes Management with Meshery\"\n  content=\"Multi-Cluster Kubernetes Management with Meshery\"\n  button_text=\"Read blog post\"\n  url=\"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\"\n  external_link={false}\n  className=\"get-start-kubernetes-resource\"\n/>\n  \n### The challenges of Kubernetes management\n\nKubernetes management can seem like a difficult endeavour. Between determining how to automate deployment and scaling and comprehending the fundamentals of how it operates, there are numerous factors to consider. Fortunately, there are numerous frameworks that simplify this procedure. But before going into new frameworks or technologies, you must grasp what Kubernetes administration comprises so that you know what you're attempting to automate. Kubernetes management comprises a variety of activities, such as building up clusters, keeping apps running on those clusters up-to-date, monitoring usage and providing alarms to keep things running smoothly, and shutting down clusters when they are no longer required.\n\nThere are numerous ways to manage these tasks: manually, with containers, with an orchestration system such as Ansible Tower, Cloud Control 12c, or ServiceNow NMS, with containers-as-a-service providers such as Docker Datacenter or AWS EKS, with container service offerings from cloud providers such as Azure Container Instances, by configuring Kubernetes with your own framework, and by installing Kubectl on your laptop for direct control. Each strategy has advantages and disadvantages that may make one more suitable for your organisation than another. Regardless of the approach you adopt, you must plan accordingly.\n\nImportantly, the fact that Kubernetes is gaining popularity does not imply that it will replace your existing infrastructure layers. It augments their capabilities with scalability and large-scale application management (which would have been difficult without automation). In addition, the definition of management varies based on the size of the organisation: small businesses may prefer self-hosted platforms, whilst larger businesses would often primarily rely on SaaS solutions.\n\n### How Meshery makes it easier to run Kubernetes\n\nMeshery is the only cloud-native manager in the world that supports more adapters than any other project or product.\n\n<img src={picture1} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n\nMeshery has been designed for the world of many service meshes and many Kubernetes clusters. As such, great attention was made to guarantee that it is an extensible management platform, able to handle a diverse range of infrastructure and new use cases quickly through its plugin mechanism. Meshery Server acts as an operation delegator, determining which Meshery Adapter has registered its capacity for the given operation. The operation is then sent to the appropriate component using a gRPC call. This could be one of Meshery's service mesh adapters, like the Istio adapter.\n\nMeshery's capability is constantly expanding, from multi-mesh to now multi-cluster, to give developers, operators, and security engineers more control over their infrastructure. Each part of Meshery's architecture makes a big difference in how it manages multiple Kubernetes clusters.\n\n### Meshery management across many clusters\n\nFrom the settings page, users can do things related to clusters, like add more clusters, remove data from existing clusters, or delete existing clusters.\n\n<img src={picture2} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n\nMeshery also deploys Meshery operators throughout the cluster it is about to manage. This operator is in charge of the Meshery broker and the MeshSync lifecycle. MeshSync is responsible for monitoring various types of resources by establishing a watch stream over each of them. MeshSync then sends the data to the NATS server, of which the Meshery server is a client. Meshery server then receives all necessary data relating to cluster activity.\n\n<img src={picture3} className=\"image-center\" alt=\"Management of Kubernetes with Meshery\" />\n\nMeshery, by default, wants to be as aware of your infrastructure as possible in order to deliver value. As such, it deploys its operator across each identified cluster. However, you can fine-tune this configuration by going over each one.\n\n### The future of Kubernetes management\n\nKubernetes management has been one of the buzzwords since 2018. But what does it actually mean? And why should you care about it? At its core, Kubernetes management is a system that helps make sense of the nuances of how different containers work together to create an application. As we rely more on containers for our everyday apps, there needs to be a way to keep track of them all. That's where Kubernetes comes in with its ability to manage these containers that are spread out across different servers and understand which ones need more resources or want to be shut down because they're no longer needed. The easier it becomes for developers and engineers to deploy applications without worrying about how they are going to be managed, the better off everyone will be. Fortunately, as containerization grows in popularity among developers and IT teams alike, so does the number of tools for managing it.\n\nA lot of container platforms provide native management functionality: Docker Swarm allows you to use simple commands like swarm stop or swarm pull when your swarm is up-to-date; Kargo automatically manages clusters using zero-touch configuration; Rancher provides tools to manage containers using any infrastructure stack; and Mesos offers both orchestration capabilities through Marathon as well as advanced resource scheduling features. It's not always easy to know which platform will work best for your organization, but it's important to find one that suits your company's needs‚Äîespecially if IT is looking forward to a future without manual management tasks!\n \n</ResourcesWrapper>\n","frontmatter":{"title":"Management of Kubernetes","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/kubernetes/management-of-kubernetes"}},{"id":"daa05956-2d58-5dc5-b0cf-e3a4428cde4b","body":"import { ResourcesWrapper } from \"../../../Resources.style.js\";\nimport picture1 from \"./Picture1.webp\";\nimport ClusterImg from \"./multi-cluster-kubernetes-management-with-meshery.webp\";\nimport KanvasDesigner from \"./KanvasDesigner.webp\";\nimport KanvasVisualizer from \"./KanvasVisualizer.webp\";\nimport CTA_FullWidth from \"../../../../../components/Call-To-Actions/CTA_FullWidth\";\n\n<ResourcesWrapper>\n<p>\nKubernetes, an open-source container orchestration platform, is growing in popularity for deploying and managing cloud-native applications. Kubernetes was created by Google in 2014, and it is now used by many major companies, including IBM, Microsoft, Red Hat, and Amazon. In this article, we'll talk about Kubernetes, its benefits, and the best ways for your organization to use it.\n </p>\n  \n  <h3> What is Kubernetes? </h3>\n  \n<p>\nKubernetes offers fully managed and adapted architecture services that optimize your cloud-native application. Kubernetes is a platform that hides virtual machines, shows the infrastructure as an infrastructure-as-a-service (IAAS), network, and load balancer, and offers data storage and operations that are consistent across containers.\n</p>\n  \n  <p> For example, Kubernetes nodes work as Kubernetes containers, such as an application, an application server, and control processes in Docker containers. Kubernetes components such as Kubernetes nodes and Kubernetes containers can be defined or modified via configuration files or can be specified subsequently. Individual Kubernetes components can be scaled according to elasticity needs to optimize performance.</p>\n  \n  <p> Kubernetes optimizes a Kubernetes environment in the cloud, Docker containers on a system for development or testing, and the master or control plane of its cloud cluster management infrastructure.</p>\n  \n  <h3> What's the Difference between Kubernetes and Docker? </h3>\n  \n<p>\nOver the past few years, containers have become increasingly popular within the software development community, and they have now evolved into two major platforms ‚Äî Docker and Kubernetes. Both are incredibly powerful tools that allow developers to containerize their applications, but they are also slightly different in a number of ways, with more differences on the horizon as Docker announces its new focus on Kubernetes and containers orchestration. How do you decide which one to use? What does the future hold for each? Here‚Äôs what you need to know about the difference between Docker and Kubernetes.\n</p>\n  \n  <p> Docker is an open-source platform designed to help developers and IT professionals create, deploy, and run applications. This containerization technology is often used in conjunction with orchestration software such as Kubernetes. However, these two technologies are not interchangeable; they serve different purposes. </p>\n  \n  <h3> Why Should You Care About Kubernetes? </h3>\n  \n  <p> Kubernetes was first made available for Google's internal use for DNS hosting. Open-source software projects were not able to use it. </p>\n  \n  <p> Today, Kubernetes is in use by large-scale companies that use container orchestration. And in January 2019, The New Stack reported that a survey conducted in that month, which included the Kubernetes user group, discovered that Kubernetes reached more than 40,000 users and 200 companies were working on Kubernetes at that point. In addition, Gartner indicated that Kubernetes Inc. would make some $8.5 billion in 2019. </p> \n  \n  <h3> What does Kubernetes Do? </h3>\n  \n  <p> In contrast to an overall infrastructure, Kubernetes is a dynamic layer-oriented computing infrastructure. The essence of Kubernetes is how an entire infrastructure hops! Kubernetes is a container orchestration and management platform that has built-in features for self-replication, elasticity, and scalability. Through these and more features, Kubernetes \"promovi-is\" for container orchestrators for both production and lab environments. </p>\n  \n  <h3> Kubernetes Architecture </h3>\n  \n  <p> Even though Kubernetes is a software platform that lets organizations manage their application workloads in containers, a traditional Kubernetes cluster may not be the best solution for a number of business needs. </p>\n \n  <img src = {picture1} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n  \n  <p> A cluster of virtual computing resources is only one option, and it has its drawbacks. What happens when you lose disk space (which can happen if you don't add new containers, users, or workloads to a cluster)? Do you have another cluster for redundancy, and how do you integrate the two together? </p>\n\n  <p> Hyperconverged infrastructures like Red Hat OpenShift are an alternative that combine several technologies into a single virtual machine or physical machine. </p> \n  \n  <h3> Best Practices for Kubernetes </h3>\n  \n<p>\nKubernetes is a container orchestration platform created by Google in 2014. It provides a way for companies to build fully self-sufficient, scalable, multi-container applications every time they need to deploy and manage their own containers. It's aimed at pretty much the same audience as Docker and other container orchestration platforms‚Äîthat is, organizations that run containerized applications and want to deploy scalable, repeatable deployments.\n</p>\n  \n<p>\nAt the most basic and most simplistic level, a group of containers (usually 16) is cross-linked together in a cluster, based on Docker. Containers run inside a cluster of virtual machines (Kubernetes VM) as a single Linux file system. Kubernetes organizes the creation, deletion, and management of containers into container concepts that provide fault tolerance, availability, scaling, permission management, and secure containers that should be able to run together and share resources. Each host runs one or more containers, providing the abstraction of which containers can run on which hosts.\n</p>\n  \n<p>Since Kubernetes services are usually very easy to use, the user experience is very similar to that of centralized solutions. </p>\n  \n<p>With Kubernetes, businesses can make data repositories and containers, federate their resources in an efficient way, manage billing, certify capacity, quota, access rights, and more. </p>\n  \n<p>It can scale to many nodes simultaneously, so when their machines scale up, then their containers could scale up too. </p>\n  \n<h3>Kubernetes Concepts and Terminology </h3>\n  \n<p>Kubernetes was developed in 2014 as a Google container orchestrator, a container scheduler and more. Kubernetes was created to manage distributed applications, including Docker containers. According to SUSE, Kubernetes is simple to learn, easy to manage, and supports an on-premise, private, public, or hybrid architecture. Kubernetes is flexible enough to be split up over many servers in your data center. </p>\n  \n<p>This simplificator, one example of many, allows one to scale independent containers. </p>\n  \n<p> Let's understand better what Kubernetes is: </p>\n  \n<p> In an application ecosystem of operating system Docker containers, Kubernetes acts as a centralized management guided by distributed logic. Kubernetes can be used to deliver web traffic, graphics work, or IP traffic from IoT devices. The main benefit is that clusters can be easily expanded to a huge size with all functions. </p>\n \n<p>\nWhat are pods? Pods are Docker instances that you can use to deploy your containers in environments like Kubernetes, which can be private, public, or a mix of the two.\n</p>\n  \n<p> Environments may be private services or public clouds. </p>\n  \n<p> Kubernetes can be used to manage containers because they are easy to use and make it easy to scale your containers. </p>\n  \n<p> Installation tutorials are sometimes yoinked without ever reading the help. </p>\n  \n<h3> RBAC and Firewall Security </h3>\n  \n<p>\nToday, everything is hackable, and so is your Kubernetes cluster. Hackers often try to find vulnerabilities in the system in order to exploit them and gain access. So, keeping your Kubernetes cluster secure should be a high priority. The first thing to do is make sure you are using RBAC in Kubernetes. RBAC is role-based access control. Assign roles to each user in your cluster and to each service account running in your cluster. Roles in RBAC contain several permissions that a user or service account can perform. You can assign the same role to multiple people, and each role can have multiple permissions.\n</p>\n  \n<p> RBAC settings can also be applied to namespaces, so if you assign roles to a user allowed in one namespace, they will not have access to other namespaces in the cluster. Kubernetes provides RBAC properties such as role and cluster role to define security policies. </p>\n  \n<p> You can create a firewall for your API server to prevent attackers from sending connection requests to your API server from the Internet. To do this, you can either use regular firewalling rules or port firewalling rules. If you are using something like GKE, you can use a master authorized network feature in order to limit the IP addresses that can access the API server. </p>\n  \n  <h3> Managing Kubernetes Clusters </h3>\n  \n<p>\nKubernetes is a project that lets you create and manage individual containers or a container cluster on a mainframe. Clusters may consist of physical, virtual, or cloud-based computing resources.\n</p>\n<CTA_FullWidth \n  image={ClusterImg}\n  alt=\"Multi-Cluster Kubernetes Management with Meshery\"\n  content=\"Multi-Cluster Kubernetes Management with Meshery\"\n  button_text=\"Read blog post\"\n  url=\"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\"\n  external_link={false}\n  className=\"get-start-kubernetes-resource\"\n/>\n<p>\nThe Kubernetes projects auto-deploy container clusters anywhere there is a pluggable environment and an open-source base that includes system-config service, service account manager, and kubelet. So, developers and system administrators can easily put containers on a single machine or on nodes of machines in any scalable cluster to save money and time.\n</p>\n  \n<p>\nKubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications. Kubernetes was made by Google, and the Cloud Native Computing Foundation now takes care of it.\n</p>\n\n<h3>Kubernetes Cluster Visualization and Designing using Kanvas</h3>\n\n<p>\nKanvas has been developed for visualizing and managing kubernetes clusters. You can learn more about Kanvas <a href=\"https://layer5.io/cloud-native-management/kanvas\">here</a>\n</p>\n\n<p>Users can drag-and-drop your cloud native infrastructure using a palette of thousands of versioned Kubernetes components. Integrate advanced performance analysis into your pipeline.</p>\n  <img src = {KanvasDesigner} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n<p>Users can deploy their designs, apply patterns, manage and operate their deployments in real-time bringing all the Kubernetes clusters under a common point of management. Interactively connect to terminal sessions or initiate and search log streams from your containers.</p>\n  <img src = {KanvasVisualizer} className=\"image-center\" alt=\"Kubernetes Architecture\" />\n  \n  <h3> Set Resource Requests & Limits</h3>\n  \n  <p> Occasionally, deploying an application to a production cluster can fail due to the limited resources available on that cluster. This is a common challenge when working with a Kubernetes cluster, and it‚Äôs caused when resource requests and limits are not set. Without resource requests and limits, pods in a cluster can start utilizing more resources than required. If the pod starts consuming more CPU or memory on the node, then the scheduler may not be able to place new pods, and even the node itself may crash. Resource requests specify the minimum amount of resources a container can use. </p>\n\n<p>\nFor both requests and limits, it‚Äôs typical to define CPU in millicores and memory in megabytes or mebibytes. Containers in a pod do not run if the request for resources made is higher than the limit you set.\n</p>\n  \n<p>\nIn this example, we have set the limit of the CPU to 800 millicores and the memory to 256 mebibytes. The maximum request which the container can make at a time is 400 millicores of CPU and 128 mebibyte of memory.\n</p>\n  \n  <h3> Guide to Containers </h3>\n  \n<p>\nContainers have been around for a while, but it wasn‚Äôt until Docker came along that they really took off. In its early days, developers were using it to build their applications in containers. Now companies like Walmart are using containers to deploy their entire infrastructure.\n</p>\n  \n<p>\nContainers are lighter-weight than virtual machines because they don't need to emulate an entire operating system. This is why containers are typically faster to start up and use less resources. However, containers cannot be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case.\n</p>\n  \n<p>\nBecause they're so lightweight and take up less space than VMs do, containers are great for running lots of them at once! If your application needs more computing power or memory than your machine can provide on its own, using multiple containers in parallel will help balance out any resource shortages without having to invest in additional physical hardware like you would with traditional VM-based deployments.\n</p>\n  \n  <p> As they're isolated from each other, containers are great for running multiple apps at once without worrying about them stepping all over each other's toes! This makes them perfect for things like hosting websites or email services where you want lots of different people to be able to use it at the same time without slowing down or crashing because there's not enough resources available for everyone. </p>\n  \n  <p> What's more, since they're so easy to spin up and take down, they're also great for testing out new ideas quickly without having to worry about making permanent changes to your system (or losing any data along the way!). So if you want to try out a new CMS but don't want to go through the trouble of installing it on your machine first, just fire up a container with it inside and see how it goes! </p>\n  \n<p>\nOne downside to using containers is that they can't easily be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case. Fortunately, there are some great open source projects out there that help solve this problem!\n</p>\n  \n  <h3> Conclusion </h3>\n  \n  <p> Kubernetes is a popular containerization solution that continues to see increasing adoption rates. That being said, using it successfully requires thorough consideration of your workflows and departmental best practices. </p>\n  \n  \n</ResourcesWrapper>\n","frontmatter":{"title":"Getting Started with Kubernetes","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/kubernetes/getting-started-with-kubernetes"}},{"id":"298319fe-14a3-5ee4-8ef1-453d93b5f4b1","body":"import { ResourcesWrapper } from \"../../Resources.style.js\";\nimport serviceMesh from \"./service-mesh.svg\";\nimport arch from \"./arch.svg\";\n\n<ResourcesWrapper>\n  \nMicroservice architectures offer some solutions while posing new ones. Application division into separate services makes scaling, updating, and development easier. It also provides you with a lot more moving pieces to connect and secure. It can get quite complicated to manage all of the network services, including load balancing, traffic management, authentication and authorisation, etc.\n\nIstio, an open-source service mesh created by Google, IBM, and Lyft, enables you to connect, monitor, and secure microservices that are hosted on-premises, in the cloud, or with orchestration systems like Kubernetes and Mesos. The beta version of Istio was announced in the year 2018 in KubeCon on Google Cloud.\n\nBefore moving on to what Istio is and how it works, let us look into what service meshes are and why there was an urgent need for them as microservices started getting used more.\n\n### Service Mesh\n\nA service mesh is an infrastructural layer that is used to provide secure communication between different services for on-prem, cloud or multi-cloud infrastructure. It allows us to add features like observability, traffic management, and security without having to add that to our code. The term \"service mesh\" refers to both the kind of software you employ to carry out this pattern and the security or network domain that results from its application.\n\nService meshes are divided into two parts: the control plane and the data plane. The control plane's responsibilities include securing the mesh, facilitating service discovery, doing regular health checks, enforcing policies, and handling other operational issues. A central registration of services and their corresponding IP addresses is referred to as service discovery. To share with other services how to communicate with it and to assist enforce rules on which services are allowed to communicate with which other services, the application must be registered on the control plane.\n\nThe communication between services, on the other hand, is handled by the data plane. Because many service mesh solutions use a sidecar proxy to manage data plane connections, the amount of knowledge that the services must have about the network environment is constrained.\n\n  <img src = {serviceMesh} className=\"image-center\" alt=\"Service Mesh\" />\n  \n### Inside the Istio service mesh\n\nA data plane and a control plane are logically separate parts of an Istio service mesh.\n\n- A group of intelligent proxies (Envoy) that are deployed as sidecars make up the data plane. All network connection among the microservices is mediated and managed by these proxies. Additionally, they gather and compile data on all mesh communications.\n- The proxies are controlled and set up by the control plane to route traffic.\n\n   <img src = {arch} className=\"image-center\" alt=\"Istio Service Mesh Architecture\" />\n  \n#### Envoy\n\nThe data plane of Istio consists of the Envoy sidecar proxy. Envoy is an edge and service proxy that is open source and free that aids in separating network concerns from core applications. Applications don't care about the network topology; they just transmit and receive messages to and from localhost. Envoy is fundamentally a network proxy that operates at the OSI model's L3 and L4 layers. It operates by processing connections through a series of pluggable network filters. Envoy additionally provides support for an extra L7 layer filter for HTTP-based traffic. Envoy also offers excellent support for the HTTP/2 and gRPC transports.\n\nMany of the features provided by Istio such as security, traffic control, network resiliency are possible due to Envoy.\n\n#### Istiod\n\nService discovery, configuration, and certificate management are offered by Istiod.\n\nHigh level routing rules that govern traffic behavior are transformed into Envoy-specific configurations by Istiod and propagated to the sidecars during runtime. Any sidecar that complies with the Envoy API can use Pilot, which synthesizes platform-specific service discovery techniques into an abstract form.\n\nIstio can handle discovery in a variety of settings, including Kubernetes or virtual machines.\n\nTo exert finer control over the traffic in your service mesh, you can ask Istiod to modify the Envoy configuration using the Traffic Management API.\n\nStrong service-to-service and end-user authentication are made possible by Istiod security's integrated identity and credential management. Istio can be used to enhance unencrypted service mesh traffic.\n\nOperators can enforce regulations with Istio based on service identity rather than on layer 3 or layer 4 network IDs, which are more prone to instability. Additionally, you can limit who has access to your services by using Istio's authorisation capability.\n\nIn order to enable secure mTLS connection in the data plane, Istiod performs the role of a Certificate Authority (CA) and issues certificates.\n\n### Features\n\n#### Traffic Management\n\nPerformance is impacted by traffic routing, both within and across clusters, which improves deployment strategy. You can simply manage the flow of traffic and API requests between services using Istio's traffic routing rules. Istio makes it simple to configure critical activities like A/B testing, canary deployments, and staged rollouts with percentage-based traffic divides, as well as service-level attributes like circuit breakers, timeouts, and retries.\n\n#### Observability\n\nIt becomes harder to comprehend behaviour and performance as services become more complicated. Istio produces comprehensive telemetry for each communication taking place within a service mesh. This telemetry makes service activity observable, enabling operators to maintain, optimise, and debug their applications. Even better, you can implement practically all of this instrumentation without making any changes to your applications. Operators are able to fully comprehend how the monitored services are communicating with Istio.\n\nDetailed metrics, distributed traces, and complete access logs are all included in Istio's telemetry. You get complete and thorough service mesh observability with Istio.\n\n#### Security Capabilities\n\nParticular security requirements for microservices include defense against man-in-the-middle attacks, adaptable access rules, auditing tools, and mutual TLS. Istio comes with a comprehensive security solution that enables administrators to handle each of these problems. To safeguard your services and data, it offers strong identity, strong policy, transparent TLS encryption, and authentication, authorization, and audit (AAA) tools.\n\nThe security architecture used by Istio is built on security-by-default, and it aims to provide in-depth defense so you may deploy security-conscious apps even across networks with a low level of trust.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh: Istio","type":"Article","technology":null,"product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/service-mesh-istio"}},{"id":"88e08e13-0ab0-5e6b-94d9-12dec5e1eab4","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport DevOps from \"./devops-adoption-choosing-the-right-metrics.pdf\";\nimport DevOpsAdoption from \"./devops-adoption.webp\";\n\n<ResourcesWrapper>\n<p>\nAccording to Puppet‚Äôs State of DevOps Report 2021, 83% of IT professionals report that their organizations have previously implemented DevOps practices or are doing so right now to unlock higher business value, achieve faster time to delivery, and boost security of systems.\n</p>\n\n<p>\nHowever, DevOps teams from many industries frequently struggle to identify the right¬†metrics to monitor and measure¬†success. In this <Link to={DevOps}>infographic</Link>, we highlight the metrics all DevOps professionals should measure to:\n</p>\n\n<ul>\n<li>Identify places in the pipeline to speed up deployments.</li>\n<li>Make data-driven decisions to improve the deployment process.</li>\n<li>Analyze the speed at which products are reaching the market in comparison to competitors.</li>\n</ul>\n\n<h3 style={{ marginTop: \"1rem\" }}>Monitor¬†these 5 metrics to understand how to speed up your DevOps toolchain:</h3>\n<ul>\n<li>Deployment Time</li>\n<li>Change Failure Rate</li>\n<li>Recovery Time</li>\n<li>Release Cadence</li>\n<li>Lead Time</li>\n</ul>\n\n<Link to={DevOps}>\n<img src={DevOpsAdoption} alt=\"Right metrics for adopting DevOps\" />\n</Link>\n</ResourcesWrapper>\n","frontmatter":{"title":"DevOps Adoption: Identifying the Right Metrics","type":"Infographic","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACQAwCdASoUAAwAPtFUpEuoJKOhsAgBABoJbACdAB4ZXhaXIPKYAPaG9u2w8AHTtU+cyhybyQ2d8jlpRY3i9sqgENC0D+v3/skF/sV1UuobVW4bKjzUIc5tTnsJeCfeE0ZwvwkTwZWhhIj9/KO9fj9pqTxNIAAA"},"images":{"fallback":{"src":"/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp","srcSet":"/static/eba4e5898081df468c1c4288ce73623d/c89db/devops-adoption.webp 750w,\n/static/eba4e5898081df468c1c4288ce73623d/0dc9a/devops-adoption.webp 1080w,\n/static/eba4e5898081df468c1c4288ce73623d/24070/devops-adoption.webp 1366w,\n/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5994791666666667}},"extension":"webp","publicURL":"/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAACQAwCdASoUAAwAPtFUpEuoJKOhsAgBABoJbACdAB4ZXhaXIPKYAPaG9u2w8AHTtU+cyhybyQ2d8jlpRY3i9sqgENC0D+v3/skF/sV1UuobVW4bKjzUIc5tTnsJeCfeE0ZwvwkTwZWhhIj9/KO9fj9pqTxNIAAA"},"images":{"fallback":{"src":"/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp","srcSet":"/static/eba4e5898081df468c1c4288ce73623d/c89db/devops-adoption.webp 750w,\n/static/eba4e5898081df468c1c4288ce73623d/0dc9a/devops-adoption.webp 1080w,\n/static/eba4e5898081df468c1c4288ce73623d/24070/devops-adoption.webp 1366w,\n/static/eba4e5898081df468c1c4288ce73623d/ce251/devops-adoption.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5994791666666667}},"extension":"webp","publicURL":"/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp"}},"fields":{"slug":"/resources/devops/devops-adoption-identifying-the-right-metrics"}},{"id":"3e1c20c1-a961-5316-8916-cf7c8d1fad19","body":"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n\nGitOps revolves around the central notion that infrastructure can be treated as code. It is an operational framework that incorporates DevOps best practices for infrastructure automation, including version control, collaboration, compliance, and CI/CD tooling, which are often used for application development. Like code, not only can you store your infrastructure configuration in a source code version system, but you can also take your infrastructure configuration and any changes to its configuration through the same change management process that you do when updating your applications and services. In part, GitOps is about change management, and consequently, it is about risk reduction and risk management. When you automate a process and classify the manner in which you systemize the process, risk is reduced through the consistency and series of processes and reviews changes go through.\n\nGitOps is the acknowledgement that declarative systems that everything is (or should be) defined as code. With all code in a source code system, that system becomes the source of truth and in the system of record for how your infrastructure is running. Well, that is, assuming that your infrastructure configuration hasn't drifted from its desired state defined in your source code system. If Git is the source of truth, you cannot run operations manually by executing random commands. Doing so would mean that Git would stop being the only source of truth. Instead, the only goal of operations is to define the desired state as code and store it in git. Then, let the machines synchronize that with the actual state. Such synchronization must be continuous so that the two states are (almost) always in sync. In other words, GitOps is about defining everything as code, storing that code in Git, and letting the machines detect the drift between the desired and the actual state ‚Äì and making sure that drifts are resolved as soon as possible, hence resulting in the two states being almost always in sync.\n\n## Principles of GitOps\n\n### 1) Declarative\n\nAccording to this principle, the entire system should have a declarative description. Let us first understand what a system description is. What is committed to your Git repository is called the System Description. One or more files that define each system component and its state will be included in the system description. According to GitOps, the way in which we store those definitions is crucial, and we must do so declaratively. That implies that the description of our system will be saved as data.\n\nIn the declarative approach, we specify how we want the system to look not how we can achieve that state. If we want to make any changes, we change the description instead of the series of steps to get there. Declarative configuration is critical for GitOps because it provides a description of the system that an automated agent can understand and utilize to take action.\n\n### 2) Single Source of Truth\n\nThe second principle mandates that we keep that system description inside of Git. Therefore, we decide to maintain the official blueprints, which outline the ideal system state version in Git. A git commit is required if we wish to modify the blueprint. The blueprint can also be called the desired state. This helps developers, testers, operations, security, and automations to have a single reference and keep uniformity in everyone‚Äôs vision.\n\nGitOps also improves a system's ability to recover from failure because it's simple to roll back an unsuccessful change or restore the entire system from the repository.\n\n### 3) Automated Change Delivery\n\nOnly automation allows us to apply modifications made to the blueprint to systems already in operation. Delivery of changes is entirely automatic. GitOps doesn't allow manual editing. Because standard workflows only need GitHub, which is such a well-known platform, automation enables changes to be delivered through simpler for developers to use workflows. Additionally, automation standardizes your delivery processes, improving the predictability and consistency of system operations.\n\n### 4) Automated State Control\n\nThe fourth principle uses automation to keep our operating system in alignment with the desired state. Drift is the deviation of the runtime state of our system from the desired state. The system's blueprints and what is actually operating in the system don't match. Therefore, if the operating system drifts from what we have specified in Git, an operator will restore it by bringing it back to the intended condition.\n\n## Benefits of GitOps\n\n### 1) Improves compliance and security:\n\nSince teams use a single platform for infrastructure management, a streamlined toolchain reduces attack surfaces. Teams can use the version control system to roll back to a desired state in the event of an assault. GitOps lessens outages and downtime as a result, allowing teams to continue working on projects in a secure environment.\n\n### 2) Boosts productivity and cooperation:\n\nGitOps includes CI/CD pipelines, Git workflows, and infrastructure as code best practices for software development. These prerequisite tools, knowledge, and skill sets are already present in operations teams, thus adopting GitOps won't need a steep learning curve. GitOps workflows streamline procedures in order to improve visibility, establish a single source of truth, and have a small number of tools on hand.\n\n### 3) Automation enhances developer efficiency and lowers costs:\n\nProductivity rises with CI/CD tooling and continuous deployment since teams can concentrate on development rather than laboriously manual processes thanks to automation. Since team members can use any language and tools they like before pushing updates to GitHub, GitOps workflows enhance the developer experience. Infrastructure automation increases output and decreases downtime while enabling better cloud resource management, which can also save costs.\n\n### 4) Increases stability and reliability:\n\nHuman mistake is decreased through infrastructure that is codified and repeatable. Code reviews and collaboration are made easier by merge requests, which also assist teams in finding and fixing issues before they are released to the public. Additionally, there is less risk because all infrastructure changes are tracked through merge requests and may be undone if an iteration is unsuccessful. By allowing rollbacks to a more stable state and providing distributed backup copies in the event of a significant outage, Git processes speed up recovery time. GitOps gives teams the freedom to iterate more quickly and release new features without worrying about creating an unstable environment.\n\n### 5) Faster development and deployment:\n\nGitOps provides quicker and more frequent deployments, making it easier for teams to make a minimum viable change. Teams can ship many times per day and roll back changes if there is a problem by utilizing GitOps best practices. Team members can offer business and customer value more quickly thanks to high velocity deployments. Teams are more flexible and able to react to customer needs more quickly with continuous integration.\n\n## Key Components of a GitOps workflow\n\nTo summarize, the following are the four components we require to a GitOps workflow:\n\n1. Git repository: The code and configuration of the application are verified there.\n2. CD pipeline: It is responsible for building, testing, and deploying the application.\n3. Application deployment tool: It is employed to manage the target environment's application resources.\n4. Monitoring system: It keeps tabs on the performance of the application and gives the development team feedback.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"What is GitOps?","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/cloud-native/what-is-gitops"}},{"id":"a082cf72-65d4-5ad3-aab7-c04e9cdcbf93","body":"import { ResourcesWrapper } from \"../../Resources.style.js\";\nimport serviceMesh from \"./consul-service-mesh.webp\";\nimport agent from \"./consul-agent-architecture.webp\";\nimport datacenter from \"./datacenter-architecture.webp\";\nimport proxy from \"./service-proxy-architecture.webp\";\n\n<ResourcesWrapper>\n  \n  ### What is a Service Mesh?\n\nA service mesh is a dedicated layer that provides secure service-to-service communication for on-prem, cloud, or multi-cloud infrastructure. Although service meshes are typically used with a microservice architectural pattern, they are useful in any situation involving complex networking. Their functionalities include traffic control, resiliency, observability and security. Traffic steering is used for content and it allows optimal usage of our resources. Service meshes provide control over chaotic situations (which usually arise in complex networks) along with proper identification and policies to enhance security.\n\nService meshes can be divided into the control plane and the data plane. The role of the control plane is to secure the mesh, facilitate service discovery, conduct frequent health checks, enforce policies and other operational concerns. Service discovery refers to a central registry of the services and their respective IP addresses. The application needs to be registered on the control plane for it to be able to share with other services how to communicate with it and helps to enforce rules on which service gets to communicate with which other services.\n\nThe data plane, on the other hand, handles the communication between services. The amount of knowledge that the services need to have about the network environment is limited by the fact that many service mesh solutions use a sidecar proxy to conduct data plane connections.\n\n<img src={serviceMesh} className=\"image-center\" alt=\"Service Mesh\" />\n\n### What is Consul?\n\nConsul Service Mesh (also known as Consul Connect) provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS). Consul is the control plane of the service mesh. Consul can be used with Virtual Machines (VMs), containers, or with container orchestration platforms such as Nomad and Kubernetes. Applications can use sidecar proxies to establish TLS connections for inbound and outbound connections or natively integrate with Connect by using Connect aware SDKs for optimal performance and security.\n\nIt is a multi-networking tool that provides a fully functional service mesh solution to address the networking and security issues associated with running cloud infrastructure and microservices. Consul offers a software technique for segmentation and routing. It also offers advantages such as handling failures, retries, and network observability. You can utilize any of these characteristics alone as required or combine them to create a full service mesh and achieve zero trust security.\n\n### Architecture\n\nConsul is a distributed system built for a node cluster to operate on. A physical server, cloud instance, virtual machine, or container can all function as a Consul node. The collection of interconnected nodes that Consul runs on is known as a datacenter. Consul supports multiple datacenters and considers this as a common case. It is expected that there will be many clients and three to five servers in a datacenter. This creates a balance between performance and availability in the event of a breakdown because consensus slows down as more machines are added. The number of clients, however, is unlimited and can easily increase to thousands or tens of thousands.\n\n<img src={datacenter} className=\"image-center\" alt=\"Image of datacenter\" />\n\nThe Consul Agent is responsible for maintaining membership information, registering services, running checks, responding to queries, etc. It is required to run on every node that is a part of the Consul cluster. In some places, client agents may cache data from the servers to make it available locally for performance and reliability. They can either run in server mode or client mode. Client nodes make up for most of the cluster and are lightweight processes. They act as an interface between server nodes for most operations. They run on every node where services are running.\n\nAlong with core agent operations, a server node participates in the consensus quorum. The Raft protocol, which offers excellent consistency and availability in the event of failure, serves as the foundation for the quorum. Because they consume more resources than client nodes, server nodes should run on dedicated instances.\n\n<img src={agent} className=\"image-center\" alt=\"Consul Agent\" />\n\nA per-service proxy sidecar manages incoming and outgoing service connections by automatically wrapping and verifying TLS connections. Consul includes its own built-in L4 proxy and has first class support for Envoy. Other than this, we can choose to use any other proxy to plug in as well. The following diagram shows how proxies work:\n\n<img src={proxy} className=\"image-center\" alt=\"Side-car proxy\" />\n\nThe lifecycle of a Consul cluster:\n\n1. An agent is started.\n2. An agent joins the cluster.\n3. Information of the agent is communicated throughout the cluster\n4. Existing servers will begin replicating to the new node.\n\n### Benefits and Compatibility of Consul Connect\n\nNew methods of networking are necessary due to the development of cloud infrastructure and microservices designs. There are numerous tools and companies, all of which make different attempts to address the issue. The Consul service mesh solution offers a pure software approach with an emphasis on simplicity and wide compatibility and makes no assumptions about the underlying network.\n\nConsul service mesh streamlines application deployment into a zero-trust network and makes service discovery easier in complex networking situations.\n\nFeatures of Consul Service Mesh:\n\n1. Service Discovery\n    Consul provides a service catalog, configurable service routing, health checks, automatic load balancing, and geo-failover across multiple instances of the same service. The capacity to control changes in the service landscape of your network becomes essential when new versions of a service are introduced and must coexist with existing instances of the same application, frequently running on different versions. The agent provides a simple service definition format to declare the availability of a service and to potentially associate it with a health check.\n2. Zero-trust Security Model\n    Trust can be exploited and with the increasing number of services, there are higher chances of breach. The Consul service mesh control plane can be configured to enforce mutual TLS (mTLS), and will automatically generate and distribute the TLS certificates for every service in the mesh. The certificates are used for both service identity verification and communication encryption.\n3. Simplify Application Security with Intentions\n    Communication between services is secure within the mesh once the service sidecar proxies have been set up. To designate which services are permitted to communicate with one another, you might want to build a more granular set of policies. Consul Intentions are used to limit which services can make requests or create connections and define access control for services through Connect. We can manage intentions via the UI, CLI, or API. The proxy or a natively integrated application enforces intentions on inbound connections or requests.\n\nCompatibility of Consul Connect:\n\n1. First-Class Kubernetes Support\n    By offering an official Helm chart for installing, configuring, and upgrading Consul on Kubernetes, Consul enables first-class Kubernetes support. The chart automates Kubernetes's Consul service mesh installation and configuration.\n2. Platform Agnostic and Multi-Cluster Mesh\n    Consul works with all cloud providers and architectures. You can expand the scope of your Kubernetes clusters to include services that aren't run using Kubernetes by using the service catalog sync and auto-join features. In order to facilitate safe service-to-service communication between Nomad tasks and jobs, Consul additionally interfaces with HashiCorp Nomad.\n  \n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh: Consul","type":"Article","technology":null,"product":null,"mesh":"Consul","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/service-mesh-consul"}},{"id":"c57a376e-18e9-5959-9332-330a4849e77a","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n<div className=\"intro\">\n  <p>Learn more about managing containers with our <a className=\"blog\" href=\"https://github.com/layer5io/containers-101-workshop\">Containers 101 Workshop</a>. Walk-through four hands-on exercises with Docker.</p>\n</div>\n\n<p>\n  Container management refers to a set of practices that govern and maintain\n  containerization software. Container management tools automate the creation,\n  deployment, destruction and scaling of application or systems containers.\n  Containerization is an approach to software development that isolates\n  processes that share an OS kernel -- unlike virtual machines (VMs), which\n  require their own -- and binds application libraries and dependencies into one\n  deployable unit. This makes containers lightweight to run, as they require\n  only the application configuration information and code from the host OS. This\n  design also increases interoperability compared to VM hosting. Each container\n  instance can scale independently with demand.\n</p>\n<p>\n  Modern Linux container technology was popularized by the Docker project, which\n  started in 2013. Interest soon expanded beyond containerization itself, to the\n  intricacies of how to effectively and efficiently deploy and manage\n  containers.\n</p>\n<p>\n  In 2015, Google introduced the container orchestration platform Kubernetes,\n  which was based on its internal data center management software called Borg.\n  At its most basic level, open source Kubernetes automates the process of\n  running, scheduling, scaling and managing a group of Linux containers. With\n  more stable releases throughout 2017 and 2018, Kubernetes rapidly attracted\n  industry adoption, and today it is the de facto container management\n  technology.\n</p>\n<p>\n  IT teams use containers for cloud-native, distributed -- often microservices-\n  based -- applications, and to package legacy applications for increased\n  portability and efficient deployment. Containers have surged in popularity as\n  IT organizations embrace DevOps, which emphasizes rapid application\n  deployment. Organizations can containerize application code from development\n  through test and deployment.\n</p>\n<h2>Benefits of container management</h2>\n<p>\n  The chief benefit of container management is simplified management for\n  clusters of container hosts. IT admins and developers can start, stop and\n  restart containers, as well as release updates or check health status, among\n  other actions. Container management includes orchestration and schedulers,\n  security tools, storage, and virtual network management systems and\n  monitoring.\n</p>\n\n<h3>Wrangling container sprawl</h3>\n<p>\n  Organizations can set policies that ensure containers share a host -- or\n  cannot share a host -- based on application design and resource requirements\n  For example, IT admins should colocate containers that communicate heavily to\n  avoid latency. Or, containers with large resource requirements might require\n  an anti-affinity rule to avoid physical storage overload. Container instances\n  can spin up to meet demand -- then shut down -- frequently. Containers also\n  must communicate for distributed applications to work, without opening an\n  attack surface to hackers.\n</p>\n<p>\n  A container management ecosystem automates orchestration, log management,\n  monitoring, networking, load balancing, testing and secrets management, along\n  with other processes. Automation enables IT organizations to manage large\n  containerized environments that are too vast for a human operator to keep up\n  with.\n</p>\n\n<h2>Challenges of container management</h2>\n<p>\n  One drawback to container management is its complexity, particularly as it\n  relates to open source container orchestration platforms such as Kubernetes\n  and Apache Mesos. The installation and setup for container orchestration tools\n  can be arduous and error prone. IT operations staff need container management\n  skills and training. It is crucial, for example, to understand the\n  relationships between clusters of host servers as well as how the container\n  network corresponds to applications and dependencies.\n</p>\n<p>\n  Issues of persistence and storage present significant container management\n  challenges. Containers are ephemeral -- designed to exist only when needed.\n  Stateful application activities are difficult because any data produced within\n  a container ceases to exist when the container spins down.\n</p>\n<p>\n  Container security is another concern. Container orchestrators have several\n  components, including an API server and monitoring and management tools. These\n  pieces make it a major attack vector for hackers. Container management system\n  vulnerabilities mirror standard types of OS vulnerabilities, such as those\n  related to access and authorization, images and intercontainer network\n  traffic. Organizations should minimize risk with security best practices --\n  for example, identify trusted image sources and close network connections\n  unless they're needed.\n</p>\n<h2>Container management strategy</h2>\n<p>\n  Forward-thinking enterprise IT organizations and startups alike use containers\n  and container management tools to quickly deploy and update applications. IT\n  organizations must first implement the correct infrastructure setup for\n  containers, with a solid grasp of the scope and scale of the containerization\n  project in terms of business projections for growth and developers'\n  requirements. IT admins must also know how the existing infrastructure's\n  pieces connect and communicate to preserve those relationships in a\n  containerized environment. Containers can run on bare-metal servers, VMs or in\n  the cloud -- or in a hybrid setup -- based on IT requirements.\n</p>\n<p>\n  In addition, the container management tool or platform should meet the\n  project's needs for multi-tenancy; user and application isolation;\n  authentication; resource requirements and constraints; logging, monitoring and\n  alerts; backup management; license management; and other management tasks. IT\n  organizations should understand their hosting commitment and future container\n  plans, such as if the company will adopt multiple cloud platforms or a\n  microservices architecture.\n</p>\n<h2>Kubernetes implementation considerations</h2>\n<p>\n  As described above, containers are arranged into pods in Kubernetes, which run\n  on clusters of nodes; pods, nodes and clusters are controlled by a master. One\n  pod can include one or multiple containers. IT admins should carefully\n  consider the relationships between pods, nodes and clusters when they set up\n  Kubernetes.\n</p>\n<p>\n  Organizations should plan their container deployment based on how many pieces\n  of the application can scale under load -- this depends on the application,\n  not the deployment method. Additionally, capacity planning is vital for\n  balanced pod-to-node mapping, and IT admins should ensure high availability\n  with redundancy with master node components.\n</p>\n<p>\n  IT organizations can address container security concerns by applying some\n  general IT security best practices to containerization. For example, create\n  multiple security layers throughout the environment, scan all container images\n  for vulnerabilities, enforce signed certificates and run the most up-to-date\n  version of any container or application image. Containers introduce the\n  benefits of an immutable infrastructure methodology as well; the regular\n  disposal and redeployment of containers, with their associated components and\n  dependencies, improves overall system availability and security. Additionally,\n  Kubernetes multi-tenancy promises greater resource isolation, but recently\n  revealed security vulnerabilities make multicluster management preferred for\n  now.\n</p>\n<p>\n  Networking is another significant factor. Kubernetes networking occurs within\n  pods, between pods and in user-to-containerized resource connections.\n  Kubernetes enables pods and nodes to communicate without address translation,\n  allocating subnets as necessary. Lastly, IT admins working with Kubernetes\n  should prepare to troubleshoot common container performance problems,\n  including those caused by unavailable nodes and noisy neighbors, in an\n  implementation.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Managing Containers","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/kubernetes/managing-containers"}},{"id":"0d05b64b-7bb7-5e13-9834-1b40f12a2e9d","body":"\nimport { Link } from \"gatsby\";\nimport ArchDiagram from \"./kubernetes-highlevel-architecture.webp\";\nimport { ResourcesWrapper } from \"../../../Resources.style.js\";\n\n<ResourcesWrapper>\n\nThe way Kubernetes is architected is what makes it powerful. Kubernetes has a basic client and server architecture, but it goes way beyond that. Kubernetes has the ability to do rolling updates, it also adapts to additional workloads by auto scaling nodes if it needs to and it can also self-heal in the case of a pod meltdown. These innate abilities provide developers and operations teams with a huge advantage in that your applications will have little to no down time. In this section we provide a brief overview of the master and its worker nodes with a high level overview of how Kubernetes manages workloads.\n\n<div className=\"right\" >\n<img src={ArchDiagram} alt=\"Simple Kubernetes Architecture Diagram\" />\n<i>Simple Kubernetes Architecture Diagram</i>\n</div>\n\n# Kubernetes Components\n\nLet's dive into each of the Kubernetes components, starting with the Master node.\n\n## Kubernetes Master\n\nThe Kubernetes master is the primary control unit for the cluster. The master is responsible for managing and scheduling the workloads in addition to the networking and communications across the entire cluster. The master node is responsible for the management of Kubernetes cluster. This is the entry point of all administrative tasks. The master node is the one taking care of orchestrating the worker nodes, where the actual services are running.\n\nThese are the components that run on the master:\n\n### Etcd Storage\nEtcd is an open-source key-value data store that can be accessed by all nodes in the cluster. It stores configuration data of the cluster‚Äôs state. etcd is a simple, distributed, consistent key-value store. It‚Äôs mainly used for shared configuration and service discovery.\n\nIt provides a REST API for CRUD operations as well as an interface to register watchers on specific nodes, which enables a reliable way to notify the rest of the cluster about configuration changes.\n\nAn example of data stored by Kubernetes in etcd is jobs being scheduled, created and deployed, pod/service details and state, namespaces and replication information, etc.\n\n### Kube-API-Server \nKube-API-Server manages requests from the worker nodes, and it receives REST requests for modifications, and serves as a front-end to control cluster. The API server is the entry points for all the REST commands used to control the cluster. It processes the REST requests, validates them, and executes the bound business logic. The result state has to be persisted somewhere, and that brings us to the next component of the master node.\n\n\n### Kube-scheduler \nKube-scheduler schedules the pods on nodes based on resource utilization and also decides where services are deployed. The deployment of configured pods and services onto the nodes happens thanks to the scheduler component. The scheduler has the information regarding resources available on the members of the cluster, as well as the ones required for the configured service to run and hence is able to decide where to deploy a specific service.\n\n### Kube-controller-manager\nKube-controller-manager runs a number of distinct controller processes in the background to regulate the shared state of the cluster and perform routine tasks. When there is a change to a service, the controller recognizes the change and initiates an update to bring the cluster up to the desired state. Optionally you can run different kinds of controllers inside the master node. controller-manager is a daemon embedding those.\n\nA controller uses apiserver to watch the shared state of the cluster and makes corrective changes to the current state to change it to the desired one.\nAn example of such a controller is the Replication controller, which takes care of the number of pods in the system. The replication factor is configured by the user, and it's the controller‚Äôs responsibility to recreate a failed pod or remove an extra-scheduled one. Other examples of controllers are endpoints controller, namespace controller, and serviceaccounts controller, but we will not dive into details here.\n\n## Worker Nodes\nThese nodes run the workloads according the schedule provided by the master. The interaction between the master and worker nodes are what‚Äôs known as the control plane. The pods are run here, so the worker node contains all the necessary services to manage the networking between the containers, communicate with the master node, and assign resources to the containers scheduled.\n\n### Kubelet\nKubelet ensures that all containers in the node are running and are in a healthy state.  If a node fails, a replication controller observes this change and launches pods on another healthy pod. Integrated into the kubelet binary is ‚ÄòcAdvisor` that auto-discovers all containers and collects CPU, memory, file system, and network usage statistics and also provides machine usage stats by analyzing the ‚Äòroot‚Äô container. \n\nKubelet gets the configuration of a pod from the apiserver and ensures that the described containers are up and running. This is the worker service that‚Äôs responsible for communicating with the master node. It also communicates with etcd, to get information about services and write the details about newly created ones.\n\n### Kube Proxy\nKube Proxy acts as a network proxy and a load balancer for a service on a single worker node. . It takes care of the network routing for TCP and UDP packets. It forwards the request to the correct pods across isolated networks in a cluster. \n\n### Pods\nA pod is the basic building block on Kubernetes. It represents the workloads that get deployed. Pods are generally collections of related containers, but a pod may also only have one container. A pod shares network/storage and also a specification for how to run the containers.\n\n### Containers \nContainers are the lowest level of microservice. These are placed inside of the pods and need external IP addresses to view any outside processes. Docker is not the only supported container runtime, but is by far, the most popular. Docker runs on each of the worker nodes, and runs the configured pods. It takes care of downloading the images and starting the containers.\n\n### kubectl\nKubectl is a command line tool to communicate with the API service and send commands to the master node. kubectl must be configured to communicate with your cluster. If you have multiple clusters, you might try using kubectx, which makes switching between contexts easy.\n\n\n#### Managing objects with kubectl\nYou can divide a Kubernetes cluster into multiple environments by using namespaces (e.g., Dev1, Dev2, QA1, QA2, etc.), and each environment can be managed by a different user. One of the inconveniences of writing kubectl commands is that every time you write a command, you need the --namespace option at the end. People often forget this and end up creating objects (pods, services, deployments) in the wrong namespace. \n\nWith this trick, you can set the namespace preference before running kubectl commands. Run the following command before executing the kubectl commands, and it will save the namespace for all subsequent kubectl commands for your current context:\n\n```\nkubectl config set-context $(kubectl config current-context) --namespace=mynamespace\n```\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Kubernetes Architecture 101","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/kubernetes/kubernetes-architecture-101"}},{"id":"2aa90303-18d9-549c-b397-e694e16459c9","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n\n<p>\n  Istio Virtual Service defines a set of traffic routing rules to apply when host is addressed. Each routing rule defines standards for the traffic of a specific protocol. If the traffic is matched, then it is sent to a named destination service defined in the registry.\n</p>\n\n<p>\n  The source of traffic can also be matched within a routing rule that allows routing to be customized for every specific client context.\n</p>  \n\n<div className=\"fact-left\">\n<p>\n  The below example on Kubernetes routes all HTTP traffic by default to pods of the reviews service with the label ‚Äúversion: v1‚Äù. Additionally, HTTP requests with path starting with /wpcatalog/ or /consumercatalog/ will be rewritten to /newcatalog and sent to the pods with label ‚Äúversion: v2‚Äù.\n</p>\n</div>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews-route\nspec:\n  hosts:\n  - reviews.prod.svc.cluster.local\n  http:\n  - name: \"reviews-v2-routes\"\n    match:\n    - uri:\n        prefix: \"/wpcatalog\"\n    - uri:\n        prefix: \"/consumercatalog\"\n    rewrite:\n      uri: \"/newcatalog\"\n    route:\n    - destination:\n        host: reviews.prod.svc.cluster.local\n        subset: v2\n  - name: \"reviews-v1-route\"\n    route:\n    - destination:\n        host: reviews.prod.svc.cluster.local\n        subset: v1\n\n```\n<h2>Virtual Service Configuration Affecting Traffic Routing </h2>\n\n<p>A single Virtual Service can be used to describe all the traffic properties of the hosts, including those for multiple HTTP and TCP ports.</p>\n\n<div>\n  <h3>Hosts</h3>\n  <ul>\n    <li>\n      The application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). \n      As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). \n    </li>\n    <li>\n      The destination hosts to which traffic is being sent it could be a DNS name with wildcard prefix or an IP address depending on the platform.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>Gateways</h3>\n  <ul>\n    <li>\n      The names of gateways and sidecars that should apply all these routes. Gateways in other namespaces may be referred to by <code> gateway namespace>/gateway name </code>; specifying a gateway with no namespace qualifier is the same as specifying the VirtualService‚Äôs namespace.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>HTTP</h3>\n  <ul>\n    <li>\n      An ordered list of route rules for HTTP traffic. The HTTP routes will be applied to the platform service ports named <code>‚Äòhttp-‚Äô/‚Äòhttp2-‚Äô/‚Äògrpc-*‚Äô, gateway ports with protocol HTTP/HTTP2/GRPC/ TLS-terminated-HTTPS </code> and service entry ports using HTTP/HTTP2/GRPC protocols.\n    </li>\n    <li>\n      The first rule is matching an incoming request which is used.\n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>TCP</h3>\n  <ul>\n    <li>  \t\n      An ordered list of all the routing rules for opaque TCP traffic. TCP routes will be applied to any of the port which is not a HTTP or TLS port. \n    </li>\n  </ul>\n</div>\n\n<div>\n  <h3>ExportTo</h3>\n  <ul>\n    <li>  \t\n      Exporting a virtual service allows it to be used by the sidecars and the gateways defined in other namespaces. \n    </li>\n    <li>  \t\n      If no namespaces are specified then the virtual service is exported to all namespaces by default.\n    </li>\n  </ul>\n</div>\n\n<h2>\n  Destination\n</h2>\n\n<p>\n  A destination indicates that the network addressable service to which the request/connection will be sent. A DestinationRule defines policies that apply to traffic intended for a service after routing has occurred.\n</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews-destination\nspec:\n  host: reviews.prod.svc.cluster.local\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n  - name: v2\n    labels:\n      version: v2\n\n```\n<div className=\"fact-left\">\n<p>A version of the route destination is identified with a reference to a named service subset which should be declared in a corresponding DestinationRule.</p>\n</div>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Istio Virtual Service","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/istio-virtual-service"}},{"id":"f2515b37-8209-5754-a3b5-ced2ef4f9551","body":"\nimport { Link } from \"gatsby\";\nimport istiosecurityarch from './istio-securityarch.svg'\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n<div className=\"intro\">\n<p>\nIstio is a massive project with a wide range of capabilities and deployment options. We will learn about the Istio‚Äôs authorization policy with an example .\n</p>\n</div>\n\n<p>\n    <h2>Let‚Äôs see Istio‚Äôs Security Architecture </h2> \n    </p>\n<p>\n    Before we directly jump into Istio's Authorization policies let's have a glance at Istio's Security architecture. The below diagram is directly referenced from Istio documentation. From the control plane, users can create things like authorization policies authentication policies, and policies will get translated into envoy config and streamed bent the varied proxies that form up the service mesh, on the information plane side there is east-west traffic from service b to c and also the actual communication takes place through sidecar proxies. If the traffic is entering it moves to the Ingress gateway and if it‚Äôs leaving it can attend the Egress gateway in between all this we will apply JWT enforcements.\n</p>\n<p>\n  <img src={istiosecurityarch} align=\"center\" alt=\"comparative spectrum\" />\n</p>\n<h2> Istio includes a high-level architecture that involves multiple factors such as:</h2>\n\n<p>\n<ul>\n    <li>  Certificate Authority for key and certificate management </li>\n    <li> Sidecar and perimeter proxies work as Policy Enforcement Points to secure communication between the clients and servers. </li>\n    <li> A set of Envoy proxy extensions is there to manage telemetry and auditing </li>\n\n</ul>\n</p>\n\n<h2> Istio‚Äôs Authorization policies</h2>\n<p>\n    <ul>\n    <li>  Workload-to-workload and end-user-to-workload authorization. </li>\n    <li> A Simple API includes one single Authorization Policy, which is easy to use and maintain.</li>\n    <li>Flexible semantics: operators can define custom conditions on Istio attributes, and use DENY and permit actions. </li>\n    <li>  High performance: Istio authorization gets enforced natively on the Envoy. </li>\n    <li> High compatibility: supports gRPC, HTTP, HTTPS, and HTTP2 natively, additionaly as well as any plain TCP protocols. </li>\n\n</ul>\n</p>\n\n<h2>\n    Example Authorization Policy\n</h2>\n<p>\nIn this example, we allow access to our service httpbin in namespace foo from any JWT (regardless of the principle) to use the GET method.\n</p>\n\n``` \napiVersion: \"security.istio.io/v1beta1\"\nkind: \"AuthorizationPolicy\"\nmetadata:\n  name: \"allow-reads\"\n  namespace: foo\nspec:\n  selector:\n    matchLabels:\n      app: httpbin\n  rules:\n  - from:\n    - source:\n        principals: [\"*\"]\n    to:\n    - operation:\n        methods: [\"GET\"]\n\n```\n<h2>Access Flow with Auth Policies</h2>\n\n<p>\n    There is some logic behind how authorization is set given defined AuthorizationPolicies. Below is that the flow as taken directly from the Istio documentation.\n    </p>\n<ul>\n    <li>If there are any CUSTOM policies that match the request, evaluate and deny the request if the evaluation result's is deny.</li>\n    <li>If there are any DENY policies that match with the request, deny the request.</li>\n    <li>If there are not any ALLOW policies for the workload, allow the request.</li>\n    <li>If any of the ALLOW policies gets match with the request, allow the request.</li>\n    <li>Deny the request.</li>\n</ul>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Authorization Policy","type":"Article","technology":"Docker","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/istio-authorization-policy"}},{"id":"0e3c402b-8ec4-5d70-ae25-47f401a3c656","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\n<div className=\"test\">\n\nThe open source Service Mesh Performance project is getting a new metric called MeshMark to help organizations manage and measure cloud-native environments. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn't always clear with a service mesh though is how well it's actually working.\n\nMeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.\n\n\"We're missing some performance characteristics,\" Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. \"We have a need for a clear and concise way of conveying the characters and the performance of an environment.\"\n\n<h3>MeshMark Brings Metrics to Cloud-Native Service Mesh</h3>\n\nThe Service Mesh Performance project at its core is an effort to define specifications for capturing the details of a cloud-native environment in a uniform and consistent way, according to Calcote. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn't always clear with a service mesh though is how well it's actually working.\n\nMeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.\n\n\"We're missing some performance characteristics,\" Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. \"We have a need for a clear and concise way of conveying the characters and the performance of an environment.\"\n\nThe Service Mesh Performance project looks at capturing infrastructure and service mesh configuration details and then providing a means to characterize the details of running workloads. The project also aims to provide the details in a consistent approach that can enable organizations to develop a baseline for an environment, as well as benchmark in a consistent way. Simply being aware of what's running in a service mesh isn't quite enough though, and there is a need for a performance metric, which is where the new MeshMark effort comes into play. Mrittika Ganguli, principal engineer and network architect at Intel, explained that MeshMark is a cloud-native value measurement.\n\n\"With MeshMark, you're essentially trying to measure if the performance of your infrastructure matches what kind of business value you want to get from your deployment,\" Ganguli said.\n\nA business value could be defined with key performance indicators on, for example, how well video gets loaded on a particular webpage, she said.\n\n\"If you click on something, you may often see the text get rendered first and then the video,\" Ganguli said. \"The load latency of the video traffic is what impacts what you see visually.\"\n\nMeshMark aims to provide metrics that an organization can use to determine how resources are being used. Ganguli said that in a cloud-native environment an organization is utilizing different kinds of resources. The utilization classes include, for example, compute or network or any other type of resource.\n\nMeshMark provides an efficiency metric called Mesh Utilization Efficiency (MUE) that can help determine a score for a given resource utilization and the level of optimization. The MeshMark score will be able to help identify what the load latency is for a given workload, given the available resources. Overall, the goal with MeshMark is to take a number of different signals coming from a service mesh and combine them into an approach that can help organizations understand how well a deployment is, or isn't, working.\n\nThe need to better understand the performance of service meshes was further underscored by a report released on May 17 by the CNCF. The report found that 60% of surveyed organizations are using a service mesh in production today ‚Äî and that key challenges for deployment of service meshes are a lack of guidance, blueprints, and best practices.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"Intel, Layer5 Announce MeshMark to Quantify Cloud-Native Performance","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAgCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwAAUU0usAD+9hPekOv5EN4vIa+8oARkiR/1LCYUhAC/k+W3o2CuRwAAAA=="},"images":{"fallback":{"src":"/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp","srcSet":"/static/49cbc7ef20d9383088e20f773af6a13e/9860d/it-pro.webp 750w,\n/static/49cbc7ef20d9383088e20f773af6a13e/9ec3b/it-pro.webp 1080w,\n/static/49cbc7ef20d9383088e20f773af6a13e/20dcd/it-pro.webp 1366w,\n/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp 1540w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5194805194805194}},"extension":"webp","publicURL":"/static/49cbc7ef20d9383088e20f773af6a13e/it-pro.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAgCdASoUAAoAPtFUo0uoJKMhsAgBABoJZwAAUU0usAD+9hPekOv5EN4vIa+8oARkiR/1LCYUhAC/k+W3o2CuRwAAAA=="},"images":{"fallback":{"src":"/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp","srcSet":"/static/49cbc7ef20d9383088e20f773af6a13e/9860d/it-pro.webp 750w,\n/static/49cbc7ef20d9383088e20f773af6a13e/9ec3b/it-pro.webp 1080w,\n/static/49cbc7ef20d9383088e20f773af6a13e/20dcd/it-pro.webp 1366w,\n/static/49cbc7ef20d9383088e20f773af6a13e/cc1f6/it-pro.webp 1540w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5194805194805194}},"extension":"webp","publicURL":"/static/49cbc7ef20d9383088e20f773af6a13e/it-pro.webp"}},"fields":{"slug":"/company/news/intel-layer5-announce-meshmark-to-quantify-cloud-native-performance"}},{"id":"787f689e-ebc6-55b4-ac65-2821194b82f3","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Working from \"./Istio Ingress Gateway.webp\";\nimport Rep from \"./Istio Ingress Gateway No Title.webp\";\n\n\n<ResourcesWrapper>\n\n<p>\n    Predominantly, Kubernetes has used an Ingress controller to handle the traffic that enters the cluster from the outside. \n    Istio has replaced all the familiar Ingress resource with new Gateway and VirtualServices resources.\n    They work in sync to route all the traffic into the mesh.\n    Inside the mesh there is no requirement for Gateways since the services can access each other by a cluster local service name.\n</p>\n<h3>Let‚Äôs understand the working with a representation</h3>\n<p>\n    <img src={Rep} align=\"center\" alt=\"Istio Ingress Gateway in Kubernetes No Title\" />\n</p>\n<p>\n<ul>\n<li>Firstly A request is made by a client on a specific port</li>\n<li>Then a load balancer on this port listens and forwards the request to one of the workers in theh cluster on same or a new port</li>\n<li>Inside the cluster the request is routed to the Istio Ingress Gateway which is listened on the port of the load balancer</li>\n<li>The Service forwards the requestto an Istio Ingress Gateway Pod which is managed by a deployment</li>\n<li>The Ingress Gateway Pod is configured by a Gateway and a VirtualService.</li>\n<li>The Gateway configures all the ports, protocol, and certificates.</li>\n<li>The Virtual Service configures all the routing information to find the correct Servicein it.</li>\n<li>The Istio Ingress Gateway Pod routes the request to the application Service.</li>\n<li>And lastly, the application Service routes the request to an application Pod which is managed by a deployment.</li>\n</ul>\n</p>\n<ul>\n</ul>\n\n<h2>\n   Ingress Gateway Service\n</h2>\n\n<p>\n    The Ingress Gateway Service must listen to all the ports to be able to forward the traffic to the Ingress Gateway pods. \n    Here we will be using routing to bring all the port numbers back to their initial state.\n</p>\n\n<p>\n    Note that a Kubernetes Service is not a real service, but, since we are using type: \n    \"NodePort\", all the request will be handled by the kube-proxy provided by Kubernetes and forwarded to a node with a current running pod. \n    Once on the node, an IP-tables is configured a request will be forwarded to the appropriate pod.\n</p>\n\n```yaml\n\n# From the istio-ingressgateway service\n  ports:\n  - name: http2\n    nodePort: 30000\n    port: 80\n    protocol: TCP\n  - name: https\n    nodePort: 30443\n    port: 443\n    protocol: TCP\n  - name: mysql\n    nodePort: 30306\n    port: 3306\n    protocol: TCP\n```\n<p>\n    If we inspect the service, we will see that it defines more ports than we have describe above.\n    So these ports will be used for all the internal Istio communication.\n</p>\n\n<h2>\n    Ingress Gateway Deployment\n</h2>\n\n<p> \nIt's a wrapper around the Envoy proxy and it is configured as the sidecars used inside the service mesh. \nWhen a Gateway or VirtualService gets changed,\nthey are detected by the Istio Pilot controller and converts this information to an Envoy configuration and sends it to all the proxies, including the Envoy inside the IngressGateway.\n</p>\n\n<p>\n    Since container ports are not supposed to be declared in Kubernetes pods, we don't have to declare the ports in the Ingress Gateway Deployment.\n    If we look inside the deployment we can see that there are a number of ports that are already declared anyway.\n    We have to take care about the Ingress Gateway Deployment in SSL certificates. \n    To access the certificates inside the Gateway resources, make sure that we have mounted all the required certificates properly.\n</p>\n\n```yaml\n\n# Example represents volume mounts\nvolumeMounts:\n- mountPath: /etc/istio/ingressgateway-certs\n  name: ingressgateway-certs\n  readOnly: true\n- mountPath: /etc/istio/ingressgateway-ca-certs\n  name: ingressgateway-ca-certs\n  readOnly: true\n\n# Example represents volumes\nvolumes:\n- name: ingressgateway-certs\n  secret:\n    defaultMode: 420\n    optional: true\n    secretName: istio-ingressgateway-certs\n- name: ingressgateway-ca-certs\n  secret:\n    defaultMode: 420\n    optional: true\n    secretName: istio-ingressgateway-ca-certs\n```\n\n<h2>The Gateway</h2>\n\n<p>\n    The Gateway resources are used to configure the ports for Envoy and also support for the Kubernetes Ingress. \n    Since all the three ports are exposed with the servies, we need these ports to be handled by the Envoy. \n    It can be handled by declaring one or more Gateways.\n</p>\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: default-gateway\n  namespace: istio-system\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n\n  - hosts:\n    - '*'\n    port:\n      name: http\n      number: 80\n      protocol: HTTP\n\n  - hosts:\n    - '*'\n    port:\n      name: https\n      number: 443\n      protocol: HTTPS\n    tls:\n      mode: SIMPLE\n      privateKey: /etc/istio/ingressgateway-certs/tls.key\n      serverCertificate: /etc/istio/ingressgateway-certs/tls.crt\n\n  - hosts: # For all the TCP routing this fields will be ignored, but it will be matched\n    - '*'  # with the VirtualService, We use * since it will match anything.\n    port:\n      name: mysql\n      number: 3306\n      protocol: TCP\n```\n\n<h2>VirtualService</h2>\n<p>\n    The last interesting resource we have is the VirtualService, it used in concert with the Gateway to configure Envoy. \n</p>\n<p>\n    A general configuration for an HTTP(s) service\n</p>\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: counter\nspec:\n  gateways:\n  - default-gateway.istio-system.svc.cluster.local\n  hosts:\n  - counter.lab.example.com\n  http:\n  - match:\n    - uri:\n      prefix: /\n    route:\n    - destination:\n        host: counter\n        port:\n          number: 80\n\n```\n<h2>Application Service and Deployment</h2>\n<p>\n    The request have now reached the application service and deployment. These are normal Kubernetes resources.\n</p>\n\n<h2>Extras:</h2>\n\n<h3>Debugging Istio Gateway</h3>\n<p>\n     First we will use istioctl to check the configuration status of Istio Ingress Gateway:\n</p>\n\n```yaml\n\n# istioctl proxy-status istio-ingressgateway-5586f47659-r64lb.istio-system\nClusters Match\nListeners Match\nRoutes Match\n\n```\n<p>\n    If anything does not get synced with it, try restarting the ingress gateway pod once - it may be possible that it somehow an update got missed.\n    If RDS looked good, we can check access logs of it. \n</p>\n\n```yaml\n\n#kubectl get configmap istio -n istio-system -o yaml | grep \"accessLogFile: \"\ndisable access log.\\naccessLogFile: \\\"/dev/stdout\\\"\\n\\n# If accessLogEncoding\n\n```\n<p>\n    Once all the access logs are enabled, we can try torequest a few more times and check the logs on the Ingress Gateway:\n</p>\n\n```yaml\n\n# kubectl logs -n istio-system istio-ingressgateway-5586f47659-r64lb | grep -v deprecated\n\n```\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Ingress Gateway in Kubernetes","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":"Istio","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4WAoAAAAQAAAAEwAACwAAQUxQSBEAAAABD9D/iAgIBJL2J98gov+ZHQBWUDggWgAAANADAJ0BKhQADAA+0VSjS6gkoyGwCAEAGglpAABSui9EcCMXxIZwAAD+9hPeHc9BJcicWg4Stt4P6RO2muLV0Jjky6cPrFHMbfr8+JsYVp9/uo+acFskxC8IAA=="},"images":{"fallback":{"src":"/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp","srcSet":"/static/eec5644b77e71f1ff68a36b674aea59c/33c00/Istio%20Ingress%20Gateway.webp 750w,\n/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp 950w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5757894736842105}},"extension":"webp","publicURL":"/static/eec5644b77e71f1ff68a36b674aea59c/Istio Ingress Gateway.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4WAoAAAAQAAAAEwAACwAAQUxQSBEAAAABD9D/iAgIBJL2J98gov+ZHQBWUDggWgAAANADAJ0BKhQADAA+0VSjS6gkoyGwCAEAGglpAABSui9EcCMXxIZwAAD+9hPeHc9BJcicWg4Stt4P6RO2muLV0Jjky6cPrFHMbfr8+JsYVp9/uo+acFskxC8IAA=="},"images":{"fallback":{"src":"/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp","srcSet":"/static/eec5644b77e71f1ff68a36b674aea59c/33c00/Istio%20Ingress%20Gateway.webp 750w,\n/static/eec5644b77e71f1ff68a36b674aea59c/0fe34/Istio%20Ingress%20Gateway.webp 950w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5757894736842105}},"extension":"webp","publicURL":"/static/eec5644b77e71f1ff68a36b674aea59c/Istio Ingress Gateway.webp"}},"fields":{"slug":"/resources/service-mesh/istio-ingress-gateway-in-kubernetes"}},{"id":"9b0a1004-cf4e-5a13-8bd0-a8bda49ae654","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\nAs a forthcoming, ubiquitous layer of cloud native infrastructure, service meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. Managing the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly summarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure of choice is a challenge unto its own.\n\nWe explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties of resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance analysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of workloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.\n\n</NewsWrapper>","frontmatter":{"title":"Analyzing Service Mesh Performance","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgCdAB6V1vFmRI1iw0AA/umSK0KdRjjz9YXdu7S/97FNJD1J4/X373Sa+zEas27Peze33ZGm9Qqc4gPEikHmOZ4vTAD704vlc6FBdmm/nPn0bdXFsSJFMUJQXAAA"},"images":{"fallback":{"src":"/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp","srcSet":"/static/1b674dee7c478103de63e91d9f37fff0/5f850/cover.webp 750w,\n/static/1b674dee7c478103de63e91d9f37fff0/2c010/cover.webp 1080w,\n/static/1b674dee7c478103de63e91d9f37fff0/5126b/cover.webp 1366w,\n/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp 1783w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5457094784071789}},"extension":"webp","publicURL":"/static/1b674dee7c478103de63e91d9f37fff0/cover.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAADQAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJYgCdAB6V1vFmRI1iw0AA/umSK0KdRjjz9YXdu7S/97FNJD1J4/X373Sa+zEas27Peze33ZGm9Qqc4gPEikHmOZ4vTAD704vlc6FBdmm/nPn0bdXFsSJFMUJQXAAA"},"images":{"fallback":{"src":"/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp","srcSet":"/static/1b674dee7c478103de63e91d9f37fff0/5f850/cover.webp 750w,\n/static/1b674dee7c478103de63e91d9f37fff0/2c010/cover.webp 1080w,\n/static/1b674dee7c478103de63e91d9f37fff0/5126b/cover.webp 1366w,\n/static/1b674dee7c478103de63e91d9f37fff0/25dfc/cover.webp 1783w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5457094784071789}},"extension":"webp","publicURL":"/static/1b674dee7c478103de63e91d9f37fff0/cover.webp"}},"fields":{"slug":"/company/news/analyzing-service-mesh-performance"}},{"id":"874bb1f5-6259-560f-a9cc-4d0264946625","body":"\nimport { Link } from \"gatsby\";\nimport Infrastructure from \"./figure1.webp\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\nWASM stands for WebAssembly, which is an open standard for defining a binary format for executable programs. It also defines Interfaces for interacting with host environments through the WebAssembly System Interface (WASI). Browsers and large web applications were the primary focus of these host environments, with the goal of securely running programmes to enhance performance. The W3C maintains WASM as an open standard, and all modern browsers have adopted it. WebAssembly is the fourth language that can run natively in web browsers, following HTML, CSS, and Javascript.\n\nGoogle's open-source high-performance JavaScript and WebAssembly engine, V8, is being embedded into Envoy, bringing WASM support to the platform. Envoy exposes an Application Binary Interface (ABI) to WASM modules via the WebAssembly System Interface, allowing them to function as Envoy filters. WASI operates effortlessly. Your application is written in one of your favorite languages, such as Rust, C++, or C. Then, for the host environment, build and compile them into a WebAssembly binary. For the resulting binary to execute, the WebAssembly runtime must offer the necessary interfaces to system calls. Conceptually, this is similar to JVM. If you have a JVM installed, then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.\n\nAdditional filters can be added to Envoy in one of two ways:\n\n- By incorporating your custom filter into Envoy's C++ source code and building a new version of Envoy natively. The disadvantage is that you'll have to maintain your own version of Envoy, but the advantage is that your custom filter will run at native speed.\n- Via WASM, by developing your custom filter in C++, Rust, AssemblyScript, or Go and integrating it as a WebAssembly binary. The disadvantage is that WASM-based filters have considerable overhead, but the advantage is that WASM-based filters may be dynamically loaded and reloaded in Envoy at runtime.\n\nOn startup, Envoy's configuration is initialised using bootstrap. The xDS APIs in Envoy enable¬†dynamic configuration loading and reloading during runtime. There are several sections in the Envoy configuration (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). WASM plugins can be configured in each section (programs).\n\n### Dynamically (Re)loadable Intelligence\n\nData planes are powerful because they can dynamically load WASM programs to inspect, rewrite, and reroute packets carrying application requests. WASM applications can integrate business logic considerations when filtering application requests when using a management plane. The service mesh can implement business logic, as well as common application infrastructure logic:\n\n- Subscription plan enforcement: rate limiting requests based on user‚Äôs subscription plan\n- Class of Service: directing requests to high performance clusters based on user demographics or activity\n- Multivariate testing: facilitating comparison a of high number of variables between deployments (service versions) and users\n\n<div className=\"fact\">\n\nTo get a feel of these¬†capabilities, try experimenting with the <Link to=\"/projects/image-hub\">Image Hub</Link>,a prototype application developed in Rust that runs on Consul and allows you to explore WebAssembly modules used as Envoy filters.\n\n</div>\n\n  <div className=\"center\" >\n  <img src={Infrastructure} align=\"center\" alt=\"application infrastructure logic\" />\n  \nFigure 1:. How the intelligence of the cloud native management plane and the power of the service mesh data plane combine to deliver application infrastructure logic.\n  </div>\n\nWebAssembly is intriguing in part because of its performance characteristics, which vary depending on the program/filter used. For network filtering use cases, some have a 10% to 20% overhead as compared to natively executed code.¬† Given its high degree of portability, WebAssembly resembles Docker in certain ways. WASM's virtual stack machine, like the Java Virtual Machine (JVM), is evolving into a write once, run anywhere system (WORA). WASM executables are precompiled with a wide range of languages that support it as a compilation target (currently around 40 languages).\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Envoy and WebAssembly","type":"Article","technology":"WebAssembly","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/webassembly-filters/envoy-and-webassembly"}},{"id":"26141097-8979-5e2e-989a-90bae6f54b40","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\n<h3>The Power of the Data Plane</h3>\n<p>\nOperators benefit from control planes because they provide much-needed element management. Data planes require control planes to apply service mesh-specific use cases to their fleet of service proxies. A control plane performs activities like configuration management, telemetry collecting, infrastructure-centric authorization, identity, etc. However, the service proxy is a massive source of power for them. Users frequently require customizing the chain of traffic filters (modules) that service proxies employ to perform much of their heavy lifting. Different technologies are used to provide data plane extensibility, and consequently, additional custom data plane intelligence, including:\n</p>\n\n<ul>\n  <li>Lua - a scripting language for execution inside a Just-In-Time compiler, LuaJIT.</li>\n  <li>WebAssembly (WASM) - a virtual stack machine as a compilation target for different languages to use as an execution environment.</li>\n</ul>\n\n<h3>Lua and WebAssembly</h3>\n<p>\nPeople are discussing the merits of using a WebAssembly runtime since the introduction of WASM into service meshes. A¬† Lua runtime¬†can be as little as 4 kb, with LuaJIT being surprisingly fast, having a runtime of only ~200 kb.\n</p>\n<p>\nThe WebAssembly loader, not the runtime, is the source of complexity for the host software. When comparing the two, how do you weigh GCC or LLVM in terms of making optimized C or C++ faster or slower than LuaJIT?\n</p>\n\n<p>\nThe complexity of a WebAssembly runtime stems from the fact that it contains arch-specific optimizers as well as an Intermediate Representation to machine code translation stage that would usually be executed inside GCC or LLVM. Machine code can be created once and then cached on non-volatile storage until the input WASM file's hash changes (like the extracted contents of a Zip file). Since WASM has a similar approach to sandboxing (making the language/bytecode unable to describe accessing resources outside of what is granted), the result is lighter than Lua once the machine code is generated. However, WASM's compiled machine code does not require a garbage collector or JIT engine.\n</p>\n\n<p>\nWebAssembly follows the same flat, garbage-collected memory model as malloc and free. Suppose you want a garbage collector in a WebAssembly application. In that case, you can either compile it to WebAssembly and run it inside the sandbox or wait for extensions currently developing, such as \"opaque reference types,\" which allows WebAssembly applications to interact with objects managed by a Garbage Collector outside the sandbox.\n</p>\n\n<h3>NGINX and Lua</h3>\n<p>\nNGINX allows you to write¬†dynamic modules that can be loaded at runtime based on¬†configuration files. By modifying the configuration files and reloading NGINX, these modules can be unloaded. NGINX enables you to use Lua to embed custom logic into dynamic modules.\n</p>\n<p>\nLua is a lightweight, embeddable scripting language that supports procedural, functional, and object-oriented programming. Lua is dynamically typed, and runs by interpreting bytecode with a register-based virtual machine.\n</p>\n<p>\nNGINX provides the ability to integrate dynamic Lua scripts using the ngx_lua module. Using NGINX with ngx_lua helps you offload logic from your services and hand their concerns off to an intelligent data plane. Leveraging NGINX's subrequests, the ngx_lua module allows the integration of Lua threads (or coroutines into the NGINX event model. Instead of passing logic to an upstream server, the Lua script can inspect and process service traffic. ngx_lua modules can be chained to be invoked at different phases of NGINX request processing.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Lua vs WebAssembly","type":"Article","technology":"WebAssembly","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/webassembly-filters/lua-vs-webassembly"}},{"id":"b6ff733a-1416-533b-90e2-d3a30f77f689","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Communication from \"./figure4.webp\";\nimport Timeouts from \"./figure3.webp\";\nimport Metrics from \"./figure2.webp\";\nimport Mixer from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\nService meshes provide visibility, resiliency, traffic, and security control of distributed application services.\n\n### Observability\n\nMany organisations are attracted to the uniform observability that service meshes provide. There is no such thing as a fully healthy complex system. Service-level¬† t elemetry¬†sheds light on difficult-to-answer questions like why your requests are slow¬†to respond. It's quite simple to figure out when a service is down, but figuring out where it's slow and why is a different story.\n\nService meshes allow both black-box (observing a system from the outside) and white-box (monitoring a system from the inside)¬†monitoring of service-to-service communication. To provide white-box monitoring, some service meshes combine with a distributed tracing library. In contrast, other service meshes¬†use protocol-specific filters as a capability of their proxies to provide a deeper level of visibility. The components of the data plane are well-positioned (transparently, in-band) to create metrics, logs, and traces, ensuring uniform and thorough observability across the mesh.\n\n  <div className=\"center\" >\n  <img src={Mixer} align=\"right\" alt=\"Istio Mixer\" />\n  <p>Figure 1: Istio‚Äôs Mixer is capable of collecting multiple telemetric signals and sending those signals to backend monitoring, authentication, and quota systems via adapters</p>\n  </div>\n\nService meshes centralize and assist in solving these observability challenges by providing the following:\n\n  <div className=\"right\" >\n  <img src={Metrics} align=\"right\" alt=\"Request Metrics\" />\n  <p>Figure 2: Request metrics generated by Istio and visible in Meshery</p>\n  </div>\n\n- **Logging**\n    \n    Logs are used to baseline visibility for access requests to your entire fleet of services. Figure 1 illustrates how telemetry transmitted through service mesh logs include source and destination, request protocol, endpoint (URL), response time, size, and associated response code.\n\n- **Metrics**\n    \n    Metrics are used to eliminate the need for the development process to instrument code in order to emit metrics. When metrics are ubiquitous¬†across your cluster, additional insights become available. Consistent metrics allow for things like autoscaling to be automated. Telemetry emitted by service mesh metrics include global request volume, global success rate, individual service responses by version, source and time.\n\n- **Tracing**\n    \n    Slow services (as opposed to services that simply fail) are the most difficult to debug without tracing. Imagine manually enumerating and tracking all of your service dependencies in a spreadsheet. Dependencies, request volumes, and failure rates are visualised using traces. Service meshes enable incorporating tracing functionality extremely simple with the help of¬†automatically generated span identifiers. The mesh's individual services still must forward context headers.¬† Many application performance management (APM) solutions, on the other hand, need manual instrumentation to extract traces from your services.\n\n### Traffic control\n\nService meshes provide for granular, declarative control over network traffic, such as determining where a request should be routed to perform¬†canary release. Circuit breaking, latency-aware load balancing, eventually consistent service discovery, timeouts, deadlines, and retries are all common resiliency features.\n\nWhen a request does not return to the client within a certain amount of predefined¬†time, a  <strong>timeout</strong> is used to terminate it. They provide a time restriction on how much time can be spent on an individual¬†request and are enforced at a point after which a response is considered invalid. <strong>Deadlines</strong> are an advanced service mesh feature that helps minimise retry storms by facilitating feature-level timeouts rather than independent service timeouts. As a request travels through the mesh, deadlines deduct time remaining to handle it at each stage, propagating elapsed time with each downstream service call.¬†\nTimeouts and deadlines¬†might be considered enforcers of your Service-Level Objectives (SLOs).\n\nYou can choose to retry a request if a service¬†times out or is unsuccessfully returned. Retrying the same call to a service that is already under water (retry three times = 300 percent additional service load) can make things worse. Retry budgets (aka¬†maximum retries) offer the benefit of multiple tries but come with a limit to avoid overloading an already a load-challenged¬†service. Some service meshes go even further to reduce client contention by using jitter and an exponential back-off algorithm to calculate the timing of the¬†next retry attempt.\n\n  <div className=\"left\" >\n  <img src={Timeouts} align=\"right\" alt=\"Deadlines\" />\n  <p>Figure 3:Deadlines, not ubiquitously supported by different service meshes, set feature-level timeouts</p>\n  </div>\n\nYou can choose to fail fast and disconnect the service, prohibiting calls to it, rather than retrying and putting more load to the service. <strong>Circuit breaking</strong> allows users to set¬†configurable¬†timeouts (or failure thresholds) to assure safe maximums and graceful failure, which is common for slow-responding services. When applications (services) are oversubscribed, using a service mesh as a distinct layer to implement circuit breaking minimises undue overhead.\n\n<strong>Rate limiting</strong>(throttling) is implemented to¬†ensure service stability. When requests by¬†one client¬†surge, the service continues to function smoothly for others. The rate limits are calculated over a period of time. You can also utilise various algorithms, such as a fixed or sliding window, a sliding log, etc. The purpose of rate limits is to ensure that your services are not oversubscribed.\n\nWhen a limit is reached, well-implemented services commonly adhere to IETF RFC 6585, sending 429 Too Many Requests as the response code, including headers, such as the following, describing the request limit, number of requests remaining, and amount of time remaining until the request counter is reset:\n\n<div className=\"fact-left\">\n<p>X-RateLimit-Limit: 60</p>\n<p>X-RateLimit-Remaining: 0</p>\n<p>X-RateLimit-Reset: 1372016266</p>\n</div>\n\n<strong>Quota management</strong> (or conditional rate-limiting) accounts for requests based on business requirements instead of limiting rates based on operational concerns. It can be difficult to tell the difference between rate limiting and quota management because both features are handled by the same service mesh capability but are exposed to users in different ways.\n\nConfiguring a policy setting a threshold for the number of client requests allowed to a service over time is the canonical example of quota management. User Lee, for example, is on the Free service plan and is allowed upto¬†10 requests per day. Quota policy imposes consumption limitations on services by keeping track of incoming requests in a distributed counter,often using¬†an in-memory datastore like Redis¬† Conditional rate limits are a powerful service mesh capability when applied based on a user-defined set of arbitrary attributes.\n\n### Security\n\n  <div className=\"right\" >\n  <img src={Communication} align=\"right\" alt=\"Communication Paths\" />\n  <p>Figure 4: An example of service mesh architecture. Secure communication paths in Istio</p>\n  </div>\n\nFor securing service-to-service communication, most service meshes include a certificate authority that manages keys and certificates. Certificates are generated for each service and serve as the service's unique identifier. When sidecar proxies are employed, they assume the identity of the service and perform lifecycle management¬†of certificates (creation, distribution, refresh, and revocation) on its behalf.¬†¬† Local TCP connections are often established between the service and the sidecar proxy, whereas mutual Transport Layer Security (mTLS) connections are typically established between proxies in sidecar proxy deployments.\n\nInternal traffic within your application should be encrypted as a matter of security. The service calls in your application are no longer contained within a single monolith via localhost; they are now exposed over the network. Allowing service calls without TLS on the transport is a recipe for disaster in terms of security. When two mesh-enabled services communicate, they have strong cryptographic proof of their peers.¬†¬† After identities have been established, they are used to create access control policies that determine whether or not a request should be serviced. Policy controls configuration of the key management system (e.g., certificate refresh interval) and operational access control are used to determine whether a request is accepted, based on service mesh employed. Approved and unapproved connection requests, as well as more granular access control parameters like time of day, are identified using white and blacklists.\n\n### Delay and fault injection\n\nIt's important to accept that your networks and/or systems will fail. Why not introduce failure and verify behaviour ahead of time? As proxies sit in line to service¬†traffic, they frequently support protocol-specific fault injection, which allows you to configure¬†the percentage of requests that should be subjected to faults or network delays. For example, generating HTTP 500 errors might be used to test the robustness of your distributed application's response behaviour.\n\nInjecting latency into requests without a service mesh is a time-consuming procedure, but it is probably a more prevalent problem encountered during¬† operation of an¬†application. Users are far more irritated by slow replies that result in an HTTP 503 after a minute of waiting than by a 503 after a few seconds. The finest element of these resilience testing capabilities¬†is that no application code needs to be changed to make these tests possible. The results of the tests, on the other hand, may prompt you to make changes to the application code.\n\nUsing a service mesh, developers spend far less time creating code to cope with infrastructure issues‚Äîcode¬†that could be commoditized by service meshes in the future. The separation of service and session-layer concerns from application code is manifested as a phenomenon I refer to as decoupling at Layer 5.\n\nA service mesh can be regarded of as surfacing the OSI model's session layer as a separately addressable, first-class citizen in your modern architecture. They are a secret weapon of cloud native systems, waiting to be exploited as a highly configurable work horse.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Value of a Service Mesh","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/value-of-a-service-mesh"}},{"id":"e5466ac3-43d5-5cb7-b523-c2fdf055b9cf","body":"\nimport { Link } from \"gatsby\";\nimport Swappingproxy from \"./figure1.webp\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about WebAssembly's use within service mesh data planes in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.</p>\n  </div>\n\nOne of the most significant¬†considerations to make when establishing a service mesh is the proxy's functionality. From the standpoint of a developer, a proxy's cloud native integrations (e.g., with OpenTelemetry / OpenTracing, Prometheus, and so on) are extremely important. Surprisingly, a developer may be uninterested in the APIs of a proxy. The control plane for the service mesh is the point of control for managing proxy settings. A developer, however, will be interested in the APIs of a management plane. Protocol support is at the top of the developers' wish list for proxies. Protocol considerations can be divided into two categories:\n\n- TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.\n- gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.\n\nThe reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:\n\n- High performance and low latency\n- High scalability and small memory footprint\n- Deep observability at all layers of the network stack\n- Programmatic configuration and ecosystem integration\n- Thorough documentation to facilitate an understanding of expected proxy behavior\n\nEnvoy is used as a service proxy by a variety of service meshes. Within Istio, Envoy is the default service proxy. Using Envoy‚Äôs APIs, various projects have demonstrated the ability to displace Envoy as the default service proxy with the choice of an alternative.\n\n  <div className=\"intro\">\n      <h3 align=\"center\">Standardizing Data Plane APIs</h3>\n    <p>\n        The xDS APIs are a collection of Envoy's APIs. The Universal Data Plane API (UDPA) working group attempts to create a set of APIs that will serve as the de facto standard for L4/L7 data plane configuration (similar to OpenFlow's role in SDN at L2/L3/L4). The Envoy xDS APIs are being evolved to address service discovery, load balancing assignments, routing discovery, listener configuration, secret discovery, load reporting, health check delegation, and more, in combination with a well-defined, stable API versioning policy.\n    </p>    \n  </div>\n\nIn early versions of Istio, Linkerd exhibited an integration in which Istio was the control plane, supplying configuration to Linkerd proxies.¬† NGINX also hosted a project called nginMesh, in which Istio served as the control plane and NGINX proxies operated as the data plane.\n\nWith many service proxies in the ecosystem, outside of Envoy, only two have currently demonstrated integration with Istio . Linkerd is not yet intended to be a general-purpose proxy; instead, it is focused on being lightweight, placing extensibility as a secondary concern by offering extensions via gRPC plug-in.¬† Consul makes use of Envoy as a proxy. Why would you want to use another¬†service proxy?\n\n**NGINX**\n\nWhile you won't be able to use NGINX as a proxy to replace Envoy, you could wish to employ NGINX based on your operational expertise, the necessity for a battle-tested proxy, or the integration of an F5 load balancer. You might also be looking for caching, a web application firewall (WAF), or other features in NGINX Plus. The service proxy used in the NGINX Service Mesh data plane is an enhanced version of NGINX Plus that interfaces natively with Kubernetes.\n\n**CPX**\n\nIf you already have Citrix Application Delivery Controllers and want to use them across your diverse infrastructure, you might choose to use the Citrix Service Mesh (which is an Istio control plane with a CPX data plane).With infrastructure diversity, holistic control, and monitoring for operational consistency across all your workloads (new microservices and existing monoliths).\n\n**MOSN**\n\nMOSN can deploy as an Istio data plane. You might choose to deploy MOSN if you need to highly customize your service proxy and are a Golang shop. MOSN supports a multi-protocol framework, and you access private protocols with a unified routing framework. It has a multi-process plug-in mechanism, which can easily extend the plug-ins of independent MOSN processes through the plug-in framework, and do some other management, bypass and other functional module extensions.\n\n<div className=\"fact\">\n    You might find this article on <a href=\"https://www.oreilly.com/content/how-to-customize-an-istio-service-mesh/\">How to customize an Istio service mesh and its adjoining webcast</a> helpful in further understanding Istio‚Äôs extensibility with respect to swappable service proxies.\n</div>\n\nWithout configuration, proxies are without instructions to perform their tasks. Pilot is the head of the ship in an Istio mesh, keeping synchronized with the underlying platform by tracking and representing its services to istio-proxy. istio-proxy contains the proxy of choice (e.g. Envoy). Typically, the same istio-proxy Docker image is used by Istio sidecar and Istio ingress gateway, which contains not only the service proxy but also the Istio Pilot agent.  At regular intervals, the Istio Pilot agent pulls configuration from Pilot to the service proxy, so that each proxy knows where to route traffic.\n\n  <div className=\"center\" >\n  <img src={Swappingproxy} align=\"center\" alt=\"Swapping Proxy\" />\n  <p>\n  Figure 1: Example of swapping proxies‚ÄîIstio + nginMesh.\n  </p>\n  </div>\n\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Swappable Sidecars","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAADQBACdASoUABIAPtFapE0oJSMiKA1RABoJYwDJEywA2g3eJStczueWulM7gfhUgAD+8EhFDF8XrmRfXTXVSni42vS8Gdj0JTekggeGiW5kPw43A0QluVRALO2BHRhEXEyP6/L1M1JfV2mQSVkGx7DxcGs+b+DrJiGjMMfCpwGSAAAA"},"images":{"fallback":{"src":"/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp","srcSet":"/static/78e798081ea95d1107c53e978a86330d/1de7a/figure1.webp 750w,\n/static/78e798081ea95d1107c53e978a86330d/ebf50/figure1.webp 1080w,\n/static/78e798081ea95d1107c53e978a86330d/479e6/figure1.webp 1366w,\n/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp 1397w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9019327129563349}},"extension":"webp","publicURL":"/static/78e798081ea95d1107c53e978a86330d/figure1.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRo4AAABXRUJQVlA4IIIAAADQBACdASoUABIAPtFapE0oJSMiKA1RABoJYwDJEywA2g3eJStczueWulM7gfhUgAD+8EhFDF8XrmRfXTXVSni42vS8Gdj0JTekggeGiW5kPw43A0QluVRALO2BHRhEXEyP6/L1M1JfV2mQSVkGx7DxcGs+b+DrJiGjMMfCpwGSAAAA"},"images":{"fallback":{"src":"/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp","srcSet":"/static/78e798081ea95d1107c53e978a86330d/1de7a/figure1.webp 750w,\n/static/78e798081ea95d1107c53e978a86330d/ebf50/figure1.webp 1080w,\n/static/78e798081ea95d1107c53e978a86330d/479e6/figure1.webp 1366w,\n/static/78e798081ea95d1107c53e978a86330d/bab30/figure1.webp 1397w","sizes":"100vw"},"sources":[]},"width":1,"height":0.9019327129563349}},"extension":"webp","publicURL":"/static/78e798081ea95d1107c53e978a86330d/figure1.webp"}},"fields":{"slug":"/resources/service-mesh/swappable-sidecars"}},{"id":"05109a77-89f8-5206-807c-40d28f604c9d","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\nMicroservices have grown tremendously in use‚Äîthey enable decoupled, reusable components and support a rapid development approach. However, it‚Äôs challenging to manage a sea of disparate microservices. It‚Äôs specifically difficult to consistently apply standard features such as traffic management, security and observability mechanisms across all microservices. This issue grows as the number of microservices climbs into the hundreds and thousands.\n\nThis is where service mesh comes in. Service mesh helps to apply common observability and security features across applications. It‚Äôs typically split into a control plane, used to configure features, and a data plane, consisting of a sidecar proxy alongside each application. Nowadays, several service mesh options exist in the market, each with varying levels of complexity.\n\nThe Cloud Native Computing Foundation (CNCF) is home to much of today‚Äôs innovative cloud-native technology. The foundation now hosts a few service meshes and related projects. Below, we‚Äôll outline the CNCF service mesh toolset to better understand how engineers can adopt these tools and their benefits.\n\n</NewsWrapper>","frontmatter":{"title":"6 CNCF Service Mesh Tools","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlQAAABXRUJQVlA4IEgAAACQAwCdASoUAAkAPtFapEwoJSOiMAgBABoJYgC7ABuk0bOyyqZgAP7p6OmnnCJO5bEuRFOOaGK/LzEkAUhqxyi9UCgm/v4AAAA="},"images":{"fallback":{"src":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp","srcSet":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/e30f5/mesh-tools.webp 750w,\n/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp 770w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42857142857142855}},"extension":"webp","publicURL":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/mesh-tools.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRlQAAABXRUJQVlA4IEgAAACQAwCdASoUAAkAPtFapEwoJSOiMAgBABoJYgC7ABuk0bOyyqZgAP7p6OmnnCJO5bEuRFOOaGK/LzEkAUhqxyi9UCgm/v4AAAA="},"images":{"fallback":{"src":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp","srcSet":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/e30f5/mesh-tools.webp 750w,\n/static/9a8ad42f3ee07fb4c143a6a162b9484c/29d51/mesh-tools.webp 770w","sizes":"100vw"},"sources":[]},"width":1,"height":0.42857142857142855}},"extension":"webp","publicURL":"/static/9a8ad42f3ee07fb4c143a6a162b9484c/mesh-tools.webp"}},"fields":{"slug":"/company/news/6-cncf-service-mesh-tools"}},{"id":"1ffdfb7b-b0bf-52fe-a1e9-68e00a4f0f56","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\nThe Cloud Native Computing Foundation (CNCF) announced this week during the ServiceMeshCon/KubeCon + CloudNativeCon conference that Meshery, a service mesh management plane created by Layer5, has become a sandbox-level project.\n\nIn addition, Layer5 has also donated Service Mesh Performance (SMP), a set of tools for measuring the efficiency of a service mesh, to the CNCF. SMP provides an open source framework to define standardized benchmarking practices, performance test configurations and measurements as part of an effort to create a MeshMark index for rating a service mesh. A set of service mesh performance methodologies will also be published by the IEEE later this month, developed in collaboration with engineers from Layer5, Intel, Red Hat and HashiCorp.\n\nLayer5 CEO Lee Calcote said the goal is to make it simpler for IT teams to determine which service mesh to employ based on their specific use case requirements.\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Meshery to Advance Service Mesh Management","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJYgC7ABuSM6zFAAD+GA/HJuewcu/c1Xfaf/pnrcrTaDXToWAnjwbkbfRz//EhC/d/Q5/gVwXVku1qn9x5wAAA"},"images":{"fallback":{"src":"/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp","srcSet":"/static/0e6f6057cddda267d28c32d2fef01c1e/9122e/devops.webp 750w,\n/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp 802w","sizes":"100vw"},"sources":[]},"width":1,"height":0.483790523690773}},"extension":"webp","publicURL":"/static/0e6f6057cddda267d28c32d2fef01c1e/devops.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJYgC7ABuSM6zFAAD+GA/HJuewcu/c1Xfaf/pnrcrTaDXToWAnjwbkbfRz//EhC/d/Q5/gVwXVku1qn9x5wAAA"},"images":{"fallback":{"src":"/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp","srcSet":"/static/0e6f6057cddda267d28c32d2fef01c1e/9122e/devops.webp 750w,\n/static/0e6f6057cddda267d28c32d2fef01c1e/1964d/devops.webp 802w","sizes":"100vw"},"sources":[]},"width":1,"height":0.483790523690773}},"extension":"webp","publicURL":"/static/0e6f6057cddda267d28c32d2fef01c1e/devops.webp"}},"fields":{"slug":"/company/news/cncf-adopts-meshery-to-advance-service-mesh-management"}},{"id":"ac5614bd-e99a-506d-a2bb-b9fab335ee3e","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\nimport smpMeshery from \"./smp-meshery.webp\";\n\n<NewsWrapper>\n\nLOS ANGELES, Oct. 13, 2021 - ServiceMeshCon/KubeCon + CloudNativeCon: Layer5 today announced Service Mesh Performance, an open source standard for service mesh efficiency, a growing consideration for cloud native operators and developers utilizing a service mesh in their infrastructure. With the myriad service meshes available and their sophisticated configurations, distributed systems efficacy and performance management is a continuous concern.\n\n‚ÄúWe donated the Service Mesh Performance specification and body of research surrounding it offers a much-needed vendor-neutral home for providing (often contentious) insights to the popular performance and efficiency questions facing service mesh vendors and more broadly cloud native infrastructure‚Äù, said Layer5 Founder and CEO Lee Calcote. ‚ÄúService Mesh Performance provides a unified framework to define standardized benchmarking practices, performance test configurations, homogenous measurements, and ultimately, MeshMark, a new performance measurement index to measure the efficiency of  service meshes and their workloads both in and outside of Kubernetes.‚Äù\n\n<h3>Standardizing Service Mesh Value Measurement</h3>\n\n<a href=\"https://smp-spec.io\">Service Mesh Performance</a> is a vendor neutral, cloud native performance measurement standard for capturing and characterizing application and infrastructure efficiency, including details of infrastructure capacity, service mesh configuration, and workload metadata.\n<ol>\n    <li>the ability to reason over the efficiency by which cloud native infrastructure is run, specifically in context of a service mesh and its network functions, including custom filters and/or protocol translators using WebAssembly or other.</li>\n    <li>standard benchmarks of service mesh performance</li>\n    <li>common vernacular and measurement for exchange of performance information from system-to-system and mesh-to-mesh</li>\n    <li>apples-to-apples performance comparisons of service mesh deployments and tooling to trend workload performance.</li>\n    <li>a universal performance index to gauge a service mesh‚Äôs efficiency against deployments in other organizations‚Äô environments.</li>\n</ol>\n\n\"A common language and understanding when dealing with system performance measurements is incredibly important when comparing benchmarks from different systems or historical data from a single system; a slight variation in the measurement approach completely invalidates the comparison.‚Äù, said Nic Jackson, SMP Maintainer and Principal Developer Advocate at HashiCorp. ‚ÄúSMP attempts to solve these problems, bringing together a community of incredibly knowledgeable practitioners passionate about improving system performance measurements.\"\n\n<img src={smpMeshery} alt=\"SMP in Meshery\"/>\n\n<h3>CNCF Adopts the Service Mesh Performance project</h3>\n\nWith multiple academic institutions and many vendors involved in the project, the CNCF provides a neutral place for publication of this research and encourages participation from each service mesh vendor under the promise of unbiased analysis, which will help all involved to collectively improve their service mesh implementations and end users to improve operations of their deployments.\n\n‚ÄúAs communication networks evolve toward cloud native 5G and Edge computing, service mesh forms the basis of underlying infrastructure and application networking‚Äù, said Sunku Raganath, SMP Maintainer and Solutions Architect at Intel. ‚ÄúStudying service mesh performance across the multitude of deployment scenarios enables us to understand its impact on latency and throughput, in turn, enabling application developers and infrastructure providers to customize and control service mesh behavior within these latency constrained environments‚Äù. Service Mesh Performance is squarely focused on critical scenarios of performance management across 5G and Edge computing environments. ‚ÄúAn efficient service mesh performance for the given combination of resources for a particular KPI will determine whether the current hardware and software scheduling environment is optimal or needs a change‚Äú, said Mrittika Ganguli, Director and PE, cloud native solutions, NEXG, Intel.\n\n\n<h3>Partnership with University of Texas at Austin, Intel, HashiCorp, and Red Hat engineers</h3>\n\n‚ÄúMore than performance, in collaboration with our maintainers from Layer5, Intel, Red Hat, and HashiCorp, we are actively standardizing service mesh value measurement in the form of a new index to be announced early next year‚Äù, said Calcote. ‚ÄúAs a foundation for this research, 5,000 service mesh performance tests donated by users of Meshery have been donated and are under analysis.‚Äù \n\nPerformance tests are run by Meshery, the open source, multi-mesh manager. Meshery is the canonical implementation of Service Mesh Performance (SMP) and the conformance tool of Service Mesh Interface (SMI). Meshery implements and helps users adopt and vendors uphold these specifications. A jointly authored paper on service mesh performance methodologies will be published by the IEEE later this month, which explores how to model your service mesh topology and optimize for your ideal configuration in context of how much operators value properties of resiliency, performance, throughput, and latency.\n\n<h3>Service Mesh Performance Resources</h3>\n<ul>\n    <li><a href=\"https://smp-spec.io/subscribe\">Community Newsletter</a></li>\n    <li><a href=\"https://discuss.layer5.io\">Discussion Forum</a></li>\n    <li><a href=\"https://www.youtube.com/watch?v=_yrncjtPpg4&list=PL3A-A6hPO2INwi8A3NNClvdCxDoHa9NOU\">Service Mesh Performance YouTube</a></li>\n    <li><a href=\"https://smp-spec.io\">Service Mesh Performance Website</a></li>\n</ul>\n\n<h3>About Layer5</h3>\nLayer5 offers cloud native application management by harnessing the unique position service meshes have in changing how developers write applications, how operators run modern infrastructure and how product owners manage their service offerings. Layer5‚Äôs MeshMap delivers the world‚Äôs only universal service mesh designer. Layer5‚Äôs leadership stewards the Network and Service Mesh groups in the CNCF.\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Service Mesh Performance Standard Established by Layer5 ","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRtYAAABXRUJQVlA4WAoAAAAQAAAAEwAABwAAQUxQSFQAAAABcFtt2/E8v139HSsFZRZgzS4dS2MDYwOr9gLJbsYCETEB+LSXrQ8v6zj5Che0AJsJ367iM0IFQOcAQcvMO71Jc77HPd1WACA03ZVKxbL9QEjgTwFWUDggXAAAADADAJ0BKhQACAA+0VSjS6gkoyGwCAEAGgllDbAAASQoegAA/u2kobYzYhdr5h/tYzGKbJ9RwZn3dQu5n9OXPnrv18eOnup445ufanApwPnJCQRbzsM3E6HsUOAA"},"images":{"fallback":{"src":"/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp","srcSet":"/static/8e7ee27ed78326adb6f595dc42afafa5/9a010/smp-dark-text-side.webp 750w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/a0387/smp-dark-text-side.webp 1080w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/25bb2/smp-dark-text-side.webp 1366w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.409375}},"extension":"webp","publicURL":"/static/8e7ee27ed78326adb6f595dc42afafa5/smp-dark-text-side.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRtYAAABXRUJQVlA4WAoAAAAQAAAAEwAABwAAQUxQSFQAAAABcFtt2/E8v139HSsFZRZgzS4dS2MDYwOr9gLJbsYCETEB+LSXrQ8v6zj5Che0AJsJ367iM0IFQOcAQcvMO71Jc77HPd1WACA03ZVKxbL9QEjgTwFWUDggXAAAADADAJ0BKhQACAA+0VSjS6gkoyGwCAEAGgllDbAAASQoegAA/u2kobYzYhdr5h/tYzGKbJ9RwZn3dQu5n9OXPnrv18eOnup445ufanApwPnJCQRbzsM3E6HsUOAA"},"images":{"fallback":{"src":"/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp","srcSet":"/static/8e7ee27ed78326adb6f595dc42afafa5/9a010/smp-dark-text-side.webp 750w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/a0387/smp-dark-text-side.webp 1080w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/25bb2/smp-dark-text-side.webp 1366w,\n/static/8e7ee27ed78326adb6f595dc42afafa5/199de/smp-dark-text-side.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.409375}},"extension":"webp","publicURL":"/static/8e7ee27ed78326adb6f595dc42afafa5/smp-dark-text-side.webp"}},"fields":{"slug":"/company/news/cncf-adopts-service-mesh-performance-standard-established-by-layer5"}},{"id":"baff9d59-5310-58fe-a823-6147f4f03957","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\nimport MeshMap from \"./MeshMap.png\";\nimport Management from \"./configuration-management.png\";\nimport Meshery from \"../../../../assets/images/meshery/full-logo/meshery-logo-light-text-side.svg\";\nimport { Link } from \"gatsby\";\n\n<NewsWrapper>\n\nLOS ANGELES, CA, Oct. 13, 2021 - ServiceMeshCon/KubeCon + CloudNativeCon:  Layer5 today announced Meshery, the cloud native management plane, has been adopted by the CNCF. Offering lifecycle, configuration, and performance management, <Link to=\"/cloud-native-management/meshery\">Meshery</Link> enables the confident operation of any service mesh and their workloads. Built for the world of many service meshes, Meshery interoperates with ten different service meshes embracing their differentiated features. \n\n<h3>The Service Mesh Management Plane</h3>\n\n‚ÄúWe‚Äôre on a mission to see that organizations are successful in their operation of the world‚Äôs next layer of cloud native infrastructure: service meshes‚Äù, said Layer5 founder and CEO, Lee Calcote. ‚ÄúThrough Meshery‚Äôs management of powerful, service mesh data planes, users can expect more from their infrastructure.‚Äù \n\n<img src={MeshMap} alt=\"Layer5 MeshMap\"/>\n\n\n\"Meshery is the perfect tool for ensuring that your applications are optimally configured and performing well; it also gives you a fantastic visual insight into what can be a large amount of textual configuration.\", said Nic Jackson, Principal Developer Advocate at HashiCorp.\n\nMeshery provides: \n\n<ol>\n    <li><i>Performance Management</i> - for workloads on and off of service meshes and inside and outside of Kubernetes clusters. .</li>\n    <li><i>Configuration Management</i> - with deployment of established usage patterns and analysis against configuration best practices; integration of Open Application Model.</li>\n    <li><i>Lifecycle Management</i> - for service mesh provisioning and workload onboarding.</li>\n    <li><i>Intelligence Management</i> - for dynamic configuration and deployment of WebAssembly filters for Envoy</li>\n    <li><i>Interoperation and federation</i> - by managing multiple service meshes concurrently.</li>\n</ol>\n\n60+ best practice deployment templates are actively being captured in the <Link to=\"/learn/service-mesh-books/service-mesh-patterns\">Service Mesh Patterns book</Link>, all of which will be deployable using Meshery. With 20+ service meshes available today, the <Link to=\"/service-mesh-landscape\">service mesh landscape</Link> offers some perspective as to why Meshery supports 10 different service meshes: \n<ul>\n    <li>AWS App Mesh </li>\n    <li>Citrix Service Mesh</li>\n    <li>HashiCorp Consul </li>\n    <li>Istio </li>\n    <li>Kuma</li>\n    <li>Linkerd</li>\n    <li>Network Service Mesh</li>\n    <li>NGINX Service Mesh </li>\n    <li>Open Service Mesh </li>\n    <li>Traefik Mesh</li>\n</ul>\n\n<h3>Meshery and Service Mesh Standards </h3>\n\nMeshery is the canonical implementation of <Link to=\"/projects/cloud-native-performance\">Service Mesh Performance (SMP)</Link> and the conformance tool of <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface (SMI)</Link> - two service mesh specifications both hosted by the CNCF. Meshery implements and validates these specifications so that users can confidently operate their service mesh infrastructure, knowing their service mesh upholds industry standards. \n\n‚ÄúLayer5 has been instrumental in helping us understand the patterns, best practices, and strategies in our approach to the service mesh ecosystem. Meshery has simplified the process of configuring and operating meshes. Meshery's service mesh neutrality, open source governance, and defining of industry standards like SMP, SMI, and now service mesh patterns  will ensure that Meshery helps any organization adopt meshes with utmost clarity curated to their needs\", said Yogi Porla, Customer Success Manager at HPE.\n\n<img src={Management} alt=\"Meshery-Configuration-Management\"/>\n\n<h3>The Extensible Cloud Native Manager </h3>\n\nNot just a service mesh manager, Meshery comprises a set of microservices each one fitted with extension points. Users and integrators may extend Meshery by taking advantage of designated extension points. ‚ÄúWith one of the world‚Äôs largest enterprise information technology companies, leveraging Meshery as an extensible platform,‚Äù said said Layer5 founder and CEO Lee Calcote, ‚Äúmaintainers have spent a lot of time ensuring that extension points allow a variety of plugins and are available through Meshery‚Äôs architecture.‚Äù\n\n<h3>CNCF Hosts Meshery </h3>\n\n‚ÄúDonation of Meshery to the CNCF has been the goal from the genesis of the project,‚Äù said Lee Calcote, chair of the CNCF‚Äôs Technical Advisory Group for Networking. ‚ÄúThe community around Meshery is what has made it the success that it is.‚Äù The CNCF‚Äôs hosting of Meshery further enables existing participation of 300+ contributors from Layer5, Red Hat, VMware, HashiCorp, Cisco, Rackspace, Citrix, Instabase, Microsoft, OpenGov, Computas AS, Rill Data, Quantex, Lumina Networks, Asteria Aerospace and others. \n\n\n<h3>Meshery Resources</h3>\n<ul>\n    <li><a href=\"https://meshery.io/\">Meshery Website </a></li>\n    <li><a href=\"https://twitter.com/mesheryio\">Meshery Twitter </a></li>\n    <li><a href=\"https://www.linkedin.com/showcase/meshery/\">Meshery LinkedIn </a></li>\n    <li><a href=\"https://meshery.io/subscribe\">Community Newsletter</a></li>\n    <li><a href=\"https://discuss.layer5.io\">Service Mesh Discussion Forum</a></li>\n</ul>\n\n<h3>About Layer5</h3>\n<p>Layer5 offers cloud native application management by harnessing the unique position service meshes have in changing how developers write applications, how operators run modern infrastructure and how product owners manage their service offerings. Layer5‚Äôs MeshMap delivers the world‚Äôs only universal service mesh designer. Layer5‚Äôs leadership stewards the Network and Service Mesh groups in the CNCF.</p>\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Adopts Meshery, the Service Mesh Management Plane","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAABMUlEQVR42hWQXUsCQRSGjxVZkX1hVDd10z+QSnZnmYxwzq47M3oxFwlRJPS9dwUFkkh3XfUHQmuXzJCQuguhMCv/Vc0cOHB4z3teeA5Ap16AbtiCr7ANP2EA8Bejvp8kueI0YhBf2+BzVKlx6m8lKZVTlUplAHRZlkgQVLOriBNGX0aMp5UaBeiFb9CLmvD58AS/jZfFqwuVyXhlO5e/dFxZJZg/slHsEeTXet4nHkeS5T5BUSNMbjtMnNsob/Q+cJg8APiOXqEbNWMf903oN1pL5bPiuoMl25Ml4so7barqgxJhok5Q3lpMHDqM7+rAdxNG0D+2XX6qPdw0QKeW17jPGrsN/ccTpdRgKuWPUbozYgmRWPG8efMChxUWNpWaNHuDnc5mZ4xmMLU2bJAppUP/4pZlyAVA21EAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/221dea7f7130231d51057a42adab9858/b2a57/meshery-logo-light-text-side.png","srcSet":"/static/221dea7f7130231d51057a42adab9858/b2a57/meshery-logo-light-text-side.png 379w","sizes":"100vw"},"sources":[{"srcSet":"/static/221dea7f7130231d51057a42adab9858/69110/meshery-logo-light-text-side.webp 379w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.21108179419525067}},"extension":"png","publicURL":"/static/221dea7f7130231d51057a42adab9858/meshery-logo-light-text-side.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAABMUlEQVR42hWQXUsCQRSGjxVZkX1hVDd10z+QSnZnmYxwzq47M3oxFwlRJPS9dwUFkkh3XfUHQmuXzJCQuguhMCv/Vc0cOHB4z3teeA5Ap16AbtiCr7ANP2EA8Bejvp8kueI0YhBf2+BzVKlx6m8lKZVTlUplAHRZlkgQVLOriBNGX0aMp5UaBeiFb9CLmvD58AS/jZfFqwuVyXhlO5e/dFxZJZg/slHsEeTXet4nHkeS5T5BUSNMbjtMnNsob/Q+cJg8APiOXqEbNWMf903oN1pL5bPiuoMl25Ml4so7barqgxJhok5Q3lpMHDqM7+rAdxNG0D+2XX6qPdw0QKeW17jPGrsN/ccTpdRgKuWPUbozYgmRWPG8efMChxUWNpWaNHuDnc5mZ4xmMLU2bJAppUP/4pZlyAVA21EAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/221dea7f7130231d51057a42adab9858/b2a57/meshery-logo-light-text-side.png","srcSet":"/static/221dea7f7130231d51057a42adab9858/b2a57/meshery-logo-light-text-side.png 379w","sizes":"100vw"},"sources":[{"srcSet":"/static/221dea7f7130231d51057a42adab9858/69110/meshery-logo-light-text-side.webp 379w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.21108179419525067}},"extension":"png","publicURL":"/static/221dea7f7130231d51057a42adab9858/meshery-logo-light-text-side.png"}},"fields":{"slug":"/company/news/cncf-adopts-meshery-the-service-mesh-management-plane"}},{"id":"683cd5d7-bc78-524d-a803-1b30c9c5ff57","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\nimport smp from \"./smp-in-meshery.png\"\n\n<NewsWrapper>\n\nLayer5 announced Service Mesh Performance, an open source standard for service mesh efficiency, a growing consideration for cloud native operators and developers utilizing a service mesh in their infrastructure. With the myriad service meshes available and their sophisticated configurations, distributed systems efficacy and performance management is a continuous concern.\n\nWith multiple academic institutions and many vendors involved in the project, the CNCF provides a neutral place for publication of this research and encourages participation from each service mesh vendor under the promise of unbiased analysis, which will help all involved to collectively improve their service mesh implementations and end users to improve operations of their deployments.\n\n\"As communication networks evolve toward cloud native 5G and Edge computing, service mesh forms the basis of underlying infrastructure and application networking\", said Sunku Raganath, SMP Maintainer and Solutions Architect at Intel. \"Studying service mesh performance across the multitude of deployment scenarios enables us to understand its impact on latency and throughput, in turn, enabling application developers and infrastructure providers to customize and control service mesh behavior within these latency constrained environments\". Service Mesh Performance is squarely focused on critical scenarios of performance management across 5G and Edge computing environments. \"An efficient service mesh performance for the given combination of resources for a particular KPI will determine whether the current hardware and software scheduling environment is optimal or needs a change\", said Mrittika Ganguli, Director and PE, cloud native solutions, NEXG, Intel.\n\n</NewsWrapper>","frontmatter":{"title":"CNCF Adopts Service Mesh Performance Standard Established by Layer5","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAADiUlEQVR42o2T309bZRjHa7wQlNgN68pKt1IMoggRZTAYtqVrhahzjoYuUyZtD5Kx2o7+Pqe/hibqdmW82bnRK3XJIpcM+QO8dUQTjUNdBiVLZGz0d117+vL1PW+LF6YXvsknz/c875vv8zzvOUdhnHQOGh3uLwdmFq4NTHvEIYdPHObCYq/1tPjCsFF85eQb4sibk+Ix6ymxb2yC5V6emBQNF2Oi4YIgDjn94qDDd+3YzMJX/WfnBhXq/oHZLsMY+g0W0jc6Bv2gAd2WM+i1nIZu2IKOkdehHx1Hx4lx6KjWjViZ7jSdYnSNvY0e65lqz1t2aIfMnEKpUbva9HqoNe3lp1ufkZ5/qU961zErTbs+kM7RKHP2fZc0dd4p2c+7JDvVdqqnph0MO+Wcw1V+j5vDxDs2p0KlVnNHOjpx+GgHUR5qwwmDCREhijm3B/OeS7jwoQehCI9k8jISiWRDIoJAkpcX4Xa7OYW2+0WuRaPDQkQga2tr+PHWLdy5u4FffruNX2+vs/jnnbtIbW1hM5XC5maNVGoLGxub2Nl5gK+/+ZZ4F3yYn6eGuu5ervlQO65+/gUBXZIk4f+uarXK4urqKgkEQzVDrU7PPfZEEz757AozzGQy7ODe3h6jUpZApAp2aSd/rK8zHuzch1QpI5vNMsOVle+J/19DPTVsehKfXrnKDOVDhDCJfLGKe38VUMtnsL29zQoWi0VWNJfPs73rN74jFz1eeL3exobVuuG93Qx++j1dN3+EdHrfTGJXk8vl2N7yzZvEFwhi3t2wwxwqdER5pbZ38cPP95ErVFEslVEqlRjlcoXGv1Eo1LpfoYb+YLDxyGV6N6RKUCoUkc2kGelcAdl8jnb3iBbM07HzdNwiKpVa4eXlZeLzB+od0pfyePNTSHz0MaFvAQ8f7rLKeXo/hUINWcvIIzJNcyU6uvxcqUhYWloi/v2RW+mH3dqmwdHnukhXTy8s4xOIJxIIhkII0DECgQBCVIfDYXgueRGiMRKJIEzZzweDQRKLJ8Bxc9RQpeZUGi2oKWk+0IpXjw8jTjejsRhisShiUQrTMfA8D14QwFOzKM0LVMvE43GSXFyEUzZUqtSzqsPtoJADz6pxfPQ1Wp1HhJcR6tSeZTO5M7n7MOuS349E/l1nXC6XoungwSMtSuUUxdbc0mLTdXbazGarzWg0N8Zc5z95k+nklMlk0v4DHk0h6/+inr4AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/d23418eba659685e2cc61bde868ee87b/0b148/smp-in-meshery.png","srcSet":"/static/d23418eba659685e2cc61bde868ee87b/97226/smp-in-meshery.png 750w,\n/static/d23418eba659685e2cc61bde868ee87b/3afb7/smp-in-meshery.png 1080w,\n/static/d23418eba659685e2cc61bde868ee87b/f8157/smp-in-meshery.png 1366w,\n/static/d23418eba659685e2cc61bde868ee87b/0b148/smp-in-meshery.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/d23418eba659685e2cc61bde868ee87b/379db/smp-in-meshery.webp 750w,\n/static/d23418eba659685e2cc61bde868ee87b/2a0e5/smp-in-meshery.webp 1080w,\n/static/d23418eba659685e2cc61bde868ee87b/c5b39/smp-in-meshery.webp 1366w,\n/static/d23418eba659685e2cc61bde868ee87b/b89d9/smp-in-meshery.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.8052083333333334}},"extension":"png","publicURL":"/static/d23418eba659685e2cc61bde868ee87b/smp-in-meshery.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAADiUlEQVR42o2T309bZRjHa7wQlNgN68pKt1IMoggRZTAYtqVrhahzjoYuUyZtD5Kx2o7+Pqe/hibqdmW82bnRK3XJIpcM+QO8dUQTjUNdBiVLZGz0d117+vL1PW+LF6YXvsknz/c875vv8zzvOUdhnHQOGh3uLwdmFq4NTHvEIYdPHObCYq/1tPjCsFF85eQb4sibk+Ix6ymxb2yC5V6emBQNF2Oi4YIgDjn94qDDd+3YzMJX/WfnBhXq/oHZLsMY+g0W0jc6Bv2gAd2WM+i1nIZu2IKOkdehHx1Hx4lx6KjWjViZ7jSdYnSNvY0e65lqz1t2aIfMnEKpUbva9HqoNe3lp1ufkZ5/qU961zErTbs+kM7RKHP2fZc0dd4p2c+7JDvVdqqnph0MO+Wcw1V+j5vDxDs2p0KlVnNHOjpx+GgHUR5qwwmDCREhijm3B/OeS7jwoQehCI9k8jISiWRDIoJAkpcX4Xa7OYW2+0WuRaPDQkQga2tr+PHWLdy5u4FffruNX2+vs/jnnbtIbW1hM5XC5maNVGoLGxub2Nl5gK+/+ZZ4F3yYn6eGuu5ervlQO65+/gUBXZIk4f+uarXK4urqKgkEQzVDrU7PPfZEEz757AozzGQy7ODe3h6jUpZApAp2aSd/rK8zHuzch1QpI5vNMsOVle+J/19DPTVsehKfXrnKDOVDhDCJfLGKe38VUMtnsL29zQoWi0VWNJfPs73rN74jFz1eeL3exobVuuG93Qx++j1dN3+EdHrfTGJXk8vl2N7yzZvEFwhi3t2wwxwqdER5pbZ38cPP95ErVFEslVEqlRjlcoXGv1Eo1LpfoYb+YLDxyGV6N6RKUCoUkc2kGelcAdl8jnb3iBbM07HzdNwiKpVa4eXlZeLzB+od0pfyePNTSHz0MaFvAQ8f7rLKeXo/hUINWcvIIzJNcyU6uvxcqUhYWloi/v2RW+mH3dqmwdHnukhXTy8s4xOIJxIIhkII0DECgQBCVIfDYXgueRGiMRKJIEzZzweDQRKLJ8Bxc9RQpeZUGi2oKWk+0IpXjw8jTjejsRhisShiUQrTMfA8D14QwFOzKM0LVMvE43GSXFyEUzZUqtSzqsPtoJADz6pxfPQ1Wp1HhJcR6tSeZTO5M7n7MOuS349E/l1nXC6XoungwSMtSuUUxdbc0mLTdXbazGarzWg0N8Zc5z95k+nklMlk0v4DHk0h6/+inr4AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/d23418eba659685e2cc61bde868ee87b/0b148/smp-in-meshery.png","srcSet":"/static/d23418eba659685e2cc61bde868ee87b/97226/smp-in-meshery.png 750w,\n/static/d23418eba659685e2cc61bde868ee87b/3afb7/smp-in-meshery.png 1080w,\n/static/d23418eba659685e2cc61bde868ee87b/f8157/smp-in-meshery.png 1366w,\n/static/d23418eba659685e2cc61bde868ee87b/0b148/smp-in-meshery.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/d23418eba659685e2cc61bde868ee87b/379db/smp-in-meshery.webp 750w,\n/static/d23418eba659685e2cc61bde868ee87b/2a0e5/smp-in-meshery.webp 1080w,\n/static/d23418eba659685e2cc61bde868ee87b/c5b39/smp-in-meshery.webp 1366w,\n/static/d23418eba659685e2cc61bde868ee87b/b89d9/smp-in-meshery.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.8052083333333334}},"extension":"png","publicURL":"/static/d23418eba659685e2cc61bde868ee87b/smp-in-meshery.png"}},"fields":{"slug":"/company/news/cncf-adopts-service-mesh-performance-standard-established-by-layer5"}},{"id":"66aed892-af50-5d83-ad6d-4dfe1659fb22","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Differences from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\nMany emerging technologies are based on or reincarnated from prior thinking and approaches to computing and networking paradigms. Why is this phenomenon required? We'll look to the microservices and containers movement for service meshes, a cloud-native approach to design scalable, independently supplied services. What was previously internal application communications have become a mesh of service-to-service remote procedure calls (RPCs) transported via networks thanks to microservices. Microservices democratize language and technology choice across independent service teams that generate new features quickly as they iteratively and continuously provide software(typically as a service). The most crucial driver of microservices as an architectural model is the decoupling of engineering teams and their enhanced speed.\n\n### Operating Many Services\n\nThe initial couple of microservices are relatively simple to deliver and operate‚Äîat least in comparison to organizations' challenges when they first use many microservices. Whether that \"many\" is three or one hundred, a major technological issue will inevitably arise. To relieve microservices headaches, several remedies are prescribed; one notable example is the use of client libraries. In microservices environments, language and framework-specific client libraries, whether pre-existing or generated, are utilized to address distributed systems challenges. Many teams first explore their path to a service mesh in these situations. The sheer volume of services that must be managed on an individual, distributed basis (rather than centrally as with monoliths) and the challenges of ensuring their reliability, observability, and security cannot be met with outmoded paradigms, necessitating the need to reincarnate prior thinking and approaches. It is necessary to adapt new tools and techniques.\n\nSince microservices are distributed (often ephemeral) by nature, and the network is critical to their functioning, we should consider the fallacy that networks are reliable, have no latency, have infinite bandwidth, and that communication is guaranteed. When you consider how important it is to be able to control and secure service communication in distributed systems that rely on network calls with every transaction, every time an application is invoked, you can see why you are under tooled and why running more than a few microservices on a network topology that is in constant flux is so difficult. In the age of microservices, a new layer of tooling for the caretaking of services is needed‚Äîa service mesh is needed.\n\n### What Is a Service Mesh?\n\nService meshes provide intent-based networking for microservices describing desired behavior of the network in the face of constantly changing conditions and network topology. At their core, service meshes provide:\n\n- A services-first network;\n- A developer-driven network;\n- A network that is primarily concerned with alleviating application developers from building infrastructure concerns into their application code; \n- A network that empowers operators with the ability to declaratively define network behavior, node identity, and traffic flow through policy; \n- A network that enables service owners to control application logic without engaging developers to change its code.\n\nValue derived from the layer of tooling that service meshes provide is most evident in the land of microservices. The more services, the more value derived from the mesh. In subsequent chapters, I show how service meshes provide value outside of the use of microservices and containers and help modernize existing services (running on virtual or bare metal servers) as well.\n\nMany of you will find yourself working in organizations that have more than one sort of service mesh. Diversity is driven by a broad set of workload requirements varying from process-based to event-driven in their design, from those running on bare metal to executing in functions and those representing every style of deployment artifact in-between. The scope of service mesh capability required by different organizations varies. As a result, different service meshes are created with slightly different use cases in mind, resulting in differences in service mesh architecture and deployment models. Service meshes, which are driven by Cloud, Hybrid, On-Prem, and Edge, can enable each of these. With the requirements of different edge devices and their functions, along with ephemeral cloud-based workloads, microservice patterns and technologies give a plethora of opportunities for service mesh differentiation and specialization. Cloud vendors produce and collaborate as they provide service mesh as a managed service on their platforms.\n\n  <div className=\"center\" >\n  <img src={Differences} align=\"center\" alt=\"comparative spectrum\" />\n  \nFigure 1: A comparative spectrum of the difference between some of the service meshes based on their individual strengths.\n  </div>\n\nThe demand for service meshes, including meshes native to specific cloud platforms, is growing in tandem with the number of microservices. As a result, many enterprises now use various service mesh products, either separately or together.\n\n### Service Mesh Abstractions\n\nBecause there are any number of service meshes available, independent specifications have cropped up to provide abstraction and standardization across them. Three service mesh abstractions exist today:\n\n- <Link to=\"/projects/cloud-native-performance\">Service Mesh Performance</Link> (SMP) is a format for describing and capturing service mesh performance. Created by Layer5; Meshery is the canonical implementation of this specification.\n- Multi-Vendor Service Mesh Interoperation (Hamlet) is a set of API standards for enabling service mesh federation. Created by VMware.\n- <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface</Link> (SMI) is a standard interface for service meshes on Kubernetes. Created by Microsoft; Meshery is the official SMI conformance tool used to ensure that a cluster is properly configured and that its behavior conforms to official SMI specifications.\n\n### Service Mesh Landscape\n\nLet's start characterizing different service meshes now that we better understand why we live in a multi-mesh world. Some service meshes support non-containerized workloads (services operating on a VM or on bare metal), while others specialize in layering on top of container orchestrators, such as Kubernetes. All service meshes support integration with service discovery systems. The subsections that follow provide a very brief survey of service mesh offerings within the current technology landscape.\n\n<div className=\"fact-left\">\n\nSee the Layer5 <Link to=\"/service-mesh-landscape\">service mesh landscape</Link> for a comprehensive overview and characterizing of all of the service meshes, service proxies, and related tools available today. This landscape is community-maintained and places service meshes in contrast with one another so that the reader might make the most informed decision about which service mesh best suits their needs.\n\n</div>\n\n### Why Do I Need One?\n\n\"I have a container orchestrator; why do I need another infrastructure layer?\" you might wonder. Container orchestrators provide most of what the cluster (nodes and containers) requires.¬† Container orchestrators' primary focus is on scheduling, discovery, and health, mainly at the infrastructure level (networking being a Layer 4 and below focus). As a result, microservices have unmet service-level¬†needs. A service mesh is a specialized infrastructure layer that makes service-to-service communication safe, fast, and reliable. Its operation is typically based on a container orchestrator or integration¬†with another service discovery system. Although service meshes are frequently deployed as a separate layer on top of container orchestrators, they do¬†not require one¬†because control and data plane components could be deployed independently of containerized infrastructure.\n\nAs stated previously, the network is directly and critically involved in every transaction, every execution of business logic, and every request made to the application in microservices deployments. For modern, cloud-native applications, network stability and latency are top priorities. A cloud native application may be made up of hundreds of microservices, each of which could have several instances, and each of those ephemeral instances could be rescheduled by a container orchestrator as needed.\n\nWhat would you want from a network that connects your microservices, given the network's criticality? You want your network to be as intelligent and resilient as possible. To improve the aggregate reliability¬†of your cluster, you want your network to route traffic around from¬†failures. You want to avoid overhead¬†like high-latency routes or servers with cold caches in your network. You want your network to protect the traffic that flows between services against trivial attacks. You want your network to provide insight into service communication failures by exposing unforeseen dependencies and root causes. You want your network to let you impose policies at the granularity of service behaviors, not just at the connection level. You also don‚Äôt want to write all this logic into your application.\n\nYou want Layer 5 management. You want a services-first network. You want a service mesh!\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh Fundamentals","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/service-mesh-fundamentals"}},{"id":"69ed0e3c-9a02-52ec-a145-d0e586e51424","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Planes from \"./figure1.webp\";\nimport Topology from \"./figure2.webp\";\nimport Architecture from \"./figure3.webp\";\nimport Meshery from \"./figure4.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<p>\nService mesh architectures typically consist of three planes: a management plane, a control plane, and a data plane. The analogy between how physical networks (and their equipment) are designed and managed along with¬†the concept of these three planes immediately resonates with network engineers.¬†\nThe OSI model is another type of training that network engineers receive. For those who haven't seen the OSI model in a while, Figure 1 serves as a refresher.\n</p>\n\n <div className=\"right\" >\n  <img src={Planes} align=\"right\" alt=\"Network Planes\" />\n  <p>Figure 1: Physical networking versus software-defined networking planes</p>\n </div>\n\n<p>Let‚Äôs contrast physical networking planes and network topologies with those of service meshes:</p>\n\n<h3>Physical network planes</h3>\n\n<p>\nThe application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). A forwarding information base (FIB) is a basic, dynamic table that maps a media access control address (MAC address) to a physical network port, allowing traffic to be transmitted at wire speed (using ASICs) to the next device.\n</p>\n\n<p>\nThe physical networking control plane is the¬†logical entity that is linked to router processes and functions and is responsible for generating and maintaining necessary intelligence about the state of the network (topology) and the router's interfaces. The control plane includes network protocols, such as routing, signaling, and link-state protocols that are used to build and maintain the operational state of the network and provide IP connectivity between IP hosts.¬†¬† As physical network control planes run in-band with network traffic, they are vulnerable to Denial of service (DoS) attacks, which can result in:\n</p>\n\n<ul>\n  <li>Exhaustion of memory and/or buffer resources.</li>\n  <li>Loss of routing protocol updates and keepalives.</li>\n  <li>Slow or blocked access to interactive management sessions.</li>\n  <li>High CPU utilization.</li>\n  <li>Routing instability, interrupted network reachability, or inconsistent packet delivery.</li>\n</ul>\n\n<p>\nThe physical networking management plane is a logical entity that specifies the traffic used to access, manage, and monitor all network elements via protocols such as SNMP, SSH, HTTPS, and¬†Telnet. All network provisioning, maintenance, and monitoring operations are supported by the management plane. Although control plane network traffic is handled in-band with all other data plane traffic, management plane traffic¬†can be carried over an out-of-band (OOB) management network to enable separate reachability if the primary in-band IP path is unavailable (and create a security boundary). Restricting management plane access to devices on trusted networks is critical.\n</p>\n\n<p>\nPhysical networking control and data planes are tightly coupled and generally vendor-provided as a proprietary integration of hardware and firmware. Software-defined networking (SDN) has done much to standardize and decouple. OpenvSwitch and OpenDaylight are two examples of SDN projects. We‚Äôll see that control and data planes of service meshes are not necessarily tightly coupled.\n</p>\n\n  <div className=\"left\" >\n  <img src={Topology} align=\"right\" alt=\"Mesh Topology\" />\n  <p>Figure 2: Mesh topology‚Äîfully connected network nodes</p>\n  </div>\n\n<h3>Physical network topologies</h3>\n\n<p>\nStar, spoke-and-hub, tree (also called¬†hierarchical), and mesh are some of the most used physical networking topologies. Nodes in mesh networks connect directly and non-hierarchically, such that each node is connected to an indefinite number (typically as many as possible or as needed dynamically) of neighbour nodes, allowing at least one path from a given node to any other node to route data efficiently .\n</p>\n\n<p>\nWireless is the canonical use case for physical mesh networks in which the networking medium is sensitive to line-of-sight, weather-induced, or other disruptions, and so reliability is a top priority. Mesh networks typically self-configure, allowing¬†dynamic task distribution. This ability is especially important to mitigate¬†the risk of failure (improving resiliency) and reacting to continuously changing topologies. It's easy to see why this network topology¬†is the preferred design for service mesh architectures.\n</p>\n\n<h3>Service mesh network planes</h3>\n\n<p>Service mesh architectures typically employ the same three networking planes: data, control, and management. </p>\n\n<div className=\"right\" >\n<img src={Architecture} align=\"right\" alt=\"Service mesh architecture\" />\n<p>Figure 3: An example of service mesh architecture. In Conduit‚Äôs architecture, control and data planes divide in-band and out-of-band responsibility for service traffic</p>\n</div>\n\n<p>\nA service mesh data plane (also known as the proxying layer) intercepts all packets in a request and performs health checks, routing, load balancing, authentication, authorization, and generation of observable signals. Service proxies are transparently inserted, and applications are oblivious of the data plane's existence when they conduct service-to-service calls. Intra-service communication, as well as inbound (ingress) and outbound (egress) service mesh traffic, are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling prior to sending (or not sending) along to the application.¬† Traffic is transparently intercepted and redirected to the service proxy in order to reroute traffic from the service proxy to the service application. The service proxy intercepts and redirects traffic between¬†the service proxy and service application places the service application‚Äôs container onto a network it would otherwise not be on.¬†All traffic to and from the service application is seen by the service proxy.¬† Service proxies are the building blocks of service mesh data planes.\n</p>\n\n<div className=\"fact\">\nTraffic Interception and Redirection:\n<p>The technology utilised to intercept and redirect traffic varies between service meshes. Some meshes allow you the option of using iptables, IPVS, or eBPF to transparently proxy requests between clients and service applications. Other service mesh proxies operate in a less transparent manner, requiring application traffic to be configured to direct their traffic to the proxy. The operating system type and kernel version used for the service mesh deployment are constrained by the choice of each of these technologies, which influences the speed with which packets are processed.</p>\n</div>\n\n<p>\nEnvoy is one of the most widely used proxy in service mesh data planes. It's also common to see it deployed¬†as a load balancer or ingress gateway. The proxies used in service mesh data planes are highly intelligent.¬† In order to manipulate network packets¬†(including application level data), they¬†may include any number of protocol-specific filters . Extending data plane capabilities with technology advancements like WebAssembly allows service meshes to inject additional logic into requests while simultaneously handling large traffic loads.\n</p>\n\n<p>\nWhen the number of proxies becomes unmanageable or when a single point of visibility and control is required, a service mesh control plane is essential. Control planes offer policy and configuration for the services in the mesh, transforming a set of isolated, stateless proxies into a service mesh. Control planes run out-of-band and do not directly touch any network packets in the mesh. Control planes usually include a command-line interface (CLI) and a user interface to interact with, both of which provide access to a centralised API for regulating proxy behaviour holistically.¬†You can use the control plane's APIs to automate changes to its configuration (for example, using a continuous integration/continuous deployment pipeline), where configuration is generally version controlled and updated.\n</p>\n\n<div className=\"fact\">\n  Proxies are generally considered stateless, but this is a thought-provoking concept. In the way in which proxies are generally informed by the control plane of the presence of services, mesh topology updates, traffic and authorization policy, and so on, proxies cache the state of the mesh but aren‚Äôt regarded as the source of truth for the state of the mesh.\n</div>\n\n<p>\n  We can see how the data and control planes are packaged and deployed in Linkerd (pronounced \"linker-dee\") and Istio (pronounced \"Ist-tee-oh\"), two prominent open source service meshes. In terms of packaging, Linkerdv1 contains both its proxying components (linkerd) and its control plane (namerd) packaged together simply as ‚ÄúLinkerd,‚Äù and Istio brings a collection of control plane components (Galley, Pilot, and Citadel) to pair by default with Envoy (a data plane) packaged together as ‚ÄúIstio.‚Äù Envoy is often labeled a service mesh, inappropriately so, because it takes packaging with a control plane to form a service mesh. \n</p>\n\n<p>\n  A service mesh management plane is a higher order level of control as shown in Figure 4. A management plane may provide a variety of functions. As such, implementations vary in their functionality: some focusing on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, providing insight across a collection of diverse meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.\n</p>\n\n  <div className=\"left\" >\n  <img src={Meshery} align=\"right\" alt=\"Meshery\" />\n  <p>Figure 4: Meshery, the cloud native management plane‚Äôs architecture.</p>\n  </div>\n  \n<p>\nA service mesh management plane is a higher order level of control. A management plane can provide¬†various functions. As a result, implementations differ in functionality, with some focused on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, which provides insight across a set of meshes.¬†Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.\n</p>\n\n<p>\nIn terms of deployments, data planes, such as Linkerdv2, contain proxies that are created as part of the project and are not designed to be configured by hand, but rather to have their behaviour completely controlled by the control plane. Other service meshes, such as Istio, prefer not to develop their own proxy and instead ingest and utilise independent proxies (separate projects), simplifying proxy selection and deployment outside of the mesh(standalone). Control planes are often deployed in a separate \"system\" namespace,¬†using¬†Kubernetes as the example infrastructure. Depending on how closely they integrate with non-containerized workloads and a business's backend systems, management planes are deployed both on and off cluster.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Service Mesh Architecture and Components","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAACwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJZwDA3BrR9Xt/P25pgAD+9hOmVk+abt1tHkl3ma3Uj4FzlaUBYXhUB46QVek8w/FQwowWf4bDOrGt2cgz076DS6IIMQQusskVT7huWtpcwAAA"},"images":{"fallback":{"src":"/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp","srcSet":"/static/31130b77471902ca1778529343876be1/eb15a/figure2.webp 750w,\n/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp 981w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6442405708460754}},"extension":"webp","publicURL":"/static/31130b77471902ca1778529343876be1/figure2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAACwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJZwDA3BrR9Xt/P25pgAD+9hOmVk+abt1tHkl3ma3Uj4FzlaUBYXhUB46QVek8w/FQwowWf4bDOrGt2cgz076DS6IIMQQusskVT7huWtpcwAAA"},"images":{"fallback":{"src":"/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp","srcSet":"/static/31130b77471902ca1778529343876be1/eb15a/figure2.webp 750w,\n/static/31130b77471902ca1778529343876be1/fc3f3/figure2.webp 981w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6442405708460754}},"extension":"webp","publicURL":"/static/31130b77471902ca1778529343876be1/figure2.webp"}},"fields":{"slug":"/resources/service-mesh/service-mesh-architecture-and-components"}},{"id":"6c707281-4d7e-5605-aea8-0c70e1869079","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n## Data Plane\n\nService proxies (gateways) are elements of the data plane. The number of proxies present depends on the number of services you‚Äôre running and the design of the service mesh‚Äôs deployment model. Some service mesh initiatives create their own proxies, while others rely on existing ones. Envoy is a popular choice as the data plane element.\n\n**BFE**\n\n<a href=\"https://github.com/bfenetworks/bfe\">BFE</a> is a Golang-based modern proxy. HTTP, HTTPS, SPDY, HTTP2, WebSocket, TLS, and FastCGI are among the load balancing algorithms and multiple protocols it supports. Users can configure rule and content-based routing using BFE's own domain-specific language.\n\n**Envoy**\n\nEnvoy is a modern proxy developed in C++. Envoy's initial success stemmed from its ability to hot-reload both its configuration and itself (update itself in place while handling connections). API gateways, ingress controllers, service meshes, and managed offerings by Cloud providers are just a few of the projects that have been built on top of Envoy. Istio, App Mesh, Kuma, Open Service Mesh, and other service meshes (discussed in the Control Plane section) have been built on top of Envoy.\n\n**Linkerdv2**\n\nThe linkerd2-proxy is explicitly built for the service mesh sidecar use case, Linkerd, can be significantly smaller and faster than Envoy-based service meshes. Rust was chosen as the implementation language because it is memory-safe and highly performant. This service proxy purports a sub-1ms p99 traffic latency. Open-source.  From Buoyant.\n\n**NGINX**\n\n<a href=\"https://github.com/nginxinc/nginmesh\">nginMesh</a> project deploys NGINX as a sidecar proxy in Istio. Open source. Written primarily in C and Rust. From NGINX.\n\nThe following are a couple of early, and now antiquated, service mesh‚Äìlike projects, forming control planes around existing load-balancers:\n\n**SmartStack**\n\nComprising two components: Nerve for health-checking and Synapse for service discovery. Open source. From AirBnB. Written in Ruby.\n\n**Nelson**\n\nTakes advantage of integrations with Envoy, Prometheus, Vault, and Nomad to provide Git-centric, developer-driven deployments with automated build-and-release workflow. Open source. From Verizon Labs. Written in Scala.\n\n## Control Plane\n\n**Consul**\n\nAnnounced service mesh capable intention in v1.5. Became a full service mesh in v1.8. Consul uses Envoy as its dataplane, offering multi-cluster federation.\nOpen and closed source. From HashiCorp. Primarily written in Go.\n\n**Linkerd**\n\nLinkerd is hosted by the Cloud Native Computing Foundation (CNCF) and has undergone two major releases with significant architectural changes and an entirely different code base used between the two versions.\n\n**Linkerdv1**\n\nThe first version of Linkerd was built on top of Twitter Finagle. Pronounced ‚Äúlinker-dee‚Äù, it includes both a proxying data plane and control plane, Namerd (‚Äúnamer-dee‚Äù), all in one package.\nOpen source. Written primarily in Scala.\n\n- Data plane can be deployed in a node proxy model (commonly)  or in a proxy sidecar (not common). Proven scale, having served more than one trillion service requests.\n- Supports services running within container orchestrators and as standalone virtual or physical machines.\n- Service discovery abstractions to unite multiple systems.\n\n**Linkerdv2**\n\nThe second major version of Linkerd is based on a project formerly known as Conduit, a Kubernetes-native and Kubernetes-only service mesh announced as a project in December 2017. In contrast to Istio and in learning from Linkerdv1, Linkerdv2‚Äôs design principles revolve around a minimalist architecture and zero configuration philosophy, optimizing for streamlined setup.\n\n- Open Source. From Buoyant. Control-plane written in Go. Hosted by the CNCF.\n- Support for gRPC, HTTP/2, and HTTP/1.x requests plus all TCP traffic. Currently only supports Kubernetes.\n\n**Istio**\n\nAnnounced as a project in May 2017, Istio is considered to be a ‚Äúsecond explosion after Kubernetes‚Äù given its architecture and surface area of functional aspiration.\n\n- Supports services running within container orchestrators and as standalone virtual or physical machines.\n- Was the first service mesh to promote the model of supporting automatic injection of service proxies as sidecars using Kubernetes Admission controller.\n- Many projects have been built around Istio. Commercial, closed source offerings built around Istio include: AspenMesh, VMware Tanzu Service Mesh, Octarine (acquired by VMware in 2020).\nCommercial, closed source offerings built inside of Istio include Citrix Service Mesh To be built ‚Äúwithin Istio‚Äù means to offer the Istio control plane with an alternative service proxy. Citrix Service Mesh displaces Envoy with CPX. \nOpen source, data plane proxy, MOSN released support for running under Istio as the control plane, while displacing Envoy as the service proxy.\n- Many projects have been built within Istio.\n- Mesher. Layer 7 (L7) proxy that runs as a sidecar deployable on Huawei Cloud Service Engine. Open source. Written primarily in Go. From Huawei.\n\n**NGINX Service Mesh**\n\nNGINX Service Mesh is a more recent arrival into the service mesh arena, having released in September 2020. Using an Nginx Plus augmented to interface with Kubernetes natively as its dataplane, supports ingress and egress gateways through NGINX Plus Kubernetes Ingress Controllers. NGINX Service Mesh offers its control plane as a CLI, meshctl, using the Service Mesh Interface (SMI) specification as its API. \nBoth Open and closed source. From NGINX. Primarily written in C.\n\n**Others including Open Service Mesh, Maesh, Kuma, App Mesh...**\n\nThis list is meant to give you an idea of the wide range of service meshes that are currently available. A complete list of service meshes and their details may be found in the Layer5 <Link to=\"/landscape\">service mesh landscape</Link>, maintained by the community.\n\n## Management Plane\n\nThe management plane sits a level above the control plane. It can perform various tasks such as operational patterns, business system integration, and application logic enhancement while functioning across different service meshes. A management plane can perform workload and mesh configuration validation, whether in preparation for onboarding a workload into the mesh or as you upgrade to new versions of components running your control and data planes or new versions of your applications. Management planes help organizations running a service mesh get the most out of their investment. Performance management is one part of maintaining service meshes, a function at which Meshery excels. \n\n**Meshery**\n\nthe cloud native management plane for adopting, operating and developing on different service meshes. Meshery integrates business processes and application logic into service meshes by deploying custom WebAssembly (WASM) modules as filters in Envoy-based data planes. It provides governance, policy and performance and configuration management of service meshes with a visual topology for designing service mesh deployments and managing the fine-grained traffic control of a service mesh. \n- Open source. Created by Layer5. Primarily written in Go.\n\n<div className=\"fact\">\nCloud Native Linguistics\n\nAs the lingua franca of the cloud-native ecosystem, Go is certainly prevalent and you might expect most projects to be written in Go. By the nature of their task, data planes must be highly efficient in the interception, introspection, and rewriting of network traffic. As a data plane component, Envoy is written in C++11 because it provides excellent performance (surprisingly, some say it provides a great developer experience). Rust has found its way into service meshes as a growing language (and something of a C++ competitor). Because of its properties around efficiency (outperforming Go) and memory safety (when written to be so) without garbage collection, Rust has been used for Linkerdv2‚Äôs data plane component, for the former nginMesh‚Äôs Mixer module (see ‚ÄúHow to customize an Istio service mesh‚Äù), and is now being used in WebAssembly programs as data plane filters (see ‚ÄúWrite WASM filters for Envoy in Rust and deploy with Consul‚Äù).\n</div>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Network Planes","type":"Article","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRn4AAABXRUJQVlA4IHIAAAAQBACdASoUAA4APtFUo0uoJKMhsAgBABoJYwCdACG/20zLpOrRzp1pAAD+64UofulJnwob3V1z7pVQLm83y8IJL2P9n6OeIYHPEGjQ7RW28lChlIv756RQsITjxgIPKXo+hXEB9JrFPstG98qGK+sQAAA="},"images":{"fallback":{"src":"/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp","srcSet":"/static/e4a8a3456e3bf7e3eab6615f593cc287/f03b4/network-planes.webp 750w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/2e49b/network-planes.webp 1080w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp 1272w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6761006289308176}},"extension":"webp","publicURL":"/static/e4a8a3456e3bf7e3eab6615f593cc287/network-planes.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRn4AAABXRUJQVlA4IHIAAAAQBACdASoUAA4APtFUo0uoJKMhsAgBABoJYwCdACG/20zLpOrRzp1pAAD+64UofulJnwob3V1z7pVQLm83y8IJL2P9n6OeIYHPEGjQ7RW28lChlIv756RQsITjxgIPKXo+hXEB9JrFPstG98qGK+sQAAA="},"images":{"fallback":{"src":"/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp","srcSet":"/static/e4a8a3456e3bf7e3eab6615f593cc287/f03b4/network-planes.webp 750w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/2e49b/network-planes.webp 1080w,\n/static/e4a8a3456e3bf7e3eab6615f593cc287/11b08/network-planes.webp 1272w","sizes":"100vw"},"sources":[]},"width":1,"height":0.6761006289308176}},"extension":"webp","publicURL":"/static/e4a8a3456e3bf7e3eab6615f593cc287/network-planes.webp"}},"fields":{"slug":"/resources/network-planes/network-planes"}},{"id":"44f6283d-2e84-5856-9fca-f4c479fcb658","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Stakeholders from \"./figure1.webp\";\nimport Graph from \"./citrix-architectures-for-kubernetes-environments.svg\";\nimport TwoTier from \"./citrix-two-tier-ingress.svg\";\nimport Unified from \"./citrix-unified-ingress.svg\";\nimport Servicemesh from \"./citrix-service-mesh.svg\";\nimport Servicemeshlite from \"./citrix-service-mesh-lite.svg\";\nimport Comparison from \"./citrix-oss-integration-categories.svg\";\n\n\n<ResourcesWrapper>\n\n<h2>The Role of Application Delivery in Your Cloud Native Journey</h2>\n<p>\n    As digital transformation is changing how your organization conducts business, so is it changing how your products and services are delivered. The infrastructure and practices by which your software is continuously deployed and operated ‚Äî your application delivery ‚Äî is the fulcrum of your organization‚Äôs digital transformation. Likely you are progressing on your cloud native journey ‚Äî that is, transitioning from monolithic to container-based microservices architectures with the goal of achieving agility, portability, and on-demand scalability. Kubernetes is the platform of choice for many, providing the automation and control necessary to manage microservices-based applications at scale and with high velocity. \n</p>\n<p>\n    With the network part and parcel to each and every service request in your microservices-based application, it may come as no surprise that at the core of application delivery is your application delivery controller, an intelligent proxy that accelerates and manages application delivery. With no standard definition of what an application delivery controller does, the capabilities of intelligent proxies vary broadly. And so in this white paper, we‚Äôll explore application delivery controllers as they relate to your architecture choices, your use of Kubernetes platforms, and open source tools. \n</p>\n\n<h2>7 Key Considerations for Microservices-Based Application Delivery</h2>\n<p>\n    Before embarking on your cloud native journey, it is essential to critically assess your organization‚Äôs readiness with regard to skill set so that you can choose the solutions that best fit the business objective you are seeking to meet in context of your ability to do so. There are seven key considerations to address when planning your microservices-based application delivery design:\n</p>\n<ol>\n<li>Architecting your foundation the right way </li>\n<li>Openly integrating with the cloud native ecosystem</li>\n<li>Choosing the perfect proxy</li>\n<li>Securing your applications and APIs</li>\n<li>Enabling CI/CD and canary deployment with advanced traffic steering </li>\n<li>Achieving holistic observability</li>\n<li>Managing monoliths and microservices</li>\n</ol>\n<p>\nA thorough evaluation of these seven considerations is best done with specific tasks and goals in mind. Depending on the size and diversity of your organization, you may need to account for a variety of stakeholders‚Äô needs ‚Äî that is, tasks and goals that differ based on role and responsibility. In context of application delivery, let‚Äôs survey the most common roles with a generalized view of their responsibilities and needs as stakeholders. To help facilitate a general understanding, we‚Äôve grouped some roles when responsibilities overlap across multiple teams:\n</p>\n\n<ul>\n    <li>\n        <h3>Platform</h3>\n        <p>\n            Platform teams are responsible for deploying and managing their Kubernetes infrastructure. They are responsible for platform governance, operational efficiency, and developer agility. The platform team is the connective tissue among various teams like DevOps, SREs, developers, and network operations teams and therefore must address and balance the unique needs of a diverse group of stakeholders, or influencers, when choosing cloud native solutions. \n        </p>    \n    </li>\n    <li>\n        <h3>DevOps</h3>\n        <p>\n             DevOps teams are responsible for continuously deploying applications. They care about faster development and release cycles, CI/CD and automation, and canary and progressive rollout.\n        </p>    \n    </li>\n    <li>\n        <h3>SREs</h3>\n        <p>\n             Site reliability engineers must ensure application availability. They care about observability, incident response, and postmortems. SREs often act as architects for DevOps team and as such are often extensions of or directly belong to DevOps teams.\n        </p>    \n    </li>\n    <li>\n        <h3>Developers</h3>\n        <p>\n             Development teams are responsible for application performance and are focused on ensuring a seamless end-user experience, including troubleshooting and microservices discovery and routing. Application performance and troubleshooting is shared responsibility among multiple teams.\n        </p>    \n    </li>\n    <li>\n        <h3>NetOps </h3>\n        <p>\n             Network operations teams are responsible for ensuring stable, high-performing network connectivity, resiliency, security (e.g. web application firewalls and TLS), and are commonly focused on north-south traffic. They care about establishing networking policies and enforcing compliance; achieving management, control, and monitoring of the network; and gaining visibility for the purpose of resources and capacity planning.\n        </p>    \n    </li>\n    <li>\n        <h3>DevSecOps</h3>\n        <p>\n             DevSecOps teams care about ensuring a strong security posture and rely on automated tools to orchestrate security for infrastructure, applications, containers, and API gateways. DevSecOps works very closley with NetOps team for holistic secure posture. \n        </p>    \n    </li>\n</ul>\n  <div className=\"center\" >\n  <img src={Stakeholders} align=\"center\" alt=\"Diverse Stakeholders have different needs\" />\n  </div>\n\n<p>\nEach role has nuanced responsibilities. Whether you have a single person or teams of people assigned to these roles, each role‚Äôs function needs to be accounted for. \n</p>\n<p>\nIt‚Äôs important to note that these stakeholders are undergoing a transformation in their responsibilities ‚Äî or at least a transformation in the way in which they perform their responsibilities. Depending upon your organization‚Äôs size and structure, your stakeholders may have clearly defined lines of accountability or not among roles. As you adopt a cloud native approach to application deployment and delivery, you may find that the once-defined lines have blurred or that they are being redrawn. Be aware that the individuals who fill these roles typically go through a period of adjustment that can be unsettling until they adapt to their own and their teams‚Äô new identities.\n</p>\n<p>\nYour cloud native infrastructure should be as accommodating as possible to you, your team, and your collective responsibilities and process, so we encourage you to seek solutions that address the needs of all your stakeholders. Significantly, this includes evaluating different architectural models for as best fit for purpose. While every organization doesn‚Äôt travel the same road to cloud native, every journey starts with initial architectural decisions ‚Äì decisions which have substantial bearing on your path to cloud native. \n</p>\n\n<h2>Architecting Your Foundation the Right Way</h2>\n<p>\nCloud native novices and experts alike find that designing their application delivery architectures is the most challenging part of building microservices. Your architectural choices will have a significant impact on your cloud native journey. Some architectures will provide greater or fewer benefits while others will prove less or more difficult to implement. \n</p>\n<p>\nWhether you are a cloud native pro or a novice, your selection of the right application delivery architecture will be one that balances the tradeoff between the greatest benefits and the simplicity needed to match your team‚Äôs skill set. Figure 1 highlights four common application delivery architecture deployment models:\n</p>\n\n  <div className=\"center\" >\n  <img src={Graph} align=\"center\" alt=\"Graph\" />\n  </div>\n\n<div className=\"intro\">\n    <h3 align=\"center\">Tip: Traffic Directions</h3>\n    <p>\n        North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.\n    </p>\n</div>\n\n<p>\n    Each of the deployment models in Figure 1 come with their list of pros and cons and are typically the point of focus of different teams. So how do you choose the right architecture for your deployment? Given the needs of your stakeholders and the many specifics involved in managing both north-south (N-S) and east-west (E-W) traffic, it is critical to assess the four different architectures with respect to the following areas:\n</p>\n<ul>\n<li>Application security </li>\n<li>Observability </li>\n<li>Continuous deployment </li>\n<li>Scalability and performance </li>\n<li>Open source tools integration </li>\n<li>Service mesh & Istio  integration </li>\n<li>IT skill set required </li>\n</ul>\n\nLet‚Äôs examine each of the four deployment models.\n\n<h3>Two-Tier Ingress</h3>\n\n  <div className=\"right\" >\n  <img src={TwoTier} align=\"centre\" alt=\"Two Tier Ingress\" />\n  </div>\n<p>\n    Two-tier ingress is the simplest architectural model to deploy to get teams up and running quickly. In this deployment model, Tthere are two layers of ADCs for N-S traffic ingress. The external ADC (at Tier 1), shown in green in Figure 2, provides L4 traffic management. Frequently, additional services are assigned to this ADC and can include web application firewall (WAF) and, secure sockets layer/transport layer security offload (SSL/TLS) functionality and authentication. A two-tier ingress deployment model is often managed by the existing network team (which is familiar with internet-facing traffic), and it can also be used as an ADC for other existing applications simultaneously.\n</p>\n<p>\n    The second ADC (Tier 2), shown in yellow in Figure 2, handles L7 load balancing for N-S traffic. It is managed by the platform team and is used within the Kubernetes cluster to direct traffic to the correct node. Layer 7 attributes, like information in the URL and HTTP headers, can be used for traffic load-balancing decisions. The yellow ADC continuously receives updates about the availability and respective IP addresses of the microservices pods within the Kubernetes cluster and can make decisions about which pod is best able to handle the request. Deployed as a container inside the Kubernetes cluster, the yellow ADC can be deployed as a container with Citrix CPX or with another similar product.\n</p>\n<p>\n    The E-W traffic between microservices pods is managed by kube-proxy, an open source, basic L4 load balancer with simple IP address-based round robin or least connection algorithm. kube-proxy lacks advanced features like Layer 7 load balancing, security, and observability, making it a blind spot for E-W traffic.\n</p>\n\n\n<b>Pros of Two-Tier Ingress</b>\n<p>\n    With the right proxy, SSL termination can be done at the edge, and traffic can be inspected easily. This enables N-S traffic to be comprehensively secured across L3-7. ADC collects and reports telemetry on the N-S application traffic it sees, which means that this architecture provides robust observability for N-S traffic. ADC can also also integrate with CI/CD tools like Spinnaker to provide traffic management to N-S traffic for excellent continuous deployment capabilities.\n</p>\n<p>\n    Two-tier ingress scales very well for N-S traffic, as an example Citrix ADC reach hundreds of Gbps or even Tbps throughput through active-active clustering of ADCs if required. Integration with third-party tools like Prometheus, Grafana and Zipkin are supported out of the box with ADC, so you can continue to use the tools with which you are familiar to collect data and manage your systems for N-S traffic. \n</p>\n<p>\n    The bifurcated design of two-tier ingress makes it relatively simple to implement demarcation points for control. The network team can own and manage the green ADC, and the platform team can work inside the Kubernetes environment. Neither the network team nor the platform team needs extensive retraining, which makes this architecture quick to implement.\n</p>\n<b>Cons of Two-Tier Ingress</b>\n<p>\n    The limitations of kube-proxy have made the use of third-party tools like Project Calico necessary to provide network policies, segmentation, and security support for inter-microservices communication. Similarly, kube-proxy's lack of detailed telemetry capabilities provides very little observability for E-W traffic. kube-proxy does not have the extensive APIs to integrate with continuous deployment tools, and its basic round-robin load balancing does not provide the granular load balancing needed to incorporate a CI/CD strategy inside the cluster. In general so you lack advanced load balancing tool set required to manage your inter-pod traffic. And kube-proxy does not currently integrate with service meshes, so there is no open source control plane integration for your E-W traffic management.\n</p>\n<p>\n    Overall, two-tier ingress provides excellent services for N-S traffic but lacks control for E-W traffic. It is a popular architecture because it is simple to implement and is frequently a starting point for enterprises on their cloud native journey to microservices adoption.\n</p>\n\n<div className=\"note\">\nBy default, kube-proxy uses iptables (x_tables kernel modules), so it does not perform as well as other proxies. You can configure kube-proxy to run in different modes by setting the --proxy-mode flag. Setting this flag to ipvs enables IPVS mode (netfilter kernel modules), which provides a much improved performance and also enables choice of load balancing algorithm through the --ipvs-scheduler parameter beyond the default round robin algorithm.\n</div>\n\n<h3>Unified Ingress</h3>\n  <div className=\"right\" >\n  <img src={Unified} align=\"centre\" height=\"50%\" alt=\"Unified Ingress\" />\n  </div>\n<p>\n    Unified ingress is very similar to the two-tier ingress architecture, except that it unifies two tiers of application delivery controllers (ADCs) for N-S traffic into one. Reducing an ADC tier effectively removes one hop of latency for N-S traffic. \n</p>\n<p>\n    Unified ingress has the same benefits and drawbacks as the two-tier ingress proxy architecture for security, observability, continuous deployment, scale and performance, open source tools support, and service mesh integration. Where it differs is in the skill sets required for implementation. With unified ingress, both the ADCs for N-S traffic and kube-proxy for the E-W traffic are managed by the platform team, who must be very network savvy to implement and manage this architecture. \n</p>\n<p>\n    A unified ingress proxy architecture is capable of participating in the Kubernetes cluster‚Äôs overlay network. This allows it to communicate directly with the microservices pods. Therefore, the platform team has to be knowledgeable about layers 3-7 of the network stack to take full advantage of this architecture. \n</p>\n<p>\n    In summary, unified ingress proxy architecture is moderately simple to deploy compared to service mesh (which we will cover next), and it offers robust capabilities for N-S traffic, but has very limited functionality for E-W traffic due to the limitations of kube-proxy. A network-savvy platform team is key for implementing this architecture.\n</p>\n\n<h3>Service Mesh</h3> \n\n<p>\n    A service mesh is a dedicated infrastructure layer to control how different parts of an application communicate with one another with one another. The service mesh landscape has exploded because service meshes offer the best observability, security, and fine-grained management for traffic among microservices ‚Äî that is, for E-W traffic. As an additional layer of infrastructure, service meshes do bear additional complexity as a tradeoff to the value they provide. \n</p>\n  <div className=\"left\" >\n  <img src={Servicemesh} align=\"centre\" alt=\"Service Mesh\" />\n  </div>\n<p>\n    A typical service mesh architecture is similar to the two-tier ingress proxy architecture for N-S traffic and offers the same rich benefits for N-S traffic. The key difference between service mesh and two-tier ingress, and where most of the value lies, is that service mesh employs a lightweight proxy as a sidecar to each microservice pod for E-W traffic. Microservices do not communicate directly: Communication among microservices happens via the sidecar, which enables inter-pod traffic to be inspected and managed as it enters and leaves the pods. \n</p>\n<p>\n    By using proxy sidecars, service mesh offers the highest levels of observability, security, and fine-grained traffic management and control among microservices. Additionally, select repetitive microservice functions like retries and encryption can be offloaded to the sidecars. Despite each sidecar‚Äôs being assigned its own memory and CPU resources, sidecars are typically lightweight.  \n</p>\n<p>\n    You have the option to use Citrix CPX as a sidecar. Sidecars, which are managed by the platform team and attached to each pod, create a highly scalable, distributed architecture, but they also add complexity because they result in more moving parts.\n</p> \n<strong>Pros of Service Mesh</strong>\n<p>\n    The advantages of service mesh for N-S traffic are similar to those for two-tier ingress. Service mesh, however, brings added advantages for E-W traffic.The presence of sidecars enables you to set security policies and control communication among your microservices. You can mandate things like authentication, encryption, and rate limiting for APIs among microservices if required. \n</p>\n<p>\n    Because E-W traffic is seen by the sidecars, there is much more telemetry to provide holistic observability for better insights and improved troubleshooting. Furthermore, Citrix CPX as a sidecar has well-defined APIs that integrate with myriad open source tools, so that you can use the observability tools you're used to. Sidecar APIs allow integration with CI/CD tools like Spinnaker. \n</p>\n<p>\n    Similarly, sidecars will integrate with a service mesh control plane like Istio for E-W traffic. Additionally, repetitive functions like retries and encryption can be offloaded to the sidecars. The distributed nature of the sidecar means that the solution is scalable for such features as observability and security. \n</p>\n<strong>Cons of Service Mesh</strong>\n<p>\n    The biggest drawback of a service mesh architecture is the complexity of implementation (managing hundreds or thousands of sidecars is not trivial). The learning curve can be steep for the platform team because there are so many moving parts. A sidecar for every pod adds to CPU and memory needs. Similarly, sidecars add latency. Latency, which may affect application performance, varies with proxy implementation and can be easily measured by the open source tool, Meshery. Citrix CPX as a sidecar offers latency as low as 1ms, whereas other solutions can add much more. \n</p>\n<p>\n    Overall, a service mesh architecture provides excellent security, observability, and fine-grained traffic management for all traffic flows. The major downside is that it is complex to implement and manage.\n</p>\n\n<h3>Service Mesh Lite</h3>\n  <div className=\"right\" >\n  <img src={Servicemeshlite} align=\"centre\" alt=\"Service Mesh Lite\" />\n  </div>\n<p>\n    What if you want service mesh-like benefits with much less complexity?  The answer is service mesh lite, which is a variant of service mesh.\n</p>\n<p>\n    With a service mesh lite architecture, the ADC shown in green in Figure 5 is responsible for Layer 4-7 load balancing for N-S traffic to handle inbound requests and load balance to the right Kubernetes cluster. The green ADC may carry out SSL termination, web application firewalling, authentication, or other network services. It is managed by the networking team. \n </p>\n<p>\n    Depending on isolation and scale requirements, service mesh lite proxy architecture uses a single or several ADCs (shown in yellow in Figure 5) that proxy communications among microservices pods to manage inter-pod (E-W) traffic rather than using individual sidecars attached to each pod. Proxies can be deployed per node or per namespace and are managed by platform teams. \n</p>\n<strong>Pros of Service Mesh Lite</strong>\n<p>\n    Service mesh lite provides many of the same benefits as service mesh but reduces the overall complexity by only having a small set of proxy instances per cluster to manage the inter-pod traffic. Passing all E-W traffic through a small set of proxies provides the same advanced policy control, security, and fine-grained traffic management of a service mesh proxy architecture without all the complexity. \n</p>\n<p>\n    Another advantage of service mesh lite is reduced latency as compared to service mesh because end user request goes through fewer  proxies. The main advantage is reduced complexity and the lower skill set required to implement compared to service mesh. Similar to two-tier ingress, the networking team can manage the green ADC, and the platform team can manage the yellow ADC. With service mesh lite, both teams can work in familiar environments and develop at their own speed.\n</p>\n<strong>Cons of Service Mesh Lite</strong>\n<p>\n    Service mesh lite removes the implementation and management associated with service mesh, but the absence of a proxy per pod means that you sacrifice some functionality offload. For example, encryption for E-W must be implemented in each microservice, itself, if required.\n </p>\n<p>\n    Overall, service mesh lite provides most of the service mesh features but with reduced complexity and a lower IT skill set requirement. Many organizations who started with the two-tier ingress architecture find it an easy transition to service mesh lite for the added benefits it brings to their E-W traffic including better observability, enhanced security, better integration with open source tools, and support for continuous deployment.\n</p>\n<p>\n    So after reviewing the four architecture choices, you‚Äôre probably wondering: What ‚Äòs the right architecture choice for my organization? There are no right or wrong answers. Like other architectural choices, proxy deployment models should be selected based on, in part, your application needs and your team structure and your team‚Äôs skill set. \n</p>\n<p>\n    Your model of proxy deployment is an important consideration, but just one of many when planning for your application delivery infrastructure. Ensuring that the application delivery components in your deployment are well-integrated into the cloud native ecosystem is your next consideration. \n</p>\n\n<h2>Openly Integrating with the Cloud Native Ecosystem </h2>\n<p>\nIt‚Äôs imperative that your various application delivery tools and processes, including your proxy, be well-integrated into commonplace cloud native infrastructure. It‚Äôs no secret that much of today‚Äôs innovation happens in open source software. And clouds, both public and private, are built upon open source software. So in most cases, your infrastructure will be comprised of popular open source infrastructure and tools that you have picked up on your journey to cloud native. To the extent this is the case, you‚Äôll find common integrations by categories in Figure below:\n</p>\n  <div className=\"center\" >\n  <img src={Comparison} align=\"center\" alt=\"\" />\n  <p>Figure - Key categories of consideration for proxy integration with Kubernetes platforms and open source tools</p>\n  </div>\n\n<p>\n    Cloud native environments make liberal use of open source software projects. Irrespective of which projects you use, suffice it to say that cloud native application delivery can‚Äôt be done with just containers. The combination of containers, container orchestration, and a service mesh will get you very far. And alongside a CI/CD system, these components are the most significant and ubiquitously used components of cloud native infrastructure. Integration with each of these categories of cloud native infrastructure is critical so that developers and operators can design and run systems that communicate and inter-operate as a whole. The fact that these bedrocks of cloud native infrastructure are open source unlocks their ability to be integrated.\n</p>\n<p>\n    At the heart of the cloud native ecosystem is the extensible and scalable orchestration infrastructure that is Kubernetes. The cloud native ecosystem (both open source and closed source) extends Kubernetes by writing custom resource definitions (CRDs) and associated controllers. The controllers and CRDs give operators a Kubernetes-native way to manage all parts of their platforms ‚Äî both open source and closed source. This integration affords tool unification and powerful composable intent-based primitives that truly enable a software-defined platform.\n</p>\n<p>\n    Critical to the speed of delivery is an early investment in continuous integration/continuous delivery (CI/CD). It‚Äôs likely you have already wrangled continuous integration. Continuous deployment pipelines are your next step in seeing that changes to your source code automatically result in a new container being built and a new version of your microservice being tested and deployed to staging and eventually to production. \n</p>\n<p>\n    For many, the notion that CI/CD is an area of early investment is counterintuitive, and they find it hard to swallow the upfront engineering effort required to get a solid pipeline in place. The sooner CI/CD basics are implemented, however, the sooner the dividends start paying out. We will cover advanced continuous delivery considerations later in this white paper.\n</p>\n<p>\n    With cloud native infrastructure‚Äôs being inherently dynamic (in contrast to infrastructure not driven by APIs,) the ability to observe cloud native infrastructure and its workloads is also necessary. Software is written with functionality and debugging in mind. Most often, developers use logging as the primary method for debugging their applications. Integration with Elasticsearch and Kibana is key here. \n</p>\n<p>\n    Performance counters are another way to track application behavior and performance. Akin to SNMP for physical and virtual network monitoring, the equivalent cloud native ‚Äústandard‚Äù is the use of Prometheus and Grafana, so it‚Äôs important that your application delivery solution integrate with these tools. Currently there is no recognized standard for cloud native application performance monitoring metrics.\n</p>\n\n<div className=\"intro\">\n    <h3 align=\"center\">OpenMetrics</h3>\n    <p>\n        The cloud native ecosystem needs a common format for the exchange of metrics. Observability pains grow with the release of each newly instrumented service that presents its own metric format. OpenMetrics is an effort to create an open standard for transmitting metrics at scale, with support for both text representation and protocolbBuffers. OpenMetrics builds on Prometheus‚Äôs exposition format, popular telemetry formats, and protocols used in infrastructure and application monitoring. \n    </p>\n</div>\n\n<p>\n    Irrespective of the metrics format, there are a few metrics that have been identified as key indicators of the health of a cloud native application (that is, the health of a service): latency, traffic, errors, and saturation. Your application delivery solution should assist in producing these signals as well as provide support for the tracing of your distributed, cloud native workloads. \n</p>\n<p>\n    The aforementioned integrations with open source tools enable loosely coupled systems that are resilient, manageable, and observable. Citrix ADC also embodies these characteristics. All of the infrastructure integrations detailed here depend upon APIs for interchange and interoperability. Cloud native applications, too, are centered around declarative APIs to interface with the infrastructure and serve user-facing workloads. \n</p>\n<p>\n    The endpoints that your APIs expose are now being managed by open source service meshes. Service meshes deliver the next generation of networking designed for cloud native applications. At the core of a service mesh is its data plane (its collection of proxies). Proxy selection criteria and deployment model tradeoffs are our next area of consideration.\n</p>\n\n_** Check out the topic <Link to=\"/resources/service-mesh/choosing-the-perfect-proxy\">Choosing the Perfect Proxy</Link> to learn more! **_\n\n\n</ResourcesWrapper>\n","frontmatter":{"title":"7 Key Considerations for Microservices-Based Application Delivery","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/7-key-considerations-for-microservices-based-application-delivery"}},{"id":"d82c6a92-eef7-56fd-9b27-61c345b946a1","body":"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n<h3>What Is a Service Proxy?</h3>\n<p>\nA service proxy is a client-side mediator that handles requests for a service. The service proxy allows applications to send and receive messages as method calls via a channel. Service proxy connections can be created as needed or persist open connections to facilitate pooling. Applications are oblivious to the data plane's existence. As applications conduct service-to-service calls, service proxies are transparently inserted. Inbound (ingress) and outbound (egress) cluster network traffic are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling. In Istio, traffic is transparently intercepted using iptables rules and redirected to the service proxy.\n</p>\n<p>\nRemember that Pilot configures traffic policy and service proxies implement it. The data plane is a collection of service proxies. Service proxies are responsible for health checks, routing, load balancing, authentication, authorization, and the production of observable signals by intercepting every packet in the request. As the service may change from location to location, proxies provide indirection so that clients may point to the same location (e.g., proxy.example.com), representing a permanent reference. They add resilience to distributed systems.\n</p>\n\n<h3>Envoy Proxy Overview</h3>\n<p>The versatile and performant Envoy has evolved as an open source, application-level service proxy, living up to its tagline as the universal data plane API. Lyft developed Envoy in order to solve major distributed systems problems. Envoy has had broad reuse¬†and has been integrated into the cloud native ecosystem.</p>\n<h4>Why Envoy?</h4>\n<p>\nEnvoy was originally intended to be used as an edge proxy rather than a sidecar. Envoy transitioned to the sidecar pattern over time.\nThe concept of hot reloads vs. hot restarts was at the center of the decision for the Istio project to leverage Envoy. Envoy's runtime configuration has always been API-driven, allowing it to drain and hot reload its own process with an old configuration with a new process and new configuration (displacing itself). Envoy achieves hot reloading of its processes by shared memory and communication through a Unix Domain Socket (UDS), in a manner that resembles GitHub's tool for zero-downtime HAProxy reloads.\nAdditionally, and uniquely, Envoy offers an Aggregated Discovery Service (ADS) for delivering the data for each xDS API.\n</p>\n\n<h4>HTTP/2 and gRPC</h4>\n<p>\nEnvoy stood apart from other proxies at the time because of its early support for HTTP/2 and gRPC. HTTP/2 significantly improves on HTTP/1.1 in that HTTP/2 enables request multiplexing over a single TCP connection. Proxies that support HTTP/2 benefit from the reduced overhead of combining several connections into a single one. HTTP/2 allows clients to send numerous parallel requests and load resources preemptively using server-push.\n</p>\n<p>\nEnvoy is HTTP/1.1 and HTTP/2 compatible, including proxying compatibility for both downstream and upstream protocols. This means Envoy can accept incoming HTTP/2 connections and proxy them to upstream HTTP/2 clusters, but it can also take HTTP/1.1 connections and proxy them to HTTP/2 clusters (and vice-versa).\n</p>\n<p>\ngRPC is an RPC protocol that uses protocol buffers on top of HTTP/2. Envoy supports gRPC natively (over HTTP/2) and can also bridge an HTTP/1.1 client to gRPC. Envoy has the ability to operate as a gRPC-JSON transcoder. The gRPC-JSON transcoder functionality allows a client to send HTTP/1.1 requests with a JSON payload to Envoy, which translates the request into the corresponding gRPC call and subsequently translates the response message back into JSON. These are powerful capabilities (and challenging to execute correctly), which set Envoy apart from other service proxies.\n</p>\n\n<h3>Envoy in Istio</h3>\n<p>\nAs an out of process proxy, Envoy transparently forms the base unit of the mesh. Akin to proxies in other service meshes, it is the workhorse of Istio. Istio deploys Envoy sidecarred to application services.\nIdentified as <code>istio-proxy</code> in deployment files, Envoy does not require root privileges to run, but runs as user 1337 (non root). \n</p>\n\n<h3>Sidecar Injection (or Sidecarring)</h3>\n<p>\nThere are two steps to adding a service proxy: sidecar injection and network capture. Sidecar injection is the method of adding a proxy to a given application. Network capture is the method of directing inbound traffic to the proxy (instead of the application) and outbound traffic to the proxy (instead of directly back to the client or directly to subsequent upstream application services).\n</p>\n\n<h4>Manual Sidecar Injection</h4>\n<p>\n<code>Istioctl</code> can be used to manually inject¬†the Envoy sidecar definition into Kubernetes manifests manually. Use <code>istioctl</code>‚Äôs <code>kube-inject</code> capability to manually inject the sidecar into deployment manifests by manipulating yaml.\n</p>\n\n```\n$ istioctl kube-inject -f samples/sleep/sleep.yaml | kubectl apply -f -\n```\n<p>\nYou can update Kubernetes specifications on-the-fly at the time of applying them to Kubernetes for scheduling. Alternatively, you might use the <code>istioctl kube-inject</code> utility like so:\n</p>\n\n```\n$ kubectl apply -f <(istioctl kube-inject -f <resource.yaml>)\n```\n<p>\nIf you don‚Äôt have the source manifests available, you can update an existing Kubernetes deployment to bring its services onto the mesh:\n</p>\n\n```\n$ kubectl get deployment -o yaml | istioctl kube-inject -f - | kubectl apply -f -\n```\n<p>\nLet's look at an example of an existing application being onboarded onto the mesh. Let's use a freshly installed copy of BookInfo as an example of a Kubernetes application that isn't¬†deployed on¬†the service mesh yet. We'll start with¬†exploring BookInfo's pods.\n</p>\n\n```\n$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\ndetails-v1-69658dcf78-nghss       1/1     Running   0          43m\nproductpage-v1-6b6798cb84-nzfhd   1/1     Running   0          43m\nratings-v1-6f97d68b6-v6wj6        1/1     Running   0          43m\nreviews-v1-7c98dcd6dc-b974c       1/1     Running   0          43m\nreviews-v2-6677766d47-2qz2g       1/1     Running   0          43m\nreviews-v3-79f9bcc54c-sjndp       1/1     Running   0          43m\n```\n<p>\nThe atomic unit of deployment in Kubernetes is a Pod.¬† Since a Pod is a collection of containers, it can be one or more containers deployed atomically together. In our example, we can see that each of BookInfo's pods is only executing one container. When <code>istioctl kube-inject</code>¬†is run against¬†¬†on BookInfo's manifests, it adds another container to the Pod specification but does not deploy anything yet.\n</p>\n<p>\n<code>istioctl kube-inject</code> supports modification of Pod-based Kubernetes objects (Job, DaemonSet, ReplicaSet, Pod and Deployment) that may be embedded into long yaml files containing other Kubernetes objects. <code>Istioctl kube-inject</code> will parse the other Kubernetes objects without modification. Unsupported resources are left unmodified so it is safe to run kube-inject over a single file that contains multiple Service, ConfigMap, Deployment, etc. definitions for a complex application. It is best to do this when the resource is initially created.\n</p>\n<p>\nIn order to onboard this existing application, we can execute <code>istioctl kube-inject</code> against each Deployment and have a rolling update of that Deployment initiated by Kubernetes as shown below. Let‚Äôs start with the <code>productpage</code> service.\n</p>\n\n```\n$ kubectl get deployment productpage-v1 -o yaml | istioctl kube-inject -f - | kubectl apply -f -\ndeployment.extensions/productpage-v1 configured\n```\n<p>\nWe now notice that the productpage pod has grown to two containers when we look at the BookInfo pods again. Istio‚Äôs sidecar has been successfully injected. The rest of BookInfo‚Äôs application services need to be onboarded in order for BookInfo as an application to work.\n</p>\n\n```\n$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\ndetails-v1-69658dcf78-nghss       1/1     Running   0          45m\nproductpage-v1-64647d4c5f-z95dl   2/2     Running   0          64s\nratings-v1-6f97d68b6-v6wj6        1/1     Running   0          45m\nreviews-v1-7c98dcd6dc-b974c       1/1     Running   0          45m\nreviews-v2-6677766d47-2qz2g       1/1     Running   0          45m\nreviews-v3-79f9bcc54c-sjndp       1/1     Running   0          45m\n```\n<p>\nYou may choose to do this manual injection operation once and persist the new manifest file with istio-proxy (Envoy) inserted instead of ad-hoc onboarding of a running application. You can create a persistent version of the sidecar injected deployment outputting the results of <code>istioctl kube-inject</code> to a file. As Istio evolves the default sidecar configuration is subject to change.\n</p>\n\n```\n$ istioctl kube-inject -f deployment.yaml -o deployment-injected.yaml\n```\nOr like so:\n\n```\n$ istioctl kube-inject -f deployment.yaml > deployment-injected.yaml\n```\n<h4>Ad-hoc Sidecarring</h4>\n<p>\nSidecar injection is responsible for configuring network capture. Injection and network capture can be selectively applied to enable incremental adoption of Istio. Using the BookInfo sample application as an example, let‚Äôs take the <code>productpage</code> service as the external-facing service and selectively remove this service (and just this service out of the set of four) from the service mesh. Let's start by checking for the presence of its sidecarred service proxy.\n</p>\n\n```\n$ kubectl get pods productpage-8459b4f9cf-tfblj -o jsonpath=\"{.spec.containers[*].image}\"\nlayer5/istio-bookinfo-productpage:v1 docker.io/istio/proxyv2:1.0.5\n```\n<p>\nAs you can see, productpage container is our application container, while the istio/proxy is the service proxy (Envoy) that Istio injected into the pod. To manually onboard and offboard a deployment onto and off of the service mesh, you can manipulate annotation within its Kubernetes Deployment specification.\n</p>\n\n```\n$ kubectl patch deployment nginx --type=json --patch='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations\", \"value\": {\"sidecar.istio.io/inject\": \"false\"}}]'\ndeployment.extensions/productpage-v1 patched\n```\n<p>\nOn opening your browser to the <code>productpage</code> application, and you‚Äôll find that it is still being served through Istio‚Äôs Ingress Gateway, but that its pods no longer have sidecars. Hence, the productpage app has been removed from the mesh.\n</p>\n\n```\nUNAVAILABLE:upstream connect error or disconnect/reset before headers\n```\n<h4>Automatic Sidecar Injection</h4>\n<p>\nNo code change to receive much more visibility into how your services are behaving and how they are being interacted gives Istio a magical feeling once your services are on the mesh. Automatic sidecar injection is the magical feeling you get as you go to onramp your services.Not only does automatic sidecar injection eliminate the need to alter your code, but it also eliminates the need to change your Kubernetes manifests. Automatic sidecar injection in Kubernetes relies on mutating admission webhooks. The <code>istio-sidecar-injector</code> is added as a mutating webhook configuration resource when Istio is installed on Kubernetes.\n</p>\n\n```\n$ kubectl get mutatingwebhookconfigurations\nNAME                                    CREATED AT\nistio-sidecar-injector                  2019-04-18T16:35:03Z\nlinkerd-proxy-injector-webhook-config   2019-04-18T16:48:49Z\n```\n\n```\n$ kubectl get mutatingwebhookconfigurations istio-sidecar-injector -o yaml\n\napiVersion: admissionregistration.k8s.io/v1beta1\nkind: MutatingWebhookConfiguration\nmetadata:\n  creationTimestamp: \"2019-04-18T16:35:03Z\"\n  generation: 2\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\n  name: istio-sidecar-injector\n  resourceVersion: \"192908\"\n  selfLink: /apis/admissionregistration.k8s.io/v1beta1/mutatingwebhookconfigurations/istio-sidecar-injector\n  uid: eaa85688-61f7-11e9-a968-00505698ee31\nwebhooks:\n- admissionReviewVersions:\n  - v1beta1\n  clientConfig:\n    caBundle: <redacted>\n    service:\n      name: istio-sidecar-injector\n      namespace: istio-system\n      path: /inject\n  failurePolicy: Fail\n  name: sidecar-injector.istio.io\n  namespaceSelector:\n    matchLabels:\n      istio-injection: enabled\n  rules:\n  - apiGroups:\n    - \"\"\n    apiVersions:\n    - v1\n    operations:\n    - CREATE\n    resources:\n    - pods\n    scope: '*'\n  sideEffects: Unknown\n  timeoutSeconds: 30\n```\n\n<p>\nIf the namespace contains the <code>istio-injection=enabled</code>¬†label, Kubernetes will transmit all Pod creation events to the <code>istio-sidecar-injector</code>¬†service (in the istio-system namespace) if this mutating¬†webhook is registered. The injector service will then modify the PodSpec to include two more containers, one for the init-container to configure traffic rules and the other for istio-proxy (Envoy) to perform proxying.¬† The sidecar injector service uses a template to add these two additional containers; the template may be found in the <code>istio-sidecar-injector configmap</code>.\n</p>\n<p>\nKubernetes lifecycle allows customization of resources before they are committed to the etcd store, the ‚Äòsource of truth‚Äô for Kubernetes configuration. When an individual Pod is created (either via kubectl or a Deployment resource), it goes through this same lifecycle, hitting mutating admission webhooks which modify the pod before it actually gets applied.\n</p>\n\n<h4>Kubernetes Labels</h4>\n<p>\nAutomatic sidecar injection relies on labels to identify which pods to inject Istio‚Äôs service proxy and initialize as pod on the data plane. Kubernetes objects, like pods and namespaces, can have user-defined labels attached to them. Labels are essentially <code>key:value</code> pairs like you finding in other systems that support the concept of tags. Webhook Admission controller relies on labels to select the namespaces they apply to. Istio-injection is the specific label that Istio uses. Familiarize by labeling the default namespace with <code>istio-injection=enabled</code>:\n</p>\n\n```\n$ kubectl label namespace default istio-injection=enabled\n````\n\n<p>Confirm which namespaces have the istio-injection label associated:</p>\n\n```\n$ kubectl get namespace -L istio-injection\nNAME           STATUS    AGE       ISTIO-INJECTION\ndefault        Active    1h        enabled\nDocker         Active    1h        enabled\nistio-system   Active    1h        disabled\nkube-public    Active    1h        \nkube-system    Active    1h\n```\n<p>\nNotice that only the <code>istio-system</code> namespace has the <code>istio-injection</code> label assigned. By virtue of having the <code>istio-injection</code> label and its value set to disabled, the <code>istio-system</code> namespace will not have service proxies automatically injected into their pods upon deployment. This does not mean that pods in this namespace cannot have service proxies. It just means that service proxies won‚Äôt be automatically injected. \n</p>\n<p>\nOne caveat to watch out for, when using the <code>namespaceSelector</code>, make sure that the namespace(s) you are selecting really has the label you are using. Keep in mind that the built-in namespaces like default and <code>kube-system</code> don‚Äôt have labels out of the box.\n</p>\n\n<p>Conversely, the namespace in the metadata section is the actual name of the namespace, not a label:</p>\n\n```\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: test-network-policy\n  namespace: default\nspec:\n...\n```\n\n<h4>Kubernetes Init Containers</h4>\n<p>\nVery similar to cloud-init for those familiar with VM provisioning, init containers in Kubernetes allows you to run temporary containers to perform a task before engaging your primary container(s). Init containers are Init containers in Kubernetes allow you to run temporary containers to execute a task before activating your principal container, comparable to cloud-init for people acquainted with VM provisioning (s). Init containers are frequently used for provisioning operations such as asset bundling, database migration, and cloning a git repository onto a volume. In the instance of Istio, init containers are used to set up network filters - iptables - that control traffic flow. used to perform provisioning tasks like bundling assets, performing database migration, or clone a git repository into a volume. In Istio‚Äôs case, init containers are used to setup network filters - iptables to control the flow of traffic.\n</p>\n\n</ResourcesWrapper>","frontmatter":{"title":"Service Proxy","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/service-proxy"}},{"id":"d93b1f22-fe0f-5ae7-9dff-dba0f5ab8ceb","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n<p>\nThis article covers Istio's Pilot, its basic model, the sources of configuration it consumes to produce a model of the mesh, how it uses that model of the mesh to push configuration to Envoys, how to debug it, and how to understand the transformation Pilot performs from Istio configuration to Envoy's. With this knowledge, you should be able to debug¬†and resolve the vast majority of issues that new and intermediate Istio users encounter.\n</p>\n<p>\nIn an Istio deployment, Pilot is in charge of programming the data plane, ingress and egress gateways, and service proxies. Pilot models a deployment¬†environment by combining Istio configuration from Galley¬†¬†with service information from a service registry, such as the Kubernetes API server or Consul. Pilot utilises this model to produce data plane configuration and pushes it out to the fleet of service proxies that are connected to it.\n</p>\n<h3>Configuring Pilot</h3>\n<p>\nLet's look at the surface area of Pilot's configuration to understand better all aspects of the mesh that concerns it. As we process this, keep in mind that Pilot's dependency on Galley for the underlying platform and environment information will grow as the Istio project progresses. Pilot has three primary sources of configuration:\n</p>\n<h4>Mesh Configuration</h4>\n<p>\nMesh configuration is a set of global configuration that is static for the installation of the mesh. Mesh configuration is split over three API objects:\n</p>\n<ol>\n<li>MeshConfig (<code>mesh.istio.io/v1alpha1.MeshConfig</code>) - MeshConfig allows you to configure how Istio components communicate with one another, where configuration sources are located, etc.</li>\n<li>ProxyConfig (<code>mesh.istio.io/v1alpha1.ProxyConfig</code>) - ProxyConfig tracks where Envoy's bootstrap configuration is located, which ports to bind to, and other options concerned with initialising Envoy.</li>\n<li>MeshNetworks (<code>mesh.istio.io/v1alpha1.MeshNetworks</code>) - MeshNetworks is a collection of networks across which the mesh is deployed, together with the addresses of each network's ingress gateways.</li>\n</ol>\n<p>\nMeshConfig is generally used to define whether policy and/or telemetry are enabled, where to load configuration and locality-based load balancing settings. The exhaustive set of concerns that MeshConfig contains is listed below:\n</p>\n<ul>\n<li>\nHow to user Mixer?\n<ul>\n<li>The addresses of the policy and telemetry servers</li>\n<li>Whether policy checks are enabled at runtime</li>\n<li>Whether to fail open or closed when Mixer Policy is inaccessible or returns an error</li>\n<li>Whether to perform policy checks on the client side.</li>\n<li>Whether to use session affinity to target the same Mixer Telemetry instance. Session affinity is always enabled for Mixer Policy (performance of the system relies on it!)</li>\n</ul>\n</li>\n<li>\nHow to configure service proxies for listening?\n<ul>\n<li>The ports to bind to to accept traffic (i.e. the port IPTables redirects to) and to accept HTTP PROXY requests</li>\n<li>TCP connection timeout and keepalive settings</li>\n<li>Access log format, output file, and encoding (JSON or text)</li>\n<li>Whether to allow all outbound traffic, or restrict outbound traffic to only services Pilot knows about</li>\n<li>Where to listen for secrets from Citadel (the SDS API), and how to bootstrap trust (in environments with local machine tokens)</li>\n</ul>\n</li>\n<li>Whether to support Kubernetes Ingress resources</li>\n<li>The set of configuration sources for all Istio components (e.g. the local file system, or Galley), and how to communicate with them (the address, whether to use TLS or not, which secrets, etc)</li>\n<li>Locality-based load balancing settings‚Äîconfiguration about failover and traffic splits between zones and regions.</li>\n</ul>\n\n<p>ProxyConfig is mostly used for customising¬†bootstrap settings for Envoy. The exhaustive set of concerns that ProxyConfig contains is the following:</p>\n<ul>\n<li>The location of the file with Envoy‚Äôs bootstrap configuration, as well as the location of the Envoy binary itself</li>\n<li>The location of the trace collector (i.e. where to send trace data)</li>\n<li>Shutdown settings (both connection draining and hot restart)</li>\n<li>The location of Envoy‚Äôs xDS server (Pilot) and how to communicate with it</li>\n<li>Envoy‚Äôs service cluster, meaning the name of the service this Envoy is sidecar for</li>\n<li>Which ports to host the proxy‚Äôs admin server and statsd listener</li>\n<li>Envoy‚Äôs concurrency (number of worker threads)</li>\n<li>Connection timeout settings</li>\n<li>How Envoy binds the socket to intercept traffic (either via IPTables REDIRECT or TPROXY)</li>\n</ul>\n<p>\nMeshNetworks defines a collection of named networks, the method for sending traffic into those networks (ingress), and their¬†locality. A CIDR range or a set of endpoints returned by a service registry define each network (e.g. the Kubernetes API server). The API object ServiceEntry, which is used to define services in Istio, has¬†a set of endpoints. A ServiceEntry can represent a service that is deployed across multiple networks(or clusters)¬†by labelling each endpoint with a network.\n</p>\n<p>\nMost values in MeshConfig cannot be updated dynamically, therefore the control plane must be restarted for them to take effect. Similarly, updates to values in ProxyConfig only occur when Envoy is redeployed (e.g., in Kubernetes, when the pod is rescheduled). MeshNetworks can be dynamically upgraded at runtime without requiring any control plane components to be restarted.\n</p>\n<p>\nOn Kubernetes, the majority of MeshConfig and ProxyConfig configuration is concealed behind options in the Helm installation, although not all of it is exposed via Helm. To have complete control over the installation, you'll need to post-process the file output by Helm.\n</p>\n\n<h4>Networking Configuration</h4>\n<p>\nNetworking configuration is Istio‚Äôs bread and butter‚Äîthe configuration to manage how traffic flows through the mesh.\n</p>\n<p>\nIstio's networking APIs revolve around ServiceEntry. ServiceEntry defines a service by its names‚Äîthe set of hostnames clients use to call the service. DestinationRules define how clients communicate with a service: what load balancing, outlier detection, circuit breaking, and connection pooling strategies to use, which TLS settings to use, etc. VirtualServices configure how traffic flows to a service: L7 and L4 routing, traffic shaping, retries, timeouts, etc. Gateways configure how services are exposed outside of the mesh: what hostnames are routed to which services, how to serve certs for those hostnames, etc. Service proxies configure how services are exposed inside of the mesh, which services are available to which clients.\n</p>\n<h4>Service Discovery</h4>\n<p>\nPilot integrates with different service discovery systems, such as the Kubernetes API server, Consul, and Eureka, to discover service and endpoint information about the local environment. Adapters in Pilot consume service discovery data from their source and synthesize ServiceEntry objects. For example, the integration with Kubernetes uses the Kubernetes SDK to watch the API server for service creation and service endpoint update events. The registry adapter in Pilot creates a ServiceEntry object based on this data. That ServiceEntry is used to update Pilot‚Äôs internal model and generate an updated configuration for the data plane.\n</p>\n<p>\nPilot registry adapters were previously implemented¬†in Golang.¬† These adapters can now be detached from Pilot with the introduction of Galley. A service discovery adapter reads an existing service registry and produces a set of ServiceEntry objects as a separate job (or an offline process done by a continuous integration system). Those ServiceEntries can then be supplied to Galley as files and uploaded to the Kubernetes API server. Alternatively, you can create your own Mesh Config Protocol server and feed Galley the ServiceEntries. Static ServiceEntries can be useful to enable Istio in largely static environments (e.g., legacy VM-based deployments with rarely-changing IP addresses).\n</p>\n<p>\nServiceEntries bind a set of hostnames to endpoints to construct a Service. IP addresses or DNS names can be those¬†endpoints. A network, locality, and weight can be assigned to each endpoint individually. ServiceEntries can define complex network topologies as a result of this. A service deployed across separate clusters (with different networks) that are geographically disparate (have different localities) can be created and have traffic split amongst its members by percentage (weights)‚Äîor in fact, by nearly any feature of the request. ¬†Since Istio knows where distant networks' ingress points are, when a service endpoint in a remote network is selected, the service proxy will route traffic to the remote network's ingress. We can even write policies to prefer local endpoints over endpoints in other localities but automatically failover to other localities if local endpoints are unhealthy.¬†\n</p>\n\n<h3>Config Serving</h3>\n<p>\nPilot constructs a model of the environment and state of a deployment using these three config sources‚Äîmesh config, networking config, and service discovery. As service proxy instances are deployed into the cluster, they connect to Pilot asynchronously. Pilot groups the service proxies based on their labels and the service to which they are sidecarred. Pilot creates Discovery Service (xDS) responses for each group of connected service proxies using this paradigm. Pilot transmits the current state of the environment and the configuration that reflects the environment when a service proxy connects. The model is updated regularly due to the generally dynamic nature of the underlying platform(s). Updates to the model mean updating the current set of xDS configurations. When the Discovery Service config is changed, Pilot computes the groups of affected service proxies and pushes the updated configuration to them.\n</p>\n<p>Service proxy (Envoy) configuration can be divided into two main groups: </p>\n<ul>\n<li>Listeners and Routes</li>\n<li>Clusters and Endpoints</li>\n</ul>\n<p>\nListeners define a set of filters (for example, an HTTP filter delivers Envoy's HTTP functionality) and how Envoy connects those filters to a port. These are of¬†two types: physical and virtual. A physical listener is one where Envoy binds to the specified port.¬†A virtual listener accepts traffic from a physical listener without binding to a port (instead, some physical listener must direct traffic to it). Listeners and Routes work together to configure how a Listener routes traffic to a specified Cluster (e.g., by matching on HTTP path or SNI name). A cluster is a collection of endpoints that includes information on how to contact them (TLS settings, load balancing strategy, connection pool settings, etc.).¬† A Cluster is analogous to a \"service.\" Finally, Endpoints are individual network hosts (IP addresses or DNS names) that Envoy will forward traffic to.¬†\n</p>\n\n<h3>Troubleshooting Pilot</h3>\n<p>\nTo examine the state of service proxies connected to Pilot, see these endpoints:\n</p>\n<ul>\n<li><code>/debug/edsz</code> - prints all of Pilot‚Äôs set of pre-computed EDS responses; i.e. the endpoints it sends to each connected service proxy</li>\n<li><code>/debug/adsz</code> - prints the set of listeners, routes, and clusters pushed to each service proxy connected to Pilot</li>\n<li><code>/debug/cdsz</code> - prints the set of clusters pushed to each service proxy connected to Pilot</li>\n<li><code>/debug/synz</code> - print the status of ADS, CDS, and EDS connections of all service proxies connected to pilot. In particular this shows the last nonce Pilot is working with vs the last nonce Envoy has ACK‚Äôd, showing which Envoys are not accepting configuration updates</li>\n</ul>\n\n<p>\nTo examine Pilot‚Äôs understanding of the state of the world (its service registries), see these endpoints:\n</p>\n<ul>\n<li><code>/debug/registryz</code> - print the set of services Pilot knows about across all registries</li>\n<li><code>/debug/endpointz[?brief=1]</code> - print the endpoints for every service Pilot knows about, including their ports, protocols, service accounts, labels, etc. If you provide the brief flag, the output will be a human-readable table (as opposed to a JSON blob for the normal version). This is a legacy endpoint and <code>/debug/endpointShardz</code> provides strictly more information.</li>\n<li><code>/debug/endpointShardz</code> - print the endpoints for every service Pilot knows about, grouped by the registry that provided the endpoint. For example, if the same service exists in both Consul and Kubernetes, endpoints for the service will be grouped into two shards, one each for Consul and Kubernetes. This endpoint provides everything from <code>/debug/endpoint</code> and more, including data like the endpoint‚Äôs network, locality, load balancer weight, representation in Envoy xDS config, etc.</li>\n<li><code>/debug/workloadz</code> - print the set of endpoints (‚Äúworkloads‚Äù) connected to Pilot, and their metadata (like labels)</li>\n<li><code>/debug/configz</code> - print the entire set of Istio configuration Pilot knows about. Only validated config that Pilot is using to construct its model will be returned; useful for understanding situations where Pilot is not processing new config itself.</li>\n</ul>\n\n<p>\nYou can also find miscellaneous endpoints with higher level debug information, be wading through these endpoints:\n</p>\n<ul>\n<li><code>/debug/authenticationz[?proxyID=pod_name.namespace]</code> - prints the Istio authentication policy status of the target proxy for each host and port it‚Äôs serving, including: the name of the authentication policy affecting it, the name of the DestinationRule affecting it, whether the port expects mTLS, standard TLS, or plain text, and if settings across configuration cause a conflict for this port.</li>\n<li><code>/debug/config_dump[?proxyID=pod_name.namespace]</code> - prints the listeners, routes, and clusters for the given node; this can be diff‚Äôd directly against the output of <code>istioctl proxy-config</code></li>\n<li><code>/debug/push_status</code> - prints the status of each connected endpoint as of Pilot‚Äôs last push period; includes the status of each connected proxy, when the push period began (and ended), and the identities assigned to each port of each host.</li>\n</ul>\n\n<h3>Tracing Configuration</h3>\n<p>\nIn this section, we‚Äôll use some tools to understand the before-and-after of Istio configuration and the resultant xDS configuration pushed to service proxies. \n</p>\n<h4>Listeners</h4>\n<p>Gateways and VirtualServices results in Listeners for Envoy. Gateways result in physical listeners (listeners that bind to a port on the network), while VirtualServices result in virtual listeners (listeners that do not bind to a port, but instead receive traffic from physical listeners). Demonstration of how Istio configuration manifests into xDS configuration by creating a Gateway:</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: foo-com-gateway\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n  - hosts:\n    - ‚Äú*.foo.com‚Äù\n    port:\n      number: 80\n      name: http\n      protocol: HTTP\n```\n<p>Creation of this Istio Gateway results in a single HTTP listener on port 80 on our Ingress Gateway.</p>\n\n```\n$ istioctl proxy-config listener istio-ingressgateway_PODNAME -o json -n istio-system\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"address\": {\n            \"socketAddress\": {\n                \"address\": \"0.0.0.0\",\n                \"portValue\": 80\n            }\n        },\n        \"filterChains\": [\n            {\n                \"filters\": [\n                    {\n                        \"name\": \"envoy.http_connection_manager\",\n...\n                            \"rds\": {\n                                \"config_source\": {\n                                    \"ads\": {}\n                                },\n                                \"route_config_name\": \"http.80\"\n                            },\n...\n```\n<p>It's worth noting that the newly created filter is listening on address 0.0.0.0. This is the listener for all HTTP traffic on port 80, regardless of the host to which it is addressed. If we enable TLS termination for this Gateway, we'll see a new listener created just for the hosts we‚Äôre terminating TLS for, while the rest would fall into this catch-all listener.</p>\n<p>Let‚Äôs bind a VirtualService to this Gateway</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n hosts:\n - bar.foo.com\n gateways:\n - foo-com-gateway\n http:\n - route:\n   - destination:\n       host: bar.foo.svc.cluster.local\n```\n\n<p>See how it manifests as virtual listener.</p>\n\n```\n$ istioctl proxy-config listener istio-ingressgateway_PODNAME -o json\n\n\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"address\": {\n            \"socketAddress\": {\n                \"address\": \"0.0.0.0\",\n                \"portValue\": 80\n            }\n        },\n        \"filterChains\": [\n            {\n                \"filters\": [\n                    {\n                        \"name\": \"envoy.http_connection_manager\",\n...\n                            \"rds\": {\n                                \"config_source\": {\n                                    \"ads\": {}\n                                },\n                                \"route_config_name\": \"http.80\"\n                            },\n...\n```\n<p>\nWe¬†encourage that you try different protocols for the ports (or list a single Gateway with many ports with various protocols) to see how this results in different filters. Configuring different TLS settings within the Gateway also changes the generated Listener configuration. For each protocol you use, you'll notice a protocol-specific filter configured in the Listener (for HTTP, this is the http connection manager and its router, for MongoDB another, for TCP another, and so on). To explore how different combinations of hosts in the Gateway and VirtualService interact, we also recommend exploring different combinations of hosts in the Gateway and VirtualService.\n</p>\n\n<h4>Routes</h4>\n<p>We've seen how VirtualServices cause Listeners to be created. In Envoy, the majority of the configuration you specify in VirtualServices manifests as Routes. Routes exist in a variety of flavors, with a set of routes for each protocol supported by Envoy.</p>\n\n```\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n[\n    {\n        \"name\": \"0.0.0.0_80\",\n        \"virtualHosts\": [\n            {\n                \"name\": \"bar.foo.com:80\",\n                \"domains\": [\n                    \"bar.foo.com\",\n                    \"bar.foo.com:80\"\n                ],\n                \"routes\": [\n                    {\n                        \"match\": {\n                            \"prefix\": \"/\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|8000||bar.foo.svc.cluster.local\",\n                            \"timeout\": \"0s\",\n                            \"retryPolicy\": {\n                                \"retryOn\": \"connect-failure,refused-stream,unavailable,cancelled,resource-exhausted,retriable-status-codes\",\n                                \"numRetries\": 2,\n                                \"retryHostPredicate\": [\n                                    {\n                                        \"name\": \"envoy.retry_host_predicates.previous_hosts\"\n                                    }\n                                ],\n                                \"hostSelectionRetryMaxAttempts\": \"3\",\n                                \"retriableStatusCodes\": [\n                                    503\n                                ]\n                            },\n...\n\n\nExample 7.5 -  Envoy Route (RDS) configuration for the VirtualService in Example 7.3. Notice the default Retry Policy and the embedded Mixer configuration (which is used for reporting telemetry back to Mixer).\n\nWe can update our Route to include some match conditions to see how this results in different Routes for Envoy (Example 7-6):\n\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n  hosts:\n  - bar.foo.com\n  gateways:\n  - foo-com-gateway\n  http:\n  - match:\n    - uri:\n        prefix: /whiz\n    route:\n    - destination:\n        host: whiz.foo.svc.cluster.local\n  - route:\n    - destination:\n        host: bar.foo.svc.cluster.local\n\n```\n<p>We can update our Route to include some match conditions to see how this results in different Routes for Envoy</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n name: foo-default\nspec:\n  hosts:\n  - bar.foo.com\n  gateways:\n  - foo-com-gateway\n  http:\n  - match:\n    - uri:\n        prefix: /whiz\n    route:\n    - destination:\n        host: whiz.foo.svc.cluster.local\n  - route:\n    - destination:\n        host: bar.foo.svc.cluster.local\n\n```\n\n<p>Similarly we can add retries, split traffic amongst several destinations, inject faults, and more. All of these options in VirtualServices manifest as Routes in Envoy.</p>\n\n```\n$ istioctl proxy-config route istio-ingressgateway_PODNAME -o json\n\n\n[\n    {\n        \"name\": \"http.80\",\n        \"virtualHosts\": [\n            {\n                \"name\": \"bar.foo.com:80\",\n                \"domains\": [\n                    \"bar.foo.com\",\n                    \"bar.foo.com:80\"\n                ],\n                \"routes\": [\n                    {\n                        \"match\": {\n                            \"prefix\": \"/whiz\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|80||whiz.foo.svc.cluster.local\",\n...\n                    {\n                        \"match\": {\n                            \"prefix\": \"/\"\n                        },\n                        \"route\": {\n                            \"cluster\": \"outbound|80||bar.foo.svc.cluster.local\",\n...\n```\n\n<h4>Clusters</h4>\n<p>We can see that Istio creates a cluster for each service and port in the mesh if we use <code>istioctl</code>¬†to look at clusters. To see a new Cluster emerge in Envoy, we can construct a new ServiceEntry:</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: ServiceEntry\nmetadata:\n  name: http-server\nspec:\n  hosts:\n  - some.domain.com\n  ports:\n  - number: 80\n    name: http\n    protocol: http\n  resolution: STATIC\n  endpoints:\n  - address: 2.2.2.2\n```\n\n```\n$ istioctl proxy-config cluster istio-ingressgateway_PODNAME -o json\n\n\n[\n...\n    {\n        \"name\": \"outbound|80||some.domain.com\",\n        \"type\": \"EDS\",\n        \"edsClusterConfig\": {\n            \"edsConfig\": {\n                \"ads\": {}\n            },\n            \"serviceName\": \"outbound|80||some.domain.com\"\n        },\n        \"connectTimeout\": \"10s\",\n        \"circuitBreakers\": {\n            \"thresholds\": [\n                {\n                    \"maxRetries\": 1024\n                }\n            ]\n        }\n    },\n...\n\n```\n<p>We can experiment with adding new ports (with different protocols) to the ServiceEntry to see how this affects the generation of new Clusters. A DestinationRule is another tool that may be used to generate and update Clusters in Istio. We establish new Clusters by creating Subsets, and we impact the configuration inside the Cluster by modifying load balancing and TLS settings.</p>\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: some-domain-com\nspec:\n  host: some.domain.com\n  subsets:\n  - name: v1\n    labels:\n      version: v1\n  - name: v2\n    labels:\n      version: v2\n```\n\n```\n$ istioctl proxy-config cluster istio-ingressgateway_PODNAME -o json\n\n\n[\n...\n    {\n        \"name\": \"outbound|80||some.domain.com\",\n...\n    },\n    {\n        \"name\": \"outbound|80|v1|some.domain.com\",\n...\n        \"metadata\": {\n            \"filterMetadata\": {\n                \"istio\": {\n                    \"config\": \"/apis/networking/v1alpha3/namespaces/default/destination-rule/some-domain-com\"\n                }\n            }\n        }\n    },\n    {\n        \"name\": \"outbound|80|v2|some.domain.com\",\n...\n    },\n...\n\n```\n\n<p>Notice that we still have our original cluster, outbound|80||some.domain.com, but that we got a new cluster for each Subset we defined as well. Istio annotates the Envoy configuration with the rule that resulted in it being created to help debug.</p>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Istio Pilot","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/istio-pilot"}},{"id":"4ce0d80d-d5ec-5b79-bd12-85e0eddf15a4","body":"import { ResourcesWrapper } from \"../../Resources.style.js\";\nimport BookinfoWith from \"./bookinfo-with-proxies.svg\";\nimport BookinfoWithout from \"./bookinfo-without-proxies.svg\";\nimport IstioArchitecture from \"./istio-architecture.svg\";\n\n<ResourcesWrapper>\n## Planes\n\nThe **data plane** in Istio intercepts each packet in the request and performs health checks, routing, load balancing, authorization, authentication,  and generation of observable signals. Service proxies are transparently placed in-band, and applications are oblivious of the data plane's presence when they conduct service-to-service calls. Intra-cluster communication and inbound (ingress), and outgoing (egress) cluster network traffic are handled by data planes. Application service traffic is directed first to the service proxy for processing, whether it is entering or leaving the mesh (ingressing or egressing). Istio's traffic is transparently intercepted and redirected to the service proxy using iptables rules.\n\nIstio's **control plane** provides a single point of administration for service proxies, which require programmatic configuration due to the need to manage a large number of them efficiently and have their configuration updated in real-time as services are rescheduled around your environment (i.e., container cluster). Control planes offer policy and configuration for the mesh's services, transforming a collection of isolated, stateless proxies into a service mesh. The control planes do not directly touch any network packets in the mesh. They operate out-of-band. Control planes usually feature a command line interface and a user interface, both of which provide access to a centralized API for regulating proxy behavior holistically. Changes to control plane configuration can be automated using its APIs (for example, using a CI/CD pipeline), however configuration is usually version-controlled and updated in practise. To summarize, Istio's control plane:\n\n- Provides policy and configuration for services in the mesh.\n    - APIs for operators to specify desired routing/resilience behavior.\n- Takes a set of isolated stateless sidecar proxies and turns them into a service mesh.\n    - APIs for the data plane to consume localized configuration.\n    - Service discovery abstraction for the data plane.\n- APIs for specifying usage policies\n    - Quota and Usage restrictions\n- Security\n    - Certificate issuance and rotation\n    - Assigning workload identity\n- Routing configuration\n    - Does not touch any packets/requests in the system.\n    - Specifying network boundaries and how to access them\n- Unified telemetry collection\n\n### Istio Control Plane Components\nWe'll go over the high-level functionality of each control plane component in this section.\n\n#### Pilot\n\nPilot is the head of the ship in an Istio mesh. Pilot keeps in sync with the underlying platform (e.g., Kubernetes) by tracking and representing the state and location of running services to the data plane.¬†Pilot communicates with the service discovery system in your environment and generates configuration for data plane service proxy.\n\nAs Istio evolves, Pilot's focus will shift¬†from interfacing with underlying platforms towards scalable serving of proxy configuration. It provides Envoy-compatible configuration by integrating configuration and endpoint information from multiple sources and translating it into xDS objects. Galley, another component, will eventually take responsibility for interfacing directly¬†with underlying platforms.\n\n#### Galley\n\nGalley is Istio's configuration aggregation and dissemination component. As its role progresses, it will insulate the rest of Istio's components from the underlying platform and user-supplied configuration by ingesting and validating configuration. Galley uses the Mesh Configuration Protocol (MCP) as a mechanism for serving and distributing configuration.\n\n#### Mixer\n\nMixer is a stand-alone control plane component that abstracts infrastructure backends from the rest of Istio. Infrastructure backends include things like Stackdriver and New Relic. Precondition checking, quota management, and telemetry reporting are all responsibilities of¬†the¬†Mixer.\n\n1. Enables platform & environment mobility\n2. Responsible for providing granular control over operational policies and telemetry for policy evaluation and telemetry reporting\n3. Has a rich configuration model\n4. Most infrastructure concerns are abstracted using intent-based configuration\n\nMixer is used by service proxies and gateways to execute precondition checks to assess whether a request should be allowed to proceed (check) or has exceeded quota depending on communication between the caller and the service, and to report telemetry once a request has completed (report). Mixer uses a set of native and third-party adapters to interface to infrastructure backends. Which telemetry is sent to which backend at what time is determined by adapter configuration. Mixer's adapters, which act as an attribute processing and routing engine, can be used by service mesh operators as a point of integration and intermediation with their infrastructure backends.\n\n#### Citadel\n\nCitadel gives Istio the ability to deliver strong service-to-service and end-user authentication via mutual TLS, as well as built-in identity and credential management. Citadel's certificate authority (CA) component¬†handles key and certificate generation, deployment, rotation, revocation, and approving and signing certificate signing requests (CSRs) sent by Citadel agents. Citadel has the (optional) ability to interact with an Identity Directory during the certificate approval process.\n\nCitadel offers a pluggable architecture that allows alternative certificate authorities (CAs) to sign workload certificates instead of Citadel's self-generated, self-signed signing key and certificate. Istio's CA pluggability enables and facilitates:\n\n- Integration with your organization‚Äôs existing Public Key Infrastructure (PKI) system.\n- Secure communication between Istio services and non-Istio legacy services (by sharing the same root of trust)\n- Protection of the CA signing key by storing it in a well-protected environment (e.g. Vault + HSM)\n\n### Istio Data Plane Components\n\nTo mediate both inbound and outbound traffic for all services in the service mesh, Istio uses an extended version of Envoy, a high-performance proxy written in C++. Istio utilizes¬† Envoy's¬†capabilities like dynamic service discovery, load balancing, TLS termination, HTTP/2 and gRPC proxying, circuit breakers, health checks, staged rollouts with %-based¬†traffic split, fault injection, and rich metrics.\n\nEnvoy is deployed as a sidecar to the relevant service in the same Kubernetes pod. This allows Istio to extract a multitude of signals about traffic behavior as attributes, which it can use in Mixer to enforce policy decisions and be sent to monitoring systems to provide information about the behavior of the entire mesh.\n\n#### Injection\n<img src={BookinfoWithout} className=\"image-right\" alt=\"BookInfo without proxies\" />\n\nYou can easily add Istio capabilities to an existing deployment without having to re-architect or rewrite code using the sidecar proxy model. This is one of the most compelling reasons to use Istio. The promises of immediate view¬†to top-level service metrics, detailed traffic control, and automated authentication and encryption across all services without having to do either:\n\n1. change your application code\n2. change your deployment manifests\n\nUsing the canonical sample application BookInfo you can see how service proxies come into play and form a mesh.\n<img src={BookinfoWith} className=\"image-left\" alt=\"BookInfo with proxies\" />\n\nIn Kubernetes, automatic proxy injection is implemented as a webhook using a Kubernetes API Server with the Mutating Webhook Admission Controller. It is stateless, relying solely on the injection template and mesh configuration configmaps and the to-be-injected pod object. It can be easily horizontally scaled, either manually via the deployment object or automatically via a Horizontal Pod Autoscaler.\n\nIstio addresses one of the most well-known distributed systems issues: the lack of homogeneous, reliable, and unchanging networks. It accomplishes this by using lightweight proxies¬† deployed between your application containers and the network.\n\n### Gateways\n\nIngress and egress gateways were first introduced in Istio 0.8. Ingress and egress gateways are symmetrically similar and serve as reverse and forward proxies for traffic entering and leaving the mesh, respectively. Istio Gateways' behavior, like that of other Istio components, is defined and controlled through configuration, allowing you to specify which traffic to let in and out of the service mesh, at what rate, and so on.\n\n#### Ingress\n\nConfiguration of ingress gateways allow you to define traffic entryways into the service mesh for incoming traffic to flow through. Consider that ingressing traffic into the mesh is a reverse proxy situation - akin to traditional web server load balancing. The configuration for egressing traffic out of the mesh is a forward proxy situation (similar to traditional) in which you determine which traffic to allow out of the mesh and where it should be routed.\n\nFor example, the following Gateway configuration sets up a proxy to act as a load balancer exposing port 80 and 9080 (http), 443 (https), and port 2379 (TCP) for ingress. The gateway will be applied to the proxy running on a pod with labels app: my-gateway-controller. While Istio will configure the proxy to listen on these ports, it is the responsibility of the user to ensure that external traffic to these ports are allowed into the mesh.\n\n\n```yaml\n\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: my-gateway\nspec:\n  selector:\n    app: my-gateway-controller\n  servers:\n  - port:\n      number: 80\n      name: http\n      protocol: HTTP\n    hosts:\n    - uk.bookinfo.com\n    - eu.bookinfo.com\n    tls:\n      httpsRedirect: true # sends 301 redirect for http requests\n  - port:\n      number: 443\n      name: https\n      protocol: HTTPS\n    hosts:\n    - uk.bookinfo.com\n    - eu.bookinfo.com\n    tls:\n      mode: SIMPLE #enables HTTPS on this port\n      serverCertificate: /etc/certs/servercert.pem\n      privateKey: /etc/certs/privatekey.pem\n  - port:\n      number: 9080\n      name: http-wildcard\n      protocol: HTTP\n    hosts:\n    - \"*\"\n  - port:\n      number: 2379 # to expose internal service via external port 2379\n      name: mongo\n      protocol: MONGO\n    hosts:\n    - \"*\"\n```\n#### Egress\nTraffic can exit an Istio service mesh in two ways - directly from the sidecar or funnelled through an egress gateway, where traffic policy may be applied.\n\n<div className=\"fact\">\n\nBy default, Istio-enabled applications are unable to access URLs external the cluster.\n\n</div>\n\n#### Direct from Service Proxy\n\nYou can configure the ConfigMap of the istio-sidecar-injector to allow traffic headed for an external source, bypassing the egress gateway. Set the following configuration in the sidecar injector, which will identify cluster-local networks and keep traffic destined locally within the mesh, while forwarding traffic for all other destinations externally.\n\n```yaml\n--set global.proxy.includeIPRanges=\"10.0.0.1/24\"\n```\n\nExternal requests bypass the sidecar and route directly to the intended destination once this configuration is deployed and istio proxies are updated. Only internal requests within the cluster will be intercepted and managed by the Istio sidecar.\n\n#### Route through an Egress Gateway\n\nIstio monitoring and route rules can be applied to traffic leaving the mesh through an egress gateway. It also enables communication between applications running in a cluster where the nodes lack public IP addresses, preventing the mesh's applications from accessing the Internet. The nodes (and the applications running on them) can access external services in a regulated manner by defining an egress gateway, directing all egress traffic through it, and allocating public IPs to the egress gateway nodes.¬†\n\n<img src={IstioArchitecture} className=\"image-center\" alt=\"Istio Architecture\" />\n\n<div className=\"intro\" style={{textAlign: \"center\"}}>\n\n**Why use Istio Gateways and not Kubernetes Ingresses?**\n\nIn general, the Istio v1alpha3 APIs leverage Gateways for richer functionality as Kubernetes Ingress has proven insufficient for Istio applications. In comparison to Kubernetes Ingress, Istio Gateways can function as a pure L4 TCP proxy and support all protocols supported by Envoy.\n\nAnother factor to examine is the division of trust domains between organizational teams. Kubernetes Ingress API combines specification for L4 to L7, which makes it challenging for different teams in organizations with separate trust domains (such as SecOps, NetOps, ClusterOps and Developers) to own Ingress traffic management.\n\n</div>\n\n</ResourcesWrapper>\n\n","frontmatter":{"title":"Istio v1.5 at a Glance","type":"Article","technology":"Kubernetes","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/istio-v15-at-a-glance"}},{"id":"be9a13a3-5dd1-581f-9e7b-e28c67e58168","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n<div className=\"intro\">\n\nIstio is a massive project with a wide range of capabilities and deployment options. We will perform a basic installation on your local machine and deploy a few services onto the mesh. Let‚Äôs start by understanding its supported platforms and configuring our environment for deployment.\n\n</div>\n\n### Preparing Your Environment for Istio\n\nIn addition to Istio, we'll be deploying BookInfo, its sample¬†application. Our Istio and BookInfo deployments will lay down several containers. We will use Kubernetes as the platform to manage these containers. Kubernetes is a robust container orchestration system capable of forming clusters (a collection of nodes) and scheduling containers across nodes within the fleet of host machines (nodes) that form the cluster. Nodes are Linux or Windows servers that can run containers with a Kubernetes agent, kubelet, installed. Kubernetes is the first and best supported underlying platform among a variety of to-be-supported underlying systems. As a result, we'll be using Kubernetes throughout our examples. To be clear, Istio is not dependent on Kubernetes. Istio is designed to be platform agnostic and supports multiple deployment platforms including those without a container orchestrator.\n\n#### Docker Desktop as the Installation Environment\n\nWe can deploy Kubernetes in a variety of ways. We'll utilize Docker Desktop as a convenient tool for this. Docker Desktop is an easy-to-install application for your Mac or Windows environment¬†that allows you to run Kubernetes and Istio on your local machine.\n\nInstall Docker Desktop and verify that you have a functional Docker environment by running `$ docker run hello-world` on the command line. If you get a ‚ÄúHello from Docker!‚Äù message, you‚Äôve confirmed that Docker isable to pull images, create new instances, and run as expected.\n\nWe'll run Kubernetes on Docker Desktop and leverage Kubernetes as the platform to deploy¬†Istio. The Docker Desktop managed Kubernetes server is a single-node Kubernetes cluster that runs locally within your Docker instance. It is not configurable.\n\nThe Docker Desktop for Mac Kubernetes integration provides the Kubernetes CLI executable at `/usr/local/bin/kubectl`. The Docker Desktop for Windows Kubernetes integration provides the Kubernetes CLI executable at `C:\\>Program Files\\Docker\\Docker\\Resources\\bin\\kubectl.exe`. This location may not be in your shell‚Äôs `PATH` variable, so you may need to type the full path of the command or add it to the `PATH`. For more information about `kubectl`, see the official `kubectl` documentation.\n\n#### Configuring Docker Desktop\n\nTo make sure your Docker Desktop virtual machine has enough memory to run Kubernetes, Istio, and Istio's sample application, BookInfo, you'll need to set it up with at least 4GiB of RAM. All Istio and BookInfo services require this amount of memory to operate effectively.¬† Pilot, in particular, may have problems running as it requests¬†2048Mi of memory in an Istio deployment with default settings (see <Link to=\"/resources/service-mesh/istio-v15-at-a-glance\"> Istio v1.5 at a Glance</Link> for a quick overview of Pilot's purpose). Considering 2048Mi is also the default limit for Docker Desktop, Pilot may refuse to start due to insufficient resources¬†if this limit is not increased in your Docker installation.\n\nInstead of increasing the amount of memory allocated to your Docker Desktop installation, you may limit the amount of memory that Pilot requests of your Kubernetes cluster.  Depending on whether you're utilizing a package manager like Helm or directly using Kubernetes spec files, there are a couple of options.\n\nUsing `install/kubernetes/istio-demo.yaml` as an example manifest, lets highlights which section of the Pilo spec to edit in order to reduce the 2048Mi of memory requested by Pilot to something smaller like 512Mi.\n\n``` \napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: istio-pilot\n  namespace: istio-system\n...\n          resources:\n            requests:\n              cpu: 500m\n              memory: 2048Mi\n...\n\n```\n\nWhen deploying Istio with Helm, you can also offer custom settings. \nTo customize Istio install using Helm, use the `--set key=value` option in Helm command to override one or more values. \nAn example of reducing Pilot‚Äôs requested memory resources is shown below.\n\n``` \n$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system --set pilot.resources.requests.memory=\"512Mi\" | kubectl apply -f -\n```\n\n#### Deploying Kubernetes\n\nIf Kubernetes is not installed on your desktop please refer to Troubleshooting for helpful tips on installing Kubernetes. Verify `kubectl` installation by running:\n\n``` \n$ kubectl version --short\nClient Version: v1.13.0\nServer Version: v1.13.0\n\n```\n\nIf you see both client and server version numbers, your `kubectl` client is installed in your `PATH` and a Kubernetes cluster is accessible. Verify Kubernetes installation and your current context by running `$ kubectl get nodes` which will confirm that your kubeconfig (typically located at `~/.kube/config`) is correctly configured to the `docker-desktop` context and your single-node cluster is up:\n\n``` \n$ kubectl get nodes\nNAME             STATUS   ROLES    AGE   VERSION\ndocker-desktop   Ready    master   32m   v1.13.0\n\n```\n\n#### Install Kubernetes Dashboard\n\nThe Kubernetes dashboard is a web-based user interface that allows you to manage your cluster and its¬†resources. Containerized applications can be deployed and troubleshooted. The Kubernetes dashboard shows the current state of¬†Kubernetes resources in your cluster¬†as well as any faults that may have occurred. The Kubernetes dashboard can be used to reinforce your understanding of how Istio runs. The easiest and most common way to access the cluster is through `kubectl proxy`, which creates a local web server that securely proxies data to the Kubernetes dashboard through the Kubernetes API server.¬†Execute the following command to deploy the Kubernetes dashboard:\n\n``` \n$ kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml\n\n```\n\nOnce deployed, you can access the Kubernetes dashboard using the kubectl command-line tool by running the following command:\n\n``` \n$ kubectl proxy\n```\n\nThis command creates a local web server that uses the Kubernetes API server to securely proxy data to the Kubernetes dashboard. It's important to note that the Kubernetes dashboard can only be accessed from the machine where the command is executed.\n\nSee `kubectl proxy --help` for more options and the Kubernetes dashboard documentation for more information. `kubectl` will make the Kubernetes dashboard available at `http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/`.\n\nDashboard deploys with a minimal RBAC configuration by default to secure your cluster data. Only a Bearer Token is currently supported for logging into the Kubernetes dashboard. Create a sample user and use its token, or use an existing token provided by your Docker Desktop deployment, and then run:\n\n``` \n$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | awk '/default-token/ {print $1}')\n```\nThis will print something similar to:\n\n``` \nName:         default-token-tktcn\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  kubernetes.io/service-account.name: default\n              kubernetes.io/service-account.uid: 3a0a68b1-4abd-11e9-8561-025000000001\n\nType:  kubernetes.io/service-account-token\n\nData\n====\nca.crt:     1025 bytes\nnamespace:  11 bytes\ntoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLXRrdGNuIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzYTBhNjhiMS00YWJkLTExZTktODU2MS0wMjUwMDAwMDAwMDEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.WBOH85PHBVjky9JZLidfzS8EWNunIlFZR8MIJjMgBxQbVnqaVl0RmzcvZqYZRY9W7bwQddkXXHAuw5QQMfy8S-I2KdgxpQEP18tfU9wicv6TWt9bRfw9N7QsvB-twlMCEpRKtHwrORZqgRb7_13UH14RB18DiUAIiMok6rs1Pl5w9y0RXVUk9_RXMA2hJnkZ09cTOqJmQ80Vg4QvgAhuxwgmb6kl2rMjb0LegXihAN6j6Yv_JHZ2Vgjk73Priig0Pbjic6t87XfO51Kgjgw7g0vCF0OlOylvp-5oroPMa3nnnlqh6PGnFzOq0zLqjqYXMXZFI5cWkNmf71Q_qKSOsA\n\n```\nCopy the token and use it to authenticate in the Kubernetes dashboard.\n\n### Installing Istio\n\nWith Kubernetes deployed and dashboard up, it‚Äôs time to install our service mesh. You can download the latest Istio release by executing the following command:\n\n```\n$ curl -L https://git.io/getLatestIstio | sh -\n```\n\nThe script fetches the latest Istio release candidate and untars it.\n\nIf you would like to fetch a particular version of Istio, specify the desired version number as so:\n\n```\n$ curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.1.0 sh -\n```\n\nIstio can also be downloaded from the [Istio release page](https://github.com/istio/istio/releases).¬†There are versions for Windows, MacOS, and Linux to pick from. After downloading the distribution for your operating system, extract the compressed file to a directory and acquaint yourself with the contents of the distribution, regardless of the operating system you're using.\n\nEach release includes `istioctl`, configuration samples, a sample application and platform-specific installation resources. `istioctl` is a command line utility for service operators to debug and diagnose their Istio service mesh. Alternatively, `istioctl` can be installed via your preferred  package manager.\n\nExplore release contents on MacOS or Linux by changing directory to ‚Äúistio-x.x.x‚Äù. For example:\n\n```\n$ cd istio-1.1.0\n```\n\nThis directory contains the files necessary for installing Istio, sample files and also `istioctl`, an important command-line tool used to manage your Istio deployment.\n\n```\n$ ls -l\ntotal 48\n-rw-r--r--   1  user  staff  11343 Mar 18 16:08 LICENSE\n-rw-r--r--   1  user  staff   5921 Mar 18 16:08 README.md\ndrwxr-xr-x   3  user  staff     96 Mar 18 16:08 bin\ndrwxr-xr-x   7  user  staff    224 Mar 18 16:08 install\n-rw-r--r--   1  user  staff    602 Mar 18 16:08 istio.VERSION\ndrwxr-xr-x  16  user  staff    512 Mar 18 16:08 samples\ndrwxr-xr-x  21  user  staff    672 Mar 18 16:08 tools\n```\n\nThe installation directory contains Istio installation `YAML` files for Kubernetes in `install/`, sample applications in `samples/`, the `istioctl` client binary in the `bin/` directory. \nThe `istio.VERSION` configuration file contains a list of Istio components and their version numbers for the release‚Äôs distribution.\n\n`istioctl` is the Istio configuration command line utility. `istioctl` is used for setting routing rules, policies, and injecting Envoy as a service proxy manually, among other things. It is also used to create, list, modify, and delete configuration resources in the Istio system. Let‚Äôs add it to your `PATH` environment variable:\n\n```\n$ export PATH=$PWD/bin:$PATH\n```\n\nVerify your istioctl installation by running:\n\n```\n$ istioctl version\n```\n\nThis should validate path and istioctl command options (see Example 4.7). If not, see Troubleshooting.\n\n```\nversion.BuildInfo{\nVersion:\"1.1.0\", GitRevision:\"82797c0c0649a3f73029b33957ae105260458c6e\", \nUser:\"root\", \nHost:\"996cd064-49c1-11e9-813c-0a580a2c0506\", GolangVersion:\"go1.10.4\", \nDockerHub:\"docker.io/istio\", \nBuildStatus:\"Clean\", \nGitTag:\"1.1.0-rc.6\"\n}\n```\n\nNow that we have downloaded an Istio distribution and verified it‚Äôs CLI tool, istioctl, is functional on our local machine, let‚Äôs perform a basic installation.\n\n#### Istio Installation Options\n\nThere are numerous installation and deployment architectures to choose from. Typically, installations fit into one of the following categories:\n\n##### Choice of Security Configuration\n\n- Install with strict mutual TLS authentication.\n    - Recommended for fresh kubernetes cluster. This method enforces authentication between sidecars by default.\n- Install with permissive mutual TLS authentication between sidecars.\n    - Recommended if you have existing clusters and services.\n    - Recommended if you have applications where services with an Istio sidecar need to be able to communicate with other non-Istio Kubernetes services\n- Custom deployments that include or exclude certain default Istio components.\n    - Recommended if a function of one of Istio‚Äôs components isn‚Äôt necessary or desired in your environment (e.g. removal of Citadel if mTLS is not to be used).\n\n##### Choice of Deployment Utility\n\n- Render Kubernetes manifests directly with kubectl.\n    - Recommended for understanding Istio‚Äôs underpinnings more explicitly.\n- Render Kubernetes manifests with a package / configuration management system like Helm or Ansible.\n    - Recommended for production deployments with templated configuration.\n\n### Registering Istio‚Äôs Custom Resources\n\nUse the following command to apply Istio‚Äôs CustomResourceDefinition objects to your cluster:\n\n```\n$ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl apply -f $i; done\n```\n\nThis installation does not leverage Helm (a package manager for Kubernetes). The generally preferred method for any installation of Istio that may find its way into production is to use Helm or Ansible; both included in the distribution you just downloaded. With Helm or Ansible you get more flexibility in which components you install and can fine-tune your setup.\n\n```\n$ kubectl  api-resources | grep istio\nmeshpolicies                                   authentication.istio.io        false        MeshPolicy\npolicies                                       authentication.istio.io        true         Policy\nadapters                                       config.istio.io                true         adapter\napikeys                                        config.istio.io                true         apikey\nattributemanifests                             config.istio.io                true         attributemanifest\nauthorizations                                 config.istio.io                true         authorization\nbypasses                                       config.istio.io                true         bypass\nchecknothings                                  config.istio.io                true         checknothing\ncirconuses                                     config.istio.io                true         circonus\ncloudwatches                                   config.istio.io                true         cloudwatch\n...\n```\n\nIstio actually registers new types of resources, Custom Resource Definitions (CRDs) which represent things like Gateways or Services. We can manipulate (create/update/delete) them just like any other Kubernetes object:\n\n```\n$ kubectl get crd | grep istio\nadapters.config.istio.io               2019-03-24T03:17:08Z\napikeys.config.istio.io                2019-03-24T03:17:07Z\nattributemanifests.config.istio.io     2019-03-24T03:17:07Z\nauthorizations.config.istio.io         2019-03-24T03:17:07Z\nbypasses.config.istio.io               2019-03-24T03:17:07Z\nchecknothings.config.istio.io          2019-03-24T03:17:07Z\ncirconuses.config.istio.io             2019-03-24T03:17:07Z\ncloudwatches.config.istio.io           2019-03-24T03:17:08Z\nclusterrbacconfigs.rbac.istio.io       2019-03-24T03:17:07Z\ndeniers.config.istio.io                2019-03-24T03:17:07Z\ndestinationrules.networking.istio.io   2019-03-24T03:17:07Z\ndogstatsds.config.istio.io             2019-03-24T03:17:08Z\nedges.config.istio.io                  2019-03-24T03:17:08Z\nenvoyfilters.networking.istio.io       2019-03-24T03:17:07Z\n...\n```\n\nOnce Istio‚Äôs custom resources are registered with Kubernetes, Istio control plane components may be installed.\n\n#### Installing Istio Control Plane Components\n\nThe istio-demo.yaml specification file contains Istio configuration that allows services to run in mutual TLS permissive mode. If you have existing services or applications in your Kubernetes cluster, it¬†is recommended to use mTLS permissive mode. If you're setting up a fresh¬†cluster, security best practises recommend using `istio-demo-auth.yaml`¬†to encrypt service traffic between sidecars.\n\n```\n$ kubectl apply -f install/kubernetes/istio-demo.yaml\n```\n\nPlease wait for a few minutes to let the installation run, for the Docker images to properly download and for the deployments to succeed. The application of this extensive yaml file has Kubernetes realize many new Custom Resource Definitions.\n\nYou might also use `istio-demo-auth.yaml`, which enforces mutual TLS authentication between all clients and servers. You might consider that initial deployment of Istio with strict mTLS enforcement configured is most successfully used within fresh Kubernetes cluster where all workloads will be Istio-enabled. To apply Istio setup with mutual TLS authentication, use the command below:\n\n```\n$ kubectl apply -f install/kubernetes/istio-demo-auth.yaml\n```\n\nIstio's control plane is installed in its own istio-system namespace, and it supervises services in all other namespaces with sidecar proxies, or in other words, all other namespaces with services on the mesh. The control plane is deployed in the istio-system namespace act as a cluster-wide, which means that behaves in a single-tenant fashion.\n\n```\n$ kubectl get namespaces\nNAME           STATUS   AGE\ndefault        Active   49d\ndocker         Active   49d\nistio-system   Active   2m15s\nkube-public    Active   49d\nkube-system    Active   49d\n```\n\nVerify installation of the control plane into the `istio-system` namespace using commands:\n\n```\n$ kubectl get namespaces\nNAME           STATUS   AGE\ndefault        Active   49d\ndocker         Active   49d\nistio-system   Active   2m15s\nkube-public    Active   49d\nkube-system    Active   49d\n\nExample 4.11 - istio-system namespace created to contain Istio control plane components.\n\nVerify installation of the control plane into the istio-system namespace using commands:\n\n$ kubectl get svc -n istio-system\nNAME                     TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                                                                      AGE\ngrafana                  ClusterIP      10.108.237.105   <none>        3000/TCP                                                                                                                                     11d\nistio-citadel            ClusterIP      10.108.165.14    <none>        8060/TCP,15014/TCP                                                                                                                           11d\nistio-egressgateway      ClusterIP      10.107.148.169   <none>        80/TCP,443/TCP,15443/TCP                                                                                                                     11d\n...\n\n$ kubectl get pod -n istio-system\nNAME                                      READY   STATUS      RESTARTS   AGE\ngrafana-57586c685b-jr2pd                  1/1     Running     0          5m45s\nistio-citadel-645ffc4999-8j4v6            1/1     Running     0          5m45s\nistio-cleanup-secrets-1.1.0-4c9pc         0/1     Completed   0          5m48s\nistio-egressgateway-5c7fd57fdb-85g26      1/1     Running     0          5m46s\nistio-galley-978f9447f-mj5xj              1/1     Running     0          5m46s\nistio-grafana-post-install-1.1.0-g49gh    0/1     Completed   0          5m48s\nistio-ingressgateway-8ccdc79bc-8mk4p      1/1     Running     0          5m46s\nistio-pilot-649455846-klc8c               2/2     Running     0          5m45s\nistio-policy-7b7d7f644b-sqsp8             2/2     Running     4          5m45s\nistio-security-post-install-1.1.0-v4ffp   0/1     Completed   0          5m48s\nistio-sidecar-injector-6dcc9d5c64-tklqz   1/1     Running     0          5m45s\nistio-telemetry-6d494cd676-n6pkz          2/2     Running     4          5m45s\nistio-tracing-656f9fc99c-nn9hd            1/1     Running     0          5m44s\nkiali-69d6978b45-7q7ms                    1/1     Running     0          5m45s\nprometheus-66c9f5694-2xzpm                1/1     Running     0          5m45s\n```\n\nWe've only deployed half of the service mesh so far, the control plane. You may not have noticed service proxies prior to deploying the sample application, and thus the data plane, because we have not deployed any services (applications) to run on the mesh. You may believe that no proxies are running, but you would be overlooking the fact that two proxies are already running. Our service proxy is up and operating on both the ingress and egress gateways. Let's have a look.\n\n#### Deploy Sample Application\n\nLet's get started by deploying our first set of services (an application) to the service mesh. We'll utilise BookInfo, an Istio sample application that demonstrates many aspects of the value proposition of service meshes. The Kubernetes manifest files for BookInfo may be found in the `samples/bookinfo/` subdirectory in your release distribution folder.¬† Let's take a moment to familiarise with this application.\n\nTo populate the page, users call the `productpage`¬†microservice, which then calls the `details`¬†and `reviews`¬†microservices. The book information can be found in the `details`¬†microservice. The `reviews` microservice contains book reviews and subsequently calls the `ratings` microservice to retrieve reviews. The `ratings` microservice contains book ranking in the form of a 1 to 5 star book review.¬†¬†There are three versions of the `reviews`¬†microservice:\nEach of the four application services are written in a different language - Python, Ruby, Java, Nodejs, which further demonstrates the value of a service mesh.\n\n- reviews v1 has no ratings (does not call the ratings service).\n- reviews v2 has ratings of 1 to 5 black stars (calls the ratings service).\n- reviews v3 has ratings of 1 to 5 red stars (calls the ratings service).\n\nThe application does not need to be changed to run the sample using Istio. Instead, we'll configure and run the services in an Istio-enabled environment, with service proxies injected alongside each service as sidecars. Istio's service proxies can be injected as sidecars to application services either manually or automatically. As we deploy our sample application, let's have a look at how automated sidecar injection works.\n\n#### Deploying Sample App with Automatic Sidecar Injection\n\nIstio will deploy a sidecar injector in order to have Envoy deployed as sidecars to each of our services. Let's check for the presence of the sidecar injector deployment and its namespace label, which specifies that pods in a specific namespace will have sidecar injected automatically upon deployment (admission):\n\n```\n$ kubectl -n istio-system get deployment -l istio=sidecar-injector\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nistio-sidecar-injector   1/1     1            1           82m\n```\n\nLabel the default namespace with `istio-injection=enabled`\n\n```\n$ kubectl label namespace default istio-injection=enabled\n```\n\nAnd confirm which namespaces have the istio-injection label associated:\n\n```\n$ kubectl get namespace -L istio-injection\nNAME           STATUS    AGE       ISTIO-INJECTION\ndefault        Active    1h        enabled\nDocker         Active    1h        enabled\nistio-system   Active    1h        disabled\nkube-public    Active    1h        \nkube-system    Active    1h\n```\n\nThe `istio-demo.yaml` deployment we ran has automatic injection configured.\n\nWe can now deploy the sample app after installing the sidecar injector with modifying admission webhook and the namespace designated for automatic sidecar injection.\n\n```\n$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n```\n\nWith sample application deployed, you can confirm that automatic sidecar injection is working in your environment by inspecting any one of the BookInfo pods and noting the istio-proxy container as a new addition to the application pod. \n\n```\n$ kubectl describe po/productpage-v1-....\n...\nistio-proxy:\n    Container ID:  docker://f28abdf1f0acf92687711488f7fcca8cc5968e2ed39d8275bf57cc46b5ae2257\n    Image:         docker.io/istio/proxyv2:1.1.7\n    Image ID:      docker-pullable://istio/proxyv2@sha256:e6f039115c7d5ef9c8f6b049866fbf9b6f5e2255d3a733bb8756b36927749822\n    Port:          15090/TCP\n    Host Port:     0/TCP\n    Args:\n      proxy\n      sidecar\n...\n```\n\n#### Networking with the Sample App\n\nAfter the Bookinfo services are up and running, you'll need to make the application accessible from outside your Kubernetes cluster, such as through a browser. This is accomplished through the usage of an Istio Gateway. You'll need to specify the application's ingress gateway:\n\n```\n$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml\n```\n\nConfirm the gateway has been created:\n\n```\n$ kubectl get gateway\n\nNAME               AGE\nbookinfo-gateway   7m\n```\n\nFind where the `productpage`¬†has been exposed as a service available to handle requests from outside of the cluster to interact with the freshly deployed application.\n\n```\n$ echo \"http://$(kubectl get nodes -o template --template='{{range.items}}{{range.status.addresses}}{{if eq .type \"InternalIP\"}}{{.address}}{{end}}{{end}}{{end}}'):$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.spec.ports[0].nodePort}')/productpage\"\n\nhttp://x.x.x.x:31380/productpage\n```\n\n#### Uninstall Istio\n\nIt's a common mistake to assume that deleting the istio-system namespace will uninstall¬†Istio. Deleting the istio-system removes Istio‚Äôs control plane components, but leaves CRDs, sidecars and other artifacts resident in your cluster. Uninstalling Istio is as simple as executing this command from within your istio release folder:\n\n```\n$ kubectl delete -f install/kubernetes/istio-demo.yaml\n```\n\nThis will not delete all of the Istio custom resource definitions, mesh configuration and sample application, however. In order to delete these, run:\n\n```\n$ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl delete -f $i; done\n$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n$ kubectl delete -f samples/bookinfo/networking/bookinfo-gateway.yaml\n```\n\nYou can verify the success of Istio and BookInfo‚Äôs removal by running:\n\n```\n$ kubectl get crds\n$ kubectl get pods\n```\n\n</ResourcesWrapper>","frontmatter":{"title":"Deploying Istio","type":"Article","technology":"Docker","product":null,"mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/deploying-istio"}},{"id":"b20bd734-eb5b-5c29-abaa-d2b13d6c327c","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Library from \"./using-different-microservice-client-libraries.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n  Client libraries (microservices frameworks) became very popular as microservices took a foothold in modern application design to avoid rewriting the same logic in every service. Example frameworks include the following:\n\n  - ### Twitter Finagle\n    An open source remote procedure call (RPC) library built on Netty for engineers that want a strongly-typed language on the Java Virtual Machine (JVM). Finagle is written in Scala.\n\n  - ### Netflix Hystrix\n    An open source latency and fault tolerance library designed to isolate points of access to remote systems, services, and third-party libraries; stop cascading failure; and enable resilience. Hystrix is written in Java.\n\n  - ### Netflix Ribbon\n    An open source Inter-Process Communication (IPCs) library with built-in software load balancers. Ribbon is written in Java.\n\n  - ### Gokit\n    An open source toolkit for building microservices (or elegant monoliths) with gRPC as the primary messaging pattern. Gokit is written in Go and comes with pluggable serialization and transport.\n\n  - ### DropWizard, Spring Boot, Akka‚Ä¶ and others.\n\n\n  <div className=\"fact\">\n    <p>\n      See the Layer5 <Link to=\"/landscape\">service mesh landscape</Link> for a comprehensive perspective of and characterizing of all popular client libraries.\n    </p>\n  </div>\n\n  Prior to the availability of service meshes, developers used language-specific microservices frameworks to improve the resiliency, security, and observability of their services. The drawback of client libraries is that they embed¬†infrastructure concerns into your application code. Services that embed the same client library across themselves in the presence of a service mesh incorporate duplicative code. Inconsistency is a concern for services that include different client libraries or different versions of the same client library. In environments with polyglot microservices, different client libraries are used.\n\n  Getting teams to update their client libraries can be an arduous process. When these infrastructure concerns are embedded in your service code, you'll need to track down your developers to update and reconfigure these libraries.¬† It can take a long time to get a consistent configuration with the same and most recent version deployed.¬† Enforcing consistency is challenging. ¬†As seen in the figure below, these frameworks couple¬†your services with¬†the infrastructure.\n\n  <div className=\"center\" >\n    <img src={Library} align=\"right\" alt=\"service mesh client libraries\" />\n    <p>Figure 1: Services architecture using client libraries coupled with application logic</p>\n  </div>\n\n  Different services teams must negotiate things like timeouts and retries when infrastructure code is embedded in the application. A service mesh not only decouples infrastructure code from application code, but it also decouples teams. Service meshes are typically implemented as infrastructure that exists outside of your applications, but as their adoption increases, this is changing, and their use for influencing or implementing business logic is becoming more prevalent.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Client Libraries","type":"Article","technology":"Docker","product":"Meshery","mesh":"Linkerd","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRi4BAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSFsAAAABYJpt243X+ax9C1hFYgWRAaxiAtUIklH0N9Pf65L8/wQRQTZpE+f2EPyykTyAieQNNCTZ75JOYJb0AK0kjU4tzg3+8ju7zFZJr1nncJSWZZkBcfkBgvITwRcAAFZQOCCsAAAAMAQAnQEqFAAPAD7RVKNLqCSjIbAIAQAaCWcAwoGMRLsm0wASOs234oIAAP6XHNuXBCJ2KQ+ecb3PQ0c5fwSZNvgHm6OoXnjbpxb69DLufGEPdUvlyKFovtxZtq7T5YKEfrAwfrmNDOvM094GU6qVTgZRo3uaELC6VNn1m1jlYWe8PKt9B890YGLcCtNa4BMInybbNJw1i5CJVGJRHTu0yMIrOUbGYRF8ggQAAA=="},"images":{"fallback":{"src":"/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp","srcSet":"/static/c20824e5fc301bc720fc8d9e96c83d9c/66907/using-different-microservice-client-libraries.webp 750w,\n/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.75}},"extension":"webp","publicURL":"/static/c20824e5fc301bc720fc8d9e96c83d9c/using-different-microservice-client-libraries.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRi4BAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSFsAAAABYJpt243X+ax9C1hFYgWRAaxiAtUIklH0N9Pf65L8/wQRQTZpE+f2EPyykTyAieQNNCTZ75JOYJb0AK0kjU4tzg3+8ju7zFZJr1nncJSWZZkBcfkBgvITwRcAAFZQOCCsAAAAMAQAnQEqFAAPAD7RVKNLqCSjIbAIAQAaCWcAwoGMRLsm0wASOs234oIAAP6XHNuXBCJ2KQ+ecb3PQ0c5fwSZNvgHm6OoXnjbpxb69DLufGEPdUvlyKFovtxZtq7T5YKEfrAwfrmNDOvM094GU6qVTgZRo3uaELC6VNn1m1jlYWe8PKt9B890YGLcCtNa4BMInybbNJw1i5CJVGJRHTu0yMIrOUbGYRF8ggQAAA=="},"images":{"fallback":{"src":"/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp","srcSet":"/static/c20824e5fc301bc720fc8d9e96c83d9c/66907/using-different-microservice-client-libraries.webp 750w,\n/static/c20824e5fc301bc720fc8d9e96c83d9c/55375/using-different-microservice-client-libraries.webp 960w","sizes":"100vw"},"sources":[]},"width":1,"height":0.75}},"extension":"webp","publicURL":"/static/c20824e5fc301bc720fc8d9e96c83d9c/using-different-microservice-client-libraries.webp"}},"fields":{"slug":"/resources/service-mesh/client-libraries"}},{"id":"36d16c3d-7694-5d62-a482-582be4038596","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Api from \"./citrix-api-security-considerations-by-traffic-direction.svg\";\n\n\n<ResourcesWrapper>\n\n  Historically, application delivery controllers were purchased, deployed, and managed by IT professionals most commonly to run enterprise-architected applications. With their distributed systems design and ephemeral infrastructure, cloud native applications require load balancers to be as dynamic as the infrastructure (containers, for example) upon which they run. These are often software load balancers. Because cloud native applications are typically developer-led initiatives in which developers are creating the application ‚Äî that is, the microservices ‚Äî and the infrastructure, developers and platform teams are increasingly making, or heavily influencing, decisions for load balancing (and other) infrastructure.\n\n  Selecting your proxy is one of the most important decision your team will make. A developer‚Äôs selection process gives heavier weight to a proxy‚Äôs APIs (due to their ability to programmatically configure the proxy) and on a proxy‚Äôs cloud native integrations (as previously noted). A top item on the list of demands for proxies is protocol support. Generally, protocol considerations can be broken into two types:\n\n  - TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.\n  - gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.\n\n  <div className=\"intro\">\n    ### Tip: HTTP2, gRPC, NATS\n    <p>\n        At the heart of many distributed systems architectures are streaming and messaging protocols. When your applications need higher performance than JSON-REST, the application architecture commonly includes use of gRPC or NATS. REST is often found on the perimeter of the services while gRPC is used for service-to-service interactions. gRPC is a universal RPC framework. NATS is a multi-modal messaging system that includes request/reply, pub/sub and load balanced queues.\n    </p>\n  </div>\n\n  The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:\n\n  - High performance and low latency\n  - High scalability and small memory footprint\n  - Deep observability at all layers of the network stack\n  - Programmatic configuration and ecosystem integration\n\n  With a Kubernetes-native control plane, using CRDs and associated controllers enables powerful simplification, easy scaling, and intent-driven infrastructure. It is critical that the proxy has the capability to be intent-driven using Kubernetes CRDs and controllers (preferably an open source proxy like the Citrix Ingress Controller). It‚Äôs the robustness of a proxy‚Äôs cloud native integrations and configuration APIs, like the Citrix Nitro API, that enables this. Not only are the proxy‚Äôs configuration APIs a key consideration, but so is the method by which they handle your applications‚Äô APIs, specifically their security.\n\n  ### TCP/UDP Support\n  There are many applications that communicate over TCP/UDP ports. Kubernetes ingress was developed with web traffic in mind. It provides a standard way to control and route HTTP/S traffic into the cluster. However, ingress mechanisms for non-HTTP traffic are inconsistent and can be challenging.\n\n  Typical methods are:\n\n  - Service.Type = Nodeport\n  Nodeports use non-standard ports and are awkward and complex to get into production.\n\n  - Service.Type = LoadBalancer\n  Typically offered only in public clouds, LoadBalancers could get expensive depending on the number of services used.\n\n  - Citrix offers Service.type = Loadbalancer with a built-in IP address manager that is  consistent across clouds and on-premises deployments. This implementation simplifies IP address management and can save on load balancer costs in public clouds. An alternate method, also supported by Citrix, is to use ingress annotations that expose TCP/UDP ports.\n\n  All three methods make it much easier for TCP/UDP applications to be used as microservices without extensive code rewrites or protocol changes.\n\n  ## Securing Your Applications and APIs\n\n  <div className=\"center\" >\n    <img src={Api} align=\"center\" alt=\"API security considerations by traffic direction.\" />\n    <p>API security considerations by traffic direction.</p>\n  </div>\n\n  While traffic direction will dictate your security needs, the reality is that several concerns are shared considerations for both north-south and east-west traffic.\n\n  Let‚Äôs walk through the API security requirements one by one:\n\n  ### Ingress Security (North-South)\n  As services are exposed outside the cluster, the security considerations remain similar to those of monolithic deployments. In addition to ensuring protections like IP blacklist/whitelist and a robust encryption profile (SSL/TLS), it is imperative that the services are protected against both layer 3-4 and layer 7 DDoS.\n\n  Authentication/authorization are equally critical to ensure that the right access controls are established and maintained on data, APIs, and services. At the same time, as attacks are moving to the application layer, web application firewall (WAF) protections like SQL injection (SQLi), buffer overflow, and signature protections are table stakes. As the types of attacks are continuously evolving and because applications and APIs are changing many times a month, it is also critical that the protection mechanisms include behavior-based methods to automate the protection policies and detect potential zero-day attacks.\n\n  ### API Gateway and Security (North-South)\n  APIs are becoming the currency for digital transformation and for microservices that provide services via API, and therefore routing, security, control, and visibility for APIs is critical. API gateways are a perfect function to achieve these capabilities and typically are combined with the ingress solution.\n\n  API gateway solutions offer key functions like authentication, authorization, rate limiting, policy-based routing of APIs, and API versioning. In addition, the traditional controls applicable to a N-S web service are equally applicable and even more important to apply to APIs. API security is not just about authentication but also about ensuring that the content coming in from authenticated sources is not malicious. API gateway functions typically get configured in ingress through configmaps or CRDs.\n\n  ### Intra-Cluster Security for Service Mesh or Service Mesh-Lite (East-West)\n  Secure application deployment and secure infrastructure best practices dictate security controls in terms of both N-S and E-W service traffic (the former is generally more intuitively understood) because one layer of security isn‚Äôt enough, and in-depth defense is needed.\n\n  As the number and variety of your microservices expand, the pattern we‚Äôve seen is that services might start as internal use only, but over time end up being exposed externally to customers and partners. The gooey center of your cluster, where you initially intend to have most of your service-to-service interactions, needs to be as secure because service-to-service interactions expand to those outside the cluster. Service meshes are a natural solution here. To obtain this added layer of security (and many other benefits), the adoption of service meshes is on the rise, dramatically. When your application delivery controller integrates with a service mesh, API security is broadly upleveled and guaranteed up to a certain point irrespective of developers' rigor in incorporating secure coding practices. That‚Äôs because a service mesh runs as a layer of your infrastructure, relieving developers of a number of (but not all) identity, authentication, and authorization concerns.\n\n  For example, inter-services communication should be mutually authenticated via transport layer security (TLS) so that only permitted API connections are allowed. Previously, this may have been implemented with each individual service, but the service mesh enables this functionality to be offloaded to a sidecar ADC, like Citrix CPX, and managed by the service mesh control plane.\n\n  Similarly, it should be possible to ensure a faster and more consistent approach to SSL policy in microservices environments through the use of SSL profiles. By defining acceptable SSL settings (for example, ciphers, protocol, and key strength) and binding them to your different entities, developers can quickly deploy consistent encryption policies that meet the appropriate security requirements. After all, isn‚Äôt the goal here to facilitate both developer velocity while ensuring that necessary security practices are met?\n\n  Another rapidly emerging technology to enable developer velocity is serverless computing. While serverless does indeed involve servers, it leverages infrastructure as code to run backend services as needed, which frees the developer from having to worry about scaling, patching, security, and infrastructure reliability. API gateways are key to applications built with serverless because the developer can simply specify policy such as authentication, authorization, and rate limits without worrying about the form factor, performance, and reliability of the proxy that usually provides these features.\n\n  Next, let‚Äôs explore aspects of another benefit use of a service mesh provides: traffic control.\n\n  ## Enabling CI/CD and Canary Deployment with Advanced Traffic Steering\n  Your application delivery solution should be an enabler of continuous delivery and canary deployments by providing advanced traffic steering. Intelligent proxies are required here. If you‚Äôre using a control plane (and not configuring the proxies directly), understand that you will only be able to harness the full power of your proxies to the extent that the control plane exposes their capabilities for configuration.\n\n  ### Canary Deployment\n  In order to facilitate canary deployments, you need a powerful proxy. Kubernetes facilitates rolling updates to a service deployment, focusing on ensuring that traffic shifting from one version of a service to the next happens gradually over time and with zero downtime. However, Kubernetes on its own doesn‚Äôt offer the level of granular control over traffic necessary for simply exposing your canary to a subset of users that you identify. Nor is it convenient for error rate and performance monitoring. Although performance monitoring is integral for canary analysis, many times the solutions for automated canary analysis are cobbled together.\n\n  A canary deployment is manual in that you will need to manually check that the canary behaves as you want before doing a full deployment (caution: the difference between canary and baseline isn't always clear). Robust application delivery solutions support **automated canary analysis** and progressive rollout. With an automated canary analysis, not only are you able to avoid manual administration of the deployment, but you can also rely on an automated statistical analysis to better detect problems in the set of metrics you‚Äôve identified as indicators of a healthy deployment.\n\n  **A/B testing** requires full control over traffic distribution with several versions of your service running in parallel as you run various experimental tests. Experimentations often include measuring differences in conversion rates between versions of a service with the aim of improving a given business metric. To facilitate these experiments, you might want to direct requests based on various criteria like a client‚Äôs browser type and version or a user segment based on the presence of a specific cookie or the effect of UI changes on user behavior and the impact on overall performance.\n\n  **Chaos engineering** is akin to A/B testing in that it is an emergent practice that facilitates experimentation. Experimentation here is for purposes of testing and improving application delivery resiliency. Chaos engineering will evolve and expand in use as the complexity and rate of change of large-scale distributed systems demand new tools and techniques for increasing reliability and resiliency. Service-oriented teams (as opposed to infrastructure-oriented platform teams) will push past chaos engineering tools such as Chaos Monkey for inducing machine failures and skip Chaos Kong for evacuating entire regions. Instead they will move to application delivery solutions to perform precise service-level experiments on their path to improving application resiliency via orchestrated chaos. It's through exploration of the impact of increased latency and methodical failure of specific services that service teams will gain confidence in their systems‚Äô capabilities to withstand turbulent conditions in production and begin to sleep more soundly at night.\n\n  Savvy cloud native engineers understand the nuances of these delivery methods, and the key role that the proxy plays in enabling these methods. Note, however, that the need for these methods is not restricted to cloud native workloads. These application delivery solution considerations generally apply to microservices and monolithic services in that irrespective of a given service‚Äôs architecture, new versions of the service need to be deployed and managed. Because we live in a hybrid world, we encourage you to seek application delivery solutions that do, too.\n\n  ## Achieving Holistic Observability\n  Observability is crucial for effective troubleshooting of microservices environments, but the ephemeral nature and complexity of distributed architecture presents serious challenges. It's incredibly hard to maintain awareness of what's happening in your environment when containers are continuously created and destroyed. Continuous deployment adds to the transient nature of containers because DevOps teams often push many new deployments per day to update their applications.\n\n  Similarly, the number of things to monitor ‚Äî services, containers, users ‚Äî is enormous, and the fact that everything is distributed makes microservices an incredibly complex environment. While it‚Äôs easy to determine if a service is down, troubleshooting slow applications is not? How can you isolate problems among all of the vast telemetry data to find the root cause, especially with inter-microservices (E-W) traffic?\n\n  You cannot monitor what you can't see. This is why it is vitally important to have inspection points through which the traffic passes. When they are correctly positioned, proxies/ADCs collect telemetry for an unprecedented view of application traffic ‚Äî both N-S and E-W traffic across both monolithic and microservices architectures ‚Äî and they report important data to collection tools.\n\n  To overcome the challenge of gaining observability into microservices, you need to build an observability stack. The stack should consist of four pillars: logging, metrics, tracing, and service graphs. However, these should not be viewed as individual, disjointed components but rather as a holistic observability stack that is integrated and can combine data as required.\n\n  **Logs**\n  Logs are an immutable record of an individual event at a particular time. They are designed into systems, and there tends to be a log record to accompany almost every action. While logs are highly granular, they are limited in their searchability, and it is not usually feasible to process them manually. ADC feeds log data into tools like Elasticsearch for processing and indexing and Kibana for data visualization.\n\n  **Metrics**\n  Metrics are data points that are measured over time that can be used to monitor trends and set alerts. In addition to the system resources of your individual proxies, the unique position of the proxies means that it sees important information about the use of the application - number of requests, HTTP request rate, errors and more. These metrics can be exported by ADCs to tools like Prometheus where they can be processed and tools like Grafana can visualize them, set alarms create heat maps to help you understand the status of your ADCs.\n\n  **Traces**\n  The flow of packets through a microservices-based application can be complex spanning multiple services (sometimes multiple times) so identifying why a service is slow can be difficult. Distributed Tracing is a technique that monitors request flow through microservices to build a map of the latency through each microservice hop. Trace is an end-to-end latency graph of a specific request. It represents the entire journey of a request and helps troubleshoot latency issues. Distributed tracing can also be used to understand the application architecture and services not being used. ADC integrates with open source tools like OpenTracing and Zipkin for distributed tracing\n\n  **Service Graphs**\n  Service graphs are dynamic graphical representations of microservices and their interdependencies. Service graphs, like that of the service graph in the Citrix Application Delivery Manager (ADM) console, provide detail on connectivity among microservices, help you identify issues via simple color coding, and learn composite health scores for each microservice based on throughput, saturation, errors, and latency. More than this, Citrix service graphs also have a built in DVR-like function, which allows you to zero in on the specific time period when an issue occurred.\n\n  Given their distillment of complex microservices into a graphical form, service graphs need to provide the ability to tag microservices and to use tags to search, sort , and filter. In this way, you can create custom service graph views of microservices running in production only or you can restrict your view to see details just for canary microservices.\n\n  As a complement to the basic pillars of observability (logs, metrics, and traces), service graphs enhance your observability stack. They provide a holistic view of your microservices-based application environments in a single place for an intuitive and convenient way to gain insight and troubleshoot microservices environments faster.\n\n  ## Managing Monoliths and Microservices\n  With hybrid cloud now a reality for many organizations, managing multiple environments with divergent capabilities and management systems is also a reality. Operating with confidence requires reconciling these differences into a uniform operational model and, subsequently, into a uniform understanding with consistent (read: quality) control. For operational consistency, you need a single pane of glass to manage your application delivery infrastructure across:\n\n  - Any application: monolithic and microservices-based applications\n  - Any environment: on-premises, public, private, and hybrid\n  - Any ADC form factor: physical, virtual, cloud, containers, sidecars, and more\n\n  You need holistic control and monitoring for operational consistency across all your workloads (new microservices and existing monoliths). Ideally, you‚Äôll get such consistency from the proxy you‚Äôve put in place. As you select your proxy, exercise caution when piecing together components from disparate vendors/projects into a solution, because this will not only require integration effort, but also separate specialization to understand and operate. The overhead of integration and specialization can be avoided when your proxy portfolio is robust and supports any application, any environment and form factor with operatonal consistancy.\n\n  Moreover, as the large public cloud providers extend their reach on-premises with offerings like Google Anthos, AWS Outposts, and Azure Stack, and as organizations adopt them as simpler paths to cloud migration, it becomes important to use a proxy that works in multiple environments. A battle-tested solution like Citrix ADC that is validated to work in Google Anthos and AWS Outposts environments both in the cloud and on-premises can be invaluable for maintaining operational consistency across your hybrid multi-cloud environment. Because Citrix ADC comes in a variety of form factors (including hardware, software, bare metal, cloud, containers, sidecars, and more) that are built on a single code base, it works across your hybrid workloads in a uniform fashion and prevents a sprawl of heterogenous load balancers across your environment.\n\n</ResourcesWrapper>","frontmatter":{"title":"Choosing the Perfect Proxy","type":"Article","technology":"Kubernetes","product":"Meshery","mesh":"Istio","thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/choosing-the-perfect-proxy"}},{"id":"8df0cdb9-44af-5a21-9ddf-4360ee85b09a","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n\n  API gateways come in a few forms:\n\n  - Traditional (e.g., Kong)\n  - Cloud-hosted (e.g., Azure Load Balancer)\n  - L7 proxy used as an API gateway and microservices API gateways (e.g., Traefik, NGINX, HAProxy, or Envoy)\n\n  L7 proxies used as API gateways generally can be represented by a collection of microservices-oriented, open source projects, which have taken the approach of wrapping existing L7 proxies with additional features needed for an API gateway.\n\n  ### NGINX\n  As a stable, efficient, ubiquitous L7 proxy, NGINX is commonly found at the core of API gateways. It may be used on its own or wrapped with additional features to facilitate container orchestrator native integration or additional self-service functionality for developers. Examples of this include:\n\n  - APIUmbrella\n  - Kong\n  - OpenResty\n\n  ### Envoy\n\n  The Envoy project also has been used as the foundation for API gateways.\n\n  - Ambassador: Based on Envoy, Ambassador is an API gateway for microservices functioning stand-alone or as a Kubernetes Ingress Controller.\n  - Contour: Based on Envoy and deployed as a Kubernetes Ingress Controller. Hosted in the CNCF.\n  - Enroute: Envoy Route Controller. API Gateway created for Kubernetes ingress controller, and standalone deployments.\n\n  Other differences between traditional API gateways and microservices API gateways revolve around which team uses the gateway: operators or developers. Operators tend to measure API calls per consumer to meter and disallow API calls when a consumer exceeds its quota. Developers, on the other hand, tend to track L7 latency, throughput, and resilience, limiting API calls when the service is not responding.\n\n  One of the most important distinctions to make when it comes to service meshes is that API gateways are designed to accept traffic from outside your organization/network and distribute it internally. API gateways expose your services as managed APIs, focused on transiting north/south traffic. They aren‚Äôt as well suited for traffic management within the service mesh necessarily, because they require traffic to travel through a central proxy and add a network hop. Service meshes are primarily designed to handle east/west traffic internal to¬†the service mesh.\n\n  <div className=\"fact-left\">\n    Traffic Directions\n    <p>North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.</p>\n  </div>\n\n  API gateways and service meshes are frequently deployed in combination due to¬†¬†their complementing nature. Service meshes are on their way to providing much, if not all, of the functionality that API gateways do.\n\n  ### API Management\n\n  API gateways work with other API management ecosystem components like API marketplaces and API publishing portals, both of which are surfacing in service mesh offerings. Analytics, business data, adjunct provider services like single sign-on, and API versioning control are all provided by API management solutions.  Many API management vendors have migrated their API management systems to a single point of architecture, with API gateways designed to be implemented at the edge.\n\n  An API gateway can call downstream services via service mesh by offloading application network functions to the service mesh. Some API management capabilities that are oriented toward developer engagement can overlap with service mesh management planes in the following ways:\n\n  - Developers use a portal to discover APIs available for API documentation and discovery,  API testing, and exercising their code.\n  - API analytics for tracking KPIs, generating reports on usage and adoption trending.\n  - API lifecycle management to secure APIs (allocate keys) and promote or demote APIs.\n  - Monetization to tracking payment plans and enforcing quotas.\n\n</ResourcesWrapper>\n","frontmatter":{"title":"API Gateways interplay with service meshes","type":"Article","technology":"API","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/service-mesh/api-gateways-interplay-with-service-meshes"}},{"id":"78adbbae-121a-5d8e-9b0f-ccc3ed02d8f5","body":"\nimport { Link } from \"gatsby\";\nimport SMP from \"./smp-light-text_2.webp\";\nimport cover from \"./ieee_bridge_issue3_2021.webp\";\nimport EWtraffic from \"./figure-1.webp\"\nimport Workload from \"./figure-2.webp\"\nimport Archictures from \"./Meshery Architecture - Clients.webp\"\nimport Code from \"./code-snippet.webp\"\nimport NetworkFunction from \"./Comparison of different modes of delivery of service mesh network functions.webp\"\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p> \n      Learn more about Service Mesh Performance from this article  \n      <a className=\"blog\" href=\"https://www.nxtbook.com/nxtbooks/ieee/bridge_issue3_2021/index.php#/p/16\"> Analyzing Service Mesh Performance</a> - Published in issue 3 of IEEE Bridge October 2021\n    </p>\n  </div>\n\n<div className=\"right\" >\n<img src={cover} align=\"center\" alt=\"IEEE The Bridge 2021 Issue 3 cover\" />\n</div>\n\n<p>\nAs a forthcoming, ubiquitous layer of cloud native infrastructure, \nservice meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. \nManaging the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly \nsummarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure \nof choice is a challenge unto its own.\n</p>\n\n<p>\nWe explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties \nof resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance \nanalysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of \nworkloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.\n</p>\n\n<p>\nWe provide core, memory and I/O combinations based on workload needs with insights into workload analysis which can influence the efficiency of the \nservice mesh and overall performance of the cluster.\n</p>\n\n\n<h2>Characterizing the Complexity of Combinatorial Analysis</h2>\n\n<p>\nConsider that the more value you try to derive from your service mesh, the more work that you will ask it to do. Said another way, \nthat as someone reflects more deeply on the architecture of a service mesh - with its distributed proxies - and the functionality it offers, \nthey will eventually wonder, \"What overhead is running my service mesh incurring?\". This is one of the most common questions engineers have as \nthey initially learn of a service mesh and the value a deployment of one offers. This is not an easy question to answer as the permutations of \nconfiguration between your infrastructure, service mesh, and applications are innumerable and any change to one of them affects their collective performance.\n</p>\n\n<p>\nHow would you describe the performance of your service mesh and that of your clusters and their workloads? Are you imagining a wall of line \ncharts with metrics capturing golden signals? The act of articulating the performance of your service mesh can take anywhere from a minute \nto even a few hours to characterize the state of your systems and the overhead incurred by your infrastructure and what this means to your users.\n</p>\n\n<p>\nMoreover, anytime performance is characterized, analysis is subjective to the specific workload, infrastructure, and instruments used for measurement. \nGiven the variety of this measurement challenge, most service meshes and their data plane proxies (if a third-party component), do not have the tooling \nnecessary or refuse to publish performance data because such tests can be:\n  <ol>\n  <li>arduous to create and sustain a capable harness</li>\n  <li>a point-in-time consideration (none of the elements under measurement are static</li>\n  <li>misinterpreted</li>\n</ol>\n</p>\n\n<p>\nRead on as we identify how to surmount each of these challenges.\n</p>\n\n<h2>Service Mesh Performance Considerations</h2>\n\n<p>\nAs the software defined networking layer of microservices, service mesh encompasses multiple aspects of critical functions of the applications, \nsuch as circuit breaking, health checks, and packet operations. Analyzing the permutations of these configurations is an impossible task without \na suitable test harness. A service mesh management plane can be such a tool. As the multi-mesh manager, <a href=\"https://meshery.io\">Meshery </a> \nis capable of provisioning 10 different service meshes, workloads atop the meshes, generating load using <a href=\"https://getnighthawk.dev\">Nighthawk</a>, \nand analyzing that load. No other tool capable of performing these tasks \nend-to-end exists. Meshery is a Cloud Native Computing Foundation project originally created by Layer5.\n</p>\n\n<h3>How are you measuring?</h3>\n\n<p>\nConsider the simple set of steps to execute performance tests in a simple Kubernetes-based cluster:\n</p>\n\n<ol>\n  <li>Setup your cluster, service mesh, and application under test.</li>\n  <li>Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.</li>\n  <li>Configure your test setup for performance, doing so in context of other constraints that you might \n  need to uphold (e.g. resiliency characteristics of your service deployment).</li>\n  <li>Choose the protocol of interest: HTTP, HTTPS, HTTP1/2, gRPC, NATS</li>\n  <li>Identify KPIs of interest - Transactions per second (TPS) or percentile latencies, etc.</li>\n  <li>Decide on the test duration: 60s or 5 minutes or 1 hour...</li>\n  <li>Choose the number of requests per second (RPS).</li>\n  <li>Execute the test.</li>\n  <li>Mark down requests per second, latencies, throughput, and any other output provided by benchmarking tools.</li>\n</ol>\n\n<h3>What are you measuring?</h3>\n\n<p>\nPerformance of a service mesh can be described across multiple dimensions covering some or all of these core functionalities \nof a service mesh. So, which dimensions are the linchpins of performance? Which metrics are key indicators of performance? \nOutside of the different types of performance tests, performance management concerns include the need for performance and \noverhead data under a permutation of different workloads (applications) and different types and sizes of infrastructure resources. \n</p>\n\n<div className=\"center\" >\n<a href={EWtraffic}>\n<img src={EWtraffic} align=\"center\" alt=\"EWtraffic\" />\n</a>\n</div>\n\n\n<p>\nHence, it is crucial to understand what is being measured in a service mesh based deployment. Certain critical considerations are \nmissing from the simple methodology previously described. For example, as indicated in Figure 1, but not limited to:\n</p>\n\n<ol>\n  <li>\n    Traffic considerations\n    <ul>\n      <li>\n        East-West traffic\n        <ol>\n          <li>between two pods within the same or two different Virtual Machines (VM).</li>\n          <li>between two pods within the same or two different bare metal nodes.</li>\n          <li>combination of above with choice of user-space or kernel-space networking stack on the host node.</li>\n        </ol>\n      </li>\n      <li>\n        North-South traffic\n        <ol>\n          <li>Throughput and latency of traffic flowing in and out of a single VM or across a single bare metal node.</li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n  <li>\n    Deployment considerations\n    <ul>\n      <li>Number of hops between traffic source and traffic destination with load balancers, API gateways, ingress controllers, \n      security components such as firewall, deep packet inspectors, and so on.</li>\n      <li>Operating system settings.</li>\n      <li>Hardware settings such as BIOS options, power management features, NUMA awareness, platform resource management, hardware \n      accelerators, and so on.</li>\n    </ul>\n  </li>\n  <li>\n    Load generators types\n    <ul>\n      <li>hardware or software based, L2-3,  L4-7, open or closed loop</li>\n    </ul>\n  </li>\n  <li>\n    Service mesh types - the service mesh landscape has over 20 meshes listed. Each share a common architecture, \n    however, their implementation differs and consequently, so does their performance.\n    <ul>\n      <li>Control plane - often a point of contention the larger the service mesh deployment is.</li>\n      <li>Data plane - not only proxies, but filters loaded in those proxies.</li>\n    </ul>\n  </li>\n  <li>\n    Service mesh configuration and number of services on the mesh. To name a few considerations:\n    <ul>\n      <li>\n        Telemetry\n        <ol>\n          <li>Including the three pillars of observability are traces, logs, and metrics.</li>\n          <li>The number of, cardinality of, sampling rate, ingest rate‚Ä¶ all bear weight (and bear load on the system).</li>\n        </ol>\n      </li>\n      <li>\n        Policy\n        <ol>\n          <li>Authentication, Authorization - frequency of checks, cache hits vs. cache misses.</li>\n        </ol>\n      </li>\n       <li>\n        Security\n        <ol>\n          <li>Encryption - overhead of handshaking and mutually authenticated TLS.</li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n</ol>\n\n<p>\nUltimately, the goal of any performance tests is to ensure repeatable measurements and obtain consistent results across multiple test runs.\n</p>\n\n<h2>Service Mesh Performance as a Specification</h2>\n\n<p>\nThe need for cross-project, apple-to-apple comparisons are also desired in order to facilitate a comparison of behavioral differences \nbetween service meshes and which one might be best-suited for specific workloads. Individual service mesh projects shy from publishing test \nresults of other, competing service mesh projects. The need for an independent, unbiased, credible, standard measurement is one of the catalysts \nfor the creation of Service Mesh Performance (SMP).\n</p>\n\n<p>\nAmidst performance concerns and the need to measure and manage performance arose the Service Mesh Performance (SMP) standard. Service Mesh \nPerformance as a specification and disseminating insights and research results. Your authors are working toward the definition of MeshMark, \na universal performance index to gauge your mesh‚Äôs efficiency against deployments in other organizations‚Äô environments.\n</p>\n\n<p>\nMany performance benchmarks are limited to single instance load generation (single pod load generator). This limits the amount of traffic \nthat can be generated to the output of the single machine that the benchmark tool runs on in or out of a cluster. Overcoming this \nlimitation would allow for more flexible and robust testing. Distributed load testing in parallel poses a challenge when merging \nresults without losing the precision we need to gain insight into the high tail percentiles. Distributed load testing offers insight \ninto system behaviours that arguably more accurately represent real-world behaviours of services under load as that load comes from \nany number of sources.\n</p>\n\n<p>\nThe specification itself provides a standard format for describing and capturing:\n</p>\n\n<ul>\n  <li>performance test configuration</li>\n  <li>Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.</li>\n  <li>service mesh configuration</li>\n  <li>environment configuration</li>\n  <li>workload configuration</li>\n  <li>performance test results</li>\n  <li>Distributed performance modeling</li>\n  <li>KPIs for service mesh performance</li>\n  <li>Test tool requirements</li>\n</ul>\n\n<p>\nValue from a service mesh is best derived when it's tuned to scale as per the deployment requirements. Given the \ncomplexity of deploying, testing and measuring performance aspects across multiple dimensions, the specification \naims to provide a simple starting point for anyone looking to understand and derive service mesh performance. The \nservice mesh performance standard aims to articulate these complexities in a methodical and automated manner in \norder for anyone to plan the performance scenarios of their deployment and execute relevant tests.\n</p>\n\n<p>\nThe code snippet provides insight on the fact that the specification defines a common collection of statistical analysis \nto be calculated for every performance test.\n</p>\n\n```yaml\nmessage PerformanceTestResult {\n  message Latency {\n    double min = 1;\n    double average = 2;\n    double p50 = 3;\n    double p90 = 4;\n    double p99 = 5;\n    double max = 6;\n  }\n}\n```\n\n<p><i>Snippet of the Service Mesh Performance specification describing how to capture statistical analysis of test results.</i></p>\n\n<h2>Defining Deployments</h2>\n\n<p>\nVirtualized deployments involve deploying microservice orchestration and service mesh stack in virtual machines (VMs). Although bare metal \nusage has performance benefits, customers often use VMs to provide hardware-level isolation between various applications. This deployment \ninvolves two VMs across two nodes, with one acting as a Kubernetes master with the other a worker node. Customers deploy VMs on a single \nNUMA node to avoid cross UPI traffic. Results in virtualized testing have shown that depending on pinning of QEMU threads to a set of \nisolated cores - either sequentially or clustering the threads together to all the cores - tail latencies are heavily impacted.\n</p>\n\n<p>\nMicroservice deployments could use a wide variety of deployment scenarios. The following list provides a sample set of how a service mesh \nperformance could be analyzed either on a same node or in a multi-node cluster:\n</p>\n\n<ul>\n  <li>Pod to pod communication.</li>\n  <li>Pod to service communication.</li>\n  <li>Ingress controller to pod and vice-versa.</li>\n  <li>Load balancer to pod and vice-versa.</li>\n  <li>Pod to Egress Gateway.</li>\n  <li>Mutual TLS termination across any of the above endpoints.</li>\n  <li>Different security rules and policies.</li>\n  <li>Communication protocol.</li>\n</ul>\n\n<p>These considerations are illustrated in a typical workload deployment as shown in <i>Figure 3.</i></p>\n\n<div className=\"center\" >\n<a href={Workload}>\n<img src={Workload} align=\"center\" alt=\"Workload\" />\n</a>\n</div>\n\n<p>\nHere is an example of deployment with Kubernetes as the orchestrator using Calico CNI and deployed in VMs, \nwhile the host infrastructure has OVS-DPDK for switching, which can be extended for VMs to leverage SR-IOV. \nTo understand impact of infrastructure elements and networking elements of microservice software stack, \nperformance impact of a service mesh and its set of data plane proxies with fortio as load generator could be \nunderstood by running the Meshery in two different environments outside the Kubernetes cluster.\n</p>\n\n<ol>\n  <li>First one with load generator running as a process outside of Kubernetes cluster in master-vm</li>\n  <li>Second one with load generator running as a bare metal process on master-host</li>\n</ol>\n\n<h3>Automating Performance Measurements</h3>\n\n<p>\nMeshery is ideal tooling in that it provides lifecycle management of a large number of service meshes and sample \napplications which need to be provisioned, configured, and deprovisioned in the process of analyzing service mesh performance. \nMeshery is capable of generating load, baselining, and comparing performance results. The canonical implementation of this \nspecification is implemented in Meshery.\n</p>\n\n<div className=\"center\" >\n<a href={Archictures}>\n<img src={Archictures} align=\"center\" alt=\"Archictures-client\" />\n</a>\n</div>\n\n<p><i>Figure 4 - Meshery‚Äôs load generators can be deployed in the same cluster under test or outside of the cluster under test.</i></p>\n\n<h4>Pipelining performance characterization</h4>\n\n<p>\nAcknowledging the living nature of user deployments, integration of automated performance testing into continuous integration \nsystems helps users deploy new versions of their applications or new configurations of their infrastructure \n(including service mesh configuration) with the assurity  afforded through the act of dry-running the service mesh and application \nconfiguration before production deployment. The Meshery and Service Mesh Performance GitHub Action offers the ability to adaptively \nanalyze application performance as a gate in your continuous delivery pipeline. In this way, the Service Mesh Performance \nspecification facilitates a measurement index that can be referenced when rolling out new versions of a service with this \nadvanced canary technique.\n</p>\n\n<p>\nThrough Meshery, techniques to mirror non-idempotent requests without fear of impacting the current version of your application \nallowing replay of user requests. And use of intelligent network functions, embedded in WebAssembly (WASM) programs, to \nfacilitate real user request reenactments to help you extract the most value out of your pipeline.\n</p>\n\n<ul>\n  <li>Repeatability of test scenarios using performance profiles and cloud native orchestration.</li>\n  <li>Baselining and comparing results.</li>\n</ul>\n\n<h3>Analyzing Performance Measurements</h3>\n\n<p>\nWe have often seen inefficiencies in the ratio of resource usage vs resources applied. Since the mesh \nelements i.e. the ingress and sidecars share resources with one or more of the application containers, \nthere may be more resources left to be utilized. Tail latencies decrease with the increase in number of \ncores for all 1, 10 and 100 clones but increase with the increase in the number of connections. Data for \nvarious connection counts, as shown, indicates that performance degradation with Istio shows up with \ninput RPS more than 1000. In a top down microarchitectural analysis (TMA), when the front proxy is pinned \nto a single core and the sidecar + flask app is pinned to another core and the number of microservices are \nscaled up. It is observed that (Figure 2):\n</p>\n\n<ul>\n  <li>Frontend Bound% decreases with increase in number of microservices‚Äã and Core Bound % increases.</li>\n  <li>Memory Bound % increases with increase in the number of microservices‚Äã.</li>\n  <li>L1 and L3 Bound% decreases for both the service cores on which the front ‚Äìproxy is running as well as the \n  core where the sidecar+flask app is running with number of microservices.</li>\n</ul>\n\n<p>\nIn customer environments, the size of the cluster as well as the amount of incoming traffic will have an impact on the number of \nworkloads and Envoy microservices. The underlying hardware and L4 networking on each node in the cluster will also impact the \nperformance observed. A call stack and cycles spent analysis of a deployment with 1-20 sidecars on a specific  \n40 core system with a 10G NIC shows bottlenecks spread between:\n</p>\n\n<ol>\n  <li>Envoy:TheadLocalStorage-Hashset-Match</li>\n  <li>\n    Linux kernel bottleneck spread between\n      <ol>\n        <li>Libpthreadscheduling</li>\n        <li>Libevent</li>\n      </ol>\n  </li>\n  <li>Envoy buffer slice management and TCP filter, if message sizes or file transfer sizes increase to 1M</li>\n  <li>Crypto operations when TLS is enabled.</li>\n</ol>\n\n<p>\nOur initial studies show that the optimal service mesh setup for the tolerable latencies and the best RPS may include:\n</p>\n\n<ol>\n  <li>Exclusive  threads allocated to Envoy processing</li>\n  <li>Reduced memory contention by allocating more memory bandwidth which can be controlled dynamically</li>\n  <li>Load balancing of worker threads among the among cores which may require</li>\n  <li>Less IO switching</li>\n  <li>Optimized memory copies with signals incorporated in addition to events (libevent)</li>\n</ol>\n\n<h4>Accelerations and Offloads</h4>\n\n<p>\nA number of accelerations and offloads to SMART NIC or other processing elements like IPUs and DPUs are \nbecoming available. How does the service mesh efficiency and performance benefitted from these deployment \noptions needs to be defined and measured. Cycles and cores saved in the host cores vs offload cores which \nmay be of different architectures and/or performance range needs to be quantified and benchmarks and \nindices created to measure.\n</p>\n\n<h3>Being Precise in Performance Studies</h3>\n\n<p>\nWhen measuring sub-millisecond response times, the noise floor of the environment as well as the sensitivity \nof the tooling may become dominant factors in measurements. Noisy neighbours, scheduler fairness, garbage collection, \nand even specifics in the timing of requests being sent as well as connection-reuse patterns may change noise floors \nsuch that similar measurements performed using different systems and tools may diverge an order of magnitude in absolute terms.\n</p>\n\n<p>\nAs a quick survey of load generators by way of those included in Meshery, we find upon close inspection \ntheir differences are noteworthy and justify their use under different circumstances.\n</p>\n\n<p>\nWritten in C, wrk2 supports ignoring coordinated omission. wrk2 lets you test a little more complex scenarios. \nUsers express load generation profiles in terms of RPS. wrk2 shows you what you normally may not see in benchmark \nresults, but what every 1,000th user might see. To see these outliers, you need to run the longer (time) performance \ntests.  Wrk2 tests the scenario where there's a string of services comprising microservices. wrk2 requires you to \nspecify the desired RPS, while wrk does not. Wrk2 is focused on driving the maximum RPS. Meshery‚Äôs fork of wrk2 \nenables testing of multiple endpoints and enables the variable rate of load generation. In the future, Meshery \nwill offer the ability to assign a weight to each endpoint for the load to be generated by wrk2.\n</p>\n\n<p>\nWritten in Golang, fortio is extremely fast and usable for testing basic response times on a per request level. \nFortio produces results in JSON on a per request basis and easy to integrate into other Golang-based tooling like Meshery.\n</p>\n\n<p>\nWritten in C++, Nighthawk supports both open- and closed- loop testing, and was designed to offer the right \nsensitivity for benchmarking microservice proxies (sub millisecond latencies). Using an open loop test \nmethodology avoids coordinated omission, and in conjunction with its adaptive load controller one can \nseek answers to questions like ‚Äúwhat RPS can my mesh reliably sustain under set latency?‚Äù.\n</p>\n\n<h4>Comparing Types of Data Plane Filtering</h4>\n\n<p>\nImportant to note is the power of the service mesh data plane and cost of that power. Envoy is a popular \nproxy of choice for service mesh data planes. Among other features, Envoy provides the ability to \nintegrate custom traffic filters via one of two methods:\n</p>\n\n<ol>\n  <li>\n  Natively by incorporating your custom traffic filter into Envoy‚Äôs C++ source code and compiling a new \n  Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit \n  being that of your custom filter running at native speed.\n  </li>\n  <li>\n  Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. \n  The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically \n  load and reload WASM-based filters in Envoy at runtime.\n  </li>\n</ol>\n\n<p>\nWhether to  integrate your traffic filters natively or as an extension, a tradeoff between the two deployment \nexists primarily in exchanging between service mesh speed and service mesh flexibility as shown in <i>Figure 4.</i>\n</p>\n\n<div className=\"center\" >\n<a href={NetworkFunction}>\n<img src={NetworkFunction} align=\"center\" alt=\"comparison of Network functions\" />\n</a>\n</div>\n\n<p>\n<i>Figure 5 - A comparison of different modes of delivery of service mesh network functions.</i>\n</p>\n\n<p>\nAs an assessment of this tradeoff, an analysis of a series of three tests run across the same rate \nlimit network function implemented as 1) a Golang-based client library, or 2) a Rust-based Envoy \nfilter running in a WebAssembly virtual machine  (or 3) a native Envoy filter) provides some insight \nas to the comparative overhead involved.\n</p>\n\n<ol>\n  <li>\n    Rate limiting with Go client library\n      <ul>\n        <li>At 100 RPS the p50 is 3.19ms.</li>\n        <li>At 500 RPS the p50 is 2.44ms.</li>\n        <li>With unlimited RPS (4,417) the p50 is 0.066ms.</li>\n      </ul>\n  </li>\n   <li>\n    Rate limiting with WASM module (Rust filter)\n      <ul>\n        <li>At 100 RPS the p50 is 2.1ms</li>\n        <li>At 500 RPS the p50 is 2.22ms</li>\n        <li>With unlimited RPS (5,781) the p50 is 0.62ms</li>\n      </ul>\n  </li>\n</ol>\n\n<p>\nUsers not only need to account for the (relatively) easy to quantify system overhead and the operational \noverhead involved in expanding development resources to implement bespoke tooling versus managing off-the-shelf filters.\n</p>\n\n<h3>Summary</h3>\n\n<p>To deploy a service mesh effectively, we need to</p>\n\n<ol>\n  <li>quantify application workload characteristics and how it utilizes a particular microarchitecture.</li>\n  <li>assess how Container Network Interface (CNI) drivers, Open Virtual Switch (OVS), rules processing, match \n  and lookup requirements between Network Address Translated (NAT) and routed networks are required</li>\n  <li> different layers of service mesh to be deployed including layer 4 load balancers, ingress and reverse proxy, \n  number of sidecars and number of microservices to be supported</li>\n  <li>and what hardware baseline performance does the setup have and </li>\n  <li> a quantifiable measure of service mesh deployed with performance measures mapped to KPIs like throughput (RPS) and latency.</li>\n</ol>\n\n\n</ResourcesWrapper>","frontmatter":{"title":"Analyzing Service Mesh Performance","type":"Article","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJQBdgBDdqTIBYAAD+y0sewoyDxaZOxu6BEnH4O26ZDf3HFLQChhSX7W+MuV0QLty3ei6VevV5j7AA"},"images":{"fallback":{"src":"/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp","srcSet":"/static/f1d1d04c93ec2f13adb202acc633bc65/57632/smp-light-text_2.webp 750w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/3fc16/smp-light-text_2.webp 1080w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/b060c/smp-light-text_2.webp 1366w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.616}},"extension":"webp","publicURL":"/static/f1d1d04c93ec2f13adb202acc633bc65/smp-light-text_2.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRl4AAABXRUJQVlA4IFIAAABQAwCdASoUAAwAPtFUo0uoJKMhsAgBABoJQBdgBDdqTIBYAAD+y0sewoyDxaZOxu6BEnH4O26ZDf3HFLQChhSX7W+MuV0QLty3ei6VevV5j7AA"},"images":{"fallback":{"src":"/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp","srcSet":"/static/f1d1d04c93ec2f13adb202acc633bc65/57632/smp-light-text_2.webp 750w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/3fc16/smp-light-text_2.webp 1080w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/b060c/smp-light-text_2.webp 1366w,\n/static/f1d1d04c93ec2f13adb202acc633bc65/8786e/smp-light-text_2.webp 1500w","sizes":"100vw"},"sources":[]},"width":1,"height":0.616}},"extension":"webp","publicURL":"/static/f1d1d04c93ec2f13adb202acc633bc65/smp-light-text_2.webp"}},"fields":{"slug":"/resources/service-mesh-performance/analyzing-service-mesh-performance"}},{"id":"bbdc2982-dc61-5931-ba48-5d1c0650ae6c","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../Resources.style.js\";\nimport Traffic from \"./figure1.webp\";\n\n<ResourcesWrapper>\n  <div className=\"intro\">\n    <p>Learn more about service mesh fundamentals in <Link className=\"blog\" to=\"/learn/service-mesh-books/the-enterprise-path-to-service-mesh-architectures-2nd-edition\">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization‚Äôs readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>\n  </div>\n\n<h2>What are practical steps to adopt a service mesh in my enterprise? </h2>\n\n<h3>Piecemeal Adoption</h3>\n<p>\n  Many organisations wish to take advantage of auto-instrumented observability\n  first, taking baby steps toward a full-service mesh after achieving first\n  success and operational comfort,¬†to better understand what's going on across\n  their distributed infrastructure. It's a high-value, relatively safe first\n  step to use a service mesh for its ability to provide enhanced observability.\n  First steps for others might be on a parallel path. For example, a financial\n  organisation¬†might seek improved security with strong identity (per-service\n  certificates) and strong encryption via mutual TLS between each¬†service.\n  Others, on the other hand, may begin with an ingress proxy as a stepping stone\n  to a larger service mesh deployment.\n</p>\n<p>\n  Consider an organisation¬†with hundreds of existing services running on virtual\n  machines (VMs) external to the¬†service mesh that have little to no\n  service-to-service traffic, with practically all traffic flowing from the\n  client to the service and back to the client. Without immediately¬†deploying\n  hundreds of service proxies, this organisation can deploy¬†a service mesh\n  ingress (e.g., Istio Ingress Gateway) to gain granular traffic control (e.g.,\n  path rewrites) and detailed service monitoring.\n</p>\n<div className=\"center\">\n  <img src={Traffic} align=\"center\" alt=\"ingress traffic control\" />\n  <p>\n    Figure 1: Simple service mesh deployment primarily using ingress traffic\n    control.\n  </p>\n</div>\n\n<h3>Practical Steps to Adoption</h3>\n<p>Here are two common paths:</p>\n<ul>\n  <li>\n    Wholesale adoption of a service mesh, commonly while designing a new\n    application (a greenfield project).\n  </li>\n  <li>\n    Piecemeal adoption of some components and capabilities of a service mesh,\n    but not others, commonly while working with an existing application (a\n    brownfield project).\n  </li>\n</ul>\n<p>\n  Let's take a look at how the second path manifests itself, because it's the\n  path that most people will face (those with existing services) and the\n  approach that most organisations take. In this method, incremental steps are\n  taken. When teams are comfortable with their understanding¬†of the deployment,\n  have gained operational expertise, and derived substantial value, another step\n  toward a full mesh is usually accomplished. Since n ot all components of a\n  full service mesh are helpful to teams based on their focus or current pain\n  points, not all teams choose to take another step. This will evolve over time,\n  as full service mesh deployments become ubiquitous. More than this,\n  application developers and service (product) owners will begin to rely on the\n  power of a service mesh to empower and satisfy their requirements as well.\n</p>\n<p>\n  Which applications should be constructed from the ground up or transformed\n  using a new service mesh architecture depends on engineering maturity and\n  skill set. You don't have to use all of the features; use¬†the ones you need.\n  Given that some service meshes provide a path to partial adoption, the best\n  way may be to mitigate risk, baby-step it, and show incremental triumphs. Some\n  service meshes can be deployed and digested in a single step. Even if this is\n  the case, you might find that you enable only¬†a subset of its¬†capabilities.\n  Presence of a service mesh‚Äôs capabilities is separate from whether those\n  capabilities are actively engaged.\n</p>\n<p>\n  Observability is at the top of the list of reasons why most organizations\n  deploy a service mesh initially. You usually obtain a service dependency graph\n  in addition to metrics, logs, and traces. These graphs visually identify how\n  much traffic is coming from one service and going to the next.¬†¬† You'll feel\n  as if you're running¬†blind if you don't have a visible topology or service\n  graph.\n</p>\n<p>\n  Alternatively, it could be your current load balancer that is running blind.¬†\n  Most service mesh proxies will come in handy if you're running gRPC services\n  and have a load balancer ignorant of¬†gRPC and treats this traffic like any\n  other TCP traffic. Modern service proxies will support HTTP/2 and, as such,\n  might provide a gRPC bridge from HTTP/1.1 to HTTP/2.\n</p>\n\n<h3>Security</h3>\n\n<p>\n  Organizations usually prioritise security last.¬† They may not want strong\n  authentication and encryption when they ultimately do look into security.\n  Although it is best practise to secure everything using strongly authenticated\n  and authorised services, some organisations fail to do so, resulting in soft,\n  gooey centres in their microservices deployments. Some teams are content to\n  secure the¬†edge of their network, but they still want the observability and\n  control that a service mesh can provide.\n</p>\n<div className=\"fact\">\n  <p>\n    Needless to say, it is recommended that you run workloads securely, using a\n    service mesh to provide authentication and authorization between all service\n    requests.\n  </p>\n</div>\n<p>\n  Why aren't certain organizations interested in using Service Mesh's managed\n  certificate authority? Because it is another¬†thing to operate? When\n  connections are established, encryption consumes resources (CPU cycles) and\n  can inject¬†a few microseconds of latency. Given this, and to aid adoption,\n  some service meshes prominently display installation options that include a\n  certificate authority (CA) and installation configurations that do not. Maybe\n  you consider the ‚Äúgooey center‚Äù of your mesh to be secure because there is\n  little to no ingress/egress traffic to/from the cluster and access is provided\n  only via VPN into the cluster.¬†Depending on workload, wallet, and sensitivity\n  to latency, you might find that you don‚Äôt want the overhead of running\n  encryption between all of your services.\n</p>\n<p>\n  Maybe you're just searching for authorization checks, and¬†you're deploying\n  monoliths rather than microservices. You don't need any further monitoring\n  integrations because you already have API management. Perhaps you use IP\n  addresses (subnets) for network security zones. Using identities and\n  encryption provided by the service mesh, together with authorization checks\n  enforced by policy you specify, a service mesh can help you get rid of network\n  partitions and firewalling on Layer 3 (L3) boundaries. You can flatten your\n  internal network by policy enforcing, authorization checks across your\n  monoliths, making services broadly reachable¬†while granularly controlling\n  which requests are authorized. The power of service mesh to analyse and reason\n  over details of request traffic much beyond IP addresses and ports (Layer 3/4)\n  provides significantly more flexibility.\n</p>\n<h3>Retrofitting a Deployment</h3>\n<p>\n  Recognize that, while some greenfield projects may have the luxury of starting\n  with a service mesh, most organizations will have existing services (monoliths\n  or otherwise) to onboard to the mesh. These services could run in VMs or\n  bare-metal hosts instead of containers. Fear not! Some service meshes squarely\n  address such environments and help with the modernization of such services,\n  allowing organizations to renovate their services inventory by:\n</p>\n<ul>\n  <li>Not having to rewrite their applications</li>\n  <li>\n    Adapting microservices and existing services using the same infrastructure\n    architecture\n  </li>\n  <li>Facilitating adoption of new languages</li>\n  <li>\n    Facilitating moving to or securely connecting with services in the cloud (or\n    on edge)\n  </li>\n</ul>\n<p>\n  For those organisations who adopt a strangler pattern of building services\n  around a legacy monolith to expose a more developer-friendly set of APIs,\n  service meshes make it easier to insert facade services as a way of breaking\n  down monoliths.\n</p>\n<p>\n  With the adoption of a service mesh, organisations can get observability\n  (e.g., metrics, logs, and traces) as well as dependency or service graphs for\n  all of their services (micro or not). The only change required within the\n  service with respect to¬†tracing is to forward certain HTTP headers. With the\n  least amount of code change, service meshes are effective for retrofitting\n  uniform and ubiquitous observability tracing into existing infrastructures.\n</p>\n\n</ResourcesWrapper>\n","frontmatter":{"title":"Considerations of Adopting a Service Mesh","type":"Article","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAAAQBACdASoUABIAPtFWpkuoJKOhqA1RABoJZwAAMXkxHzbHC1lj/ajugAD+8/kxgzcWpp4uhQloavgkHs7qXUs5nsa3XSfdp4I8OAF4chFSyXoDanAf6Ra3GboYQOdkK00E3XVIdsORLy/ka40fcEjZy30gAAAA"},"images":{"fallback":{"src":"/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp","srcSet":"/static/5ad477e74c5a92fa29a9be876d138224/2f2a6/figure1.webp 750w,\n/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp 901w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8967813540510544}},"extension":"webp","publicURL":"/static/5ad477e74c5a92fa29a9be876d138224/figure1.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAAAQBACdASoUABIAPtFWpkuoJKOhqA1RABoJZwAAMXkxHzbHC1lj/ajugAD+8/kxgzcWpp4uhQloavgkHs7qXUs5nsa3XSfdp4I8OAF4chFSyXoDanAf6Ra3GboYQOdkK00E3XVIdsORLy/ka40fcEjZy30gAAAA"},"images":{"fallback":{"src":"/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp","srcSet":"/static/5ad477e74c5a92fa29a9be876d138224/2f2a6/figure1.webp 750w,\n/static/5ad477e74c5a92fa29a9be876d138224/9b2af/figure1.webp 901w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8967813540510544}},"extension":"webp","publicURL":"/static/5ad477e74c5a92fa29a9be876d138224/figure1.webp"}},"fields":{"slug":"/resources/service-mesh/considerations-of-adopting-a-service-mesh"}},{"id":"94564ad9-d1c3-5deb-922d-275f845fefa0","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\nBoth the Meshery and Service Mesh Performance (SMP) projects joined the Cloud Native Computing Foundation (CNCF) earlier this month at the Sandbox level.\n\nMeshery is a multiservice mesh management plane offering lifecycle, configuration, and performance management of service meshes and their workloads, while SMP is a standard for capturing and characterizing the details of infrastructure capacity, service mesh configuration, and workload metadata.\n\nWhen the projects first applied in April for inclusion, the Technical Oversight Committee (TOC) had one clarifying question for them: should they be combined with or aligned in some manner with the Service Mesh Interface (SMI) project?\n\nLee Calcote, founder of Layer5, the company partly behind both of the projects, explained that it was an alluring prospect for the CNCF, but that, for the time being at least, the projects would continue on their own separate paths.\n\nCalcote, who also serves as the chair of the Network special interest group (SIG) at the CNCF, said he then presented to the CNCF the following diagram, which shows the relation between the three projects. For the time being, he said, both SMI and SMP are ‚Äúrelatively younger projects, both of which still are figuring out what they want to be when they grow up,‚Äù and may be considered for consolidation later on down the line, while Meshery has a larger focus than the two projects and will definitely be kept on its own.\n\nWhile the SMI works to define the broadest characteristics that could apply to something defined as a service mesh, looking for the lowest common denominator, Meshery works in the opposite direction, trying to accentuate the differences and strengths of the individual services meshes. SMP, meanwhile, is more of a specification and works to provide a common format for capturing and describing data around the performance of the service mesh itself.\n\nIn comparison to SMI, Calcote said that ‚ÄúSMP essentially just goes a lot deeper. Part of what is trying to address is this long-standing question ‚Äî and it‚Äôs a question that faces the people who are adopting a service mesh today, people who are adopting service mesh tomorrow, people who have already adopted a service mesh ‚Äî What should I be measuring to consider how efficiently I‚Äôm running my service mesh?‚Äù\n\nBetween the three projects, then, users have not just a way to interface with any SMI-compatible service mesh via a common API, but also a way to measure the performance of different service meshes, and finally, a method with which to interface with and operate those service meshes while taking advantage of their specific advantages.\n\n‚ÄúPart of the belief is that service meshes are an inevitable new layer in your cloud native infrastructure that over time will be a ubiquitous component,‚Äù said Calcote. ‚ÄúThere‚Äôs a lot that can be done in the network, a lot of intelligence, and so Meshery, as a management plane, picks off some of those features.‚Äù\n\n</NewsWrapper>\n","frontmatter":{"title":"CNCF Projects Bring Service Mesh Interoperability, Benchmarks","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAqUlEQVR42mNgWPe5lWHt50aG9V8msqz9tIhh998Jl9xmVvw3aJ3/16B9xRez7lKz6Q+mzcxZf2xDxIrJDBu+1DCu/dwAUg9kT2VY96WeYd2nVIYNn9czbPwWyQA0MIxhw/dEhvVf25jXfJrHsPV392X3mbH/DVrm/Tdq2/DBojujpmb39Jk5Gy7tjFjkxLDjTznzmo8zgOqbgXgm0LAlQMOTgXgVw9pP6QDWcFfhh0v1AgAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/666bce02056775aeb9a1de0f96dc0f9f/bc8df/The-New-Stack-Logo.png","srcSet":"/static/666bce02056775aeb9a1de0f96dc0f9f/bc8df/The-New-Stack-Logo.png 367w","sizes":"100vw"},"sources":[{"srcSet":"/static/666bce02056775aeb9a1de0f96dc0f9f/e45b8/The-New-Stack-Logo.webp 367w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.11989100817438691}},"extension":"png","publicURL":"/static/666bce02056775aeb9a1de0f96dc0f9f/The-New-Stack-Logo.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAqUlEQVR42mNgWPe5lWHt50aG9V8msqz9tIhh998Jl9xmVvw3aJ3/16B9xRez7lKz6Q+mzcxZf2xDxIrJDBu+1DCu/dwAUg9kT2VY96WeYd2nVIYNn9czbPwWyQA0MIxhw/dEhvVf25jXfJrHsPV392X3mbH/DVrm/Tdq2/DBojujpmb39Jk5Gy7tjFjkxLDjTznzmo8zgOqbgXgm0LAlQMOTgXgVw9pP6QDWcFfhh0v1AgAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/666bce02056775aeb9a1de0f96dc0f9f/bc8df/The-New-Stack-Logo.png","srcSet":"/static/666bce02056775aeb9a1de0f96dc0f9f/bc8df/The-New-Stack-Logo.png 367w","sizes":"100vw"},"sources":[{"srcSet":"/static/666bce02056775aeb9a1de0f96dc0f9f/e45b8/The-New-Stack-Logo.webp 367w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.11989100817438691}},"extension":"png","publicURL":"/static/666bce02056775aeb9a1de0f96dc0f9f/The-New-Stack-Logo.png"}},"fields":{"slug":"/company/news/cncf-projects-bring-service-mesh-interoperability-benchmarks"}},{"id":"d5db9e8a-0505-5a0f-8718-60931d1ea9f9","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\n<div>\nDevOps teams use the right tools to automate deployment plans to minimize risk to the product and customer experience. These service mesh tools also provide synchronization with web communication standards, adapted to varying security protocols, and offer better management.\n\n## Here are some lesser-known Kubernetes service mesh tools:\n\n**Autopilot:** Autopilot is a toolkit and SDK used for deploying and developing service mesh operators. It is developed by Solo.io, a service connectivity company. This service was launched in late-2019. The service allows its users to automate the service mesh interface for chaos experimentation, adaptive security, canary automation, and more.\n\n**Consul:** Consul, a service mesh solution, has a full-featured control plane. It was first released in 2014 and developed by HashiCorp. This service mesh can be installed and configured on an existing Kubernetes cluster. Its latest version is 1.9.5 that was released on April 15, 2021\n\n**OSM:** Open Service Mesh (OSM) is an open-source service mesh created by Microsoft that supports the Kubernetes environment. It is a cloud-native service mesh that allows users to manage and secure service meshes consistently. It also offers out-of-the-box observability features for dynamic microservice environments.\n\n**Layer5:** Layer5 is a service mesh company and a worldwide community that offers a large collection of service mesh projects. The community creates and maintains several projects that focus on the service mesh-centric capabilities in a cloud-based environment.\nThe key projects operating under the Layer5 community include: `Meshery`, `Learn Layer5`, `Service Mesh Landscape`, `Image Hub`, `Meshery Operator`, `Service Mesh Interface Conformance`, and `NightHawk`.\n\n**Kuma:** Kuma is an open-source service mesh that provides support for multiple environments across clouds, such as Kubernetes and virtual machines. It was created by Kong, and it was recently added to CNCF as a Sandbox project. Moreover, Kuma is production-ready, and it is still under active development.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"5 Lesser-Known, But Extremely Powerful Kubernetes Service Mesh Tools","type":"News","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAABQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZgCdAB9pIQtJHMb0adr3YHYAAP7tJ1NrnPpDtvGpt7brKer8G134gCRlvCJ7Hiq5yiKFcbg2BqHU0Clqc10JmY4yTR+84sxdcD1YOdAgx4a3nDtOLfW2qE7XFh1g8iqu+AQbOhJYa/oa2/r8yr14MRMAAA=="},"images":{"fallback":{"src":"/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp","srcSet":"/static/43427f194c9f6f161811d46d58e960ba/a66aa/kubernetes-with-mesh-tools.webp 750w,\n/static/43427f194c9f6f161811d46d58e960ba/65dd5/kubernetes-with-mesh-tools.webp 1080w,\n/static/43427f194c9f6f161811d46d58e960ba/4fad6/kubernetes-with-mesh-tools.webp 1366w,\n/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/43427f194c9f6f161811d46d58e960ba/kubernetes-with-mesh-tools.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAABQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZgCdAB9pIQtJHMb0adr3YHYAAP7tJ1NrnPpDtvGpt7brKer8G134gCRlvCJ7Hiq5yiKFcbg2BqHU0Clqc10JmY4yTR+84sxdcD1YOdAgx4a3nDtOLfW2qE7XFh1g8iqu+AQbOhJYa/oa2/r8yr14MRMAAA=="},"images":{"fallback":{"src":"/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp","srcSet":"/static/43427f194c9f6f161811d46d58e960ba/a66aa/kubernetes-with-mesh-tools.webp 750w,\n/static/43427f194c9f6f161811d46d58e960ba/65dd5/kubernetes-with-mesh-tools.webp 1080w,\n/static/43427f194c9f6f161811d46d58e960ba/4fad6/kubernetes-with-mesh-tools.webp 1366w,\n/static/43427f194c9f6f161811d46d58e960ba/c512e/kubernetes-with-mesh-tools.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/43427f194c9f6f161811d46d58e960ba/kubernetes-with-mesh-tools.webp"}},"fields":{"slug":"/company/news/5-lesser-known-but-extremely-powerful-kubernetes-service-mesh-tools"}},{"id":"459562ad-b96a-5c5e-b19c-6870f3a21187","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\n<div>\n\n\"Cloud native\" doesn't just mean \"running in the cloud.\" It's a specific deployment paradigm and uses containers and an orchestration system (usually Kubernetes) to help provision, schedule, run and control a production workload in the cloud, or even across multiple clouds. Within cloud native deployments, an increasingly common approach to networking is the service mesh concept. With a service mesh, instead of each individual container requiring a full networking stack, a grouping of containers all benefit from a mesh that provides connectivity and networking with other containers as well as the outside world.\n\nService mesh in the wild\nWhile the concept of a service mesh has applicability beyond just Kubernetes deployments, that's arguably where the vast majority of deployments are today. Among the earliest cloud-native service mesh approaches is the open source Linkerd project, which is backed by Buoyant and began to really ramp up adoption in 2017.\n\nOver the past three years there has been an explosion of open source service mesh technology. Layer5, which develops service mesh aggregation technology, currently tracks over 20 different open and closed source mesh projects. Beyond Linkerd, among the most popular is the Google-backed Istio project, which recently hit its 1.8 milestone release. Cisco has backed the Network Service Mesh (NSM) effort, which works at a lower level in the networking stack than Linkerd, Istio and most others.\n\nEach mesh has its own take on configuration and capabilities, which is a good thing for users. Simply put, there is no shortage of options and there is likely to be a service mesh that already exists to meet just about any need.\n\nService mesh abstraction\nWhile having lots of different service mesh technologies is good for choice, it's not necessarily a good thing for simplicity or interoperability. That's where the concept of service mesh abstraction comes into play.\n\nAt the recent KubeCon NA 2020 virtual event, Lee Calcote, co-chair of the Cloud Native Computing Foundation (CNCF) Networking Special Interest Group (SIG) and founder of Layer5, outlined how the different service mesh abstraction technologies fit together.\n\nThe Service Mesh Interface (SMI) is a way for any compliant service mesh to plug into Kubernetes. The Service Mesh Performance (SMP) abstraction is all about providing visibility into service mesh performance though a common interface. The third key abstraction is known as Hamlet and it provides multi-vendor service interoperation and mesh federation capabilities.\n\nService mesh benefits\nThere are a number of different benefits that service meshes can bring, which are helping to accelerate adoption. Calcote explained that with a service mesh there is a decoupling of developer and operations teams such that each can iterate independently.\n\nAs such, operators can make changes to infrastructure independent of developers. DevOps is supposed to mean developer and operations teams work together, but the reality is often quite different and the ability to build application and infrastructure separately is why service mesh has been such a winning proposition for so many organizations.\n\n\"We live within a software defined network landscape, and service meshes in some respects are sort of a next-gen SDN,\" Calcote said.\n\n</div>\n\n</NewsWrapper>\n","frontmatter":{"title":"Service Mesh Offers Promising Solution for Cloud Native Networking","type":"News","technology":"Cloud","product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC7IDZgmudmGpiGoFX6QKQA/vJjCvgvJkbUF3Y/liMf2Cr8/xo37hrE91bGryC9YOKTJG8D8g1+ChfX6+G1GWpa9O7A7elEBZNUcKzVonLWpxYHA/+hwJ2RWKO+4cLpZL/I4FlFrcEH454AAA=="},"images":{"fallback":{"src":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp","srcSet":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5266666666666667}},"extension":"webp","publicURL":"/static/a2808ac8b497f7848fa6155fba8bb718/service-mesh.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpIAAABXRUJQVlA4IIYAAAAwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZQC7IDZgmudmGpiGoFX6QKQA/vJjCvgvJkbUF3Y/liMf2Cr8/xo37hrE91bGryC9YOKTJG8D8g1+ChfX6+G1GWpa9O7A7elEBZNUcKzVonLWpxYHA/+hwJ2RWKO+4cLpZL/I4FlFrcEH454AAA=="},"images":{"fallback":{"src":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp","srcSet":"/static/a2808ac8b497f7848fa6155fba8bb718/6d672/service-mesh.webp 600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5266666666666667}},"extension":"webp","publicURL":"/static/a2808ac8b497f7848fa6155fba8bb718/service-mesh.webp"}},"fields":{"slug":"/company/news/service-mesh-offers-promising-solution-for-cloud-native-networking"}},{"id":"fd6ca157-b8fb-5194-9d9f-4ebdc2afca86","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\nimport serviceMeshAbstractions from \"./service-mesh-abstractions.webp\";\nimport serviceMeshPerformance from \"./service-mesh-performance.webp\";\n\n<NewsWrapper>\n\nAs more organizations implement service meshes, they are finding what works and what needs more work, and they are creating new management practices around this knowledge. A few tried-and-tested best practices were detailed last month during KubeCon+CloudNativeCon.\n\n‚ÄúThere‚Äôs a lot to say about each of these service meshes and how they work: their architecture, why they‚Äôre made, what they‚Äôre focused on, what they do when they came about and why some of them aren‚Äôt here anymore and why we‚Äôre still seeing new ones,‚Äù Lee Calcote, founder of Layer5, explained during his talk entitled ‚ÄúService Mesh Specifications and Why They Matter in Your Deployment.‚Äù\n\nService mesh is increasingly seen as a requirement to manage microservices in Kubernetes environments, offering a central control plane to manage microservices access, testing, metrics and other functionalities. One-third of the respondents in The New Stack survey of our readers said their organizations already use service mesh. Among the numerous service mesh options available; Envoy, Istio, Linkerd and Kuma are but a few on offer.\n\n### Interoperability Is Key as Service Meshes Come and Go\n\nOrganizations will likely look to use at least more than one API service layer and service mesh for their clusters. This is why interoperability, and thus specifications, are critical for control planes as well. During his talk ‚Äî ‚ÄúService Mesh Specifications and Why They Matter in Your Deployment‚Äù mentioned above ‚Äî for example, Calcote, asked rhetorically:\n\n‚ÄúHow many specifications, how many standards are there that have come to the rescue, so to speak, for understanding and interoperating with the various service meshes that are out there?‚Äù Calcote said.\n\n<a href={serviceMeshAbstractions}><img src={serviceMeshAbstractions} alt=\"service-mesh-abstractions\" width=\"100%\" /></a>\n\nA service mesh can be used for testing router performance, service latency and other variables. However, determining service mesh performance in an apples-to-apples way can be challenging. When studying ‚Äúpublished results from some of the service meshes [from providers] that do publish results about performance‚Ä¶ what you‚Äôll find is that they‚Äôre probably using an environment that isn‚Äôt necessarily like yours,‚Äù Calcote said. ‚ÄúThey‚Äôre also using different statistics and metrics to measure [their service meshes] ‚Ä¶ and it doesn‚Äôt help.‚Äù\n\n<a href={serviceMeshPerformance}><img src={serviceMeshPerformance} alt=\"service-mesh-performance\" width=\"100%\" /></a>\n\nService mesh performance (SMP) was created in an attempt to establish a way of comparing the performance of different services. ‚ÄúThe SMP was born in combination with engaging with a few of those different service mesh maintainers and creating a standard way of articulating a performance of a mesh,‚Äù Calcote said.\n\nAmong the variables in consideration, in addition to the service mesh itself, include the number of clusters, workloads, the types of nodes, control plan configuration and the use of client libraries all affect performance.\n\n‚ÄúWhat costs more, what‚Äôs more efficient and what‚Äôs more powerful: These are all open questions that SMP assists in answering in your environment,‚Äù Calcote said.\n\n</NewsWrapper>\n","frontmatter":{"title":"KubeCon+CloudNativeCon","type":"News","technology":null,"product":"Service Mesh Performance","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAgAPtFWpEuoJKOhsAgBABoJYgCdMoADf76Io9ukEMKaAAD+0NVX8yrCCYso0t4m+uqXvUNcjspWp5cPsm9igQenys+i4un1qy0qCumd6/zcds2HFNCb9SqZQTZuLg8wT+AA"},"images":{"fallback":{"src":"/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp","srcSet":"/static/3bbaf49e171ac3012bc61c5567dd6aed/b07c1/service-mesh-implementations.webp 750w,\n/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":0.41503906250000006}},"extension":"webp","publicURL":"/static/3bbaf49e171ac3012bc61c5567dd6aed/service-mesh-implementations.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAgAPtFWpEuoJKOhsAgBABoJYgCdMoADf76Io9ukEMKaAAD+0NVX8yrCCYso0t4m+uqXvUNcjspWp5cPsm9igQenys+i4un1qy0qCumd6/zcds2HFNCb9SqZQTZuLg8wT+AA"},"images":{"fallback":{"src":"/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp","srcSet":"/static/3bbaf49e171ac3012bc61c5567dd6aed/b07c1/service-mesh-implementations.webp 750w,\n/static/3bbaf49e171ac3012bc61c5567dd6aed/09f13/service-mesh-implementations.webp 1024w","sizes":"100vw"},"sources":[]},"width":1,"height":0.41503906250000006}},"extension":"webp","publicURL":"/static/3bbaf49e171ac3012bc61c5567dd6aed/service-mesh-implementations.webp"}},"fields":{"slug":"/company/news/kubeconcloudnativecon"}},{"id":"83a4f01b-acfc-5f1d-9d6c-af88173ebdd9","body":"\nimport kubernetes from \"./kubernetes-platform.webp\";\n\n<img align=\"left\" style={{ padding: \"15px\" }} src={kubernetes} alt=\"Kubernetes-platform\" />\n\nA service mesh has become a critical part of platforms based on Kubernetes clusters. It provides both east-west and north-south traffic managementxi, security, observability, and shaping for services implemented by the cluster and supporting components. As clusters have grown in size and platforms have become comprised of many clusters, maintaining a consistent view, management, and policies for network layer 4 ‚Äì 7 traffic has become increasingly complex.\n\nIn response, a number of vendors have extended control planes with a multi-cluster management layer such that they federate and manage service meshes at scale across multiple clouds and on-premises deployments. Both Hashicorp Consul and VMWare Tanzu NSX Service Mesh extend the service mesh control plane past the local service mesh to allow a management layer over multiple clouds and clusters. The open source project <a href=\"/cloud-native-management/meshery\"><b>Meshery</b></a> is also providing a service mesh management plane as separate software that can interact using the Service Mesh Interface or through built-for-purpose adapters for a variety of existing service mesh products and projects.\n\nLike Kubernetes control planes, this extension of the service mesh control plane allows for consistent management and policies across clusters in different environments, a situation that is becoming more typical in enterprise IT applications.\n\nService mesh control plane federation is an emerging feature of service mesh products. Unlike Kubernetes control planes, it is not yet commonplace, but Amalgam Insights predicts that we will see service mesh control plane federation become a normal part of the service mesh landscape.\n\n<center>\n<h5 className=\"black-text\">Access the full <a href=\"https://amalgaminsights.com/2018/12/20/the-view-from-kubeconcloudnativecon-seattle/\">research from Amalgam Insights</a></h5>\n</center>\n","frontmatter":{"title":"Meshery Provides the Service Mesh Management Plane and Kubernetes Evolves into an Enterprise Platform","type":"News","technology":"Kubernetes","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAABwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJaQAAUz7ZZ8qBWQAA/vGd5EmHfVUQRyXKfh9ED+fAbmSNCQRFF7yTAAA="},"images":{"fallback":{"src":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp","srcSet":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp 404w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504950495049505}},"extension":"webp","publicURL":"/static/d5ca72e88de08ce71380ce562f67719c/kubernetes-platform.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRk4AAABXRUJQVlA4IEIAAABwAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJaQAAUz7ZZ8qBWQAA/vGd5EmHfVUQRyXKfh9ED+fAbmSNCQRFF7yTAAA="},"images":{"fallback":{"src":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp","srcSet":"/static/d5ca72e88de08ce71380ce562f67719c/b669d/kubernetes-platform.webp 404w","sizes":"100vw"},"sources":[]},"width":1,"height":0.504950495049505}},"extension":"webp","publicURL":"/static/d5ca72e88de08ce71380ce562f67719c/kubernetes-platform.webp"}},"fields":{"slug":"/company/news/meshery-provides-the-service-mesh-management-plane-and-kubernetes-evolves-into-an-enterprise-platform"}},{"id":"bbc29500-fde1-5510-8899-cab604e7f720","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\nMeshery took its first steps into the Cloud Native world in July of 2019 with the vision to ease the adoption and operation of any service mesh. Since then, Meshery as a project and Layer5 as an open source community has grown by leaps and bounds. Now, right at a year later, we are bursting with pride in announcement of:\n\n<h3 style={{ textAlign: \"center\" }}>Meshery is officially accepted into the Cloud Native Computing Foundation's Landscape!</h3>\n\n<br/>\nRead about our journey in the words of one of our valued contributors and proud Meshery user, Anton Weiss: <br/>\n<i>\n\"Open source contributions are a must-do for becoming a true cloud native hero. Cloud native is all about the community and one can't be a part of a community by only taking and never giving back. So, if you were looking for a promising and welcoming project to join - look no further! <br/> Hop on to Layer5 Slack and we'll happily embrace you and help you get started. And it's not only coding! Documentation, testing, UI design, logos, blogs, videos - you decide where to apply your talent.\"\n</i>\n<br/>\n\n</NewsWrapper>\n","frontmatter":{"title":"Meshery accepted into the CNCF Landscape","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXElEQVR42mOwT1qSkT513/auM7dW+NWu3KwR2BJoqqtgZ2Bgpm9oaGhiZGQUCMTGQHa4iYmJKZBtYWxs7ArCQLYPUDwISNsC+XFAbMSQu+D0rHvf////+e3Gz0t3Dv93ad5apSfPH2Ribh4DNCARqCgTqCkRqKkSyA4Asn2BdBMQlwPZIDV+QLloILsBJMfQeuL29J7L6/7PPLvky8pbp/8XbD6Vz8DAIBRTXMwN1KQM1CCrp6cnBqTVoa7j19HRETc3NxcHGiBlYGAgampqKmFjYyMIpIUZ3CtWzPJc2/Tff2/VT68Fff/dsuZW6EoxqBuY2WgBNecBDXEHYaCBINd4Ag2JAIq7mZmZ6QPFE4CGxINcCRRLBmJHBrukZYbhbQfD6088DfAu2h5qETNbxVBLWcXYykoZqFkFqJEPhEFskIuAmuSAfBmgCxWAfHlQuOrr6yvo6urKgFwKAM3tedLTsuqdAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/6214a68ea923f8daf5b41c2873891dd5/c5f2d/cncf-landscape-horizontal-color.png","srcSet":"/static/6214a68ea923f8daf5b41c2873891dd5/61979/cncf-landscape-horizontal-color.png 750w,\n/static/6214a68ea923f8daf5b41c2873891dd5/c5f2d/cncf-landscape-horizontal-color.png 925w","sizes":"100vw"},"sources":[{"srcSet":"/static/6214a68ea923f8daf5b41c2873891dd5/60d85/cncf-landscape-horizontal-color.webp 750w,\n/static/6214a68ea923f8daf5b41c2873891dd5/dfc90/cncf-landscape-horizontal-color.webp 925w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.2562162162162162}},"extension":"png","publicURL":"/static/6214a68ea923f8daf5b41c2873891dd5/cncf-landscape-horizontal-color.png"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXElEQVR42mOwT1qSkT513/auM7dW+NWu3KwR2BJoqqtgZ2Bgpm9oaGhiZGQUCMTGQHa4iYmJKZBtYWxs7ArCQLYPUDwISNsC+XFAbMSQu+D0rHvf////+e3Gz0t3Dv93ad5apSfPH2Ribh4DNCARqCgTqCkRqKkSyA4Asn2BdBMQlwPZIDV+QLloILsBJMfQeuL29J7L6/7PPLvky8pbp/8XbD6Vz8DAIBRTXMwN1KQM1CCrp6cnBqTVoa7j19HRETc3NxcHGiBlYGAgampqKmFjYyMIpIUZ3CtWzPJc2/Tff2/VT68Fff/dsuZW6EoxqBuY2WgBNecBDXEHYaCBINd4Ag2JAIq7mZmZ6QPFE4CGxINcCRRLBmJHBrukZYbhbQfD6088DfAu2h5qETNbxVBLWcXYykoZqFkFqJEPhEFskIuAmuSAfBmgCxWAfHlQuOrr6yvo6urKgFwKAM3tedLTsuqdAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/6214a68ea923f8daf5b41c2873891dd5/c5f2d/cncf-landscape-horizontal-color.png","srcSet":"/static/6214a68ea923f8daf5b41c2873891dd5/61979/cncf-landscape-horizontal-color.png 750w,\n/static/6214a68ea923f8daf5b41c2873891dd5/c5f2d/cncf-landscape-horizontal-color.png 925w","sizes":"100vw"},"sources":[{"srcSet":"/static/6214a68ea923f8daf5b41c2873891dd5/60d85/cncf-landscape-horizontal-color.webp 750w,\n/static/6214a68ea923f8daf5b41c2873891dd5/dfc90/cncf-landscape-horizontal-color.webp 925w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.2562162162162162}},"extension":"png","publicURL":"/static/6214a68ea923f8daf5b41c2873891dd5/cncf-landscape-horizontal-color.png"}},"fields":{"slug":"/company/news/meshery-accepted-into-the-cncf-landscape"}},{"id":"251537a7-cdcc-51ce-81cf-50a9e792197f","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\nimport layer5_hashicorp_partnership from \"./Layer5-HashiCorp-Service-Mesh-Partnership.webp\";\nimport layer5_image_hub from \"./layer5-image-hub-on-hashicorp-consul.webp\";\n\n<NewsWrapper>\n<link rel=\"canonical\" href=\"/company/news/layer5-and-hashicorp-launch-service-mesh-partnership\" />\n\n_Announced on May 28th, 2020 at DockerCon Live 2020._\n\n## Meshery Announces Native Support for Consul Service Mesh\n\nToday, we are pleased to announce the technology partnership of Layer5 and HashiCorp. Layer5‚Äôs [Meshery](https://layer5.io/cloud-native-management/meshery), the cloud native management plane, and HashiCorp‚Äôs [Consul](https://consul.io) integrate to provide advanced, cloud native infrastructure solutions for containerized and non-containerized workloads - strengths of Consul. The marriage of these technologies forms a layering of network planes: data, control, and management.\n\n<a href={layer5_hashicorp_partnership}>\n  <img\n    src={layer5_hashicorp_partnership}\n    alt=\"layer5-hashicorp-partnership\"\n    width=\"100%\"\n  />\n</a>\n\n_Service Mesh Planes: Consul and Meshery. Learn more about service mesh planes in [The Enterprise Path to Service Mesh Architectures](https://layer5.io/books/the-enterprise-path-to-service-mesh-architectures)._\n\nConsul‚Äôs broad and prevalent use across [any runtime or infrastructure](https://learn.hashicorp.com/consul/datacenter-deploy/reference-architecture) (bare metal servers, virtual machines, Kubernetes clusters, and any cloud) is a key facilitator of the modernization of IT infrastructure - a significant attractant for Layer5 to focus on this integration; to meet customers where they‚Äôre at. The lynchpin of the integration of Consul and Meshery is the Meshery Adapter for Consul. Through this adapter, Meshery facilitates lifecycle management of Consul service mesh deployments, evaluates and espouses configuration best practices published by HashiCorp. Meshery provides users with an interface to apply custom configuration to their Consul service mesh in an ad hoc fashion.\n\n### Lifecycle management of sample applications\n\nThe [Meshery Adapter for Consul](https://docs.meshery.io/service-meshes/adapters/consul) comes bundled with a handful of sample applications for evaluating, exploring, and learning how to operate Consul service mesh. Many operators are new to the ongoing administrative tasks of running a healthy and optimized Consul service mesh deployment. In advance of their production deployments, operators may utilize Meshery to quickly deploy Consul with sample applications to gain familiarity with the many features of Consul.\n\nDemonstrated at DockerCon 2020, is the ‚Äú[Image Hub](https://github.com/layer5io/image-hub)‚Äù, a sample application built to allow users to explore Consul‚Äôs feature set, and specifically, an experimental area of Consul‚Äôs data plane: Envoy‚Äôs impending support for WebAssembly.\n\n### Performance management of Consul and it‚Äôs workloads\n\nIn order to assess the overall performance of the service mesh, and the overhead of individual, fine-grained traffic control mechanisms defined in Consul‚Äôs control plane and enforced through Consul‚Äôs intelligent data plane, Meshery provides users with statistical analysis of the responsiveness of their services and performance of the service mesh. As highlighted by Docker Captain, [Luc Juggery](https://twitter.com/lucjuggery), performance is an ongoing concern:\n\n<div style={{ margin: \"20px\" }}>\n  Running a performance test is not a one shot thing. Tests should be run on a\n  regular basis to (re)establish baselines and evaluate configuration changes:\n  <ul>\n    <li>- for each new release of the chosen service mesh</li>\n    <li>- for each change of the configuration of your service mesh</li>\n    <li>- for each new release of the application\"</li>\n  </ul>\n</div>\n\nMeshery‚Äôs ability to connect to Prometheus instances to retrieve and account for cluster and application-level metrics is popularly used during Meshery‚Äôs service mesh performance tests. Likewise, Meshery‚Äôs ability to connect to and import existing dashboards, panels, and charts from Grafana is instrumental in allowing users to retain their existing investment in dashboards and metrics they have curated over time.\n\n## Meshery Announces Experimental Support for WebAssembly using Consul\n\nToday, at [DockerCon 2020](https://docker.events.cube365.net/docker/dockercon/content/Videos/63TCCNpzDC7Xxnm8b), we demonstrate technology leadership in advanced data plane engineering for near-native performance of fine-grained traffic control facilitated by Meshery and Consul with the use of Envoy and WebAssembly.\n\n<a href={layer5_image_hub}>\n  <img src={layer5_image_hub} alt=\"layer5-hashicorp-imagehub\" width=\"100%\" />\n</a>\n\n_In this demonstration, Meshery takes advantage of Consul‚Äôs use of Envoy. Envoy support for WebAssembly is impending._\n\n### WebAssembly‚Äôs near-native performance\n\nWebAssembly, or WASM, is an open standard that defines a binary format for executable programs. Through WebAssembly System Interface (WASI), it also defines interfaces for facilitating interaction with host environments. The initial focus of these host environments was browsers and large web applications with the intention of securely running programs to improve performance. As an open standard, WASM is maintained by the W3C, and has been adopted by all modern browsers. After HTML, CSS, and Javascript, WebAssembly is the fourth language to natively run in web browsers.\n\nWebAssembly is exciting because of its performance characteristics, running between 10% to 20% overhead as compared to natively executed code for network filtering use cases. WebAssembly bears some resemblance to Docker given its high degree of portability. Like the Java Virtual Machine (JVM), WASM‚Äôs virtual stack machine is becoming a write once, run anywhere (WORA). WASM executables are precompiled with a healthy variety of languages supporting it as a compilation target - currently about 40 languages.\n\nWASM support is coming to Envoy through the efforts of Google, and Envoy maintainers embedding Google's open source high-performance JavaScript and WebAssembly engine, V8, into Envoy. Through the WebAssembly System Interface, Envoy exposes an Application Binary Interface (ABI) to WASM modules, so that they can operate as Envoy filters. The way WASI works is straight-forward. You write your application in your favourite languages like Rust, C or C++. Then, build and compile them into a WebAssembly binary targeting the host environment. The generated binary requires the WebAssembly runtime to provide the necessary interfaces to system calls for the binary to execute. Conceptually, this is similar to JVM. If you have a JVM installed then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.\n\n## Learn more\n\nThis integration of management, control, and data planes is a powerful combination. See Meshery and Consul in-action at [DockerCon 2020](https://docker.events.cube365.net/docker/dockercon/content/Videos/63TCCNpzDC7Xxnm8b). Learn more about [Layer5 and HashiCorp‚Äôs partnership](https://www.hashicorp.com/integrations/layer5-io/consul/).\n\n**About Consul**\n\nFor more information about Consul, please visit: [https://www.consul.io](https://www.consul.io).\n\n**About HashiCorp**\n\nFor more information about HashiCorp, please visit: [https://hashicorp.com](https://hashicorp.com)\n\n**About Meshery**\n\nFor more information about Meshery, please visit: [https://meshery.io](https://meshery.io)\n\n**About Layer5**\n\nFor more information about Layer5, please visit: [https://layer5.io](https://layer5.io)\n\n</NewsWrapper>\n","frontmatter":{"title":"Layer5 and HashiCorp Launch Service Mesh Partnership","type":"News","technology":"WebAssembly","product":"Meshery","mesh":"Consul","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpQAAABXRUJQVlA4IIgAAADwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJaQAD4coOltM3zZ3rJcoAAP7qVt1qgj75t4tSHc71Vn+D2BXmrz/efUjPU+mokWbpyHp9/p5q0ywR6Lv2yZZ0kDFBb8d0hb0HH6GF3sGgq02ng+tLemIT+URQs5nV3CV0rtFdBp7tNRXpaWaJKgAA"},"images":{"fallback":{"src":"/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp","srcSet":"/static/a36abfe42e42455496b77e017dce4822/ca8ed/layer5-hashicorp.webp 750w,\n/static/a36abfe42e42455496b77e017dce4822/8b691/layer5-hashicorp.webp 1080w,\n/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5275}},"extension":"webp","publicURL":"/static/a36abfe42e42455496b77e017dce4822/layer5-hashicorp.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpQAAABXRUJQVlA4IIgAAADwAwCdASoUAAsAPtFUo0uoJKMhsAgBABoJaQAD4coOltM3zZ3rJcoAAP7qVt1qgj75t4tSHc71Vn+D2BXmrz/efUjPU+mokWbpyHp9/p5q0ywR6Lv2yZZ0kDFBb8d0hb0HH6GF3sGgq02ng+tLemIT+URQs5nV3CV0rtFdBp7tNRXpaWaJKgAA"},"images":{"fallback":{"src":"/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp","srcSet":"/static/a36abfe42e42455496b77e017dce4822/ca8ed/layer5-hashicorp.webp 750w,\n/static/a36abfe42e42455496b77e017dce4822/8b691/layer5-hashicorp.webp 1080w,\n/static/a36abfe42e42455496b77e017dce4822/f9149/layer5-hashicorp.webp 1200w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5275}},"extension":"webp","publicURL":"/static/a36abfe42e42455496b77e017dce4822/layer5-hashicorp.webp"}},"fields":{"slug":"/company/news/layer5-and-hashicorp-launch-service-mesh-partnership"}},{"id":"64df8149-6294-5076-9c8d-f16dfd23e718","body":"\nimport { NewsWrapper } from \"../../News.style.js\"\n\n<NewsWrapper>\nService mesh technologies have emerged as a reliable way to manage observability, security and traffic management in microservices environments, typically with the use of Kubernetes for container orchestration. Specific use cases and needs for service meshes also vary.\n<br/><br/>\nThe New Stack recently completed a survey about service mesh use cases. While one third of those surveyed said their organizations already use service meshes to control traffic between microservices and Kubernetes environments, adoption rates and use varied significantly among the respondents. Sixteen percent of respondents said that their organization broadly uses service mesh in production environments and 17% said service meshes have limited use in production environments, for example.\n<br/><br/>\nIn this latest episode of The New Stack Analysts podcast, <a href=\"https://www.linkedin.com/in/leecalcote\">Lee Calcote</a>, an analyst and founder of service mesh provider <a href=\"https://layer5.io/\">Layer5</a>, and <a href=\"https://www.linkedin.com/in/brianredbeard/\">Brian ‚ÄúRedbeard‚Äù Harrington</a>, a principal product manager for OpenShift service mesh at Red Hat, discussed the many nuances of what the survey numbers really mean.\n<br/><br/>\n<iframe width=\"100%\" height=\"166\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/774586579%3Fsecret_token%3Ds-es7L3&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true\" loading=\"lazy\"></iframe>\n<br/><br/>\nCalcote notes how traffic management is seen as a key feature among the many different service mesh capabilities, but it‚Äôs most useful to advanced users. Speaking about the use of traffic management functionalities, Calcote said: ‚ÄúFolks tend to be a little more advanced as they get into that because they‚Äôre at that point they‚Äôre actually affecting traffic and then routing requests differently, as opposed to something like just purely observing or getting a ‚Äòread-only‚Äô view in their environment.‚Äù\n<br/><br/>\n\n</NewsWrapper>\n\n\n","frontmatter":{"title":"The New Stack: What the Numbers Say about How Service Meshes Are Used Today","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAACQBACdASoUABEAPtFcpU6oJSMiKAqpABoJaTcAAADheslpkcZR0v8TjFjJzAAA/vCjjd7ZN/+hiZMLVyqN5EDUMLtP25EUQ4dbE8BqzJoC++39ZzdWJEUqFLlNAGLiRcfoB2AuwCvh2CIg09W3O7i88d/Ao2wc29oCC/vc0Oq/kC5lDgpihv3T4AAAAA=="},"images":{"fallback":{"src":"/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp","srcSet":"/static/1d413ecd41b509f9ab80fce27e78f284/1e798/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 750w,\n/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 761w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8554533508541393}},"extension":"webp","publicURL":"/static/1d413ecd41b509f9ab80fce27e78f284/what-the-numbers-say-about-how-service-meshes-are-used-today.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRpgAAABXRUJQVlA4IIwAAACQBACdASoUABEAPtFcpU6oJSMiKAqpABoJaTcAAADheslpkcZR0v8TjFjJzAAA/vCjjd7ZN/+hiZMLVyqN5EDUMLtP25EUQ4dbE8BqzJoC++39ZzdWJEUqFLlNAGLiRcfoB2AuwCvh2CIg09W3O7i88d/Ao2wc29oCC/vc0Oq/kC5lDgpihv3T4AAAAA=="},"images":{"fallback":{"src":"/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp","srcSet":"/static/1d413ecd41b509f9ab80fce27e78f284/1e798/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 750w,\n/static/1d413ecd41b509f9ab80fce27e78f284/7290b/what-the-numbers-say-about-how-service-meshes-are-used-today.webp 761w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8554533508541393}},"extension":"webp","publicURL":"/static/1d413ecd41b509f9ab80fce27e78f284/what-the-numbers-say-about-how-service-meshes-are-used-today.webp"}},"fields":{"slug":"/company/news/the-new-stack-what-the-numbers-say-about-how-service-meshes-are-used-today"}},{"id":"617e3e58-0541-5058-8d5c-8cbd1b69c619","body":"\nimport { NewsWrapper } from \"../../News.style.js\"\n\n<NewsWrapper>\n\nWhen an organization is forced to manage distributed service-to-service communication over a large network, service mesh provides a dedicated layer where separate parts of an application can communicate with each other. This way, software teams can centralize communication, rather than monitor each individual service message exchange independently.\n\nWhen service mesh emerged in 2018, many saw this technology as a way to tackle the complexity of container deployment at production scale. They also saw it as a way to address unsustainable manual traffic management processes.\n\nIn 2019, the success of service mesh implementation inspired a rush of vendors that hoped to cash in on the need to manage services at scale. The industry saw a booming sub-ecosystem around two major service mesh options, Google's Istio and the open source Envoy, plus many √† la carte tools, such as Tetrate and Meshery. A handful of newcomers jumped into the fray, such as HashiCorp, Kong, Containous, Aspen Mesh and Layer5. Despite the competition, Istio and Envoy led the pack.\n\nThe service mesh market saw two significant events in 2019. First, Envoy Project Authors fine-tuned its increasingly popular sidecar proxy design pattern. Second, Google kept its service mesh technology, and Istio, out of the open source Cloud Native Computing Foundation (CNCF), and thereby retained proprietary control.\n\n</NewsWrapper>\n","frontmatter":{"title":"Vendors make a splash in 2019 service mesh implementation rush","type":"News","technology":null,"product":null,"mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAABQBACdASoUAAYAPtFWpEuoJKOhsAgBABoJZQCdH8G6A5/8B5Pd7JAOdIsAAP7Hfg7V6Cw+lBvPBuF5PLewMAEGH3x14wTH6pKuiqCh/pETb+DWCdaMnSQXMD8R1kSMqbBP+Ao0ZoAAAA=="},"images":{"fallback":{"src":"/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp","srcSet":"/static/34068b4bb8760d9d00922b48df09397b/440b4/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 750w,\n/static/34068b4bb8760d9d00922b48df09397b/4dabe/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1080w,\n/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1274w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3021978021978022}},"extension":"webp","publicURL":"/static/34068b4bb8760d9d00922b48df09397b/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnQAAABXRUJQVlA4IGgAAABQBACdASoUAAYAPtFWpEuoJKOhsAgBABoJZQCdH8G6A5/8B5Pd7JAOdIsAAP7Hfg7V6Cw+lBvPBuF5PLewMAEGH3x14wTH6pKuiqCh/pETb+DWCdaMnSQXMD8R1kSMqbBP+Ao0ZoAAAA=="},"images":{"fallback":{"src":"/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp","srcSet":"/static/34068b4bb8760d9d00922b48df09397b/440b4/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 750w,\n/static/34068b4bb8760d9d00922b48df09397b/4dabe/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1080w,\n/static/34068b4bb8760d9d00922b48df09397b/c6e26/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp 1274w","sizes":"100vw"},"sources":[]},"width":1,"height":0.3021978021978022}},"extension":"webp","publicURL":"/static/34068b4bb8760d9d00922b48df09397b/2019-12-27-vendors-make-a-splash-in-2019-service-mesh-implementation-rush.webp"}},"fields":{"slug":"/company/news/vendors-make-a-splash-in-2019-service-mesh-implementation-rush"}},{"id":"d54999fc-e89f-5c6b-935a-5af585bf53eb","body":"\nimport { NewsWrapper } from \"../../News.style.js\";\n\n<NewsWrapper>\n\nIn 2019, we saw service mesh move beyond an experimental technology and into a solution that organizations are beginning to learn is an elemental building block for any successful Kubernetes deployment. Adoption of service mesh at scale, across companies large and small, began to gain steam. As the second wave of adopters watched the cutting edge adopters trial and succeed with service mesh technology, they too began to evaluate service mesh to address the challenges Kubernetes leaves on the table.\n<br/>\n\nIn tandem with growing adoption of service mesh, 2019 offered a burgeoning service mesh market. Istio and Linkerd keep chugging along, and the tooling and vendor ecosystem around Istio almost tripled throughout the year. But there were also many new players that entered the market providing alternative approaches to solving layer seven networking challenges. Meshes, such as those Kuma and Maesh offer, have emerged to provide different approaches to service mesh in order to address various edge use cases. We also saw the introduction of tools like [Service Mesh Interface](https://smi-spec.io/) spec and [Meshery](https://layer5.io/meshery/) attempt to engage an early market that is flourishing due to immense opportunity, but has yet to contract while key players are waiting for the market to choose the winners first. Adjacent projects like [Network Service Mesh](https://networkservicemesh.io/) bring service mesh principles to lower layers of the stack.\n<br/>\n\n\n</NewsWrapper>\n","frontmatter":{"title":"Meshery in top 3 service mesh developments in 2020","type":"News","technology":null,"product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBQCdASoUABIAPtFcok4oJSKiKA1RABoJZAC1Gy/lvQwDPxKvEGRfFu90PUVDp1QXgAAA/ufjO56dRxtwAdARiX21W2xYHKwFys8WfnpU3Q8u912iDFv4Yyhpmy0BSZ1fpQ+ikh9JSGSXilJufNsKum3VfZPJAXJeWKrKdBX1RLkiM9SDJKoyFAzgdj3y76yFQiTlVbANwJsHp45bR+OKeWis0LDrCQe9jcPYAs3WCAAA"},"images":{"fallback":{"src":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp","srcSet":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp 649w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8921417565485361}},"extension":"webp","publicURL":"/static/b8151b980f351e8733505acaa801c470/Meshery_top3_servish_mesh_development.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBQCdASoUABIAPtFcok4oJSKiKA1RABoJZAC1Gy/lvQwDPxKvEGRfFu90PUVDp1QXgAAA/ufjO56dRxtwAdARiX21W2xYHKwFys8WfnpU3Q8u912iDFv4Yyhpmy0BSZ1fpQ+ikh9JSGSXilJufNsKum3VfZPJAXJeWKrKdBX1RLkiM9SDJKoyFAzgdj3y76yFQiTlVbANwJsHp45bR+OKeWis0LDrCQe9jcPYAs3WCAAA"},"images":{"fallback":{"src":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp","srcSet":"/static/b8151b980f351e8733505acaa801c470/265bf/Meshery_top3_servish_mesh_development.webp 649w","sizes":"100vw"},"sources":[]},"width":1,"height":0.8921417565485361}},"extension":"webp","publicURL":"/static/b8151b980f351e8733505acaa801c470/Meshery_top3_servish_mesh_development.webp"}},"fields":{"slug":"/company/news/meshery-in-top-3-service-mesh-developments-in-2020"}},{"id":"dfec3ca5-0f24-5bdd-a318-0e9807c344ba","body":"\nimport { Link } from \"gatsby\";\nimport { ResourcesWrapper } from \"../../../Resources.style\";\n\nLearn more about how to wrangle <Link to=\"/blog/meshery/multi-cluster-kubernetes-management-with-meshery\">multiple Kubernetes clusters with Meshery</Link>.\n\n<ResourcesWrapper>\n\nDevelopers working in fast-paced environments often face infrastructure sprawl. Even with containerized deployments on Kubernetes, managing hundreds or thousands of clusters across projects remains a challenge.\n\nA **Kubernetes multi-cluster** setup solves this by distributing workloads across several independent clusters, delivering better **isolation**, **availability**, and **scalability**.\n\n## What Is a Kubernetes Multi-Cluster Setup?\n\nIn a multi-cluster architecture you run multiple, independent Kubernetes clusters ‚Äî they can live on the same physical host, across data centers, or in different regions and cloud providers. Each cluster manages its own control plane and resources.\n\nThis approach gives you:\n\n- Stronger workload isolation\n- Geographic distribution & lower latency\n- Reduced blast radius in case of failures or breaches\n- Easier compliance and governance\n\n## Why Use Multi-Cluster Kubernetes?\n\nCommon drivers include:\n\n- **Tenant & environment isolation** (dev / staging / prod)\n- **High availability & failover** across regions\n- **Avoiding vendor lock-in**\n- **Security & compliance boundaries**\n- **Independent upgrade schedules** per environment\n\n### Cluster Discovery and Tenant Isolation\n\nNamespaces offer only soft multi-tenancy. A compromised or noisy neighbor in one namespace can affect the entire cluster. Separate clusters give you hard isolation ‚Äî perfect for different teams, customers, or compliance regimes.\n\n### Failover and Resilience\n\nWith multiple clusters, traffic can shift to healthy clusters automatically if one fails ‚Äî eliminating single points of failure.\n\n## Multi-Cluster vs Multitenancy\n\n| Approach       | Shared Control Plane | Isolation Level | Typical Use Case                     |\n|----------------|----------------------|-------------------|--------------------------------------|\n| Multitenancy   | Yes                  | Soft (namespaces) | Cost-sensitive, moderate isolation   |\n| Multi-cluster  | No                   | Hard              | Production, compliance, HA, geo-distribution |\n\nMany organizations use a mix of both.\n\n## When Should You Go Multi-Cluster?\n\nConsider multi-cluster if you need:\n\n- Workloads in multiple geographic regions\n- Strict regulatory or security separation\n- Independent lifecycle management per environment\n- Zero-downtime upgrades or blue/green deployments\n\n## Key Benefits\n\n- **True tenant isolation** ‚Äî changes in one cluster never affect others\n- **No single point of failure**\n- **No vendor lock-in** ‚Äî move workloads freely between clouds\n- **Independent scaling & upgrades** per cluster\n\n## Managing the Complexity\n\nThe more clusters you have, the greater the operational overhead. You need:\n\n- A unified view of all clusters\n- Easy context switching\n- Consistent policy enforcement\n- Automated lifecycle management\n\nThat‚Äôs exactly where <Link to=\"/meshery\">Meshery</Link>, the open-source cloud native manager, shines. Meshery provides a single management plane for any number of Kubernetes clusters (and service meshes) with its built-in MeshSync controller continuously discovering and cataloging resources across all connected clusters.\n\n### Deprovisioning Old Clusters\n\nWhen a cluster is no longer needed, delete it cleanly:\n\n```bash\n# Example with GKE\ngcloud container clusters delete CLUSTER_NAME --region REGION\n```\n\n</ResourcesWrapper>","frontmatter":{"title":"What is Multi-Cluster Kubernetes?","type":"Article","technology":"Kubernetes","product":null,"mesh":null,"thumbnail":null,"darkthumbnail":null},"fields":{"slug":"/resources/kubernetes/what-is-multi-cluster-kubernetes"}},{"id":"f4d50376-3927-53c2-8d49-f2ad34e4c73b","body":"Too lazy to implement multi-tenancy? Don't have time to implement per user rate limiting in your application's endpoints? In this talk, we will examine how to let application infrastructure concerns melt off your Dockerized workloads and have your infrastructure implement multi-tenancy on your behalf.\n\nLearn how to use Docker Desktop and Kubernetes as your development platforms of choice in combination with Meshery, the cloud native management plane, to easily deploy a service mesh. Using Consul and Envoy's latest capabilities, see how WASM can be used to move user authentication and authorization from your application to the infrastructure.","frontmatter":{"title":"DockerCon LIVE","type":"Event","technology":"Docker","product":"Meshery","mesh":null,"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoQAAABXRUJQVlA4IHgAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdH8GJ/gPNEbtVx2W1tm4OgAD+8YB+o/JPMBUszhbX2XgfyYa480xd/nGXIU7QxsbxU+kloDLJf6a9ZPl5uX0PNims/4PMDglbDuYeHIVMNVVNctCcxMDaj6npYAA="},"images":{"fallback":{"src":"/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp","srcSet":"/static/9497b4aad63f55a6d041b550a7c9b01a/a66aa/dockerCon2020.webp 750w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/65dd5/dockerCon2020.webp 1080w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/4fad6/dockerCon2020.webp 1366w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/9497b4aad63f55a6d041b550a7c9b01a/dockerCon2020.webp"},"darkthumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRoQAAABXRUJQVlA4IHgAAABwBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdH8GJ/gPNEbtVx2W1tm4OgAD+8YB+o/JPMBUszhbX2XgfyYa480xd/nGXIU7QxsbxU+kloDLJf6a9ZPl5uX0PNims/4PMDglbDuYeHIVMNVVNctCcxMDaj6npYAA="},"images":{"fallback":{"src":"/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp","srcSet":"/static/9497b4aad63f55a6d041b550a7c9b01a/a66aa/dockerCon2020.webp 750w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/65dd5/dockerCon2020.webp 1080w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/4fad6/dockerCon2020.webp 1366w,\n/static/9497b4aad63f55a6d041b550a7c9b01a/c512e/dockerCon2020.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}},"extension":"webp","publicURL":"/static/9497b4aad63f55a6d041b550a7c9b01a/dockerCon2020.webp"}},"fields":{"slug":"/community/events/dockercon-live"}}]}}}