{"componentChunkName":"component---src-templates-blog-category-list-js","path":"/blog/category/service-mesh.html","result":{"data":{"allMdx":{"nodes":[{"id":"b171f9fc-a31b-5e80-ba6b-cd0f83878e10","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport bugEnvoy from \"./debug-envoy-proxy.svg\";\nimport DockerExtensionCTA from \"../../../../sections/Docker-Meshery/docker-extension-CTA\";\nimport Code from \"../../../../components/CodeBlock\";\n\n<BlogWrapper>\n    Trying to figure out what's happening with your request traffic? Not sure why your Envoy configuration isn't working? If you're using Istio as your gateway and need to troubleshoot your ingress traffic requests, here are a few tips for debugging Envoy proxy.\n<h2>Enable Envoy Debug Logging</h2>\n  By default Envoy system logs are sent to <code>/dev/stderr</code>. This location be overridden using <code>--log-path</code>. Logging to <code>/dev/stderr</code>  for system logs and to <code>/dev/stdout</code> for access logs can be useful when running Envoy inside a container. In this way, these two individual logstreams can be separated, and using this approach, logging requires no additional files or directories to be mounted.\n<div className=\"intro\">\n  We recommend setting the Envoy proxy’s log level to debug in a pre-production environment. Debug logs can help you identify issues before you graduate the associated configuration to your production environment.\n</div>\n<h3>Using envoy CLI</h3>\n  The envoy command has a <code>--log-level</code> flag that can be useful for debugging. By default, it’s set to info. To change it to debug, edit the envoy DaemonSet in the istio-system namespace and replace the <code>--log-level info</code> flag with <code>--log-level debug</code>. Setting the Envoy log level to debug can be particilarly useful for debugging TLS connection failures.\n<h3>Using container image</h3>\n  If you’re using the Envoy image, you can set the log level to debug through the <code>ENVOY_LOG_LEVEL</code> environment variable. The log level for Envoy system logs can be set using the <code>-l</code> or <code>--log-level</code> option.\nThe available log levels are:\n\n<ul>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>trace</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>debug</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>info</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>warning/warn</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>error</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>critical</li>\n  <li className=\"highlight\" style={{ width: \"fit-content\" }}>off</li>\n</ul>\n\nThe default is <span className=\"highlight\">info</span>.\n\n<h3>Setting Envoy logs in the Helm configuration</h3>\n\n  The Consul helm chart uses <code>envoyExtraArgs:</code> to leverage Envoy command line options. One of the helpful options is <code>--component-log-level</code>. This provides granular control over setting log levels for Envoy components. In the example below, the components upstream, http, router and config are set to the debug log level. These four components are vital when debugging issues with requests between your services(sidecar proxies).\n<div>\n  <pre>\n    <code>connectInject:\n  enabled: true\n  envoyExtraArgs: \"--component-log-level upstream:debug,http:debug,router:debug,config:debug\"</code>\n  </pre>\n</div>\n\n  If you haven't set envoyExtraArgs: in consul-values.yaml just yet, you can set the log levels on the fly by using the following kubectl command:\n<div>\n  <pre>\n    <code>$ kubectl exec pod/pod-name -c container-name -- curl -X POST http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\nExample:\n<div>\n  <pre>\n    <code>$ kubectl exec pod/static-client-5bf4575d9c-zr2b -c static-client -- curl -X POST  http://localhost:19000/logging?config=debug</code>\n  </pre>\n</div>\n\n  You will execute the kubectl command for each component. Make sure to append the correct component at the end of the curl command, i.e. <code>logging? component = debug</code>.\n  If curl is not able to be used in your pod, you can alternatively use <code>kubectl port-forward pod-name 19000</code> to make the Envoy admin accessible. From another terminal window, you can then curl to change the log levels. The output you receive in the terminal will show the modified component log levels.\n<div>\n  <pre>\n    <code>$ curl -X POST http://localhost:19000/logging? component = debug</code>\n  </pre>\n</div>\n<h3>Access Envoy logs in Kubernetes</h3>\n\nAccessing Envoy logs via pods can be done with the following command:\n<div>\n  <pre>\n    <code>$ kubectl logs --follow pod/ pod-name -c envoy-sidecar</code>\n  </pre>\n</div>\n\nThe --follow flag provides a real time observation into Envoy logs.\n<h3>Setting and Accessing Envoy logs when not using Helm.</h3>\n\nThe following command will start an envoy side car proxy, set the log level to debug with -l debug and capture Envoy logs in envoy_logs.txt. The .txt file will need to be created before executing this command.\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- -l debug --log-path envoy_logs.txt</code>\n  </pre>\n</div>\n\nTo have granular control over the Envoy components that is needed to be debugged, use the following command:\n<div>\n  <pre>\n    <code>$ consul connect envoy -sidecar-for counting-1 -- --log-path envoy_logs.txt --component-log-level upstream:debug,http:debug,router:debug,config:debug</code>\n  </pre>\n</div>\n\n<h2>Find your Istio Ingress Gateway</h2>\n  With Istio as your gateway, you should first look at <code>VirtualService</code> objects. These can show if the hosts are registered to the gateway correctly.\n<div>\n  <pre>\n    <code>$ kubectl get virtualservice -o=yaml</code>\n  </pre>\n</div>\n\n  However, sometimes, the <a  className=\"highlight\" href=\"https://envoyproxy.io\">Envoy</a> inside the gateway container is not properly configured (likely due to a bug). You can dump Envoy configuration to debug this further.\n<div>\n  <pre>\n    <code># find istio ingress gateway pod \\\n      $ kubectl get pods -n istio-system -l app=istio-ingressgateway</code>\n  </pre>\n</div>\n\n  Let's use <code>istio-ingressgateway-a93019f9dfw-l39xd</code> as an example pod name.\n<div>\n  <pre>\n    <code>\n      # enable debugging on envoy \\\n      $ kubectl exec --namespace=istio-system \\\n      istio-ingressgateway-a93019f9dfw-l39xd \\\n      -c istio-proxy -- curl -X POST \\\n      http://localhost:15000/logging?level=debug\n    </code>\n  </pre>\n</div>\n  Then, use <code>istioctl</code> tool to dump route configuration (this will show the output from the <a href=\"https://www.envoyproxy.io/docs/envoy/latest/operations/admin#operations-admin-interface-config-dump\"><code>/config_dump</code> admin endpoint</a> on Envoy):\n<div>\n  <pre>\n    <code>\n    $ istioctl proxy-config routes -n istio-system -o=json \\\n      istio-ingressgateway-a93019f9dfw-l39xd\n    </code>\n  </pre>\n</div>\n  We hope these steps are useful to you. If you're still having trouble configuring Envoy proxy, open up a new thread on the <a href=\"https://discuss.layer5.io\" className=\"highlight\">community discussion forum</a> or subscribe to the <Link to=\"/subscribe\" className=\"highlight\">Layer5 newletter</Link> for tips and tricks.\n</BlogWrapper>","frontmatter":{"title":"Debug Envoy Proxy","subtitle":"","date":"May 27th, 2022","author":"Layer5 Team","thumbnail":{"extension":"webp","publicURL":"/static/86469654139cd83c10102b4b7340a05b/debug-envoy-proxy.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYBAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSMAAAAABgGPb2rHn+W3bsW3btlmlUmfbtu2k+utoAnYyg1SpbLxfhhAREwA/5RzAbDvWNZyIxWorhwixTWieSwvGI3SYUtcXVVUFt2bUezvn5LRMeRUp8LOahjjvhMGQ9NBxXLZdb1HxVsVqDPypGwOE3LK8CkN3ACLUdAoAa6T46jZBH4cUefB4djh8mgKoRg+N2x8v2o9KIYKi9lKW9PG6/9HORQD/e+OWtxftXRsJBTf18nqUHyOn4VAAzNKI8I9CQARWUDggkAAAAHAEAJ0BKhQADwA+0VSjS6gkoyGwCAEAGglsAJ0vj/GAPH2dlBNaf2wZATiAAP7ASS/mP6a2Y+hs5t5eJvQi4+mGcsP07df1gED073L+PvHX6SzjzFJJrgvLrJ/bvxxRU7AjtrkOARQf7D08V4gAE2dUXwgM1otrPffYMi+KwR4hd8IMLnKUWTT00mrORnXAAA=="},"images":{"fallback":{"src":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp","srcSet":"/static/86469654139cd83c10102b4b7340a05b/ca36e/debug-envoy-proxy.webp 553w","sizes":"100vw"},"sources":[]},"width":1,"height":0.7432188065099458}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/86469654139cd83c10102b4b7340a05b/debug-envoy-proxy.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRnYBAABXRUJQVlA4WAoAAAAQAAAAEwAADgAAQUxQSMAAAAABgGPb2rHn+W3bsW3btlmlUmfbtu2k+utoAnYyg1SpbLxfhhAREwA/5RzAbDvWNZyIxWorhwixTWieSwvGI3SYUtcXVVUFt2bUezvn5LRMeRUp8LOahjjvhMGQ9NBxXLZdb1HxVsVqDPypGwOE3LK8CkN3ACLUdAoAa6T46jZBH4cUefB4djh8mgKoRg+N2x8v2o9KIYKi9lKW9PG6/9HORQD/e+OWtxftXRsJBTf18nqUHyOn4VAAzNKI8I9CQARWUDggkAAAAHAEAJ0BKhQADwA+0VSjS6gkoyGwCAEAGglsAJ0vj/GAPH2dlBNaf2wZATiAAP7ASS/mP6a2Y+hs5t5eJvQi4+mGcsP07df1gED073L+PvHX6SzjzFJJrgvLrJ/bvxxRU7AjtrkOARQf7D08V4gAE2dUXwgM1otrPffYMi+KwR4hd8IMLnKUWTT00mrORnXAAA=="},"images":{"fallback":{"src":"/static/86469654139cd83c10102b4b7340a05b/05b6e/debug-envoy-proxy.webp","srcSet":"/static/86469654139cd83c10102b4b7340a05b/82655/debug-envoy-proxy.webp 125w,\n/static/86469654139cd83c10102b4b7340a05b/f6b5d/debug-envoy-proxy.webp 250w,\n/static/86469654139cd83c10102b4b7340a05b/05b6e/debug-envoy-proxy.webp 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":372}}}},"fields":{"slug":"/blog/service-mesh/debug-envoy-proxy"}},{"id":"44b1509f-0ba1-5ea3-9341-82abe59558cd","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport { Link } from \"gatsby\";\n\nimport meshmark from './meshmark-dark-text-side.svg';\nimport performanceQuestion from './performance-question.webp';\nimport smp from './smp.webp';\nimport meshmarkSlide from './meshmark.webp';\nimport example from './example.webp';\nimport formula from './formula.webp';\nimport MUE from './mue.webp';\nimport MeshMapDemo from './meshmark-score.webp';\n\n<BlogWrapper>\n\n<div className=\"intro\">\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> and{\" \"}\n  <Link to=\"#\">Mrittika Ganguli</Link> presented <i>MeshMark: Service Mesh value measurement</i> at ServiceMeshCon Europe 2022.\n</div>\n\n<p>\n  <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovative product and technology leader. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.\n</p>\n\n<p>\n  <Link to=\"#\">Mrittika Ganguli</Link> is the Director of Cloud Native Data Plane, Principal Engineer, and Network Architect at Intel.\n</p>\n\n<img src={meshmark} alt=\"MeshMark Graphic\" style={{ display: \"block\", margin: \"0 auto 0.5rem\", width: \"40%\" }} />\n\n---\n\n## What is MeshMark?\n\nMeshMark is a performance index that measures the value and overhead of your cloud native environment. It converts performance measurements into insights about the value of application networking functions, distilling overhead signals and KPIs into a simple index.\n\n<img src={performanceQuestion} alt=\"Performance characteristics question\" style={{ width: \"50%\", float: \"right\" }} />\n\n### Talk started with a question to the audience\n\n<Blockquote\n  className=\"pull-left\"\n  quote=\"We are missing some performance characteristics, as people have many metrics to track environments. It might take a while to articulate the performance characteristics of your environment.\"\n  person=\"Lee Calcote\"\n/>\n\n---\n\n### Lee Calcote explains “Business Performance”\n\n<p>\nWe're frequently overlooking business performance — the reason we run the infrastructure in the first place. Rather than only focusing on quantitative speeds and feeds, we should quantify the value the infrastructure provides.\n</p>\n\n<img src={smp} alt=\"Service Mesh Performance\" style={{ width: \"50%\", float: \"right\" }} />\n\n---\n\n## Introduction to Service Mesh Performance (SMP)\n\nThe Service Mesh Performance project (a CNCF project) provides a consistent specification for capturing infrastructure configuration, service mesh configuration, and workload characteristics. This enables:\n\n- Baselines  \n- Benchmark comparisons  \n- System-to-system exchange of performance data  \n\n---\n\n## Mrittika Ganguli introduces MeshMark with an example\n\nMeshMark measures whether the performance of your infrastructure aligns with the value your deployment is intended to provide.\n\n<Blockquote\n  className=\"pull-right\"\n  quote=\"Are my resources utilized as best as possible? Why am I not getting the SLO met with 4 resources when I only needed 1 without the service mesh? Is the network a performance hog? MeshMark intends to help provide an index for many of these areas.\"\n  person=\"Mrittika Ganguli\"\n/>\n\n<p>\nOften when loading a YouTube video, text appears before the video. The load latency of the video traffic determines the experience. MeshMark helps quantify the efficiency of infrastructure functions that impact this latency and ties it directly to resource usage and cost (TCO).\n</p>\n\n<img src={meshmarkSlide} className=\"slides\" style={{ marginLeft: \"30px\" }} alt=\"MeshMark slides\" />\n<img src={example} className=\"slides\" style={{ marginLeft: \"30px\" }} alt=\"MeshMark example\" />\n\n<img src={formula} alt=\"MeshMark formula\" style={{ width: \"50%\", float: \"right\" }} />\n\n---\n\n# MeshMark: The Formula\n\nMeshMark scores from 0–100 and includes:\n\n- Value vs. overhead calculations  \n- Resource utilization efficiency  \n- Categorized consumption classes  \n\n---\n\n## Mrittika explains MUE (Mesh Utilization Efficiency)\n\n<p>\nMUE represents the ratio of measured platform resources to assigned resources.\n</p>\n\n<img src={MUE} alt=\"MeshMark MUE\" style={{ width: \"50%\", float: \"left\", paddingRight: \"1rem\" }} />\n\n<p>\nCPU performance is an easy example:  \nMUE = 1 – (CPU Utilization / 100).  \nHigher latency lowers MUE, indicating reduced efficiency as QPS increases.\n</p>\n\n<p>\nMeshery, a cloud native management plane, helps visualize MUEs and evaluate efficiency of workloads across any service mesh.\n</p>\n\n<img src={MeshMapDemo} alt=\"MeshMap demo\" style={{ width: \"40%\", float: \"right\" }} />\n\n---\n\n## Lee demonstrates MeshMap with an example Consul application\n\n<p>\nIn the demo, a Consul workload is loaded into MeshMap's visual designer to inspect:\n</p>\n\n- Service splitting  \n- Service intentions  \n- Efficiency (MeshMark) calculations  \n\n---\n\n<div style={{ textAlign: \"center\" }}>\n  <iframe\n    width=\"70%\"\n    height=\"450px\"\n    style={{ marginRight: \"1.5rem\", marginLeft: \"1.5rem\" }}\n    src=\"https://www.youtube.com/embed/yvqn6ckO7BI\"\n    title=\"MeshMark demo video\"\n    frameBorder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n    allowFullScreen\n  />\n  <p style={{ fontStyle: \"italic\", fontSize: \"1rem\", marginLeft: \"1rem\" }}>\n    MeshMark in Meshery (excerpt from ServiceMeshCon EU 2022 demo)\n  </p>\n</div>\n\n---\n\n<strong>\n  Lee Calcote and Mrittika Ganguli covered all the concepts of SMP and MeshMark.  \n  Learn more on the <Link to=\"https://meshery.io/service-mesh-interface\">Service Mesh Performance</Link> website.\n</strong>\n\n</BlogWrapper>\n","frontmatter":{"title":"MeshMark: Cloud Native Value Measurement","subtitle":null,"date":"May 17th, 2022","author":"Gaurav Chadha","thumbnail":{"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/c8936/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/8d8ff/banner.webp 750w,\n/static/262c08771cc081196228e58152adc495/fc98a/banner.webp 1080w,\n/static/262c08771cc081196228e58152adc495/62268/banner.webp 1366w,\n/static/262c08771cc081196228e58152adc495/c8936/banner.webp 1898w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5600632244467861}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/262c08771cc081196228e58152adc495/banner.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJZACdMoADAVZpocZffp7rwAD+8eCe2HI33vty8iA8g87WkluUHUOOVrCnLZT6QrpQ3MgZ8CTBlCyKjycJ5kqTGGOPP80t64fDwjjCC4PKH6lVg+SCeFAA"},"images":{"fallback":{"src":"/static/262c08771cc081196228e58152adc495/f03ce/banner.webp","srcSet":"/static/262c08771cc081196228e58152adc495/46142/banner.webp 125w,\n/static/262c08771cc081196228e58152adc495/2cd09/banner.webp 250w,\n/static/262c08771cc081196228e58152adc495/f03ce/banner.webp 500w,\n/static/262c08771cc081196228e58152adc495/3a00d/banner.webp 1000w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":280}}}},"fields":{"slug":"/blog/service-mesh/meshmark-cloud-native-value-measurement"}},{"id":"a8f09cde-c9bd-5f47-b328-0d7aea181ac9","body":"\nimport { Link } from \"gatsby\";\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\nimport token from \"./download-token.webp\";\nimport perfdashboard from \"./service-mesh-performance-profile-test-results.webp\"\nimport smidashboard from \"./smi-conformance-result.webp\";\nimport smpLogo from \"../../../../assets/images/service-mesh-performance/horizontal/smp-dark-text-side.svg\";\nimport smiLogo from \"../../../../assets/images/service-mesh-icons/service-mesh-interface/horizontal-stackedtext/color/servicemeshinterface-horizontal-stackedtext-color.svg\";\nimport githubBlack from \"../../../../assets/images/socialIcons/github_black.svg\";\n\n<BlogWrapper>\n  \nWith growing adoption of service meshes in cloud native environments, service mesh abstractions - service mesh-neutral specifications - have emerged. <Link to=\"/projects/cloud-native-performance\">Service Mesh Performance</Link>  and <Link to=\"/projects/service-mesh-interface-conformance\">Service Mesh Interface</Link> are two open specifications that address the need for universal interfaces for interacting with and managing any type of service mesh. Let’s examine what each specification provides.\n<img src={smpLogo} className=\"image-left-no-shadow\" alt=\"service mesh performance logo\"/><a href=\"https://smp-spec.io\">Service Mesh Performance</a> standardizes service mesh value measurement, characterizing any deployment's performance by capturing the details of infrastructure capacity, service mesh configuration and workload metadata.\n<img src={smiLogo} className=\"image-right-no-shadow\" alt=\"service mesh interface logo\"/><a href=\"https://smi-spec.io\">Service Mesh Interface</a> provides a standard interface for service meshes on Kubernetes. These (currently) four specfications offer a common denominator set of interfaces to support most common service mesh use cases and the flexibility to evolve to support new service mesh capabilities over time.\nAs a service mesh agnostic tool that provides lifecycle and performance management of a large number of (10+) service meshes, Kubernetes applications, service mesh patterns and WebAssembly filters, Meshery is the ideal tool for the job when it comes to implementing these specifications.\nMeshery also comes with two new GitHub Actions that do exactly this. The <a href=\"https://github.com/layer5io/meshery-smi-conformance-action\">Meshery SMI Conformance Action</a> which <a href=\"https://meshery.io/blog/validating-smi-conformance-with-meshery\">validates SMI conformance</a> in your pipeline and the <a href=\"https://github.com/layer5io/meshery-smp-action\">Meshery SMP Action</a> which runs <a href=\"https://docs.meshery.io/functionality/performance-management\">SMP compatible performance benchmarks</a>.\nBut how do we use these actions? What do they offer? Let’s find out!\n<h2>Service Mesh Interface Conformance GitHub Action</h2>\n\nConformance of SMI specifications is defined as a series of test assertions. These test assertions are categorised by SMI specification (of which, there are currently four specifications) and comprise the complete suite of SMI conformance tests. Conformance requirements will change appropriately as each new version of the SMI spec is released. Refer to Meshery's documentation for details of how <a href=\"https://docs.meshery.io/functionality/service-mesh-interface\">Meshery performs SMI conformance</a>.\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth:\"9vw\"}}/>\n\n<h3>Using Meshery's SMI Conformance GitHub Action</h3>\n\nThe <a href=\"https://github.com/marketplace/actions/service-mesh-interface-conformance-with-meshery\">Service Mesh Interface Conformance GitHub Action</a> is available in the GitHub Marketplace. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event.\nAn example of the action configuration which runs on every release is shown below. The action handles setting up a Kubernetes environment, deploying the service mesh (see supported service meshes), running the conformance tests and reporting back the results to the SMI Conformance dashboard in Meshery.\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: false\n```\n\nYou can also bring in their own cluster with specific capabilities and with a service mesh already installed.\n```yaml\nname: SMI Conformance with Meshery\non:\n  push:\n    branches:\n      - 'master'\n\njobs:\n  smi-conformance:\n    name: SMI Conformance tests on master\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Install OSM\n        run: |\n           curl -LO https://github.com/openservicemesh/osm/releases/download/v0.9.1/osm-v0.9.1-linux-amd64.tar.gz\n           tar -xzf osm-v0.9.1-linux-amd64.tar.gz\n           mkdir -p ~/osm/bin\n           mv ./linux-amd64/osm ~/osm/bin/osm-bin\n           PATH=\"$PATH:$HOME/osm/bin/\"\n           osm-bin install --osm-namespace default\n\n      - name: SMI conformance tests\n        uses: layer5io/mesheryctl-smi-conformance-action@master\n        with:\n          provider_token: ${{ secrets.MESHERY_PROVIDER_TOKEN }}\n          service_mesh: open_service_mesh\n          mesh_deployed: true\n```\n\nYou can download a token from Meshery and add it as a GitHub secret (in the example above, the secret is <code>MESHERY_PROVIDER_TOKEN</code>). After the test is run, you can view the results from the Service Mesh Interface dashboard in Meshery UI.\n<p style={{ textAlign: \"center\" }}><img src={smidashboard} className=\"image-center-shadow\" style={{width:\"70%\"}} alt=\"smi conformance dashboard\" /></p>\n<i>Meshery's Service Mesh Interface Conformance Results</i>\nParticipating projects can also automatically report their conformance test results to the <a href=\"https://meshery.io/service-mesh-interface\">SMI Conformance dashboard</a>\n\n<h2>Service Mesh Performance GitHub Action</h2>\n\nMeasuring and managing the performance of a service mesh is key to efficient operation of any service mesh. Meshery is the canonical implementation of the Service Mesh Performance specification. You can choose from multiple load generators and use a highly configurable set of load profiles with variable tunable facets to run a performance test. Meshery packages all these features into an easy-to-use GitHub Action.\n<img src={githubBlack} className=\"image-left-no-shadow\" style={{maxWidth:\"9vw\"}}/>\n\n<h3>Using Meshery's Service Mesh Performance GitHub Action</h3>\n\nThe <a href=\"https://github.com/marketplace/actions/performance-testing-with-meshery\">Service Mesh Performance GitHub Action</a> is available in the GitHub Marketplace.You can create your own performance profiles to run repeatable tests with Meshery. You can configure this action to trigger with each of your releases, on every pull request. or any GitHub workflow trigger event. A sample configuration of the action is shown below.\n```yaml\nname: Meshery SMP Action\non:\n  push:\n    branches:\n      'master'\n\njobs:\n  performance-test:\n    name: Performance Test\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v2\n        with:\n          ref: 'perf'\n\n      - name: Deploy k8s-minikube\n        uses: manusa/actions-setup-minikube@v2.4.1\n        with:\n          minikube version: 'v1.21.0'\n          kubernetes version: 'v1.20.7'\n          driver: docker\n\n      - name: Run Performance Test\n        uses: layer5io/meshery-smp-action@master\n        with:\n          provider_token: ${{ secrets.PROVIDER_TOKEN }}\n          platform: docker\n          profile_name: soak-test\n```\n\nYou can also define your test configuration in an SMP compatible configuration file as shown below.\n```yaml\nsmp_version: v0.0.1\nid:\nname: Istio Performance Test\nlabels: {}\nclients:\n- internal: false\n  load_generator: fortio\n  protocol: 1\n  connections: 2\n  rps: 10\n  headers: {}\n  cookies: {}\n  body: \"\"\n  content_type: \"\"\n  endpoint_urls:\n  - http://localhost:2323/productpage\nduration: \"30m\"\n```\n\nSee this sample GitHub workflow (<a href=\"https://github.com/layer5io/meshery-smp-action/blob/master/action.yml\">action.yml</a>) for more configuration details.\n<img src={perfdashboard} className=\"image-center\" alt=\"performance management dashboard\"/>\n\nThe results from the tests are updated on the Performance Management dashboard in Meshery. To learn more about interpreting the test results, check out <a href=\"https://docs.meshery.io/guides/interpreting-performance-test-results\">this guide</a>. You can always checkout the <a href=\"https://docs.meshery.io/guides\">Meshery User Guides</a> to dive deep into these features.\nStay meshy!\n</BlogWrapper>\n","frontmatter":{"title":"Pipelining Service Mesh Specifications","subtitle":"Using SMI and SMP specs on your CI/CD pipelines with Meshery's GitHub Actions","date":"November 9th, 2021","author":"Layer5 Team","thumbnail":{"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/a66aa/service-mesh-specifications.webp 750w,\n/static/81aa70f0509f2123d8f460d3633f063c/65dd5/service-mesh-specifications.webp 1080w,\n/static/81aa70f0509f2123d8f460d3633f063c/4fad6/service-mesh-specifications.webp 1366w,\n/static/81aa70f0509f2123d8f460d3633f063c/e9d78/service-mesh-specifications.webp 1600w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5625}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/81aa70f0509f2123d8f460d3633f063c/service-mesh-specifications.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAAAwBACdASoUAAsAPtFWo0uoJKMhsAgBABoJQAqP23yHCf3s8zj7Q4Ot54AA/vYSdhBu5a5XcB/63qjz5sojm43GF+2H9fEBMTKbmVPEU59GLBaiyKva9gYciPhcLWvnHZREEmuIToMwwyupq3UEwAAA"},"images":{"fallback":{"src":"/static/81aa70f0509f2123d8f460d3633f063c/cd07d/service-mesh-specifications.webp","srcSet":"/static/81aa70f0509f2123d8f460d3633f063c/46142/service-mesh-specifications.webp 125w,\n/static/81aa70f0509f2123d8f460d3633f063c/81c3e/service-mesh-specifications.webp 250w,\n/static/81aa70f0509f2123d8f460d3633f063c/cd07d/service-mesh-specifications.webp 500w,\n/static/81aa70f0509f2123d8f460d3633f063c/bf95e/service-mesh-specifications.webp 1000w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":281}}}},"fields":{"slug":"/blog/service-mesh/pipelining-service-mesh-specifications"}},{"id":"c0ba14fc-089b-5939-abc8-083252a26606","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\nimport Hamlet from \"./Hamlet.webp\";\nimport Graph from \"./Graph1.webp\";\nimport Bucket from \"./Graph2.webp\";\nimport SMI from \"./SMI-demo.webp\";\nimport SMP from \"./SMP.webp\";\nimport Abstractions from \"./abstractions.webp\";\nimport Journey from \"./cloud-native-journey.webp\";\nimport Flowchart from \"./flowchart.webp\";\nimport { Link } from \"gatsby\";\n\n\n<BlogWrapper>\n\n<div className=\"intro \">\n\n     <Link to=\"/community/members/lee-calcote\">Lee Calcote</Link> is an innovator, product and technology leader, active in the community as a Docker Captain, Cloud Native Ambassador and GSoC, GSoD, and Community Bridge Mentor. In this talk, he walked through service mesh specifications and why they matter in your deployment.\n   How many service mesh specifications do you know? He went through all of them. So, no worries if you're unfamiliar.\n\n</div>   \n\n### Service Mesh Specifications:\n<img src={Abstractions} className=\"slides-left\" align=\"left\" alt=\"abstractions\"/>\n\nAs the ubiquity of service meshes unfolds and they become a commonplace for any cloud native or edge environment, so does the need for vendor and technology-agnostic interfaces to interact with them. The Service Mesh Interface (SMI), the Service Mesh Performance (SMP), and Multi-Vendor Service Mesh Interoperation (Hamlet) are three open specifications solving the challenge of interoperability, workload and performance management between service meshes. \n\nLearn what makes each of them unique and why they are much needed. See each of these three specifications in action as we use Meshery, the open-source service mesh management plane to demonstrate the value and functionality of each service mesh abstraction, and the adherence of these specifications by Istio, Linkerd, Consul and other popular service meshes.\n\n### Cloud native Journey to service meshes:\n\n<img src={Journey} className=\"slides-right\" align=\"right\" alt=\"journey-image\"/>\n\nThe advent of cloud native was the popularization of containers. Thank you Docker! From there, containers took off like wildfire. Turns out you need an orchestrator to wrangle that sprawl. We saw a number of orchestrators come and we still have a number of orchestrators around.\n\nService meshes have become a hot topic in the last few years. They still continue to be, rightfully so, a very powerful piece of technology. “A lot of the power is yet to come from my perspective. For my part, I believe that there is a tomorrow in which data plane intelligence really matters. And matters about how people write cloud native applications.”, Lee emphasized. Not everyone quite understands the capabilities of meshes as they are promoted and spoken about today. So come along into the journey of service mesh.\n\nThere are a number of service meshes out there. One of the community projects is to track the landscape of all of the meshes there are. There’s a lot to say about each of them, their architecture, and their working. Why are they made? Who are they focused on? What do they do? When did they come about? Why are some of them not here anymore? Why are we still seeing new ones? A lot of things to go through. You might be interested in any number of the details that the landscape tracks.\n <div className=\"note\">Be Aware, It's Meshy Out There!</div>\n\n### Service Mesh Interface\n<img src={SMI} className=\"slides-left\" align=\"left\" alt=\"smi-image\"/>\n- Its goal and genesis were born inside of Kubernetes.\n- Being a specification that is native to Kubernetes, its focus is on lowest common denominator functionality.\n- The focus on bringing forth APIs that highlight and reinforce the most common use cases that service meshes are being used for currently\n- Leaves space and provides extensibility room for additional APIs to address other service mesh functionality as more people adopt and make use cases well known.\n- There are seven service meshes that claim compatibility with SMI. There's been a community effort, open-source effort to create service mesh conformance tests to assert whether or not a given service mesh is compatible with SMI\n- In order to facilitate those types of tests, you need to have a tool to provision a sample application on those services which will generate load and test whether traffic splitting behaves as expected or works with that service mesh implementation properly.\n- Then you need to be able to collect the results, guarantee the provenance of those results and publish them.\n- As a community, we turned to Meshery as the tool to implement <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link> and we have been working with the individual service meshes to validate their conformance.\n<b>Meshery</b>\n- We work on an open-source project called <Link to=\"/cloud-native-management/meshery\">Meshery</Link>.\n- Meshery, the cloud native management plane, is the canonical implementation of the service mesh performance.\n- The management planes can do a number of things to help bridge the divide between other back-end systems and service meshes. They also help performance management, configuration management, making sure you are following best practices in your implementations by taking common patterns and applying them to your environment\nLet's take a moment to demo what it looks like to validate conformance in SMI using Meshery.\n\n<img src={Graph} className=\"slides-left\" align=\"left\" alt=\"graph\"/>\n- We need to spin up Meshery locally\n- We use mesheryctl as the command line interface to work with Meshery.\n- We can interact with a number of different service mesh. The service mesh we’re going to work with today is an Open service mesh (one of those 7 that is compatible with SMI). Let’s put it to the test.\n- We'll initiate <Link to=\"/projects/service-mesh-interface-conformance\">SMI conformance</Link>\n- These tests go and do assertions across these different specifications. We’re looking at traffic access, traffic splitting, traffic specification. Meshery then collects these results and will eventually be publishing them in combination with the SMI project.\n\n### Service Mesh Performance\n<img src={SMP} className=\"slides-right\" align=\"right\" alt=\"smp-image\"/>\n- Focused on describing and capturing the performance of a service mesh.\n- The overhead of the value is another way of looking at it and characterizing it.\n- Trying to characterize the performance of the infrastructure of a service mesh can be really difficult.\n- Considering the number of variables that you would have to track, how difficult it can be to have repeatable tests, and benchmark your environment, to track your history based on your environment, compare performance between other meshes people need.\n- SMP creates a standard way of capturing the performance of the mesh to help with these issues.\n- It's also the way in which you're configuring your control plan of your service mesh.\n\nYou might be using a client library to do some service mesh functionality. Maybe you're using those in combination with the service mesh. What costs more? What's more efficient? What's more powerful? Maybe you're using web assembly and filters there.\nThese are all open questions that <Link to=\"/projects/cloud-native-performance\">SMP</Link> assists in answering in your environment. You’d be surprised by some of the results of some tests that we have done and that the community has done in combination with a couple of universities and graduate students.\n\n<b>Performance Test</b>\n\nDemonstration of the implementation of service mesh Performance:\n\n<img src={Flowchart} className=\"slides-left\" align=\"left\" alt=\"flowchart\"/>\n- On the terminal, we have a local deployment of Meshery running. You can also deploy on Kubernetes as well as the vendor Kubernetes platforms like AKS, EKS and GCP or you can use a dockerized container to run Meshery. You can also have your Kubernetes on Docker desktop.\n- We have the Open service mesh deployed.\n- The Meshery UI is exposed at 9081 port. This is the UI which is used to instantiate a Load test.\n- Over here you can see we have 3 load generators fortio, wrk2, nighthawk.\n- All of these load generators have their own set of attributes which they record correctly and each of its attributes have their own significance. We begin with fortio.\n- <img src={Bucket} className=\"slides-right\" align=\"right\" alt=\"graph\"/>\n\n- You can actually download the test results or you can just browse into the Results Tab and see all of the tests which you have run until now.\n- Next, we used nighthawk to generate the load and benchmark the service for the same. Nighthawk is a load generator which is maintained by the Envoy community and is relatively new. It still hasn't got its 1.0 release but right now Nighthawk has sufficient features to compete with different generators which are still in the play. It can generate a gRPC service on its own and it has some more attributes which you can expose using their CLI tools.\n- You can also see that Meshery has the capability to search your environment, see what specifications are being used and what's the load on your Kubernetes.\n- Jump into the results Tab and see how we compare with these results.\n- You can click on the download. You will see that a yaml gets downloaded in which you can browse and see that the start time, load time, the performance latencies, the metrics are being captured.\n\n### Hamlet or Multi-vendor Service Mesh Interoperation\n<img src={Hamlet} className=\"slides-left\" align=\"left\" alt=\"hamlet-image\"/>\n- Focus on service mesh federation\n- Specifies a set of API standards for enabling service mesh federation\n- Hamlet takes on a client-server architecture in which resources and services of one service mesh are discovered, registered and using a common format, information about them is exchanged between different service mesh.\n- Rules around authentication and authorization rules around which Services get exposed and to whom and who can communicate with them and whether or not they can do it securely. These are things that Hamlet addresses.\n- The specification currently consists of two APIs:\n    - **The Federated Resource Discovery API**: API to authenticate and securely distribute resources between federated service meshes.\n    - The **Federated Service Discovery API**: API to discover, reach, authenticate and securely communicate with federated services.\n- Part of the real power is the ability to overcome what are likely to be separate administrative domains. The intention here is to marry up connect two disparate service mesh deployments, those deployments might be of the same type, they might be of two different types.\n\nIn addition to SMI, SMP and Hamlet there has been an emergence of service mesh patterns, by which people are running and operating service meshes. There is a service mesh working group under CNCFs network that is helping identify those patterns of which there's a list right now unbeknownst to you. Reach out, join it, help us work through the 60 patterns that are defined right now. 30 of those are going into an <Link to=\"/learn/service-mesh-books\">O’Reilly</Link> book called <Link to=\"/learn/service-mesh-books/service-mesh-patterns\">Service Mesh Patterns</Link>.\n\nSomething that isn’t always obvious to folks is this piece of value that people get from a service mesh and actually from the specifications that we were just mentioning. It is the fact that teams are decoupled when you’re running a mesh. Developers get to iterate a bit independently of operators, and so do operators get to make changes to implement infrastructure to the way that applications behave independent of developers in the presence of a mesh.  Both of these teams are significantly empowered. Everybody gets a piece of power when they deploy a mesh.\n\n\n_**P.S.: If these topics excite  come and say \"Hi\" on our [Slack Channel](http://slack.layer5.io) and one of us will reach out to you!**_\n\n</BlogWrapper>","frontmatter":{"title":"Service Mesh Specifications and Why They Matter","subtitle":null,"date":"September 20th, 2021","author":"Debopriya Bhattacharjee","thumbnail":{"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/a66aa/Cover-image.webp 750w,\n/static/f9e70b0d102359852501532eaf88c857/65dd5/Cover-image.webp 1080w,\n/static/f9e70b0d102359852501532eaf88c857/f9724/Cover-image.webp 1366w,\n/static/f9e70b0d102359852501532eaf88c857/92e8b/Cover-image.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5630208333333334}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/f9e70b0d102359852501532eaf88c857/Cover-image.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRnYAAABXRUJQVlA4IGoAAAAQBACdASoUAAsAPtFUo0uoJKMhsAgBABoJbACdMoR3N4AAWScxK3A0AAD+y+7TltDm8faWnWkrgNwKEaB+a5F7h6kfv+PNmIbiHtDLJbrKy70mpaSz/NUvAS+UKSii+WgoY4/+Ld6wAAAA"},"images":{"fallback":{"src":"/static/f9e70b0d102359852501532eaf88c857/cd07d/Cover-image.webp","srcSet":"/static/f9e70b0d102359852501532eaf88c857/46142/Cover-image.webp 125w,\n/static/f9e70b0d102359852501532eaf88c857/81c3e/Cover-image.webp 250w,\n/static/f9e70b0d102359852501532eaf88c857/cd07d/Cover-image.webp 500w,\n/static/f9e70b0d102359852501532eaf88c857/bf95e/Cover-image.webp 1000w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":281}}}},"fields":{"slug":"/blog/service-mesh/service-mesh-specifications-and-why-they-matter"}},{"id":"41186fe5-9702-5f79-9115-7013aba6492e","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport conformance from \"./conformance-results.webp\";\n\n<BlogWrapper>\n\nReleased on August 5th, 2020 by Microsoft, [Open Service Mesh](https://openservicemesh.io/) (OSM) is a lightweight and [Service Mesh Interace conformant](https://layer5.io/smi) (SMI). Open Service Mesh is a contemporary addition to the [service mesh landscape](/service-mesh-landscape). Using Envoy as its data plane proxy component and SMI specifications as it's control plane APIs, OSM draws lessons and code from existing service mesh projects, like Linkerd. The Open Service Mesh project has some miles to go as it is one of a growing list of choices available in the service mesh landscape.\n\nFirst pronounced to be SMI compliant by [Meshery](https://meshery.io/), the cloud native management plane, the first release of OSM supports a myriad of basic\n\n<ul>\n    <li>Securing service to service links</li>\n    <li>Supporting traffic shifting</li>\n    <li>Managing observability for your services</li>\n    <li>Validating and Implementing access control policies</li>\n    <li>Auto addition of applications and services</li>\n</ul>\n\n### Get started with OSM using Meshery\nIn Layer5's effort to support our multi-mesh world, our Meshery project provides an effortless way for Kubernetes operators to install, maintain and run service meshes. [Meshery v0.4.3](https://github.com/layer5io/meshery/releases/tag/v0.4.3) includes the [Meshery Adapter for Open Service Mesh](https://github.com/layer5io/meshery-osm), enabling you to quickly provision OSM, run any number of sample applications, manage its performance using [Service Mesh Performance](https://smp-spec.io/) (SMP), validate OSM's compliance to SMI using a suite of conformance tests. Meshery offers configuraiton management with builtin best practice configuration analysis giving you confidence in applying custom configuration to OSM. Meshery's documenation on the [Open Service Mesh integation](https://docs.meshery.io/service-meshes/adapters/osm) provides a complete walkthrough on how to get set up, install, deploy and configure OSM according to your needs.\n\n<img src={conformance} className=\"\" alt=\"meshery-smi-conformance-results-image\" />\n\nTry Open Service Mesh now, by [getting started with Meshery](/cloud-native-management/meshery/getting-started).\n\n\n</BlogWrapper>\n","frontmatter":{"title":"Announcing the Meshery Adapter for Open Service Mesh","subtitle":"Adding another service mesh to the landscape and another adapter to Meshery","date":"August 20th, 2020","author":"Lee Calcote","thumbnail":{"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/280d5/meshery-open-service.webp 750w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/5b49f/meshery-open-service.webp 1080w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f8bdf/meshery-open-service.webp 1366w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/770cd/meshery-open-service.webp 1920w","sizes":"100vw"},"sources":[]},"width":1,"height":0.5010416666666666}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/meshery-open-service.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRnwAAABXRUJQVlA4IHAAAABQAwCdASoUAAoAPtFUo0uoJKMhsAgBABoJQBdgBDvIHyHlAAD+9R5BqQSsiWNeJNqE7PLbzQ9M/Tvb9CSqaIr+n2R5upIraZpU7CzXHZesE7BZyYNioCJXqMKKJGxFbL89G+X6eR3+pLo8zCJoAAAA"},"images":{"fallback":{"src":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/cd5ef/meshery-open-service.webp","srcSet":"/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/f6072/meshery-open-service.webp 125w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/cb4bd/meshery-open-service.webp 250w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/cd5ef/meshery-open-service.webp 500w,\n/static/1e896538fdd2f9faaa30e0b7dd7f2f6a/9306b/meshery-open-service.webp 1000w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":250}}}},"fields":{"slug":"/blog/service-mesh/announcing-the-meshery-adapter-for-open-service-mesh"}},{"id":"47a58ab5-c67e-52d4-ae1d-1623eeab8aed","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport listioLayer5 from \"./layer5-and-istio.webp\";\nimport img1 from \"./image1.webp\";\nimport img2 from \"./image2.webp\";\nimport img3 from \"./image3.webp\";\nimport img4 from \"./image4.webp\";\n\n<BlogWrapper>\n\n<img src={listioLayer5} className=\"image-left\" alt=\"Layer5 and Istio\"/>\n\nRecently, I started learning on Service Mesh and it was a very interesting journey as I explored the Service Mesh\nlandscape starting with [Layer5 tutorials](https://github.com/layer5io/istio-service-mesh-workshop) and by exploring\nthe blogs at [Istio.io](https://istio.io/).\n\nOur organization decided to use the features of Istio for securing, managing and automating microservices. However, we have to support a multi-tenant environment and that became a challenge due to lack of sufficient documentation and clarity. To give a little bit of background on the problem, we have a single cluster with multiple tenants in different namespaces sharing the same cluster . We do not want to provide each tenant their own separate Kubernetes Cluster because that would be additional provisioning overhead, management overhead and also additional resource overhead on the platform.\n\nIn this blog, I will go over the concepts and visual representation as well as the steps to learn and build your setup.\nNow there are different combinations possible depending on the requirements. These could be :\n\n1. Single Istio Control Plane with its own Ingress-Gateway to ensure traffic for the control plane is coming via the same control plane Ingress-Gateway.\n1. One or more Workspace namespaces for the workload applications and each with its own instance of the ingress gateway\n1. More advanced scenario would be multiple Control Plane and its associated Data Plane or essentially Multiple Service Mesh within a single Kubernetes Cluster. This is presently feasible using the Maistra Istio Operator, but its not fully supported using the upstream Istio at present. I intend to go over this use case in a later article.\n\nHere by Ingress Gateway we mean the Istio Ingress Gateway and not the Kubernetes Ingress Gateway.\nNow, before we get into the steps for building an Istio Multi-tenant setup, lets quickly review the prerequisite :\n\n- Kubernetes setup (in the steps below I am using v1.18 on ubuntu 18.04)\n\n  ```sh\n  $ sudo apt-get install -y docker.io\n  $ sudo sh -c “echo ‘deb http://apt.kubernetes.io/ kubernetes-xenial main’ >> /etc/apt/sources.list.d/kubernetes.list”\n  $ sudo sh -c “curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -”\n  $ sudo apt-get update\n  $ sudo apt-get install -y kubeadm=1.18.1–00 kubelet=1.18.1–00 kubectl=1.18.1–00\n  $ sudo kubeadm init — kubernetes-version 1.18.1 — pod-network-cidr 192.168.0.0/16\n  $ mkdir -p $HOME/.kube\n  $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n  $ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n  ```\n\n- Get the latest istioctl binary\n\n  ```sh\n  $ curl -L https://git.io/getLatestIstio | sh -\n  cd istio-*\n  export PATH=$PWD/bin:$PATH\n  istioctl version\n  ```\n\n- Initialize the Istio Operator\n  ```sh\n  $ istioctl operator init\n  Using operator Deployment image: docker.io/istio/operator:1.6.3\n  ✔ Istio operator installed\n  ✔ Installation complete\n  $ kubectl get all -n istio-operator\n  NAME READY STATUS RESTARTS AGE\n  pod/istio-operator-5998f6c744-vrkbk 1/1 Running 1 78m\n  NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n  service/istio-operator ClusterIP 10.107.183.94 <none> 8383/TCP 78m\n  NAME READY UP-TO-DATE AVAILABLE AGE\n  deployment.apps/istio-operator 1/1 1 1 78m\n  NAME DESIRED CURRENT READY AGE\n  replicaset.apps/istio-operator-5998f6c744 1 1 1 78m\n  ```\n\nNext we will look into the details of the multitenancy scenarios; but before that a few word on the Istio operator would be nice. The Istio Operator follows the Kubernetes Controller and Custom Resource Definition mechanism and basically the above steps create an Istio operator controller in the istio-operator namespace and also registers the CRDs in the Kubernetes Registry. Basically, it extends the API for Kubernetes and allows management of a Custom Resource(CR). A word of caution, the existing upstream Istio Operator does not follow any Operator Framework like kubebuilder or Operator SDK. Hence, many of the expected behavior fail like trying to create two Istio Operator Custom Resource(the community mentions it as `iop` instances) in different namespaces or multiple `iop` instances and are under heavy development.\n\nOk, so now lets jump into action. We will build our Istio Setup for the scenario 1 &2 above shown in the diagram below. There are three different instances of Ingress Gateway(and it could be egress gateway as well) :\n\na. Ingress Gateway in Control Plane for traffic entry point to the Control plane Observability Components like `Kiali`(for the Service Mesh Graph), `Prometheus`(for metrics),Grafana(for visual charts of the metrics)and `Jaeger` (for distributed tracing between the services)\nb. Ingress Gateway in the Worskpace 1 namespace for traffic entry point to the workspace 1 microservices.\nc. Ingress Gateway in the Worskpace 2 namespace for traffic entry point to the workspace 2 microservices.\n\n<img src={img1} alt=\"kubernetes-cluster\"/>\n<div style={{ textAlign: \"center\" }}>\n\n  Single Control Plane with Multiple Data Plane each with separate Ingress\n  Gateway\n\n</div>\n- Creation of Control Plane CR and Data Plane CR\n  A sample CR for creation of the Control plane and Data Plane CR can be referred below :\n  ```sh\n  $ cat iop-platform.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: platform-istiocontrolplane\n  spec:\n  profile: demo\n  $ cat iop-wk1-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk1-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  - name: wk1-ingressgw\n  namespace: workspace-1\n  enabled: true\n  label:\n  istio: ingressgateway-1\n  app: istio-ingressgateway-1\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  $ cat iop-wk2-gw.yaml\n  apiVersion: install.istio.io/v1alpha1\n  kind: IstioOperator\n  metadata:\n  namespace: istio-system\n  name: wk2-gwconfig\n  spec:\n  profile: empty\n  components:\n  ingressGateways:\n  - name: wk2-ingressgw\n  namespace: workspace-2\n  enabled: true\n  label:\n  istio: ingressgateway-2\n  app: istio-ingressgateway-2\n  values:\n  gateways:\n  istio-ingressgateway:\n  debug: error\n  ```\n\nIt is important to make sure the indentation is correct ,otherwise it would lead to errors.\nReference: [Istio Website](https://istio.io/latest/docs/setup/install/)\n\nDeploy the CRs using kubectl:\n\n```sh\n$ kubectl create ns istio-system\n$ kubectl create ns workspace-1\n$ kubectl create ns workspace-2\n$ kubectl apply -f ../iop-platform.yaml\nistiooperator.install.istio.io/platform-istiocontrolplane created\n$ kubectl apply -f ../iop-wk1-gw.yaml\nistiooperator.install.istio.io/wk1-gwconfig configured\n$ kubectl apply -f ../iop-wk2-gw.yaml\nistiooperator.install.istio.io/wk2-gwconfig configured\n```\n\n- Troubleshooting the Istio Operator Controller.\n  Its a good idea to run another window and execute the below command to observe the running logs on the controller pod.\n  ```sh\n  $ kubectl logs -f -n istio-operator\n  $(kubectl get pods -n istio-operator -lname=istio-operator -o jsonpath=’{.items[0].metadata.name}’)\n  ```\n\n<img src={img2} alt=\"image\"/>\n\n- Observe the created objects in istio-system and the workspace namespaces for all pods to be in running state.\n\n  ```sh\n  $ kubectl get all -n istio-system\n  NAME READY STATUS RESTARTS AGE\n  pod/grafana-b54bb57b9-k84xf 1/1 Running 0 79s\n  pod/istio-egressgateway-77c7d594c5-fr79j 1/1 Running 0 83s\n  pod/istio-ingressgateway-766c84dfdc-p6g6t 1/1 Running 0 83s\n  pod/istio-tracing-9dd6c4f7c-ndjvn 1/1 Running 0 79s\n  pod/istiod-7b69ff6f8c-9gwp8 1/1 Running 0 94s\n  pod/kiali-d45468dc4–4sww2 1/1 Running 0 79s\n  pod/prometheus-5fdfc44fb7–67khx 2/2 Running 0 78s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-1\n  NAME READY STATUS RESTARTS AGE\n  pod/wk1-ingressgw-5674488c8b-fg2w5 1/1 Running 0 21s\n  <truncated>\n  esudbat@istio:~/istio$ kubectl get all -n workspace-2\n  ```\n\n- Now we will label the namespaces for istio-injection\n\n  ```sh\n  $kubectl label namespace workspace-1 istio-injection=enabled\n  $kubectl label namespace workspace-2 istio-injection=enabled\n  ```\n\n- Now we will deploy the bookinfo sample application in both namespaces but before that we need to make sure that the Gateway resource is updated with the correct label selector as below :\n\n  ```sh\n  $ cat istio/bookinfo-gateway-1.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-1 # use istio gateway-1 controller in workspace-1\n  servers:\n  - port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  - “*”\n  $ cat istio/bookinfo-gateway-2.yaml\n  apiVersion: networking.istio.io/v1alpha3\n  kind: Gateway\n  metadata:\n  name: bookinfo-gateway\n  spec:\n  selector:\n  istio: ingressgateway-2 # use istio gateway-2 controller in workspace-1\n  servers:\n  - port:\n  number: 80\n  name: http\n  protocol: HTTP\n  hosts:\n  - “*”\n  ```\n\n\nDeploy the applications in workspace-1 and workspace-2 and deploy the Gateway, VirtualService and DestinationRules.\n\n{/* */}\n\n```sh\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml -n workspace-2\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-1\n$kubectl apply -f samples/bookinfo/networking/destination-rule-all-mtls.yaml -n workspace-2\n```\n\nEssentially what is happening is the Gateway CR is configuring the traffic to come via the ingress-gateway, it specifies the label selector based on which the ingress-gateway is selected and the host from where the traffic is allowed and port on which the traffic is allowed. It is important to ensure the label maps the label on the ingress-gateway.\nOnce this is done the traffic will start flowing the intended gateway and it could be observed on the Kiali dashboard.\nPlease note that in this scenario the Kiali is also accessed via the default control plane ingress-gateway running in the istio-system control plane namespace.\n\n<img src={img3} alt=\"image\" />\n<div style={{ textAlign: \"center\" }}>Kiali view for Workspace-1</div>\n<img src={img4} alt=\"image\" />\n<div style={{ textAlign: \"center\" }}>Kiali view for Workspace-2</div>\nShortly, we will go over the 3rd scenario which is to run multiple Istio Control Planes (Multiple Service Meshes) within the same Kubernetes Cluster. For that, we will need to build an open-shift setup and deploy the Maistra Istio Operator.\nSpecial thanks to the [Istio Community](https://istio.slack.com/) for helping me understand the concepts and also answering my queries and of course to [Lee Calcote](https://calcotestudios.com/talks/), who helped me embark on my Istio journey.\n\n<div>\n\n  <b>\n    Connect with Sudeep Batra on\n    <a href=\"https://www.linkedin.com/in/sudeep-batra\"> LinkedIn</a>, <a href=\"https://github.com/sb1975\">GitHub</a>, or <a href=\"https://twitter.com/sudeepbatra\"> Twitter</a>.\n  </b>\n\n</div>\n\n</BlogWrapper>\n","frontmatter":{"title":"Service Mesh (Istio) patterns for Multitenancy","subtitle":"","date":"July 18th, 2020","author":"Sudeep Batra","thumbnail":{"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/1f1d0/image2.webp 750w,\n/static/6126014dd6a4c684993008406f28dae0/d65dc/image2.webp 1050w","sizes":"100vw"},"sources":[]},"width":1,"height":0.638095238095238}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/6126014dd6a4c684993008406f28dae0/image2.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRkYAAABXRUJQVlA4IDoAAAAwAwCdASoUAA0APtFUpEuoJKOhsAgBABoJaQAAetGLLsAAAP7vhDiT/XpMBU3mvncWVJalRVYSIAAA"},"images":{"fallback":{"src":"/static/6126014dd6a4c684993008406f28dae0/cf24b/image2.webp","srcSet":"/static/6126014dd6a4c684993008406f28dae0/cef72/image2.webp 125w,\n/static/6126014dd6a4c684993008406f28dae0/8451e/image2.webp 250w,\n/static/6126014dd6a4c684993008406f28dae0/cf24b/image2.webp 500w,\n/static/6126014dd6a4c684993008406f28dae0/c5f45/image2.webp 1000w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":319}}}},"fields":{"slug":"/blog/service-mesh/service-mesh-istio-patterns-for-multitenancy"}}]}},"pageContext":{"category":"Service Mesh"}},"staticQueryHashes":["1485533831","4047814605","408154852","4152005505"],"slicesMap":{},"matchPath":"/blog/category/service-mesh"}