{"componentChunkName":"component---src-templates-blog-tag-list-js","path":"/blog/tag/networking.html","result":{"data":{"allMdx":{"nodes":[{"id":"8506be5c-8c38-5051-9aa1-efa2e5635e60","body":"\nimport { BlogWrapper } from \"../../Blog.style.js\";\nimport { Link } from \"gatsby\";\nimport Button from \"../../../../reusecore/Button\";\nimport Blockquote from \"../../../../reusecore/Blockquote\";\n\n<BlogWrapper>\n\nKubernetes provides a Service to offer a unified traffic endpoint for the Pods. While it offers a VIP to the clients for access and Kubernetes ensures traffic balancing for the accessing back-end Pods, it has a limitation of routing traffic from outside the cluster. The Kubernetes Service setting of \"NodePort\" was created to overcome this issue. \n\nBy setting up a mapping to a specific port of all nodes in the cluster, a NodePort Service redirects traffic from the outside to the inside of the cluster. When a NodePort Service is created, Kubernetes control plane allocates its corresponding ports in two ways. The first is dynamic, where Kubernetes control plane automatically assigns an unused port at the creation time. The second is static, which assigns a port within the nodeport port range configuration. It is crucial to assign a unique nodePort across the entire cluster while manually assigning nodePort, or it will result in an error if a service of type NodePort already uses that port. \n\nSometimes, there is a need to run a NodePort Service on well-known ports so that other components and users inside or outside the cluster can use them. In such cases, users need to reserve the required ports before using them. Kubernetes 1.27 introduced a new feature gate \"ServiceNodePortStaticSubrange\" that allows users to use a different port allocation strategy for type NodePort Services. Enabling this feature gate will divide the port range for NodePort Services based on a formula that uses nodeport size and determines the size of the static port range.\n\nHere are a few examples of different port ranges and their band offset values:\n<div className=\"table-3\">\n\n| Range properties | Values |\n| --- | --- |\n| service-node-port-range | 30000-32767 |\n| Band Offset | 86 |\n| Static band start | 30000 |\n| Static band end | 30085 |\n| Dynamic band start | 30086 |\n| Dynamic band end | 32767 |\n\n</div>\n<br />\n<div className=\"table-3\">\n\n| Range properties | Values |\n| --- | --- |\n| service-node-port-range | 30000-30015 |\n| Band Offset | 16 |\n| Static band start | 30000 |\n| Static band end | 30015 |\n| Dynamic band start | N/A |\n| Dynamic band end | N/A |\n\n</div>\n\nNodePort Services can be useful in many scenarios. For example, consider a user that needs to expose a Minio object storage service on Kubernetes to clients running outside the Kubernetes cluster. The agreed port is 30009, and the user needs to create a Service as follows:\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: minio\nspec:\n  ports:\n  - name: api\n    nodePort: 30009\n    port: 9000\n    protocol: TCP\n    targetPort: 9000\n  selector:\n    app: minio\n  type: NodePort\n```\nIf the port required for the Minio Service is not reserved and another NodePort (or possibly LoadBalancer) Service is created and dynamically allocated before or concurrently with the Minio Service, the TCP port 30009 might be allocated to that other Service. In this case, creation of the Minio Service will fail due to a node port collision. \n\nIn conclusion, using the NodePort Service will help Kubernetes users by allowing traffic to be routed from outside to inside the cluster, providing a unified traffic endpoint for the Pods. By enabling the ServiceNodePortStaticSubrange feature gate, users can adopt a different port allocation strategy, reducing the risk of collisions while using a different range of ports.\n\n</BlogWrapper>","frontmatter":{"title":"Kubernetes NodePorts - Static and Dynamic Assignments","subtitle":"Avoiding Port Collisions","date":"May 12th, 2023","author":"Lee Calcote","thumbnail":{"extension":"webp","publicURL":"/static/7ff62eaeba27512aa31c04535a060e72/k8s-nodeports.webp","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBACdASoUABQAPtFcpU6oJSMiKAqpABoJagCdAA7o/xI+daMhu4ZyKIc8AP5sMkrm/KSMElhNhyFx1gsn7iAKtDbnb2EOpN1Lu4ERxHR8dZzo2nLfaBjTkL7HUoWJ2ZeN3kbroyt5qSiHJrjn1s8R/0YvwxgPzzQOJ6Z6/jny3fK+Q/p/RG8WRYpz7F7kTd49j//OPWbkB/vQwHCyP2a8pf47eyzW5wuh8SG+Fee1AAAA"},"images":{"fallback":{"src":"/static/7ff62eaeba27512aa31c04535a060e72/c1587/k8s-nodeports.webp","srcSet":"/static/7ff62eaeba27512aa31c04535a060e72/4f03f/k8s-nodeports.webp 750w,\n/static/7ff62eaeba27512aa31c04535a060e72/c1587/k8s-nodeports.webp 800w","sizes":"100vw"},"sources":[]},"width":1,"height":1}}},"darkthumbnail":{"extension":"webp","publicURL":"/static/7ff62eaeba27512aa31c04535a060e72/k8s-nodeports.webp","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/webp;base64,UklGRr4AAABXRUJQVlA4ILIAAABQBACdASoUABQAPtFcpU6oJSMiKAqpABoJagCdAA7o/xI+daMhu4ZyKIc8AP5sMkrm/KSMElhNhyFx1gsn7iAKtDbnb2EOpN1Lu4ERxHR8dZzo2nLfaBjTkL7HUoWJ2ZeN3kbroyt5qSiHJrjn1s8R/0YvwxgPzzQOJ6Z6/jny3fK+Q/p/RG8WRYpz7F7kTd49j//OPWbkB/vQwHCyP2a8pf47eyzW5wuh8SG+Fee1AAAA"},"images":{"fallback":{"src":"/static/7ff62eaeba27512aa31c04535a060e72/5f169/k8s-nodeports.webp","srcSet":"/static/7ff62eaeba27512aa31c04535a060e72/d66e1/k8s-nodeports.webp 125w,\n/static/7ff62eaeba27512aa31c04535a060e72/e7160/k8s-nodeports.webp 250w,\n/static/7ff62eaeba27512aa31c04535a060e72/5f169/k8s-nodeports.webp 500w","sizes":"(min-width: 500px) 500px, 100vw"},"sources":[]},"width":500,"height":500}}}},"fields":{"slug":"/blog/kubernetes/kubernetes-nodeports-static-and-dynamic-assignments"}}]}},"pageContext":{"tag":"Networking"}},"staticQueryHashes":["1485533831","4047814605","408154852","4152005505"],"slicesMap":{},"matchPath":"/blog/tag/networking"}