<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Layer5 Blog]]></title><description><![CDATA[Making service meshes available to the rest of us. Open source software for management of service meshes. Allowing developers to focus on business logic, not infrastructure concerns. Empowering operators to confidentally run modern infrastructure.]]></description><link>https://layer5.io</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 25 Jan 2022 02:25:37 GMT</lastBuildDate><item><title><![CDATA[Considerations of Adopting a Service Mesh]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Considerations of Adopting a Service Mesh",
  "thumbnail": "./figure1.png",
  "category": "Service Mesh",
  "tags": ["Service mesh"],
  "type": "Blog",
  "product": "Meshery",
  "technology": "Docker",
  "mesh": "Istio",
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, " The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("h2", null, "What are practical steps to adopt a service mesh in my enterprise? "), mdx("h3", null, "Piecemeal Adoption"), mdx("p", null, "Many organisations wish to take advantage of auto-instrumented observability first, taking baby steps toward a full-service mesh after achieving first success and operational comfort,\xA0to better understand what's going on across their distributed infrastructure. It's a high-value, relatively safe first step to use a service mesh for its ability to provide enhanced observability. First steps for others might be on a parallel path. For example, a financial organisation\xA0might seek improved security with strong identity (per-service certificates) and strong encryption via mutual TLS between each\xA0service. Others, on the other hand, may begin with an ingress proxy as a stepping stone to a larger service mesh deployment."), mdx("p", null, "Consider an organisation\xA0with hundreds of existing services running on virtual machines (VMs) external to the\xA0service mesh that have little to no service-to-service traffic, with practically all traffic flowing from the client to the service and back to the client. Without immediately\xA0deploying hundreds of service proxies, this organisation can deploy\xA0a service mesh ingress (e.g., Istio Ingress Gateway) to gain granular traffic control (e.g., path rewrites) and detailed service monitoring."), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Traffic,
    align: "center",
    alt: "ingress traffic control"
  }), mdx("p", null, "Figure 1: Simple service mesh deployment primarily using ingress traffic control.")), mdx("h3", null, "Practical Steps to Adoption"), mdx("p", null, "Here are two common paths:"), mdx("ul", null, mdx("li", null, "Wholesale adoption of a service mesh, commonly while designing a new application (a greenfield project)."), mdx("li", null, "Piecemeal adoption of some components and capabilities of a service mesh, but not others, commonly while working with an existing application (a brownfield project).")), mdx("p", null, "Let's take a look at how the second path manifests itself, because it's the path that most people will face (those with existing services) and the approach that most organisations take. In this method, incremental steps are taken. When teams are comfortable with their understanding\xA0of the deployment, have gained operational expertise, and derived substantial value, another step toward a full mesh is usually accomplished. Since n ot all components of a full service mesh are helpful to teams based on their focus or current pain points, not all teams choose to take another step. This will evolve over time, as full service mesh deployments become ubiquitous. More than this, application developers and service (product) owners will begin to rely on the power of a service mesh to empower and satisfy their requirements as well."), mdx("p", null, "Which applications should be constructed from the ground up or transformed using a new service mesh architecture depends on engineering maturity and skill set. You don't have to use all of the features; use\xA0the ones you need. Given that some service meshes provide a path to partial adoption, the best way may be to mitigate risk, baby-step it, and show incremental triumphs. Some service meshes can be deployed and digested in a single step. Even if this is the case, you might find that you enable only\xA0a subset of its\xA0capabilities. Presence of a service mesh\u2019s capabilities is separate from whether those capabilities are actively engaged."), mdx("p", null, "Observability is at the top of the list of reasons why most organizations deploy a service mesh initially. You usually obtain a service dependency graph in addition to metrics, logs, and traces. These graphs visually identify how much traffic is coming from one service and going to the next.\xA0\xA0 You'll feel as if you're running\xA0blind if you don't have a visible topology or service graph."), mdx("p", null, "Alternatively, it could be your current load balancer that is running blind.\xA0 Most service mesh proxies will come in handy if you're running gRPC services and have a load balancer ignorant of\xA0gRPC and treats this traffic like any other TCP traffic. Modern service proxies will support HTTP/2 and, as such, might provide a gRPC bridge from HTTP/1.1 to HTTP/2."), mdx("h3", null, "Security"), mdx("p", null, "Organizations usually prioritise security last.\xA0 They may not want strong authentication and encryption when they ultimately do look into security. Although it is best practise to secure everything using strongly authenticated and authorised services, some organisations fail to do so, resulting in soft, gooey centres in their microservices deployments. Some teams are content to secure the\xA0edge of their network, but they still want the observability and control that a service mesh can provide."), mdx("div", {
    className: "fact"
  }, mdx("p", null, "Needless to say, I recommend that you run workloads securely, using a service mesh to provide authentication and authorization between all service requests.")), mdx("p", null, "Why aren't certain organizations interested in using Service Mesh's managed certificate authority? Because it is another\xA0thing to operate? When connections are established, encryption consumes resources (CPU cycles) and can inject\xA0a few microseconds of latency. Given this, and to aid adoption, some service meshes prominently display installation options that include a certificate authority (CA) and installation configurations that do not. Maybe you consider the \u201Cgooey center\u201D of your mesh to be secure because there is little to no ingress/egress traffic to/from the cluster and access is provided only via VPN into the cluster.\xA0Depending on workload, wallet, and sensitivity to latency, you might find that you don\u2019t want the overhead of running encryption between all of your services."), mdx("p", null, "Maybe you're just searching for authorization checks, and\xA0you're deploying monoliths rather than microservices. You don't need any further monitoring integrations because you already have API management. Perhaps you use IP addresses (subnets) for network security zones. Using identities and encryption provided by the service mesh, together with authorization checks enforced by policy you specify, a service mesh can help you get rid of network partitions and firewalling on Layer 3 (L3) boundaries. You can flatten your internal network by policy enforcing, authorization checks across your monoliths, making services broadly reachable\xA0while granularly controlling which requests are authorized. The power of service mesh to analyse and reason over details of request traffic much beyond IP addresses and ports (Layer 3/4) provides significantly more flexibility."), mdx("h3", null, "Retrofitting a Deployment"), mdx("p", null, "Recognize that, while some greenfield projects may have the luxury of starting with a service mesh, most organizations will have existing services (monoliths or otherwise) to onboard to the mesh. These services could run in VMs or bare-metal hosts instead of containers. Fear not! Some service meshes squarely address such environments and help with the modernization of such services, allowing organizations to renovate their services inventory by:"), mdx("ul", null, mdx("li", null, "Not having to rewrite their applications"), mdx("li", null, "Adapting microservices and existing services using the same infrastructure architecture"), mdx("li", null, "Facilitating adoption of new languages"), mdx("li", null, "Facilitating moving to or securely connecting with services in the cloud (or on edge)")), mdx("p", null, "For those organisations who adopt a strangler pattern of building services around a legacy monolith to expose a more developer-friendly set of APIs, service meshes make it easier to insert facade services as a way of breaking down monoliths."), mdx("p", null, "With the adoption of a service mesh, organisations can get observability (e.g., metrics, logs, and traces) as well as dependency or service graphs for all of their services (micro or not). The only change required within the service with respect to\xA0tracing is to forward certain HTTP headers. With the least amount of code change, service meshes are effective for retrofitting uniform and ubiquitous observability tracing into existing infrastructures.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/considerations-of-adopting-a-service-mesh</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/considerations-of-adopting-a-service-mesh</guid><enclosure url="https://layer5.io/static/1716a305b053b5c56dbf883dfd5cd5cc/figure1.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt; The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;What are practical steps to adopt a service mesh in my enterprise? &lt;/h2&gt;&lt;h3&gt;Piecemeal Adoption&lt;/h3&gt;&lt;p&gt;Many organisations wish to take advantage of auto-instrumented observability first, taking baby steps toward a full-service mesh after achieving first success and operational comfort, to better understand what&amp;#x27;s going on across their distributed infrastructure. It&amp;#x27;s a high-value, relatively safe first step to use a service mesh for its ability to provide enhanced observability. First steps for others might be on a parallel path. For example, a financial organisation might seek improved security with strong identity (per-service certificates) and strong encryption via mutual TLS between each service. Others, on the other hand, may begin with an ingress proxy as a stepping stone to a larger service mesh deployment.&lt;/p&gt;&lt;p&gt;Consider an organisation with hundreds of existing services running on virtual machines (VMs) external to the service mesh that have little to no service-to-service traffic, with practically all traffic flowing from the client to the service and back to the client. Without immediately deploying hundreds of service proxies, this organisation can deploy a service mesh ingress (e.g., Istio Ingress Gateway) to gain granular traffic control (e.g., path rewrites) and detailed service monitoring.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-0096c54e72c9eceadcfa1d55a0714c2b.png&quot; align=&quot;center&quot; alt=&quot;ingress traffic control&quot;/&gt;&lt;p&gt;Figure 1: Simple service mesh deployment primarily using ingress traffic control.&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Practical Steps to Adoption&lt;/h3&gt;&lt;p&gt;Here are two common paths:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Wholesale adoption of a service mesh, commonly while designing a new application (a greenfield project).&lt;/li&gt;&lt;li&gt;Piecemeal adoption of some components and capabilities of a service mesh, but not others, commonly while working with an existing application (a brownfield project).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Let&amp;#x27;s take a look at how the second path manifests itself, because it&amp;#x27;s the path that most people will face (those with existing services) and the approach that most organisations take. In this method, incremental steps are taken. When teams are comfortable with their understanding of the deployment, have gained operational expertise, and derived substantial value, another step toward a full mesh is usually accomplished. Since n ot all components of a full service mesh are helpful to teams based on their focus or current pain points, not all teams choose to take another step. This will evolve over time, as full service mesh deployments become ubiquitous. More than this, application developers and service (product) owners will begin to rely on the power of a service mesh to empower and satisfy their requirements as well.&lt;/p&gt;&lt;p&gt;Which applications should be constructed from the ground up or transformed using a new service mesh architecture depends on engineering maturity and skill set. You don&amp;#x27;t have to use all of the features; use the ones you need. Given that some service meshes provide a path to partial adoption, the best way may be to mitigate risk, baby-step it, and show incremental triumphs. Some service meshes can be deployed and digested in a single step. Even if this is the case, you might find that you enable only a subset of its capabilities. Presence of a service mesh’s capabilities is separate from whether those capabilities are actively engaged.&lt;/p&gt;&lt;p&gt;Observability is at the top of the list of reasons why most organizations deploy a service mesh initially. You usually obtain a service dependency graph in addition to metrics, logs, and traces. These graphs visually identify how much traffic is coming from one service and going to the next.   You&amp;#x27;ll feel as if you&amp;#x27;re running blind if you don&amp;#x27;t have a visible topology or service graph.&lt;/p&gt;&lt;p&gt;Alternatively, it could be your current load balancer that is running blind.  Most service mesh proxies will come in handy if you&amp;#x27;re running gRPC services and have a load balancer ignorant of gRPC and treats this traffic like any other TCP traffic. Modern service proxies will support HTTP/2 and, as such, might provide a gRPC bridge from HTTP/1.1 to HTTP/2.&lt;/p&gt;&lt;h3&gt;Security&lt;/h3&gt;&lt;p&gt;Organizations usually prioritise security last.  They may not want strong authentication and encryption when they ultimately do look into security. Although it is best practise to secure everything using strongly authenticated and authorised services, some organisations fail to do so, resulting in soft, gooey centres in their microservices deployments. Some teams are content to secure the edge of their network, but they still want the observability and control that a service mesh can provide.&lt;/p&gt;&lt;div class=&quot;fact&quot;&gt;&lt;p&gt;Needless to say, I recommend that you run workloads securely, using a service mesh to provide authentication and authorization between all service requests.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Why aren&amp;#x27;t certain organizations interested in using Service Mesh&amp;#x27;s managed certificate authority? Because it is another thing to operate? When connections are established, encryption consumes resources (CPU cycles) and can inject a few microseconds of latency. Given this, and to aid adoption, some service meshes prominently display installation options that include a certificate authority (CA) and installation configurations that do not. Maybe you consider the “gooey center” of your mesh to be secure because there is little to no ingress/egress traffic to/from the cluster and access is provided only via VPN into the cluster. Depending on workload, wallet, and sensitivity to latency, you might find that you don’t want the overhead of running encryption between all of your services.&lt;/p&gt;&lt;p&gt;Maybe you&amp;#x27;re just searching for authorization checks, and you&amp;#x27;re deploying monoliths rather than microservices. You don&amp;#x27;t need any further monitoring integrations because you already have API management. Perhaps you use IP addresses (subnets) for network security zones. Using identities and encryption provided by the service mesh, together with authorization checks enforced by policy you specify, a service mesh can help you get rid of network partitions and firewalling on Layer 3 (L3) boundaries. You can flatten your internal network by policy enforcing, authorization checks across your monoliths, making services broadly reachable while granularly controlling which requests are authorized. The power of service mesh to analyse and reason over details of request traffic much beyond IP addresses and ports (Layer 3/4) provides significantly more flexibility.&lt;/p&gt;&lt;h3&gt;Retrofitting a Deployment&lt;/h3&gt;&lt;p&gt;Recognize that, while some greenfield projects may have the luxury of starting with a service mesh, most organizations will have existing services (monoliths or otherwise) to onboard to the mesh. These services could run in VMs or bare-metal hosts instead of containers. Fear not! Some service meshes squarely address such environments and help with the modernization of such services, allowing organizations to renovate their services inventory by:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Not having to rewrite their applications&lt;/li&gt;&lt;li&gt;Adapting microservices and existing services using the same infrastructure architecture&lt;/li&gt;&lt;li&gt;Facilitating adoption of new languages&lt;/li&gt;&lt;li&gt;Facilitating moving to or securely connecting with services in the cloud (or on edge)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For those organisations who adopt a strangler pattern of building services around a legacy monolith to expose a more developer-friendly set of APIs, service meshes make it easier to insert facade services as a way of breaking down monoliths.&lt;/p&gt;&lt;p&gt;With the adoption of a service mesh, organisations can get observability (e.g., metrics, logs, and traces) as well as dependency or service graphs for all of their services (micro or not). The only change required within the service with respect to tracing is to forward certain HTTP headers. With the least amount of code change, service meshes are effective for retrofitting uniform and ubiquitous observability tracing into existing infrastructures.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Analyzing Service Mesh Performance]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Analyzing Service Mesh Performance",
  "subtitle": "",
  "thumbnail": "./smp-light-text_2.png",
  "category": "Service Mesh Performance",
  "tags": ["Service Mesh Performance", "GetNighthawk", "Meshery"],
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about Service Mesh Performance from this article", mdx("a", {
    className: "blog",
    href: "https://www.nxtbook.com/nxtbooks/ieee/bridge_issue3_2021/index.php#/p/16"
  }, " Analyzing Service Mesh Performance"), " - Published in issue 3 of IEEE Bridge October 2021")), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: cover,
    align: "center",
    alt: "IEEE The Bridge 2021 Issue 3 cover"
  })), mdx("p", null, "As a forthcoming, ubiquitous layer of cloud native infrastructure, service meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. Managing the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly summarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure of choice is a challenge unto its own."), mdx("p", null, "We explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties of resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance analysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of workloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations."), mdx("p", null, "We provide core, memory and I/O combinations based on workload needs with insights into workload analysis which can influence the efficiency of the service mesh and overall performance of the cluster."), mdx("h2", null, "Characterizing the Complexity of Combinatorial Analysis"), mdx("p", null, "Consider that the more value you try to derive from your service mesh, the more work that you will ask it to do. Said another way, that as someone reflects more deeply on the architecture of a service mesh - with its distributed proxies - and the functionality it offers, they will eventually wonder, \"What overhead is running my service mesh incurring?\". This is one of the most common questions engineers have as they initially learn of a service mesh and the value a deployment of one offers. This is not an easy question to answer as the permutations of configuration between your infrastructure, service mesh, and applications are innumerable and any change to one of them affects their collective performance."), mdx("p", null, "How would you describe the performance of your service mesh and that of your clusters and their workloads? Are you imagining a wall of line charts with metrics capturing golden signals? The act of articulating the performance of your service mesh can take anywhere from a minute to even a few hours to characterize the state of your systems and the overhead incurred by your infrastructure and what this means to your users."), mdx("p", null, "Moreover, anytime performance is characterized, analysis is subjective to the specific workload, infrastructure, and instruments used for measurement. Given the variety of this measurement challenge, most service meshes and their data plane proxies (if a third-party component), do not have the tooling necessary or refuse to publish performance data because such tests can be:", mdx("ol", null, mdx("li", null, "arduous to create and sustain a capable harness"), mdx("li", null, "a point-in-time consideration (none of the elements under measurement are static"), mdx("li", null, "misinterpreted"))), mdx("p", null, "Read on as we identify how to surmount each of these challenges."), mdx("h2", null, "Service Mesh Performance Considerations"), mdx("p", null, "As the software defined networking layer of microservices, service mesh encompasses multiple aspects of critical functions of the applications, such as circuit breaking, health checks, and packet operations. Analyzing the permutations of these configurations is an impossible task without a suitable test harness. A service mesh management plane can be such a tool. As the multi-mesh manager, ", mdx("a", {
    href: "https://meshery.io"
  }, "Meshery "), "is capable of provisioning 10 different service meshes, workloads atop the meshes, generating load using ", mdx("a", {
    href: "https://getnighthawk.dev"
  }, "Nighthawk"), ", and analyzing that load. No other tool capable of performing these tasks end-to-end exists. Meshery is a Cloud Native Computing Foundation project originally created by Layer5."), mdx("h3", null, "How are you measuring?"), mdx("p", null, "Consider the simple set of steps to execute performance tests in a simple Kubernetes-based cluster:"), mdx("ol", null, mdx("li", null, "Setup your cluster, service mesh, and application under test."), mdx("li", null, "Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance."), mdx("li", null, "Configure your test setup for performance, doing so in context of other constraints that you might need to uphold (e.g. resiliency characteristics of your service deployment)."), mdx("li", null, "Choose the protocol of interest: HTTP, HTTPS, HTTP1/2, gRPC, NATS"), mdx("li", null, "Identify KPIs of interest - Transactions per second (TPS) or percentile latencies, etc."), mdx("li", null, "Decide on the test duration: 60s or 5 minutes or 1 hour..."), mdx("li", null, "Choose the number of requests per second (RPS)."), mdx("li", null, "Execute the test."), mdx("li", null, "Mark down requests per second, latencies, throughput, and any other output provided by benchmarking tools.")), mdx("h3", null, "What are you measuring?"), mdx("p", null, "Performance of a service mesh can be described across multiple dimensions covering some or all of these core functionalities of a service mesh. So, which dimensions are the linchpins of performance? Which metrics are key indicators of performance? Outside of the different types of performance tests, performance management concerns include the need for performance and overhead data under a permutation of different workloads (applications) and different types and sizes of infrastructure resources."), mdx("div", {
    className: "center"
  }, mdx("a", {
    href: EWtraffic
  }, mdx("img", {
    src: EWtraffic,
    align: "center",
    alt: "EWtraffic"
  }))), mdx("p", null, "Hence, it is crucial to understand what is being measured in a service mesh based deployment. Certain critical considerations are missing from the simple methodology previously described. For example, as indicated in Figure 1, but not limited to:"), mdx("ol", null, mdx("li", null, "Traffic considerations", mdx("ul", null, mdx("li", null, "East-West traffic", mdx("ol", null, mdx("li", null, "between two pods within the same or two different Virtual Machines (VM)."), mdx("li", null, "between two pods within the same or two different bare metal nodes."), mdx("li", null, "combination of above with choice of user-space or kernel-space networking stack on the host node."))), mdx("li", null, "North-South traffic", mdx("ol", null, mdx("li", null, "Throughput and latency of traffic flowing in and out of a single VM or across a single bare metal node."))))), mdx("li", null, "Deployment considerations", mdx("ul", null, mdx("li", null, "Number of hops between traffic source and traffic destination with load balancers, API gateways, ingress controllers, security components such as firewall, deep packet inspectors, and so on."), mdx("li", null, "Operating system settings."), mdx("li", null, "Hardware settings such as BIOS options, power management features, NUMA awareness, platform resource management, hardware accelerators, and so on."))), mdx("li", null, "Load generators types", mdx("ul", null, mdx("li", null, "hardware or software based, L2-3,  L4-7, open or closed loop"))), mdx("li", null, "Service mesh types - the service mesh landscape has over 20 meshes listed. Each share a common architecture, however, their implementation differs and consequently, so does their performance.", mdx("ul", null, mdx("li", null, "Control plane - often a point of contention the larger the service mesh deployment is."), mdx("li", null, "Data plane - not only proxies, but filters loaded in those proxies."))), mdx("li", null, "Service mesh configuration and number of services on the mesh. To name a few considerations:", mdx("ul", null, mdx("li", null, "Telemetry", mdx("ol", null, mdx("li", null, "Including the three pillars of observability are traces, logs, and metrics."), mdx("li", null, "The number of, cardinality of, sampling rate, ingest rate\u2026 all bear weight (and bear load on the system)."))), mdx("li", null, "Policy", mdx("ol", null, mdx("li", null, "Authentication, Authorization - frequency of checks, cache hits vs. cache misses."))), mdx("li", null, "Security", mdx("ol", null, mdx("li", null, "Encryption - overhead of handshaking and mutually authenticated TLS.")))))), mdx("p", null, "Ultimately, the goal of any performance tests is to ensure repeatable measurements and obtain consistent results across multiple test runs."), mdx("h2", null, "Service Mesh Performance as a Specification"), mdx("p", null, "The need for cross-project, apple-to-apple comparisons are also desired in order to facilitate a comparison of behavioral differences between service meshes and which one might be best-suited for specific workloads. Individual service mesh projects shy from publishing test results of other, competing service mesh projects. The need for an independent, unbiased, credible, standard measurement is one of the catalysts for the creation of Service Mesh Performance (SMP)."), mdx("p", null, "Amidst performance concerns and the need to measure and manage performance arose the Service Mesh Performance (SMP) standard. Service Mesh Performance as a specification and disseminating insights and research results. Your authors are working toward the definition of MeshMark, a universal performance index to gauge your mesh\u2019s efficiency against deployments in other organizations\u2019 environments."), mdx("p", null, "Many performance benchmarks are limited to single instance load generation (single pod load generator). This limits the amount of traffic that can be generated to the output of the single machine that the benchmark tool runs on in or out of a cluster. Overcoming this limitation would allow for more flexible and robust testing. Distributed load testing in parallel poses a challenge when merging results without losing the precision we need to gain insight into the high tail percentiles. Distributed load testing offers insight into system behaviours that arguably more accurately represent real-world behaviours of services under load as that load comes from any number of sources."), mdx("p", null, "The specification itself provides a standard format for describing and capturing:"), mdx("ul", null, mdx("li", null, "performance test configuration"), mdx("li", null, "Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance."), mdx("li", null, "service mesh configuration"), mdx("li", null, "environment configuration"), mdx("li", null, "workload configuration"), mdx("li", null, "performance test results"), mdx("li", null, "Distributed performance modeling"), mdx("li", null, "KPIs for service mesh performance"), mdx("li", null, "Test tool requirements")), mdx("p", null, "Value from a service mesh is best derived when it's tuned to scale as per the deployment requirements. Given the complexity of deploying, testing and measuring performance aspects across multiple dimensions, the specification aims to provide a simple starting point for anyone looking to understand and derive service mesh performance. The service mesh performance standard aims to articulate these complexities in a methodical and automated manner in order for anyone to plan the performance scenarios of their deployment and execute relevant tests."), mdx("p", null, "The code snippet provides insight on the fact that the specification defines a common collection of statistical analysis to be calculated for every performance test."), mdx("pre", null, mdx("code", {
    parentName: "pre",
    "className": "language-yaml"
  }, "message PerformanceTestResult {\n  message Latency {\n    double min = 1;\n    double average = 2;\n    double p50 = 3;\n    double p90 = 4;\n    double p99 = 5;\n    double max = 6;\n  }\n}\n")), mdx("p", null, mdx("i", null, "Snippet of the Service Mesh Performance specification describing how to capture statistical analysis of test results.")), mdx("h2", null, "Defining Deployments"), mdx("p", null, "Virtualized deployments involve deploying microservice orchestration and service mesh stack in virtual machines (VMs). Although bare metal usage has performance benefits, customers often use VMs to provide hardware-level isolation between various applications. This deployment involves two VMs across two nodes, with one acting as a Kubernetes master with the other a worker node. Customers deploy VMs on a single NUMA node to avoid cross UPI traffic. Results in virtualized testing have shown that depending on pinning of QEMU threads to a set of isolated cores - either sequentially or clustering the threads together to all the cores - tail latencies are heavily impacted."), mdx("p", null, "Microservice deployments could use a wide variety of deployment scenarios. The following list provides a sample set of how a service mesh performance could be analyzed either on a same node or in a multi-node cluster:"), mdx("ul", null, mdx("li", null, "Pod to pod communication."), mdx("li", null, "Pod to service communication."), mdx("li", null, "Ingress controller to pod and vice-versa."), mdx("li", null, "Load balancer to pod and vice-versa."), mdx("li", null, "Pod to Egress Gateway."), mdx("li", null, "Mutual TLS termination across any of the above endpoints."), mdx("li", null, "Different security rules and policies."), mdx("li", null, "Communication protocol.")), mdx("p", null, "These considerations are illustrated in a typical workload deployment as shown in ", mdx("i", null, "Figure 3.")), mdx("div", {
    className: "center"
  }, mdx("a", {
    href: Workload
  }, mdx("img", {
    src: Workload,
    align: "center",
    alt: "Workload"
  }))), mdx("p", null, "Here is an example of deployment with Kubernetes as the orchestrator using Calico CNI and deployed in VMs, while the host infrastructure has OVS-DPDK for switching, which can be extended for VMs to leverage SR-IOV. To understand impact of infrastructure elements and networking elements of microservice software stack, performance impact of a service mesh and its set of data plane proxies with fortio as load generator could be understood by running the Meshery in two different environments outside the Kubernetes cluster."), mdx("ol", null, mdx("li", null, "First one with load generator running as a process outside of Kubernetes cluster in master-vm"), mdx("li", null, "Second one with load generator running as a bare metal process on master-host")), mdx("h3", null, "Automating Performance Measurements"), mdx("p", null, "Meshery is ideal tooling in that it provides lifecycle management of a large number of service meshes and sample applications which need to be provisioned, configured, and deprovisioned in the process of analyzing service mesh performance. Meshery is capable of generating load, baselining, and comparing performance results. The canonical implementation of this specification is implemented in Meshery."), mdx("div", {
    className: "center"
  }, mdx("a", {
    href: Archictures
  }, mdx("img", {
    src: Archictures,
    align: "center",
    alt: "Archictures-client"
  }))), mdx("p", null, mdx("i", null, "Figure 4 - Meshery\u2019s load generators can be deployed in the same cluster under test or outside of the cluster under test.")), mdx("h4", null, "Pipelining performance characterization"), mdx("p", null, "Acknowledging the living nature of user deployments, integration of automated performance testing into continuous integration systems helps users deploy new versions of their applications or new configurations of their infrastructure (including service mesh configuration) with the assurity  afforded through the act of dry-running the service mesh and application configuration before production deployment. The Meshery and Service Mesh Performance GitHub Action offers the ability to adaptively analyze application performance as a gate in your continuous delivery pipeline. In this way, the Service Mesh Performance specification facilitates a measurement index that can be referenced when rolling out new versions of a service with this advanced canary technique."), mdx("p", null, "Through Meshery, techniques to mirror non-idempotent requests without fear of impacting the current version of your application allowing replay of user requests. And use of intelligent network functions, embedded in WebAssembly (WASM) programs, to facilitate real user request reenactments to help you extract the most value out of your pipeline."), mdx("ul", null, mdx("li", null, "Repeatability of test scenarios using performance profiles and cloud native orchestration."), mdx("li", null, "Baselining and comparing results.")), mdx("h3", null, "Analyzing Performance Measurements"), mdx("p", null, "We have often seen inefficiencies in the ratio of resource usage vs resources applied. Since the mesh elements i.e. the ingress and sidecars share resources with one or more of the application containers, there may be more resources left to be utilized. Tail latencies decrease with the increase in number of cores for all 1, 10 and 100 clones but increase with the increase in the number of connections. Data for various connection counts, as shown, indicates that performance degradation with Istio shows up with input RPS more than 1000. In a top down microarchitectural analysis (TMA), when the front proxy is pinned to a single core and the sidecar + flask app is pinned to another core and the number of microservices are scaled up. It is observed that (Figure 2):"), mdx("ul", null, mdx("li", null, "Frontend Bound% decreases with increase in number of microservices\u200B and Core Bound % increases."), mdx("li", null, "Memory Bound % increases with increase in the number of microservices\u200B."), mdx("li", null, "L1 and L3 Bound% decreases for both the service cores on which the front \u2013proxy is running as well as the core where the sidecar+flask app is running with number of microservices.")), mdx("p", null, "In customer environments, the size of the cluster as well as the amount of incoming traffic will have an impact on the number of workloads and Envoy microservices. The underlying hardware and L4 networking on each node in the cluster will also impact the performance observed. A call stack and cycles spent analysis of a deployment with 1-20 sidecars on a specific 40 core system with a 10G NIC shows bottlenecks spread between:"), mdx("ol", null, mdx("li", null, "Envoy:TheadLocalStorage-Hashset-Match"), mdx("li", null, "Linux kernel bottleneck spread between", mdx("ol", null, mdx("li", null, "Libpthreadscheduling"), mdx("li", null, "Libevent"))), mdx("li", null, "Envoy buffer slice management and TCP filter, if message sizes or file transfer sizes increase to 1M"), mdx("li", null, "Crypto operations when TLS is enabled.")), mdx("p", null, "Our initial studies show that the optimal service mesh setup for the tolerable latencies and the best RPS may include:"), mdx("ol", null, mdx("li", null, "Exclusive  threads allocated to Envoy processing"), mdx("li", null, "Reduced memory contention by allocating more memory bandwidth which can be controlled dynamically"), mdx("li", null, "Load balancing of worker threads among the among cores which may require"), mdx("li", null, "Less IO switching"), mdx("li", null, "Optimized memory copies with signals incorporated in addition to events (libevent)")), mdx("h4", null, "Accelerations and Offloads"), mdx("p", null, "A number of accelerations and offloads to SMART NIC or other processing elements like IPUs and DPUs are becoming available. How does the service mesh efficiency and performance benefitted from these deployment options needs to be defined and measured. Cycles and cores saved in the host cores vs offload cores which may be of different architectures and/or performance range needs to be quantified and benchmarks and indices created to measure."), mdx("h3", null, "Being Precise in Performance Studies"), mdx("p", null, "When measuring sub-millisecond response times, the noise floor of the environment as well as the sensitivity of the tooling may become dominant factors in measurements. Noisy neighbours, scheduler fairness, garbage collection, and even specifics in the timing of requests being sent as well as connection-reuse patterns may change noise floors such that similar measurements performed using different systems and tools may diverge an order of magnitude in absolute terms."), mdx("p", null, "As a quick survey of load generators by way of those included in Meshery, we find upon close inspection their differences are noteworthy and justify their use under different circumstances."), mdx("p", null, "Written in C, wrk2 supports ignoring coordinated omission. wrk2 lets you test a little more complex scenarios. Users express load generation profiles in terms of RPS. wrk2 shows you what you normally may not see in benchmark results, but what every 1,000th user might see. To see these outliers, you need to run the longer (time) performance tests.  Wrk2 tests the scenario where there's a string of services comprising microservices. wrk2 requires you to specify the desired RPS, while wrk does not. Wrk2 is focused on driving the maximum RPS. Meshery\u2019s fork of wrk2 enables testing of multiple endpoints and enables the variable rate of load generation. In the future, Meshery will offer the ability to assign a weight to each endpoint for the load to be generated by wrk2."), mdx("p", null, "Written in Golang, fortio is extremely fast and usable for testing basic response times on a per request level. Fortio produces results in JSON on a per request basis and easy to integrate into other Golang-based tooling like Meshery."), mdx("p", null, "Written in C++, Nighthawk supports both open- and closed- loop testing, and was designed to offer the right sensitivity for benchmarking microservice proxies (sub millisecond latencies). Using an open loop test methodology avoids coordinated omission, and in conjunction with its adaptive load controller one can seek answers to questions like \u201Cwhat RPS can my mesh reliably sustain under set latency?\u201D."), mdx("h4", null, "Comparing Types of Data Plane Filtering"), mdx("p", null, "Important to note is the power of the service mesh data plane and cost of that power. Envoy is a popular proxy of choice for service mesh data planes. Among other features, Envoy provides the ability to integrate custom traffic filters via one of two methods:"), mdx("ol", null, mdx("li", null, "Natively by incorporating your custom traffic filter into Envoy\u2019s C++ source code and compiling a new Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit being that of your custom filter running at native speed."), mdx("li", null, "Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically load and reload WASM-based filters in Envoy at runtime.")), mdx("p", null, "Whether to  integrate your traffic filters natively or as an extension, a tradeoff between the two deployment exists primarily in exchanging between service mesh speed and service mesh flexibility as shown in ", mdx("i", null, "Figure 4.")), mdx("div", {
    className: "center"
  }, mdx("a", {
    href: NetworkFunction
  }, mdx("img", {
    src: NetworkFunction,
    align: "center",
    alt: "comparison of Network functions"
  }))), mdx("p", null, mdx("i", null, "Figure 5 - A comparison of different modes of delivery of service mesh network functions.")), mdx("p", null, "As an assessment of this tradeoff, an analysis of a series of three tests run across the same rate limit network function implemented as 1) a Golang-based client library, or 2) a Rust-based Envoy filter running in a WebAssembly virtual machine  (or 3) a native Envoy filter) provides some insight as to the comparative overhead involved."), mdx("ol", null, mdx("li", null, "Rate limiting with Go client library", mdx("ul", null, mdx("li", null, "At 100 RPS the p50 is 3.19ms."), mdx("li", null, "At 500 RPS the p50 is 2.44ms."), mdx("li", null, "With unlimited RPS (4,417) the p50 is 0.066ms."))), mdx("li", null, "Rate limiting with WASM module (Rust filter)", mdx("ul", null, mdx("li", null, "At 100 RPS the p50 is 2.1ms"), mdx("li", null, "At 500 RPS the p50 is 2.22ms"), mdx("li", null, "With unlimited RPS (5,781) the p50 is 0.62ms")))), mdx("p", null, "Users not only need to account for the (relatively) easy to quantify system overhead and the operational overhead involved in expanding development resources to implement bespoke tooling versus managing off-the-shelf filters."), mdx("h3", null, "Summary"), mdx("p", null, "To deploy a service mesh effectively, we need to"), mdx("ol", null, mdx("li", null, "quantify application workload characteristics and how it utilizes a particular microarchitecture."), mdx("li", null, "assess how Container Network Interface (CNI) drivers, Open Virtual Switch (OVS), rules processing, match and lookup requirements between Network Address Translated (NAT) and routed networks are required"), mdx("li", null, " different layers of service mesh to be deployed including layer 4 load balancers, ingress and reverse proxy, number of sidecars and number of microservices to be supported"), mdx("li", null, "and what hardware baseline performance does the setup have and "), mdx("li", null, " a quantifiable measure of service mesh deployed with performance measures mapped to KPIs like throughput (RPS) and latency."))));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh-performance/analyzing-service-mesh-performance</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh-performance/analyzing-service-mesh-performance</guid><enclosure url="https://layer5.io/static/76fd2590061b4fc01a710ba21d61b901/smp-light-text_2.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about Service Mesh Performance from this article&lt;a class=&quot;blog&quot; href=&quot;https://www.nxtbook.com/nxtbooks/ieee/bridge_issue3_2021/index.php#/p/16&quot;&gt; Analyzing Service Mesh Performance&lt;/a&gt; - Published in issue 3 of IEEE Bridge October 2021&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/ieee_bridge_issue3_2021-8c3419112f1cce7d7d1955ee37b55a70.jpg&quot; align=&quot;center&quot; alt=&quot;IEEE The Bridge 2021 Issue 3 cover&quot;/&gt;&lt;/div&gt;&lt;p&gt;As a forthcoming, ubiquitous layer of cloud native infrastructure, service meshes offer deep and uniform control and visibility into the topology and state of ephemeral microservices. Managing the myriad configurations of cloud native infrastructure is greatly facilitated by a service mesh, but succinctly summarizing and characterizing the performance of your service mesh in context of your unique workloads and your infrastructure of choice is a challenge unto its own.&lt;/p&gt;&lt;p&gt;We explore how to model your service mesh topology and optimize for your ideal configuration in context of how much you value properties of resiliency, performance, throughput, latency, and so on before you deploy to production. Readers will understand how distributed performance analysis offers unique insights on the behavior of microservices and their efficiency of operation, see examples of how common types of workloads perform under specific service mesh functions, and be empowered with analytical tooling that can be used to make optimized configurations.&lt;/p&gt;&lt;p&gt;We provide core, memory and I/O combinations based on workload needs with insights into workload analysis which can influence the efficiency of the service mesh and overall performance of the cluster.&lt;/p&gt;&lt;h2&gt;Characterizing the Complexity of Combinatorial Analysis&lt;/h2&gt;&lt;p&gt;Consider that the more value you try to derive from your service mesh, the more work that you will ask it to do. Said another way, that as someone reflects more deeply on the architecture of a service mesh - with its distributed proxies - and the functionality it offers, they will eventually wonder, &amp;quot;What overhead is running my service mesh incurring?&amp;quot;. This is one of the most common questions engineers have as they initially learn of a service mesh and the value a deployment of one offers. This is not an easy question to answer as the permutations of configuration between your infrastructure, service mesh, and applications are innumerable and any change to one of them affects their collective performance.&lt;/p&gt;&lt;p&gt;How would you describe the performance of your service mesh and that of your clusters and their workloads? Are you imagining a wall of line charts with metrics capturing golden signals? The act of articulating the performance of your service mesh can take anywhere from a minute to even a few hours to characterize the state of your systems and the overhead incurred by your infrastructure and what this means to your users.&lt;/p&gt;&lt;p&gt;Moreover, anytime performance is characterized, analysis is subjective to the specific workload, infrastructure, and instruments used for measurement. Given the variety of this measurement challenge, most service meshes and their data plane proxies (if a third-party component), do not have the tooling necessary or refuse to publish performance data because such tests can be:&lt;ol&gt;&lt;li&gt;arduous to create and sustain a capable harness&lt;/li&gt;&lt;li&gt;a point-in-time consideration (none of the elements under measurement are static&lt;/li&gt;&lt;li&gt;misinterpreted&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;p&gt;Read on as we identify how to surmount each of these challenges.&lt;/p&gt;&lt;h2&gt;Service Mesh Performance Considerations&lt;/h2&gt;&lt;p&gt;As the software defined networking layer of microservices, service mesh encompasses multiple aspects of critical functions of the applications, such as circuit breaking, health checks, and packet operations. Analyzing the permutations of these configurations is an impossible task without a suitable test harness. A service mesh management plane can be such a tool. As the multi-mesh manager, &lt;a href=&quot;https://meshery.io&quot;&gt;Meshery &lt;/a&gt;is capable of provisioning 10 different service meshes, workloads atop the meshes, generating load using &lt;a href=&quot;https://getnighthawk.dev&quot;&gt;Nighthawk&lt;/a&gt;, and analyzing that load. No other tool capable of performing these tasks end-to-end exists. Meshery is a Cloud Native Computing Foundation project originally created by Layer5.&lt;/p&gt;&lt;h3&gt;How are you measuring?&lt;/h3&gt;&lt;p&gt;Consider the simple set of steps to execute performance tests in a simple Kubernetes-based cluster:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Setup your cluster, service mesh, and application under test.&lt;/li&gt;&lt;li&gt;Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.&lt;/li&gt;&lt;li&gt;Configure your test setup for performance, doing so in context of other constraints that you might need to uphold (e.g. resiliency characteristics of your service deployment).&lt;/li&gt;&lt;li&gt;Choose the protocol of interest: HTTP, HTTPS, HTTP1/2, gRPC, NATS&lt;/li&gt;&lt;li&gt;Identify KPIs of interest - Transactions per second (TPS) or percentile latencies, etc.&lt;/li&gt;&lt;li&gt;Decide on the test duration: 60s or 5 minutes or 1 hour...&lt;/li&gt;&lt;li&gt;Choose the number of requests per second (RPS).&lt;/li&gt;&lt;li&gt;Execute the test.&lt;/li&gt;&lt;li&gt;Mark down requests per second, latencies, throughput, and any other output provided by benchmarking tools.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;What are you measuring?&lt;/h3&gt;&lt;p&gt;Performance of a service mesh can be described across multiple dimensions covering some or all of these core functionalities of a service mesh. So, which dimensions are the linchpins of performance? Which metrics are key indicators of performance? Outside of the different types of performance tests, performance management concerns include the need for performance and overhead data under a permutation of different workloads (applications) and different types and sizes of infrastructure resources.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;a href=&quot;static/figure-1-2e917eeefb309ad5b67cdb79d82d5faf.png&quot;&gt;&lt;img src=&quot;static/figure-1-2e917eeefb309ad5b67cdb79d82d5faf.png&quot; align=&quot;center&quot; alt=&quot;EWtraffic&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;Hence, it is crucial to understand what is being measured in a service mesh based deployment. Certain critical considerations are missing from the simple methodology previously described. For example, as indicated in Figure 1, but not limited to:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Traffic considerations&lt;ul&gt;&lt;li&gt;East-West traffic&lt;ol&gt;&lt;li&gt;between two pods within the same or two different Virtual Machines (VM).&lt;/li&gt;&lt;li&gt;between two pods within the same or two different bare metal nodes.&lt;/li&gt;&lt;li&gt;combination of above with choice of user-space or kernel-space networking stack on the host node.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;North-South traffic&lt;ol&gt;&lt;li&gt;Throughput and latency of traffic flowing in and out of a single VM or across a single bare metal node.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Deployment considerations&lt;ul&gt;&lt;li&gt;Number of hops between traffic source and traffic destination with load balancers, API gateways, ingress controllers, security components such as firewall, deep packet inspectors, and so on.&lt;/li&gt;&lt;li&gt;Operating system settings.&lt;/li&gt;&lt;li&gt;Hardware settings such as BIOS options, power management features, NUMA awareness, platform resource management, hardware accelerators, and so on.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Load generators types&lt;ul&gt;&lt;li&gt;hardware or software based, L2-3,  L4-7, open or closed loop&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Service mesh types - the service mesh landscape has over 20 meshes listed. Each share a common architecture, however, their implementation differs and consequently, so does their performance.&lt;ul&gt;&lt;li&gt;Control plane - often a point of contention the larger the service mesh deployment is.&lt;/li&gt;&lt;li&gt;Data plane - not only proxies, but filters loaded in those proxies.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Service mesh configuration and number of services on the mesh. To name a few considerations:&lt;ul&gt;&lt;li&gt;Telemetry&lt;ol&gt;&lt;li&gt;Including the three pillars of observability are traces, logs, and metrics.&lt;/li&gt;&lt;li&gt;The number of, cardinality of, sampling rate, ingest rate… all bear weight (and bear load on the system).&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Policy&lt;ol&gt;&lt;li&gt;Authentication, Authorization - frequency of checks, cache hits vs. cache misses.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Security&lt;ol&gt;&lt;li&gt;Encryption - overhead of handshaking and mutually authenticated TLS.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Ultimately, the goal of any performance tests is to ensure repeatable measurements and obtain consistent results across multiple test runs.&lt;/p&gt;&lt;h2&gt;Service Mesh Performance as a Specification&lt;/h2&gt;&lt;p&gt;The need for cross-project, apple-to-apple comparisons are also desired in order to facilitate a comparison of behavioral differences between service meshes and which one might be best-suited for specific workloads. Individual service mesh projects shy from publishing test results of other, competing service mesh projects. The need for an independent, unbiased, credible, standard measurement is one of the catalysts for the creation of Service Mesh Performance (SMP).&lt;/p&gt;&lt;p&gt;Amidst performance concerns and the need to measure and manage performance arose the Service Mesh Performance (SMP) standard. Service Mesh Performance as a specification and disseminating insights and research results. Your authors are working toward the definition of MeshMark, a universal performance index to gauge your mesh’s efficiency against deployments in other organizations’ environments.&lt;/p&gt;&lt;p&gt;Many performance benchmarks are limited to single instance load generation (single pod load generator). This limits the amount of traffic that can be generated to the output of the single machine that the benchmark tool runs on in or out of a cluster. Overcoming this limitation would allow for more flexible and robust testing. Distributed load testing in parallel poses a challenge when merging results without losing the precision we need to gain insight into the high tail percentiles. Distributed load testing offers insight into system behaviours that arguably more accurately represent real-world behaviours of services under load as that load comes from any number of sources.&lt;/p&gt;&lt;p&gt;The specification itself provides a standard format for describing and capturing:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;performance test configuration&lt;/li&gt;&lt;li&gt;Pick a benchmarking tool that can measure Layer 4 or Layer 7 performance.&lt;/li&gt;&lt;li&gt;service mesh configuration&lt;/li&gt;&lt;li&gt;environment configuration&lt;/li&gt;&lt;li&gt;workload configuration&lt;/li&gt;&lt;li&gt;performance test results&lt;/li&gt;&lt;li&gt;Distributed performance modeling&lt;/li&gt;&lt;li&gt;KPIs for service mesh performance&lt;/li&gt;&lt;li&gt;Test tool requirements&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Value from a service mesh is best derived when it&amp;#x27;s tuned to scale as per the deployment requirements. Given the complexity of deploying, testing and measuring performance aspects across multiple dimensions, the specification aims to provide a simple starting point for anyone looking to understand and derive service mesh performance. The service mesh performance standard aims to articulate these complexities in a methodical and automated manner in order for anyone to plan the performance scenarios of their deployment and execute relevant tests.&lt;/p&gt;&lt;p&gt;The code snippet provides insight on the fact that the specification defines a common collection of statistical analysis to be calculated for every performance test.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 eJDaax&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 dmwFhm&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 eJDaax prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;message PerformanceTestResult &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  message Latency &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double min = 1;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double average = 2;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double p50 = 3;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double p90 = 4;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double p99 = 5;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    double max = 6;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;}&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;&lt;i&gt;Snippet of the Service Mesh Performance specification describing how to capture statistical analysis of test results.&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;Defining Deployments&lt;/h2&gt;&lt;p&gt;Virtualized deployments involve deploying microservice orchestration and service mesh stack in virtual machines (VMs). Although bare metal usage has performance benefits, customers often use VMs to provide hardware-level isolation between various applications. This deployment involves two VMs across two nodes, with one acting as a Kubernetes master with the other a worker node. Customers deploy VMs on a single NUMA node to avoid cross UPI traffic. Results in virtualized testing have shown that depending on pinning of QEMU threads to a set of isolated cores - either sequentially or clustering the threads together to all the cores - tail latencies are heavily impacted.&lt;/p&gt;&lt;p&gt;Microservice deployments could use a wide variety of deployment scenarios. The following list provides a sample set of how a service mesh performance could be analyzed either on a same node or in a multi-node cluster:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pod to pod communication.&lt;/li&gt;&lt;li&gt;Pod to service communication.&lt;/li&gt;&lt;li&gt;Ingress controller to pod and vice-versa.&lt;/li&gt;&lt;li&gt;Load balancer to pod and vice-versa.&lt;/li&gt;&lt;li&gt;Pod to Egress Gateway.&lt;/li&gt;&lt;li&gt;Mutual TLS termination across any of the above endpoints.&lt;/li&gt;&lt;li&gt;Different security rules and policies.&lt;/li&gt;&lt;li&gt;Communication protocol.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These considerations are illustrated in a typical workload deployment as shown in &lt;i&gt;Figure 3.&lt;/i&gt;&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;a href=&quot;static/figure-2-56880ed83f94d4c64e6163163859a6ea.png&quot;&gt;&lt;img src=&quot;static/figure-2-56880ed83f94d4c64e6163163859a6ea.png&quot; align=&quot;center&quot; alt=&quot;Workload&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;Here is an example of deployment with Kubernetes as the orchestrator using Calico CNI and deployed in VMs, while the host infrastructure has OVS-DPDK for switching, which can be extended for VMs to leverage SR-IOV. To understand impact of infrastructure elements and networking elements of microservice software stack, performance impact of a service mesh and its set of data plane proxies with fortio as load generator could be understood by running the Meshery in two different environments outside the Kubernetes cluster.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;First one with load generator running as a process outside of Kubernetes cluster in master-vm&lt;/li&gt;&lt;li&gt;Second one with load generator running as a bare metal process on master-host&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Automating Performance Measurements&lt;/h3&gt;&lt;p&gt;Meshery is ideal tooling in that it provides lifecycle management of a large number of service meshes and sample applications which need to be provisioned, configured, and deprovisioned in the process of analyzing service mesh performance. Meshery is capable of generating load, baselining, and comparing performance results. The canonical implementation of this specification is implemented in Meshery.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;a href=&quot;static/Meshery Architecture - Clients-1bb8a8dd590218403e5f9c4ef02e80a3.png&quot;&gt;&lt;img src=&quot;static/Meshery Architecture - Clients-1bb8a8dd590218403e5f9c4ef02e80a3.png&quot; align=&quot;center&quot; alt=&quot;Archictures-client&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;Figure 4 - Meshery’s load generators can be deployed in the same cluster under test or outside of the cluster under test.&lt;/i&gt;&lt;/p&gt;&lt;h4&gt;Pipelining performance characterization&lt;/h4&gt;&lt;p&gt;Acknowledging the living nature of user deployments, integration of automated performance testing into continuous integration systems helps users deploy new versions of their applications or new configurations of their infrastructure (including service mesh configuration) with the assurity  afforded through the act of dry-running the service mesh and application configuration before production deployment. The Meshery and Service Mesh Performance GitHub Action offers the ability to adaptively analyze application performance as a gate in your continuous delivery pipeline. In this way, the Service Mesh Performance specification facilitates a measurement index that can be referenced when rolling out new versions of a service with this advanced canary technique.&lt;/p&gt;&lt;p&gt;Through Meshery, techniques to mirror non-idempotent requests without fear of impacting the current version of your application allowing replay of user requests. And use of intelligent network functions, embedded in WebAssembly (WASM) programs, to facilitate real user request reenactments to help you extract the most value out of your pipeline.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Repeatability of test scenarios using performance profiles and cloud native orchestration.&lt;/li&gt;&lt;li&gt;Baselining and comparing results.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Analyzing Performance Measurements&lt;/h3&gt;&lt;p&gt;We have often seen inefficiencies in the ratio of resource usage vs resources applied. Since the mesh elements i.e. the ingress and sidecars share resources with one or more of the application containers, there may be more resources left to be utilized. Tail latencies decrease with the increase in number of cores for all 1, 10 and 100 clones but increase with the increase in the number of connections. Data for various connection counts, as shown, indicates that performance degradation with Istio shows up with input RPS more than 1000. In a top down microarchitectural analysis (TMA), when the front proxy is pinned to a single core and the sidecar + flask app is pinned to another core and the number of microservices are scaled up. It is observed that (Figure 2):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Frontend Bound% decreases with increase in number of microservices​ and Core Bound % increases.&lt;/li&gt;&lt;li&gt;Memory Bound % increases with increase in the number of microservices​.&lt;/li&gt;&lt;li&gt;L1 and L3 Bound% decreases for both the service cores on which the front –proxy is running as well as the core where the sidecar+flask app is running with number of microservices.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In customer environments, the size of the cluster as well as the amount of incoming traffic will have an impact on the number of workloads and Envoy microservices. The underlying hardware and L4 networking on each node in the cluster will also impact the performance observed. A call stack and cycles spent analysis of a deployment with 1-20 sidecars on a specific 40 core system with a 10G NIC shows bottlenecks spread between:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Envoy:TheadLocalStorage-Hashset-Match&lt;/li&gt;&lt;li&gt;Linux kernel bottleneck spread between&lt;ol&gt;&lt;li&gt;Libpthreadscheduling&lt;/li&gt;&lt;li&gt;Libevent&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Envoy buffer slice management and TCP filter, if message sizes or file transfer sizes increase to 1M&lt;/li&gt;&lt;li&gt;Crypto operations when TLS is enabled.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Our initial studies show that the optimal service mesh setup for the tolerable latencies and the best RPS may include:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Exclusive  threads allocated to Envoy processing&lt;/li&gt;&lt;li&gt;Reduced memory contention by allocating more memory bandwidth which can be controlled dynamically&lt;/li&gt;&lt;li&gt;Load balancing of worker threads among the among cores which may require&lt;/li&gt;&lt;li&gt;Less IO switching&lt;/li&gt;&lt;li&gt;Optimized memory copies with signals incorporated in addition to events (libevent)&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;Accelerations and Offloads&lt;/h4&gt;&lt;p&gt;A number of accelerations and offloads to SMART NIC or other processing elements like IPUs and DPUs are becoming available. How does the service mesh efficiency and performance benefitted from these deployment options needs to be defined and measured. Cycles and cores saved in the host cores vs offload cores which may be of different architectures and/or performance range needs to be quantified and benchmarks and indices created to measure.&lt;/p&gt;&lt;h3&gt;Being Precise in Performance Studies&lt;/h3&gt;&lt;p&gt;When measuring sub-millisecond response times, the noise floor of the environment as well as the sensitivity of the tooling may become dominant factors in measurements. Noisy neighbours, scheduler fairness, garbage collection, and even specifics in the timing of requests being sent as well as connection-reuse patterns may change noise floors such that similar measurements performed using different systems and tools may diverge an order of magnitude in absolute terms.&lt;/p&gt;&lt;p&gt;As a quick survey of load generators by way of those included in Meshery, we find upon close inspection their differences are noteworthy and justify their use under different circumstances.&lt;/p&gt;&lt;p&gt;Written in C, wrk2 supports ignoring coordinated omission. wrk2 lets you test a little more complex scenarios. Users express load generation profiles in terms of RPS. wrk2 shows you what you normally may not see in benchmark results, but what every 1,000th user might see. To see these outliers, you need to run the longer (time) performance tests.  Wrk2 tests the scenario where there&amp;#x27;s a string of services comprising microservices. wrk2 requires you to specify the desired RPS, while wrk does not. Wrk2 is focused on driving the maximum RPS. Meshery’s fork of wrk2 enables testing of multiple endpoints and enables the variable rate of load generation. In the future, Meshery will offer the ability to assign a weight to each endpoint for the load to be generated by wrk2.&lt;/p&gt;&lt;p&gt;Written in Golang, fortio is extremely fast and usable for testing basic response times on a per request level. Fortio produces results in JSON on a per request basis and easy to integrate into other Golang-based tooling like Meshery.&lt;/p&gt;&lt;p&gt;Written in C++, Nighthawk supports both open- and closed- loop testing, and was designed to offer the right sensitivity for benchmarking microservice proxies (sub millisecond latencies). Using an open loop test methodology avoids coordinated omission, and in conjunction with its adaptive load controller one can seek answers to questions like “what RPS can my mesh reliably sustain under set latency?”.&lt;/p&gt;&lt;h4&gt;Comparing Types of Data Plane Filtering&lt;/h4&gt;&lt;p&gt;Important to note is the power of the service mesh data plane and cost of that power. Envoy is a popular proxy of choice for service mesh data planes. Among other features, Envoy provides the ability to integrate custom traffic filters via one of two methods:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Natively by incorporating your custom traffic filter into Envoy’s C++ source code and compiling a new Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit being that of your custom filter running at native speed.&lt;/li&gt;&lt;li&gt;Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically load and reload WASM-based filters in Envoy at runtime.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Whether to  integrate your traffic filters natively or as an extension, a tradeoff between the two deployment exists primarily in exchanging between service mesh speed and service mesh flexibility as shown in &lt;i&gt;Figure 4.&lt;/i&gt;&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;a href=&quot;static/Comparison of different modes of delivery of service mesh network functions-35336a794ba87248f68ea66ffd850253.png&quot;&gt;&lt;img src=&quot;static/Comparison of different modes of delivery of service mesh network functions-35336a794ba87248f68ea66ffd850253.png&quot; align=&quot;center&quot; alt=&quot;comparison of Network functions&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;Figure 5 - A comparison of different modes of delivery of service mesh network functions.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;As an assessment of this tradeoff, an analysis of a series of three tests run across the same rate limit network function implemented as 1) a Golang-based client library, or 2) a Rust-based Envoy filter running in a WebAssembly virtual machine  (or 3) a native Envoy filter) provides some insight as to the comparative overhead involved.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Rate limiting with Go client library&lt;ul&gt;&lt;li&gt;At 100 RPS the p50 is 3.19ms.&lt;/li&gt;&lt;li&gt;At 500 RPS the p50 is 2.44ms.&lt;/li&gt;&lt;li&gt;With unlimited RPS (4,417) the p50 is 0.066ms.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Rate limiting with WASM module (Rust filter)&lt;ul&gt;&lt;li&gt;At 100 RPS the p50 is 2.1ms&lt;/li&gt;&lt;li&gt;At 500 RPS the p50 is 2.22ms&lt;/li&gt;&lt;li&gt;With unlimited RPS (5,781) the p50 is 0.62ms&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Users not only need to account for the (relatively) easy to quantify system overhead and the operational overhead involved in expanding development resources to implement bespoke tooling versus managing off-the-shelf filters.&lt;/p&gt;&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;To deploy a service mesh effectively, we need to&lt;/p&gt;&lt;ol&gt;&lt;li&gt;quantify application workload characteristics and how it utilizes a particular microarchitecture.&lt;/li&gt;&lt;li&gt;assess how Container Network Interface (CNI) drivers, Open Virtual Switch (OVS), rules processing, match and lookup requirements between Network Address Translated (NAT) and routed networks are required&lt;/li&gt;&lt;li&gt; different layers of service mesh to be deployed including layer 4 load balancers, ingress and reverse proxy, number of sidecars and number of microservices to be supported&lt;/li&gt;&lt;li&gt;and what hardware baseline performance does the setup have and &lt;/li&gt;&lt;li&gt; a quantifiable measure of service mesh deployed with performance measures mapped to KPIs like throughput (RPS) and latency.&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[API Gateways interplay with service meshes]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "API Gateways interplay with service meshes",
  "thumbnail": "../service-mesh.svg",
  "category": "Service Mesh",
  "tags": ["Service mesh"],
  "type": "Demo",
  "product": "Meshery",
  "technology": "Docker",
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, " The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("p", null, "API gateways come in a few forms:"), mdx("ul", null, mdx("li", null, "Traditional (e.g., Kong)"), mdx("li", null, "Cloud-hosted (e.g., Azure Load Balancer)"), mdx("li", null, "L7 proxy used as an API gateway and microservices API gateways (e.g., Traefik, NGINX, HAProxy, or Envoy)")), mdx("p", null, "L7 proxies used as API gateways generally can be represented by a collection of microservices-oriented, open source projects, which have taken the approach of wrapping existing L7 proxies with additional features needed for an API gateway."), mdx("h3", null, "NGINX"), mdx("p", null, "As a stable, efficient, ubiquitous L7 proxy, NGINX is commonly found at the core of API gateways. It may be used on its own or wrapped with additional features to facilitate container orchestrator native integration or additional self-service functionality for developers. Examples of this include:"), mdx("ul", null, mdx("li", null, "APIUmbrella"), mdx("li", null, "Kong"), mdx("li", null, "OpenResty")), mdx("h3", null, "Envoy"), mdx("p", null, "The Envoy project also has been used as the foundation for API gateways."), mdx("ul", null, mdx("li", null, "Ambassador: Based on Envoy, Ambassador is an API gateway for microservices functioning stand-alone or as a Kubernetes Ingress Controller. "), mdx("li", null, "Contour: Based on Envoy and deployed as a Kubernetes Ingress Controller. Hosted in the CNCF."), mdx("li", null, "Enroute: Envoy Route Controller. API Gateway created for Kubernetes ingress controller, and standalone deployments.")), mdx("p", null, "Other differences between traditional API gateways and microservices API gateways revolve around which team uses the gateway: operators or developers. Operators tend to measure API calls per consumer to meter and disallow API calls when a consumer exceeds its quota. Developers, on the other hand, tend to track L7 latency, throughput, and resilience, limiting API calls when the service is not responding."), mdx("p", null, "One of the most important distinctions to make when it comes to service meshes is that API gateways are designed to accept traffic from outside your organization/network and distribute it internally. API gateways expose your services as managed APIs, focused on transiting north/south traffic. They aren\u2019t as well suited for traffic management within the service mesh necessarily, because they require traffic to travel through a central proxy and add a network hop. Service meshes are primarily designed to handle east/west traffic internal to\xA0the service mesh."), mdx("div", {
    className: "fact-left"
  }, "Traffic Directions", mdx("p", null, "North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.")), mdx("p", null, "API gateways and service meshes are frequently deployed in combination due to\xA0\xA0their complementing nature. Service meshes are on their way to providing much, if not all, of the functionality that API gateways do."), mdx("h3", null, "API Management"), mdx("p", null, "API gateways work with other API management ecosystem components like API marketplaces and API publishing portals, both of which are surfacing in service mesh offerings. Analytics, business data, adjunct provider services like single sign-on, and API versioning control are all provided by API management solutions.  Many API management vendors have migrated their API management systems to a single point of architecture, with API gateways designed to be implemented at the edge."), mdx("p", null, "An API gateway can call downstream services via service mesh by offloading application network functions to the service mesh. Some API management capabilities that are oriented toward developer engagement can overlap with service mesh management planes in the following ways:"), mdx("ul", null, mdx("li", null, "Developers use a portal to discover APIs available for API documentation and discovery,  API testing, and exercising their code."), mdx("li", null, "API analytics for tracking KPIs, generating reports on usage and adoption trending."), mdx("li", null, "API lifecycle management to secure APIs (allocate keys) and promote or demote APIs."), mdx("li", null, "Monetization to tracking payment plans and enforcing quotas."))));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/api-gateways-interplay-with-service-meshes</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/api-gateways-interplay-with-service-meshes</guid><enclosure url="https://layer5.io/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt; The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;API gateways come in a few forms:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Traditional (e.g., Kong)&lt;/li&gt;&lt;li&gt;Cloud-hosted (e.g., Azure Load Balancer)&lt;/li&gt;&lt;li&gt;L7 proxy used as an API gateway and microservices API gateways (e.g., Traefik, NGINX, HAProxy, or Envoy)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;L7 proxies used as API gateways generally can be represented by a collection of microservices-oriented, open source projects, which have taken the approach of wrapping existing L7 proxies with additional features needed for an API gateway.&lt;/p&gt;&lt;h3&gt;NGINX&lt;/h3&gt;&lt;p&gt;As a stable, efficient, ubiquitous L7 proxy, NGINX is commonly found at the core of API gateways. It may be used on its own or wrapped with additional features to facilitate container orchestrator native integration or additional self-service functionality for developers. Examples of this include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;APIUmbrella&lt;/li&gt;&lt;li&gt;Kong&lt;/li&gt;&lt;li&gt;OpenResty&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Envoy&lt;/h3&gt;&lt;p&gt;The Envoy project also has been used as the foundation for API gateways.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Ambassador: Based on Envoy, Ambassador is an API gateway for microservices functioning stand-alone or as a Kubernetes Ingress Controller. &lt;/li&gt;&lt;li&gt;Contour: Based on Envoy and deployed as a Kubernetes Ingress Controller. Hosted in the CNCF.&lt;/li&gt;&lt;li&gt;Enroute: Envoy Route Controller. API Gateway created for Kubernetes ingress controller, and standalone deployments.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Other differences between traditional API gateways and microservices API gateways revolve around which team uses the gateway: operators or developers. Operators tend to measure API calls per consumer to meter and disallow API calls when a consumer exceeds its quota. Developers, on the other hand, tend to track L7 latency, throughput, and resilience, limiting API calls when the service is not responding.&lt;/p&gt;&lt;p&gt;One of the most important distinctions to make when it comes to service meshes is that API gateways are designed to accept traffic from outside your organization/network and distribute it internally. API gateways expose your services as managed APIs, focused on transiting north/south traffic. They aren’t as well suited for traffic management within the service mesh necessarily, because they require traffic to travel through a central proxy and add a network hop. Service meshes are primarily designed to handle east/west traffic internal to the service mesh.&lt;/p&gt;&lt;div class=&quot;fact-left&quot;&gt;Traffic Directions&lt;p&gt;North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;API gateways and service meshes are frequently deployed in combination due to  their complementing nature. Service meshes are on their way to providing much, if not all, of the functionality that API gateways do.&lt;/p&gt;&lt;h3&gt;API Management&lt;/h3&gt;&lt;p&gt;API gateways work with other API management ecosystem components like API marketplaces and API publishing portals, both of which are surfacing in service mesh offerings. Analytics, business data, adjunct provider services like single sign-on, and API versioning control are all provided by API management solutions.  Many API management vendors have migrated their API management systems to a single point of architecture, with API gateways designed to be implemented at the edge.&lt;/p&gt;&lt;p&gt;An API gateway can call downstream services via service mesh by offloading application network functions to the service mesh. Some API management capabilities that are oriented toward developer engagement can overlap with service mesh management planes in the following ways:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Developers use a portal to discover APIs available for API documentation and discovery,  API testing, and exercising their code.&lt;/li&gt;&lt;li&gt;API analytics for tracking KPIs, generating reports on usage and adoption trending.&lt;/li&gt;&lt;li&gt;API lifecycle management to secure APIs (allocate keys) and promote or demote APIs.&lt;/li&gt;&lt;li&gt;Monetization to tracking payment plans and enforcing quotas.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Choosing the Perfect Proxy]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Choosing the Perfect Proxy",
  "thumbnail": "../service-mesh.svg",
  "category": "Service Mesh",
  "tags": ["Proxy"],
  "type": "Article",
  "product": "Meshery",
  "technology": "Kubernetes",
  "mesh": "Istio",
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("p", null, "Historically, application delivery controllers were purchased, deployed, and managed by IT professionals most commonly to run enterprise-architected applications. With their distributed systems design and ephemeral infrastructure, cloud native applications require load balancers to be as dynamic as the infrastructure (containers, for example) upon which they run. These are often software load balancers. Because cloud native applications are typically developer-led initiatives in which developers are creating the application \u2014 that is, the microservices \u2014 and the infrastructure, developers and platform teams are increasingly making, or heavily influencing, decisions for load balancing (and other) infrastructure."), mdx("p", null, "Selecting your proxy is one of the most important decision your team will make. A developer\u2019s selection process gives heavier weight to a proxy\u2019s APIs (due to their ability to programmatically configure the proxy) and on a proxy\u2019s cloud native integrations (as previously noted). A top item on the list of demands for proxies is protocol support. Generally, protocol considerations can be broken into two types:"), mdx("ul", null, mdx("li", null, "TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing."), mdx("li", null, "gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.")), mdx("div", {
    className: "intro"
  }, mdx("h3", {
    align: "center"
  }, "Tip: HTTP2, gRPC, NATS"), mdx("p", null, "At the heart of many distributed systems architectures are streaming and messaging protocols. When your applications need higher performance than JSON-REST, the application architecture commonly includes use of gRPC or NATS. REST is often found on the perimeter of the services while gRPC is used for service-to-service interactions. gRPC is a universal RPC framework. NATS is a multi-modal messaging system that includes request/reply, pub/sub and load balanced queues.")), mdx("p", null, "The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:"), mdx("ul", null, mdx("li", null, "High performance and low latency"), mdx("li", null, "High scalability and small memory footprint"), mdx("li", null, "Deep observability at all layers of the network stack"), mdx("li", null, "Programmatic configuration and ecosystem integration")), mdx("p", null, "With a Kubernetes-native control plane, using CRDs and associated controllers enables powerful simplification, easy scaling, and intent-driven infrastructure. It is critical that the proxy has the capability to be intent-driven using Kubernetes CRDs and controllers (preferably an open source proxy like the Citrix Ingress Controller It\u2019s the robustness of a proxy\u2019s cloud native integrations and configuration APIs, like the Citrix Nitro API, that enables this. Not only are the proxy\u2019s configuration APIs a key consideration, but so is the method by which they handle your applications\u2019 APIs, specifically their security."), mdx("h3", null, "TCP/UDP Support"), mdx("p", null, "There are many applications that communicate over TCP/UDP ports. Kubernetes ingress was developed with web traffic in mind. It provides a standard way to control and route HTTP/S traffic into the cluster. However, ingress mechanisms for non-HTTP traffic are inconsistent and can be challenging."), mdx("p", null, "Typical methods are:"), mdx("ul", null, mdx("p", null, "Service.Type = Nodeport Nodeports use non-standard ports and are awkward and complex to get into production."), mdx("p", null, "Service.Type = LoadBalancer Typically offered only in public clouds, LoadBalancers could get expensive depending on the number of services used."), mdx("p", null, "Citrix offers Service.type = Loadbalancer with a built-in IP address manager that is  consistent across clouds and on-premises deployments. This implementation simplifies IP address management and can save on load balancer costs in public clouds. An alternate method, also supported by Citrix, is to use ingress annotations that expose TCP/UDP ports. ")), mdx("p", null, "All three methods make it much easier for TCP/UDP applications to be used as microservices without extensive code rewrites or protocol changes."), mdx("h2", null, "Securing Your Applications and APIs"), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Api,
    align: "center",
    alt: "API security considerations by traffic direction."
  }), mdx("p", null, "API security considerations by traffic direction.")), mdx("p", null, "While traffic direction will dictate your security needs, the reality is that several concerns are shared considerations for both north-south and east-west traffic."), mdx("p", null, "Let\u2019s walk through the API security requirements one by one:"), mdx("h3", null, "Ingress Security (North-South) "), mdx("p", null, "As services are exposed outside the cluster, the security considerations remain similar to those of monolithic deployments. In addition to ensuring protections like IP blacklist/whitelist and a robust encryption profile (SSL/TLS), it is imperative that the services are protected against both layer 3-4 and layer 7 DDoS."), mdx("p", null, "Authentication/authorization are equally critical to ensure that the right access controls are established and maintained on data, APIs, and services. At the same time, as attacks are moving to the application layer, web application firewall (WAF) protections like SQL injection (SQLi), buffer overflow, and signature protections are table stakes. As the types of attacks are continuously evolving and because applications and APIs are changing many times a month, it is also critical that the protection mechanisms include behavior-based methods to automate the protection policies and detect potential zero-day attacks."), mdx("h3", null, "API Gateway and Security (North-South)"), mdx("p", null, "APIs are becoming the currency for digital transformation and for microservices that provide services via API, and therefore routing, security, control, and visibility for APIs is critical. API gateways are a perfect function to achieve these capabilities and typically are combined with the ingress solution."), mdx("p", null, "API gateway solutions offer key functions like authentication, authorization, rate limiting, policy-based routing of APIs, and API versioning. In addition, the traditional controls applicable to a N-S web service are equally applicable and even more important to apply to APIs. API security is not just about authentication but also about ensuring that the content coming in from authenticated sources is not malicious. API gateway functions typically get configured in ingress through configmaps or CRDs."), mdx("h3", null, "Intra-Cluster Security for Service Mesh or Service Mesh-Lite (East-West)"), mdx("p", null, "Secure application deployment and secure infrastructure best practices dictate security controls in terms of both N-S and E-W service traffic (the former is generally more intuitively understood) because one layer of security isn\u2019t enough, and in-depth defense is needed."), mdx("p", null, "As the number and variety of your microservices expand, the pattern we\u2019ve seen is that services might start as internal use only, but over time end up being exposed externally to customers and partners. The gooey center of your cluster, where you initially intend to have most of your service-to-service interactions, needs to be as secure because service-to-service interactions expand to those outside the cluster. Service meshes are a natural solution here. To obtain this added layer of security (and many other benefits), the adoption of service meshes is on the rise, dramatically. When your application delivery controller integrates with a service mesh, API security is broadly upleveled and guaranteed up to a certain point irrespective of developers' rigor in incorporating secure coding practices. That\u2019s because a service mesh runs as a layer of your infrastructure, relieving developers of a number of (but not all) identity, authentication, and authorization concerns."), mdx("p", null, "For example, inter-services communication should be mutually authenticated via transport layer security (TLS) so that only permitted API connections are allowed. Previously, this may have been implemented with each individual service, but the service mesh enables this functionality to be offloaded to a sidecar ADC, like Citrix CPX, and managed by the service mesh control plane."), mdx("p", null, "Similarly, it should be possible to ensure a faster and more consistent approach to SSL policy in microservices environments through the use of SSL profiles. By defining acceptable SSL settings (for example, ciphers, protocol, and key strength) and binding them to your different entities, developers can quickly deploy consistent encryption policies that meet the appropriate security requirements. After all, isn\u2019t the goal here to facilitate both developer velocity while ensuring that necessary security practices are met?"), mdx("p", null, "Another rapidly emerging technology to enable developer velocity is serverless computing. While serverless does indeed involve servers, it leverages infrastructure as code to run backend services as needed, which frees the developer from having to worry about scaling, patching, security, and infrastructure reliability. API gateways are key to applications built with serverless because the developer can simply specify policy such as authentication, authorization, and rate limits without worrying about the form factor, performance, and reliability of the proxy that usually provides these features."), mdx("p", null, "Next, let\u2019s explore aspects of another benefit use of a service mesh provides: traffic control."), mdx("h2", null, "Enabling CI/CD and Canary Deployment with Advanced Traffic Steering"), mdx("p", null, "Your application delivery solution should be an enabler of continuous delivery and canary deployments by providing advanced traffic steering. Intelligent proxies are required here. If you\u2019re using a control plane (and not configuring the proxies directly), understand that you will only be able to harness the full power of your proxies to the extent that the control plane exposes their capabilities for configuration."), mdx("h3", null, "Canary Deployment  "), mdx("p", null, "In order to facilitate canary deployments, you need a powerful proxy. Kubernetes facilitates rolling updates to a service deployment, focusing on ensuring that traffic shifting from one version of a service to the next happens gradually over time and with zero downtime. However, Kubernetes on its own doesn\u2019t offer the level of granular control over traffic necessary for simply exposing your canary to a subset of users that you identify. Nor is it convenient for error rate and performance monitoring. Although performance monitoring is integral for canary analysis, many times the solutions for automated canary analysis are cobbled together."), mdx("p", null, "A canary deployment is manual in that you will need to manually check that the canary behaves as you want before doing a full deployment (caution: the difference between canary and baseline isn't always clear). Robust application delivery solutions support ", mdx("b", null, "automated canary analysis"), " and progressive rollout. With an automated canary analysis, not only are you able to avoid manual administration of the deployment, but you can also rely on an automated statistical analysis to better detect problems in the set of metrics you\u2019ve identified as indicators of a healthy deployment."), mdx("p", null, mdx("b", null, "A/B testing"), " requires full control over traffic distribution with several versions of your service running in parallel as you run various experimental tests. Experimentations often include measuring differences in conversion rates between versions of a service with the aim of improving a given business metric. To facilitate these experiments, you might want to direct requests based on various criteria like a client\u2019s browser type and version or a user segment based on the presence of a specific cookie or the effect of UI changes on user behavior and the impact on overall performance."), mdx("p", null, mdx("b", null, "Chaos engineering"), " is akin to A/B testing in that it is an emergent practice that facilitates experimentation. Experimentation here is for purposes of testing and improving application delivery resiliency. Chaos engineering will evolve and expand in use as the complexity and rate of change of large-scale distributed systems demand new tools and techniques for increasing reliability and resiliency. Service-oriented teams (as opposed to infrastructure-oriented platform teams) will push past chaos engineering tools such as Chaos Monkey for inducing machine failures and skip Chaos Kong for evacuating entire regions. Instead they will move to application delivery solutions to perform precise service-level experiments on their path to improving application resiliency via orchestrated chaos. It's through exploration of the impact of increased latency and methodical failure of specific services that service teams will gain confidence in their systems\u2019 capabilities to withstand turbulent conditions in production and begin to sleep more soundly at night."), mdx("p", null, "Savvy cloud native engineers understand the nuances of these delivery methods, and the key role that the proxy plays in enabling these methods. Note, however, that the need for these methods is not restricted to cloud native workloads. These application delivery solution considerations generally apply to microservices and monolithic services in that irrespective of a given service\u2019s architecture, new versions of the service need to be deployed and managed. Because we live in a hybrid world, we encourage you to seek application delivery solutions that do, too."), mdx("h2", null, "Achieving Holistic Observability "), mdx("p", null, "Observability is crucial for effective troubleshooting of microservices environments, but the ephemeral nature and complexity of distributed architecture presents serious challenges. It's incredibly hard to maintain awareness of what's happening in your environment when containers are continuously created and destroyed. Continuous deployment adds to the transient nature of containers because DevOps teams often push many new deployments per day to update their applications."), mdx("p", null, "Similarly, the number of things to monitor \u2014 services, containers, users \u2014 is enormous, and the fact that everything is distributed makes microservices an incredibly complex environment. While it\u2019s easy to determine if a service is down, troubleshooting slow applications is not? How can you isolate problems among all of the vast telemetry data to find the root cause, especially with inter-microservices (E-W) traffic?"), mdx("p", null, "You cannot monitor what you can't see. This is why it is vitally important to have inspection points through which the traffic passes. When they are correctly positioned, proxies/ADCs collect telemetry for an unprecedented view of application traffic \u2014 both N-S and E-W traffic across both monolithic and microservices architectures \u2014 and they report important data to collection tools."), mdx("p", null, "To overcome the challenge of gaining observability into microservices, you need to build an observability stack. The stack should consist of four pillars: logging, metrics, tracing, and service graphs. However, these should not be viewed as individual, disjointed components but rather as a holistic observability stack that is integrated and can combine data as required."), mdx("strong", null, "Logs"), mdx("p", null, "Logs are an immutable record of an individual event at a particular time. They are designed into systems, and there tends to be a log record to accompany almost every action. While logs are highly granular, they are limited in their searchability, and it is not usually feasible to process them manually. ADC feeds log data into tools like Elasticsearch for processing and indexing and Kibana for data visualization."), mdx("strong", null, "Metrics"), mdx("p", null, "Metrics are data points that are measured over time that can be used to monitor trends and set alerts. In addition to the system resources of your individual proxies, the unique position of the proxies means that it sees important information about the use of the application - number of requests, HTTP request rate, errors and more. These metrics can be exported by ADCs to tools like Prometheus where they can be processed and tools like Grafana can visualize them, set alarms create heat maps to help you understand the status of your ADCs."), mdx("strong", null, "Traces"), mdx("p", null, "The flow of packets through a microservices-based application can be complex spanning multiple services (sometimes multiple times) so identifying why a service is slow can be difficult. Distributed Tracing is a technique that monitors request flow through microservices to build a map of the latency through each microservice hop. Trace is an end-to-end latency graph of a specific request. It represents the entire journey of a request and helps troubleshoot latency issues. Distributed tracing can also be used to understand the application architecture and services not being used. ADC integrates with open source tools like OpenTracing and Zipkin for distributed tracing"), mdx("strong", null, "Service Graphs"), mdx("p", null, "Service graphs are dynamic graphical representations of microservices and their interdependencies. Service graphs, like that of the service graph in the Citrix Application Delivery Manager (ADM) console, provide detail on connectivity among microservices, help you identify issues via simple color coding, and learn composite health scores for each microservice based on throughput, saturation, errors, and latency. More than this, Citrix service graphs also have a built in DVR-like function, which allows you to zero in on the specific time period when an issue occurred."), mdx("p", null, "Given their distillment of complex microservices into a graphical form, service graphs need to provide the ability to tag microservices and to use tags to search, sort , and filter. In this way, you can create custom service graph views of microservices running in production only or you can restrict your view to see details just for canary microservices."), mdx("p", null, "As a complement to the basic pillars of observability (logs, metrics, and traces), service graphs enhance your observability stack. They provide a holistic view of your microservices-based application environments in a single place for an intuitive and convenient way to gain insight and troubleshoot microservices environments faster."), mdx("h2", null, "Managing Monoliths and Microservices"), mdx("p", null, "With hybrid cloud now a reality for many organizations, managing multiple environments with divergent capabilities and management systems is also a reality. Operating with confidence requires reconciling these differences into a uniform operational model and, subsequently, into a uniform understanding with consistent (read: quality) control. For operational consistency, you need a single pane of glass to manage your application delivery infrastructure across:"), mdx("ul", null, mdx("li", null, "Any application: monolithic and microservices-based applications"), mdx("li", null, "Any environment: on-premises, public, private, and hybrid "), mdx("li", null, "Any ADC form factor: physical, virtual, cloud, containers, sidecars, and more")), mdx("p", null, "You need holistic control and monitoring for operational consistency across all your workloads (new microservices and existing monoliths). Ideally, you\u2019ll get such consistency from the proxy you\u2019ve put in place. As you select your proxy, exercise caution when piecing together components from disparate vendors/projects into a solution, because this will not only require integration effort, but also separate specialization to understand and operate. The overhead of integration and specialization can be avoided when your proxy portfolio is robust and supports any application, any environment and form factor with operatonal consistancy."), mdx("p", null, "Moreover, as the large public cloud providers extend their reach on-premises with offerings like Google Anthos, AWS Outposts, and Azure Stack, and as organizations adopt them as simpler paths to cloud migration, it becomes important to use a proxy that works in multiple environments. A battle-tested solution like Citrix ADC that is validated to work in Google Anthos and AWS Outposts environments both in the cloud and on-premises can be invaluable for maintaining operational consistency across your hybrid multi-cloud environment. Because Citrix ADC comes in a variety of form factors (including hardware, software, bare metal, cloud, containers, sidecars, and more) that are built on a single code base, it works across your hybrid workloads in a uniform fashion and prevents a sprawl of heterogenous load balancers across your environment.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/choosing-the-perfect-proxy</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/choosing-the-perfect-proxy</guid><enclosure url="https://layer5.io/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;Historically, application delivery controllers were purchased, deployed, and managed by IT professionals most commonly to run enterprise-architected applications. With their distributed systems design and ephemeral infrastructure, cloud native applications require load balancers to be as dynamic as the infrastructure (containers, for example) upon which they run. These are often software load balancers. Because cloud native applications are typically developer-led initiatives in which developers are creating the application — that is, the microservices — and the infrastructure, developers and platform teams are increasingly making, or heavily influencing, decisions for load balancing (and other) infrastructure.&lt;/p&gt;&lt;p&gt;Selecting your proxy is one of the most important decision your team will make. A developer’s selection process gives heavier weight to a proxy’s APIs (due to their ability to programmatically configure the proxy) and on a proxy’s cloud native integrations (as previously noted). A top item on the list of demands for proxies is protocol support. Generally, protocol considerations can be broken into two types:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.&lt;/li&gt;&lt;li&gt;gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;intro&quot;&gt;&lt;h3 align=&quot;center&quot;&gt;Tip: HTTP2, gRPC, NATS&lt;/h3&gt;&lt;p&gt;At the heart of many distributed systems architectures are streaming and messaging protocols. When your applications need higher performance than JSON-REST, the application architecture commonly includes use of gRPC or NATS. REST is often found on the perimeter of the services while gRPC is used for service-to-service interactions. gRPC is a universal RPC framework. NATS is a multi-modal messaging system that includes request/reply, pub/sub and load balanced queues.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;High performance and low latency&lt;/li&gt;&lt;li&gt;High scalability and small memory footprint&lt;/li&gt;&lt;li&gt;Deep observability at all layers of the network stack&lt;/li&gt;&lt;li&gt;Programmatic configuration and ecosystem integration&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;With a Kubernetes-native control plane, using CRDs and associated controllers enables powerful simplification, easy scaling, and intent-driven infrastructure. It is critical that the proxy has the capability to be intent-driven using Kubernetes CRDs and controllers (preferably an open source proxy like the Citrix Ingress Controller It’s the robustness of a proxy’s cloud native integrations and configuration APIs, like the Citrix Nitro API, that enables this. Not only are the proxy’s configuration APIs a key consideration, but so is the method by which they handle your applications’ APIs, specifically their security.&lt;/p&gt;&lt;h3&gt;TCP/UDP Support&lt;/h3&gt;&lt;p&gt;There are many applications that communicate over TCP/UDP ports. Kubernetes ingress was developed with web traffic in mind. It provides a standard way to control and route HTTP/S traffic into the cluster. However, ingress mechanisms for non-HTTP traffic are inconsistent and can be challenging.&lt;/p&gt;&lt;p&gt;Typical methods are:&lt;/p&gt;&lt;ul&gt;&lt;p&gt;Service.Type = Nodeport Nodeports use non-standard ports and are awkward and complex to get into production.&lt;/p&gt;&lt;p&gt;Service.Type = LoadBalancer Typically offered only in public clouds, LoadBalancers could get expensive depending on the number of services used.&lt;/p&gt;&lt;p&gt;Citrix offers Service.type = Loadbalancer with a built-in IP address manager that is  consistent across clouds and on-premises deployments. This implementation simplifies IP address management and can save on load balancer costs in public clouds. An alternate method, also supported by Citrix, is to use ingress annotations that expose TCP/UDP ports. &lt;/p&gt;&lt;/ul&gt;&lt;p&gt;All three methods make it much easier for TCP/UDP applications to be used as microservices without extensive code rewrites or protocol changes.&lt;/p&gt;&lt;h2&gt;Securing Your Applications and APIs&lt;/h2&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/citrix-api-security-considerations-by-traffic-direction-fd6855ee14436ab0085a6960ffce8734.svg&quot; align=&quot;center&quot; alt=&quot;API security considerations by traffic direction.&quot;/&gt;&lt;p&gt;API security considerations by traffic direction.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;While traffic direction will dictate your security needs, the reality is that several concerns are shared considerations for both north-south and east-west traffic.&lt;/p&gt;&lt;p&gt;Let’s walk through the API security requirements one by one:&lt;/p&gt;&lt;h3&gt;Ingress Security (North-South) &lt;/h3&gt;&lt;p&gt;As services are exposed outside the cluster, the security considerations remain similar to those of monolithic deployments. In addition to ensuring protections like IP blacklist/whitelist and a robust encryption profile (SSL/TLS), it is imperative that the services are protected against both layer 3-4 and layer 7 DDoS.&lt;/p&gt;&lt;p&gt;Authentication/authorization are equally critical to ensure that the right access controls are established and maintained on data, APIs, and services. At the same time, as attacks are moving to the application layer, web application firewall (WAF) protections like SQL injection (SQLi), buffer overflow, and signature protections are table stakes. As the types of attacks are continuously evolving and because applications and APIs are changing many times a month, it is also critical that the protection mechanisms include behavior-based methods to automate the protection policies and detect potential zero-day attacks.&lt;/p&gt;&lt;h3&gt;API Gateway and Security (North-South)&lt;/h3&gt;&lt;p&gt;APIs are becoming the currency for digital transformation and for microservices that provide services via API, and therefore routing, security, control, and visibility for APIs is critical. API gateways are a perfect function to achieve these capabilities and typically are combined with the ingress solution.&lt;/p&gt;&lt;p&gt;API gateway solutions offer key functions like authentication, authorization, rate limiting, policy-based routing of APIs, and API versioning. In addition, the traditional controls applicable to a N-S web service are equally applicable and even more important to apply to APIs. API security is not just about authentication but also about ensuring that the content coming in from authenticated sources is not malicious. API gateway functions typically get configured in ingress through configmaps or CRDs.&lt;/p&gt;&lt;h3&gt;Intra-Cluster Security for Service Mesh or Service Mesh-Lite (East-West)&lt;/h3&gt;&lt;p&gt;Secure application deployment and secure infrastructure best practices dictate security controls in terms of both N-S and E-W service traffic (the former is generally more intuitively understood) because one layer of security isn’t enough, and in-depth defense is needed.&lt;/p&gt;&lt;p&gt;As the number and variety of your microservices expand, the pattern we’ve seen is that services might start as internal use only, but over time end up being exposed externally to customers and partners. The gooey center of your cluster, where you initially intend to have most of your service-to-service interactions, needs to be as secure because service-to-service interactions expand to those outside the cluster. Service meshes are a natural solution here. To obtain this added layer of security (and many other benefits), the adoption of service meshes is on the rise, dramatically. When your application delivery controller integrates with a service mesh, API security is broadly upleveled and guaranteed up to a certain point irrespective of developers&amp;#x27; rigor in incorporating secure coding practices. That’s because a service mesh runs as a layer of your infrastructure, relieving developers of a number of (but not all) identity, authentication, and authorization concerns.&lt;/p&gt;&lt;p&gt;For example, inter-services communication should be mutually authenticated via transport layer security (TLS) so that only permitted API connections are allowed. Previously, this may have been implemented with each individual service, but the service mesh enables this functionality to be offloaded to a sidecar ADC, like Citrix CPX, and managed by the service mesh control plane.&lt;/p&gt;&lt;p&gt;Similarly, it should be possible to ensure a faster and more consistent approach to SSL policy in microservices environments through the use of SSL profiles. By defining acceptable SSL settings (for example, ciphers, protocol, and key strength) and binding them to your different entities, developers can quickly deploy consistent encryption policies that meet the appropriate security requirements. After all, isn’t the goal here to facilitate both developer velocity while ensuring that necessary security practices are met?&lt;/p&gt;&lt;p&gt;Another rapidly emerging technology to enable developer velocity is serverless computing. While serverless does indeed involve servers, it leverages infrastructure as code to run backend services as needed, which frees the developer from having to worry about scaling, patching, security, and infrastructure reliability. API gateways are key to applications built with serverless because the developer can simply specify policy such as authentication, authorization, and rate limits without worrying about the form factor, performance, and reliability of the proxy that usually provides these features.&lt;/p&gt;&lt;p&gt;Next, let’s explore aspects of another benefit use of a service mesh provides: traffic control.&lt;/p&gt;&lt;h2&gt;Enabling CI/CD and Canary Deployment with Advanced Traffic Steering&lt;/h2&gt;&lt;p&gt;Your application delivery solution should be an enabler of continuous delivery and canary deployments by providing advanced traffic steering. Intelligent proxies are required here. If you’re using a control plane (and not configuring the proxies directly), understand that you will only be able to harness the full power of your proxies to the extent that the control plane exposes their capabilities for configuration.&lt;/p&gt;&lt;h3&gt;Canary Deployment  &lt;/h3&gt;&lt;p&gt;In order to facilitate canary deployments, you need a powerful proxy. Kubernetes facilitates rolling updates to a service deployment, focusing on ensuring that traffic shifting from one version of a service to the next happens gradually over time and with zero downtime. However, Kubernetes on its own doesn’t offer the level of granular control over traffic necessary for simply exposing your canary to a subset of users that you identify. Nor is it convenient for error rate and performance monitoring. Although performance monitoring is integral for canary analysis, many times the solutions for automated canary analysis are cobbled together.&lt;/p&gt;&lt;p&gt;A canary deployment is manual in that you will need to manually check that the canary behaves as you want before doing a full deployment (caution: the difference between canary and baseline isn&amp;#x27;t always clear). Robust application delivery solutions support &lt;b&gt;automated canary analysis&lt;/b&gt; and progressive rollout. With an automated canary analysis, not only are you able to avoid manual administration of the deployment, but you can also rely on an automated statistical analysis to better detect problems in the set of metrics you’ve identified as indicators of a healthy deployment.&lt;/p&gt;&lt;p&gt;&lt;b&gt;A/B testing&lt;/b&gt; requires full control over traffic distribution with several versions of your service running in parallel as you run various experimental tests. Experimentations often include measuring differences in conversion rates between versions of a service with the aim of improving a given business metric. To facilitate these experiments, you might want to direct requests based on various criteria like a client’s browser type and version or a user segment based on the presence of a specific cookie or the effect of UI changes on user behavior and the impact on overall performance.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Chaos engineering&lt;/b&gt; is akin to A/B testing in that it is an emergent practice that facilitates experimentation. Experimentation here is for purposes of testing and improving application delivery resiliency. Chaos engineering will evolve and expand in use as the complexity and rate of change of large-scale distributed systems demand new tools and techniques for increasing reliability and resiliency. Service-oriented teams (as opposed to infrastructure-oriented platform teams) will push past chaos engineering tools such as Chaos Monkey for inducing machine failures and skip Chaos Kong for evacuating entire regions. Instead they will move to application delivery solutions to perform precise service-level experiments on their path to improving application resiliency via orchestrated chaos. It&amp;#x27;s through exploration of the impact of increased latency and methodical failure of specific services that service teams will gain confidence in their systems’ capabilities to withstand turbulent conditions in production and begin to sleep more soundly at night.&lt;/p&gt;&lt;p&gt;Savvy cloud native engineers understand the nuances of these delivery methods, and the key role that the proxy plays in enabling these methods. Note, however, that the need for these methods is not restricted to cloud native workloads. These application delivery solution considerations generally apply to microservices and monolithic services in that irrespective of a given service’s architecture, new versions of the service need to be deployed and managed. Because we live in a hybrid world, we encourage you to seek application delivery solutions that do, too.&lt;/p&gt;&lt;h2&gt;Achieving Holistic Observability &lt;/h2&gt;&lt;p&gt;Observability is crucial for effective troubleshooting of microservices environments, but the ephemeral nature and complexity of distributed architecture presents serious challenges. It&amp;#x27;s incredibly hard to maintain awareness of what&amp;#x27;s happening in your environment when containers are continuously created and destroyed. Continuous deployment adds to the transient nature of containers because DevOps teams often push many new deployments per day to update their applications.&lt;/p&gt;&lt;p&gt;Similarly, the number of things to monitor — services, containers, users — is enormous, and the fact that everything is distributed makes microservices an incredibly complex environment. While it’s easy to determine if a service is down, troubleshooting slow applications is not? How can you isolate problems among all of the vast telemetry data to find the root cause, especially with inter-microservices (E-W) traffic?&lt;/p&gt;&lt;p&gt;You cannot monitor what you can&amp;#x27;t see. This is why it is vitally important to have inspection points through which the traffic passes. When they are correctly positioned, proxies/ADCs collect telemetry for an unprecedented view of application traffic — both N-S and E-W traffic across both monolithic and microservices architectures — and they report important data to collection tools.&lt;/p&gt;&lt;p&gt;To overcome the challenge of gaining observability into microservices, you need to build an observability stack. The stack should consist of four pillars: logging, metrics, tracing, and service graphs. However, these should not be viewed as individual, disjointed components but rather as a holistic observability stack that is integrated and can combine data as required.&lt;/p&gt;&lt;strong&gt;Logs&lt;/strong&gt;&lt;p&gt;Logs are an immutable record of an individual event at a particular time. They are designed into systems, and there tends to be a log record to accompany almost every action. While logs are highly granular, they are limited in their searchability, and it is not usually feasible to process them manually. ADC feeds log data into tools like Elasticsearch for processing and indexing and Kibana for data visualization.&lt;/p&gt;&lt;strong&gt;Metrics&lt;/strong&gt;&lt;p&gt;Metrics are data points that are measured over time that can be used to monitor trends and set alerts. In addition to the system resources of your individual proxies, the unique position of the proxies means that it sees important information about the use of the application - number of requests, HTTP request rate, errors and more. These metrics can be exported by ADCs to tools like Prometheus where they can be processed and tools like Grafana can visualize them, set alarms create heat maps to help you understand the status of your ADCs.&lt;/p&gt;&lt;strong&gt;Traces&lt;/strong&gt;&lt;p&gt;The flow of packets through a microservices-based application can be complex spanning multiple services (sometimes multiple times) so identifying why a service is slow can be difficult. Distributed Tracing is a technique that monitors request flow through microservices to build a map of the latency through each microservice hop. Trace is an end-to-end latency graph of a specific request. It represents the entire journey of a request and helps troubleshoot latency issues. Distributed tracing can also be used to understand the application architecture and services not being used. ADC integrates with open source tools like OpenTracing and Zipkin for distributed tracing&lt;/p&gt;&lt;strong&gt;Service Graphs&lt;/strong&gt;&lt;p&gt;Service graphs are dynamic graphical representations of microservices and their interdependencies. Service graphs, like that of the service graph in the Citrix Application Delivery Manager (ADM) console, provide detail on connectivity among microservices, help you identify issues via simple color coding, and learn composite health scores for each microservice based on throughput, saturation, errors, and latency. More than this, Citrix service graphs also have a built in DVR-like function, which allows you to zero in on the specific time period when an issue occurred.&lt;/p&gt;&lt;p&gt;Given their distillment of complex microservices into a graphical form, service graphs need to provide the ability to tag microservices and to use tags to search, sort , and filter. In this way, you can create custom service graph views of microservices running in production only or you can restrict your view to see details just for canary microservices.&lt;/p&gt;&lt;p&gt;As a complement to the basic pillars of observability (logs, metrics, and traces), service graphs enhance your observability stack. They provide a holistic view of your microservices-based application environments in a single place for an intuitive and convenient way to gain insight and troubleshoot microservices environments faster.&lt;/p&gt;&lt;h2&gt;Managing Monoliths and Microservices&lt;/h2&gt;&lt;p&gt;With hybrid cloud now a reality for many organizations, managing multiple environments with divergent capabilities and management systems is also a reality. Operating with confidence requires reconciling these differences into a uniform operational model and, subsequently, into a uniform understanding with consistent (read: quality) control. For operational consistency, you need a single pane of glass to manage your application delivery infrastructure across:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Any application: monolithic and microservices-based applications&lt;/li&gt;&lt;li&gt;Any environment: on-premises, public, private, and hybrid &lt;/li&gt;&lt;li&gt;Any ADC form factor: physical, virtual, cloud, containers, sidecars, and more&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You need holistic control and monitoring for operational consistency across all your workloads (new microservices and existing monoliths). Ideally, you’ll get such consistency from the proxy you’ve put in place. As you select your proxy, exercise caution when piecing together components from disparate vendors/projects into a solution, because this will not only require integration effort, but also separate specialization to understand and operate. The overhead of integration and specialization can be avoided when your proxy portfolio is robust and supports any application, any environment and form factor with operatonal consistancy.&lt;/p&gt;&lt;p&gt;Moreover, as the large public cloud providers extend their reach on-premises with offerings like Google Anthos, AWS Outposts, and Azure Stack, and as organizations adopt them as simpler paths to cloud migration, it becomes important to use a proxy that works in multiple environments. A battle-tested solution like Citrix ADC that is validated to work in Google Anthos and AWS Outposts environments both in the cloud and on-premises can be invaluable for maintaining operational consistency across your hybrid multi-cloud environment. Because Citrix ADC comes in a variety of form factors (including hardware, software, bare metal, cloud, containers, sidecars, and more) that are built on a single code base, it works across your hybrid workloads in a uniform fashion and prevents a sprawl of heterogenous load balancers across your environment.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Client Libraries]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Client Libraries",
  "thumbnail": "./using-different-microservice-client-libraries.png",
  "category": "Service Mesh",
  "tags": ["Service mesh"],
  "type": "Demo",
  "product": "Meshery",
  "technology": "Docker",
  "mesh": "Linkerd",
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, " The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("p", null, "Client libraries (microservices frameworks) became very popular as microservices took a foothold in modern application design to avoid rewriting the same logic in every service. Example frameworks include the following:"), mdx("ul", null, mdx("li", null, mdx("h3", null, "Twitter Finagle "), mdx("p", null, "An open source remote procedure call (RPC) library built on Netty for engineers that want a strongly-typed language on the Java Virtual Machine (JVM). Finagle is written in Scala.")), mdx("li", null, mdx("h3", null, "Netflix Hystrix"), mdx("p", null, "An open source latency and fault tolerance library designed to isolate points of access to remote systems, services, and third-party libraries; stop cascading failure; and enable resilience. Hystrix is written in Java.")), mdx("li", null, mdx("h3", null, " Netflix Ribbon"), mdx("p", null, "An open source Inter-Process Communication (IPCs) library with built-in software load balancers. Ribbon is written in Java.")), mdx("li", null, mdx("h3", null, " Gokit"), mdx("p", null, "An open source toolkit for building microservices (or elegant monoliths) with gRPC as the primary messaging pattern. Gokit is written in Go and comes with pluggable serialization and transport.")), mdx("li", null, mdx("h3", null, "DropWizard, Spring Boot, Akka\u2026 and others."))), mdx("div", {
    className: "fact"
  }, mdx("p", null, "See the Layer5 ", mdx(Link, {
    to: "/landscape",
    mdxType: "Link"
  }, "service mesh landscape"), " for a comprehensive perspective of and characterizing of all popular client libraries.")), mdx("p", null, "Prior to the availability of service meshes, developers used language-specific microservices frameworks to improve the resiliency, security, and observability of their services. The drawback of client libraries is that they embed\xA0infrastructure concerns into your application code. Services that embed the same client library across themselves in the presence of a service mesh incorporate duplicative code. Inconsistency is a concern for services that include different client libraries or different versions of the same client library. In environments with polyglot microservices, different client libraries are used.  "), mdx("p", null, "Getting teams to update their client libraries can be an arduous process. When these infrastructure concerns are embedded in your service code, you'll need to track down your developers to update and reconfigure these libraries.\xA0 It can take a long time to get a consistent configuration with the same and most recent version deployed.\xA0 Enforcing consistency is challenging. \xA0As seen in the figure below, these frameworks couple\xA0your services with\xA0the infrastructure."), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Library,
    align: "right",
    alt: "service mesh client libraries"
  }), mdx("p", null, "Figure 1: Services architecture using client libraries coupled with application logic")), mdx("p", null, "Different services teams must negotiate things like timeouts and retries when infrastructure code is embedded in the application. A service mesh not only decouples infrastructure code from application code, but it also decouples teams. Service meshes are typically implemented as infrastructure that exists outside of your applications, but as their adoption increases, this is changing, and their use for influencing or implementing business logic is becoming more prevalent.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/client-libraries</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/client-libraries</guid><enclosure url="https://layer5.io/static/706fddc28c79130042c325a584799427/using-different-microservice-client-libraries.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt; The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Client libraries (microservices frameworks) became very popular as microservices took a foothold in modern application design to avoid rewriting the same logic in every service. Example frameworks include the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;h3&gt;Twitter Finagle &lt;/h3&gt;&lt;p&gt;An open source remote procedure call (RPC) library built on Netty for engineers that want a strongly-typed language on the Java Virtual Machine (JVM). Finagle is written in Scala.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;Netflix Hystrix&lt;/h3&gt;&lt;p&gt;An open source latency and fault tolerance library designed to isolate points of access to remote systems, services, and third-party libraries; stop cascading failure; and enable resilience. Hystrix is written in Java.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt; Netflix Ribbon&lt;/h3&gt;&lt;p&gt;An open source Inter-Process Communication (IPCs) library with built-in software load balancers. Ribbon is written in Java.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt; Gokit&lt;/h3&gt;&lt;p&gt;An open source toolkit for building microservices (or elegant monoliths) with gRPC as the primary messaging pattern. Gokit is written in Go and comes with pluggable serialization and transport.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;DropWizard, Spring Boot, Akka… and others.&lt;/h3&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;fact&quot;&gt;&lt;p&gt;See the Layer5 &lt;a href=&quot;/landscape&quot;&gt;service mesh landscape&lt;/a&gt; for a comprehensive perspective of and characterizing of all popular client libraries.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Prior to the availability of service meshes, developers used language-specific microservices frameworks to improve the resiliency, security, and observability of their services. The drawback of client libraries is that they embed infrastructure concerns into your application code. Services that embed the same client library across themselves in the presence of a service mesh incorporate duplicative code. Inconsistency is a concern for services that include different client libraries or different versions of the same client library. In environments with polyglot microservices, different client libraries are used.  &lt;/p&gt;&lt;p&gt;Getting teams to update their client libraries can be an arduous process. When these infrastructure concerns are embedded in your service code, you&amp;#x27;ll need to track down your developers to update and reconfigure these libraries.  It can take a long time to get a consistent configuration with the same and most recent version deployed.  Enforcing consistency is challenging.  As seen in the figure below, these frameworks couple your services with the infrastructure.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/using-different-microservice-client-libraries-dcccc0e38e613c81b5129099e46e8549.png&quot; align=&quot;right&quot; alt=&quot;service mesh client libraries&quot;/&gt;&lt;p&gt;Figure 1: Services architecture using client libraries coupled with application logic&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Different services teams must negotiate things like timeouts and retries when infrastructure code is embedded in the application. A service mesh not only decouples infrastructure code from application code, but it also decouples teams. Service meshes are typically implemented as infrastructure that exists outside of your applications, but as their adoption increases, this is changing, and their use for influencing or implementing business logic is becoming more prevalent.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Learn How to Write WebAssembly Filters]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Learn How to Write WebAssembly Filters",
  "thumbnail": "./webassembly-logo-horizontal.png",
  "category": "WebAssembly Filters",
  "tags": ["WebAssembly", "Envoy"],
  "type": "Article",
  "product": "Meshery",
  "technology": "WebAssembly",
  "mesh": "Linkerd",
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about WebAssembly's use within service mesh data planes in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.")), mdx("p", null, "WebAssembly, or WASM, is an open standard that defines a binary format for executable programs. Through WebAssembly System Interface (WASI), it also defines interfaces for facilitating interaction with host environments. The initial focus of these host environments was browsers and large web applications with the intention of securely running programs to improve performance. As an open standard, WASM is maintained by the W3C, and has been adopted by all modern browsers. After HTML, CSS, and Javascript, WebAssembly is the fourth language to natively run in web browsers."), mdx("p", null, "WASM support is coming to Envoy through the efforts of Google, and Envoy maintainers embedding Google's open source high-performance JavaScript and WebAssembly engine, V8, into Envoy. Through the WebAssembly System Interface, Envoy exposes an Application Binary Interface (ABI) to WASM modules, so that they can operate as Envoy filters. The way WASI works is straight-forward. You write your application in your favourite languages like Rust, C or C++. Then, build and compile them into a WebAssembly binary targeting the host environment. The generated binary requires the WebAssembly runtime to provide the necessary interfaces to system calls for the binary to execute. Conceptually, this is similar to JVM. If you have a JVM installed then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary."), mdx("h4", null, "Envoy Proxy WASM SDK"), mdx("p", null, "Envoy Proxy runs WASM filters inside a stack-based virtual machine, thus the filter\u2019s memory is isolated from the host environment. All interactions between the embedding host (Envoy Proxy) and the WASM filter are realized through functions and callbacks provided by the Envoy Proxy WASM SDK. The Envoy Proxy WASM SDK has implementations in various programming languages like:"), mdx("ul", null, mdx("li", null, "C++"), mdx("li", null, "Rust"), mdx("li", null, "AssemblyScript"), mdx("li", null, "Go")), mdx("p", null, "Let's examine how to write WASM filters for Envoy using the Rust Envoy Proxy WASM SDK. While we will not delve into all the details of the Application Binary Interface (ABI) for Envoy Proxy's WASM SDK, we will touch on a few of the things that are necessary to grasp the basics of writing WASM filters for Envoy."), mdx("p", null, "Our filter implementation must be derived from the following two classes."), mdx("p", null, "Envoy provides the ability to integrate additional filters by either:"), mdx("ul", null, mdx("li", null, "Natively by incorporating your custom filter into Envoy\u2019s C++ source code and compiling a new Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit being that of your custom filter running at native speed."), mdx("li", null, "Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically load and reload WASM-based filters in Envoy at runtime.")), mdx("p", null, "Envoy configuration is initialized via bootstrap on startup. Envoy\u2019s xDS APIs allow configuration to be loaded and reloaded dynamically during runtime. Envoy configuration has different sections (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). Each of the sections can configure WASM plugins (programs).")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/webassembly-filters/learn-how-to-write-webassembly-filters</link><guid isPermaLink="false">https://layer5.io/resources/webassembly-filters/learn-how-to-write-webassembly-filters</guid><enclosure url="https://layer5.io/static/06e071d3040728c69145f5d670854c6d/webassembly-logo-horizontal.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about WebAssembly&amp;#x27;s use within service mesh data planes in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;WebAssembly, or WASM, is an open standard that defines a binary format for executable programs. Through WebAssembly System Interface (WASI), it also defines interfaces for facilitating interaction with host environments. The initial focus of these host environments was browsers and large web applications with the intention of securely running programs to improve performance. As an open standard, WASM is maintained by the W3C, and has been adopted by all modern browsers. After HTML, CSS, and Javascript, WebAssembly is the fourth language to natively run in web browsers.&lt;/p&gt;&lt;p&gt;WASM support is coming to Envoy through the efforts of Google, and Envoy maintainers embedding Google&amp;#x27;s open source high-performance JavaScript and WebAssembly engine, V8, into Envoy. Through the WebAssembly System Interface, Envoy exposes an Application Binary Interface (ABI) to WASM modules, so that they can operate as Envoy filters. The way WASI works is straight-forward. You write your application in your favourite languages like Rust, C or C++. Then, build and compile them into a WebAssembly binary targeting the host environment. The generated binary requires the WebAssembly runtime to provide the necessary interfaces to system calls for the binary to execute. Conceptually, this is similar to JVM. If you have a JVM installed then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.&lt;/p&gt;&lt;h4&gt;Envoy Proxy WASM SDK&lt;/h4&gt;&lt;p&gt;Envoy Proxy runs WASM filters inside a stack-based virtual machine, thus the filter’s memory is isolated from the host environment. All interactions between the embedding host (Envoy Proxy) and the WASM filter are realized through functions and callbacks provided by the Envoy Proxy WASM SDK. The Envoy Proxy WASM SDK has implementations in various programming languages like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;C++&lt;/li&gt;&lt;li&gt;Rust&lt;/li&gt;&lt;li&gt;AssemblyScript&lt;/li&gt;&lt;li&gt;Go&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Let&amp;#x27;s examine how to write WASM filters for Envoy using the Rust Envoy Proxy WASM SDK. While we will not delve into all the details of the Application Binary Interface (ABI) for Envoy Proxy&amp;#x27;s WASM SDK, we will touch on a few of the things that are necessary to grasp the basics of writing WASM filters for Envoy.&lt;/p&gt;&lt;p&gt;Our filter implementation must be derived from the following two classes.&lt;/p&gt;&lt;p&gt;Envoy provides the ability to integrate additional filters by either:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Natively by incorporating your custom filter into Envoy’s C++ source code and compiling a new Envoy version. The drawback being that you need to maintain your own version of Envoy, while the benefit being that of your custom filter running at native speed.&lt;/li&gt;&lt;li&gt;Via WASM by incorporating your custom filter as a WebAssembly binary writing in C++, Rust, AssemblyScript or Go. The drawback being that WASM-based filters incur some overhead, while the benefit being that you can dynamically load and reload WASM-based filters in Envoy at runtime.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Envoy configuration is initialized via bootstrap on startup. Envoy’s xDS APIs allow configuration to be loaded and reloaded dynamically during runtime. Envoy configuration has different sections (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). Each of the sections can configure WASM plugins (programs).&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[7 Key Considerations for Microservices-Based Application Delivery]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "7 Key Considerations for Microservices-Based Application Delivery",
  "subtitle": "Ensuring the Success of Your Cloud Native Journey",
  "thumbnail": "./citrix-path-to-cloud-native.svg",
  "category": "Service Mesh",
  "tags": ["Microservices"],
  "featured": false,
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("h2", null, "The Role of Application Delivery in Your Cloud Native Journey"), mdx("p", null, "As digital transformation is changing how your organization conducts business, so is it changing how your products and services are delivered. The infrastructure and practices by which your software is continuously deployed and operated \u2014 your application delivery \u2014 is the fulcrum of your organization\u2019s digital transformation. Likely you are progressing on your cloud native journey \u2014 that is, transitioning from monolithic to container-based microservices architectures with the goal of achieving agility, portability, and on-demand scalability. Kubernetes is the platform of choice for many, providing the automation and control necessary to manage microservices-based applications at scale and with high velocity."), mdx("p", null, "With the network part and parcel to each and every service request in your microservices-based application, it may come as no surprise that at the core of application delivery is your application delivery controller, an intelligent proxy that accelerates and manages application delivery. With no standard definition of what an application delivery controller does, the capabilities of intelligent proxies vary broadly. And so in this white paper, we\u2019ll explore application delivery controllers as they relate to your architecture choices, your use of Kubernetes platforms, and open source tools."), mdx("h2", null, "7 Key Considerations for Microservices-Based Application Delivery"), mdx("p", null, "Before embarking on your cloud native journey, it is essential to critically assess your organization\u2019s readiness with regard to skill set so that you can choose the solutions that best fit the business objective you are seeking to meet in context of your ability to do so. There are seven key considerations to address when planning your microservices-based application delivery design:"), mdx("ol", null, mdx("li", null, "Architecting your foundation the right way "), mdx("li", null, "Openly integrating with the cloud native ecosystem"), mdx("li", null, "Choosing the perfect proxy"), mdx("li", null, "Securing your applications and APIs"), mdx("li", null, "Enabling CI/CD and canary deployment with advanced traffic steering "), mdx("li", null, "Achieving holistic observability"), mdx("li", null, "Managing monoliths and microservices")), mdx("p", null, "A thorough evaluation of these seven considerations is best done with specific tasks and goals in mind. Depending on the size and diversity of your organization, you may need to account for a variety of stakeholders\u2019 needs \u2014 that is, tasks and goals that differ based on role and responsibility. In context of application delivery, let\u2019s survey the most common roles with a generalized view of their responsibilities and needs as stakeholders. To help facilitate a general understanding, we\u2019ve grouped some roles when responsibilities overlap across multiple teams:"), mdx("ul", null, mdx("li", null, mdx("h3", null, "Platform"), mdx("p", null, "Platform teams are responsible for deploying and managing their Kubernetes infrastructure. They are responsible for platform governance, operational efficiency, and developer agility. The platform team is the connective tissue among various teams like DevOps, SREs, developers, and network operations teams and therefore must address and balance the unique needs of a diverse group of stakeholders, or influencers, when choosing cloud native solutions.")), mdx("li", null, mdx("h3", null, "DevOps"), mdx("p", null, "DevOps teams are responsible for continuously deploying applications. They care about faster development and release cycles, CI/CD and automation, and canary and progressive rollout.")), mdx("li", null, mdx("h3", null, "SREs"), mdx("p", null, "Site reliability engineers must ensure application availability. They care about observability, incident response, and postmortems. SREs often act as architects for DevOps team and as such are often extensions of or directly belong to DevOps teams.")), mdx("li", null, mdx("h3", null, "Developers"), mdx("p", null, "Development teams are responsible for application performance and are focused on ensuring a seamless end-user experience, including troubleshooting and microservices discovery and routing. Application performance and troubleshooting is shared responsibility among multiple teams.")), mdx("li", null, mdx("h3", null, "NetOps "), mdx("p", null, "Network operations teams are responsible for ensuring stable, high-performing network connectivity, resiliency, security (e.g. web application firewalls and TLS), and are commonly focused on north-south traffic. They care about establishing networking policies and enforcing compliance; achieving management, control, and monitoring of the network; and gaining visibility for the purpose of resources and capacity planning.")), mdx("li", null, mdx("h3", null, "DevSecOps"), mdx("p", null, "DevSecOps teams care about ensuring a strong security posture and rely on automated tools to orchestrate security for infrastructure, applications, containers, and API gateways. DevSecOps works very closley with NetOps team for holistic secure posture."))), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Stakeholders,
    align: "center",
    alt: "Diverse Stakeholders have different needs"
  })), mdx("p", null, "Each role has nuanced responsibilities. Whether you have a single person or teams of people assigned to these roles, each role\u2019s function needs to be accounted for."), mdx("p", null, "It\u2019s important to note that these stakeholders are undergoing a transformation in their responsibilities \u2014 or at least a transformation in the way in which they perform their responsibilities. Depending upon your organization\u2019s size and structure, your stakeholders may have clearly defined lines of accountability or not among roles. As you adopt a cloud native approach to application deployment and delivery, you may find that the once-defined lines have blurred or that they are being redrawn. Be aware that the individuals who fill these roles typically go through a period of adjustment that can be unsettling until they adapt to their own and their teams\u2019 new identities."), mdx("p", null, "Your cloud native infrastructure should be as accommodating as possible to you, your team, and your collective responsibilities and process, so we encourage you to seek solutions that address the needs of all your stakeholders. Significantly, this includes evaluating different architectural models for as best fit for purpose. While every organization doesn\u2019t travel the same road to cloud native, every journey starts with initial architectural decisions \u2013 decisions which have substantial bearing on your path to cloud native."), mdx("h2", null, "Architecting Your Foundation the Right Way"), mdx("p", null, "Cloud native novices and experts alike find that designing their application delivery architectures is the most challenging part of building microservices. Your architectural choices will have a significant impact on your cloud native journey. Some architectures will provide greater or fewer benefits while others will prove less or more difficult to implement."), mdx("p", null, "Whether you are a cloud native pro or a novice, your selection of the right application delivery architecture will be one that balances the tradeoff between the greatest benefits and the simplicity needed to match your team\u2019s skill set. Figure 1 highlights four common application delivery architecture deployment models:"), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Graph,
    align: "center",
    alt: "Graph"
  })), mdx("div", {
    className: "intro"
  }, mdx("h3", {
    align: "center"
  }, "Tip: Traffic Directions"), mdx("p", null, "North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.")), mdx("p", null, "Each of the deployment models in Figure 1 come with their list of pros and cons and are typically the point of focus of different teams. So how do you choose the right architecture for your deployment? Given the needs of your stakeholders and the many specifics involved in managing both north-south (N-S) and east-west (E-W) traffic, it is critical to assess the four different architectures with respect to the following areas:"), mdx("ul", null, mdx("li", null, "Application security "), mdx("li", null, "Observability "), mdx("li", null, "Continuous deployment "), mdx("li", null, "Scalability and performance "), mdx("li", null, "Open source tools integration "), mdx("li", null, "Service mesh & Istio  integration "), mdx("li", null, "IT skill set required ")), mdx("p", null, "Let\u2019s examine each of the four deployment models."), mdx("h3", null, "Two-Tier Ingress"), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: TwoTier,
    align: "centre",
    alt: "Two Tier Ingress"
  })), mdx("p", null, "Two-tier ingress is the simplest architectural model to deploy to get teams up and running quickly. In this deployment model, Tthere are two layers of ADCs for N-S traffic ingress. The external ADC (at Tier 1), shown in green in Figure 2, provides L4 traffic management. Frequently, additional services are assigned to this ADC and can include web application firewall (WAF) and, secure sockets layer/transport layer security offload (SSL/TLS) functionality and authentication. A two-tier ingress deployment model is often managed by the existing network team (which is familiar with internet-facing traffic), and it can also be used as an ADC for other existing applications simultaneously."), mdx("p", null, "The second ADC (Tier 2), shown in yellow in Figure 2, handles L7 load balancing for N-S traffic. It is managed by the platform team and is used within the Kubernetes cluster to direct traffic to the correct node. Layer 7 attributes, like information in the URL and HTTP headers, can be used for traffic load-balancing decisions. The yellow ADC continuously receives updates about the availability and respective IP addresses of the microservices pods within the Kubernetes cluster and can make decisions about which pod is best able to handle the request. Deployed as a container inside the Kubernetes cluster, the yellow ADC can be deployed as a container with Citrix CPX or with another similar product."), mdx("p", null, "The E-W traffic between microservices pods is managed by kube-proxy, an open source, basic L4 load balancer with simple IP address-based round robin or least connection algorithm. kube-proxy lacks advanced features like Layer 7 load balancing, security, and observability, making it a blind spot for E-W traffic."), mdx("b", null, "Pros of Two-Tier Ingress"), mdx("p", null, "With the right proxy, SSL termination can be done at the edge, and traffic can be inspected easily. This enables N-S traffic to be comprehensively secured across L3-7. ADC collects and reports telemetry on the N-S application traffic it sees, which means that this architecture provides robust observability for N-S traffic. ADC can also also integrate with CI/CD tools like Spinnaker to provide traffic management to N-S traffic for excellent continuous deployment capabilities."), mdx("p", null, "Two-tier ingress scales very well for N-S traffic, as an example Citrix ADC reach hundreds of Gbps or even Tbps throughput through active-active clustering of ADCs if required. Integration with third-party tools like Prometheus, Grafana and Zipkin are supported out of the box with ADC, so you can continue to use the tools with which you are familiar to collect data and manage your systems for N-S traffic."), mdx("p", null, "The bifurcated design of two-tier ingress makes it relatively simple to implement demarcation points for control. The network team can own and manage the green ADC, and the platform team can work inside the Kubernetes environment. Neither the network team nor the platform team needs extensive retraining, which makes this architecture quick to implement."), mdx("b", null, "Cons of Two-Tier Ingress"), mdx("p", null, "The limitations of kube-proxy have made the use of third-party tools like Project Calico necessary to provide network policies, segmentation, and security support for inter-microservices communication. Similarly, kube-proxy's lack of detailed telemetry capabilities provides very little observability for E-W traffic. kube-proxy does not have the extensive APIs to integrate with continuous deployment tools, and its basic round-robin load balancing does not provide the granular load balancing needed to incorporate a CI/CD strategy inside the cluster. In general so you lack advanced load balancing tool set required to manage your inter-pod traffic. And kube-proxy does not currently integrate with service meshes, so there is no open source control plane integration for your E-W traffic management."), mdx("p", null, "Overall, two-tier ingress provides excellent services for N-S traffic but lacks control for E-W traffic. It is a popular architecture because it is simple to implement and is frequently a starting point for enterprises on their cloud native journey to microservices adoption."), mdx("div", {
    className: "note"
  }, "By default, kube-proxy uses iptables (x_tables kernel modules), so it does not perform as well as other proxies. You can configure kube-proxy to run in different modes by setting the --proxy-mode flag. Setting this flag to ipvs enables IPVS mode (netfilter kernel modules), which provides a much improved performance and also enables choice of load balancing algorithm through the --ipvs-scheduler parameter beyond the default round robin algorithm."), mdx("h3", null, "Unified Ingress"), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Unified,
    align: "centre",
    height: "50%",
    alt: "Unified Ingress"
  })), mdx("p", null, "Unified ingress is very similar to the two-tier ingress architecture, except that it unifies two tiers of application delivery controllers (ADCs) for N-S traffic into one. Reducing an ADC tier effectively removes one hop of latency for N-S traffic."), mdx("p", null, "Unified ingress has the same benefits and drawbacks as the two-tier ingress proxy architecture for security, observability, continuous deployment, scale and performance, open source tools support, and service mesh integration. Where it differs is in the skill sets required for implementation. With unified ingress, both the ADCs for N-S traffic and kube-proxy for the E-W traffic are managed by the platform team, who must be very network savvy to implement and manage this architecture."), mdx("p", null, "A unified ingress proxy architecture is capable of participating in the Kubernetes cluster\u2019s overlay network. This allows it to communicate directly with the microservices pods. Therefore, the platform team has to be knowledgeable about layers 3-7 of the network stack to take full advantage of this architecture."), mdx("p", null, "In summary, unified ingress proxy architecture is moderately simple to deploy compared to service mesh (which we will cover next), and it offers robust capabilities for N-S traffic, but has very limited functionality for E-W traffic due to the limitations of kube-proxy. A network-savvy platform team is key for implementing this architecture."), mdx("h3", null, "Service Mesh"), mdx("p", null, "A service mesh is a dedicated infrastructure layer to control how different parts of an application communicate with one another with one another. The service mesh landscape has exploded because service meshes offer the best observability, security, and fine-grained management for traffic among microservices \u2014 that is, for E-W traffic. As an additional layer of infrastructure, service meshes do bear additional complexity as a tradeoff to the value they provide."), mdx("div", {
    className: "left"
  }, mdx("img", {
    src: Servicemesh,
    align: "centre",
    alt: "Service Mesh"
  })), mdx("p", null, "A typical service mesh architecture is similar to the two-tier ingress proxy architecture for N-S traffic and offers the same rich benefits for N-S traffic. The key difference between service mesh and two-tier ingress, and where most of the value lies, is that service mesh employs a lightweight proxy as a sidecar to each microservice pod for E-W traffic. Microservices do not communicate directly: Communication among microservices happens via the sidecar, which enables inter-pod traffic to be inspected and managed as it enters and leaves the pods."), mdx("p", null, "By using proxy sidecars, service mesh offers the highest levels of observability, security, and fine-grained traffic management and control among microservices. Additionally, select repetitive microservice functions like retries and encryption can be offloaded to the sidecars. Despite each sidecar\u2019s being assigned its own memory and CPU resources, sidecars are typically lightweight."), mdx("p", null, "You have the option to use Citrix CPX as a sidecar. Sidecars, which are managed by the platform team and attached to each pod, create a highly scalable, distributed architecture, but they also add complexity because they result in more moving parts."), mdx("strong", null, "Pros of Service Mesh"), mdx("p", null, "The advantages of service mesh for N-S traffic are similar to those for two-tier ingress. Service mesh, however, brings added advantages for E-W traffic.The presence of sidecars enables you to set security policies and control communication among your microservices. You can mandate things like authentication, encryption, and rate limiting for APIs among microservices if required."), mdx("p", null, "Because E-W traffic is seen by the sidecars, there is much more telemetry to provide holistic observability for better insights and improved troubleshooting. Furthermore, Citrix CPX as a sidecar has well-defined APIs that integrate with myriad open source tools, so that you can use the observability tools you're used to. Sidecar APIs allow integration with CI/CD tools like Spinnaker."), mdx("p", null, "Similarly, sidecars will integrate with a service mesh control plane like Istio for E-W traffic. Additionally, repetitive functions like retries and encryption can be offloaded to the sidecars. The distributed nature of the sidecar means that the solution is scalable for such features as observability and security."), mdx("strong", null, "Cons of Service Mesh"), mdx("p", null, "The biggest drawback of a service mesh architecture is the complexity of implementation (managing hundreds or thousands of sidecars is not trivial). The learning curve can be steep for the platform team because there are so many moving parts. A sidecar for every pod adds to CPU and memory needs. Similarly, sidecars add latency. Latency, which may affect application performance, varies with proxy implementation and can be easily measured by the open source tool, Meshery. Citrix CPX as a sidecar offers latency as low as 1ms, whereas other solutions can add much more."), mdx("p", null, "Overall, a service mesh architecture provides excellent security, observability, and fine-grained traffic management for all traffic flows. The major downside is that it is complex to implement and manage."), mdx("h3", null, "Service Mesh Lite"), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Servicemeshlite,
    align: "centre",
    alt: "Service Mesh Lite"
  })), mdx("p", null, "What if you want service mesh-like benefits with much less complexity?  The answer is service mesh lite, which is a variant of service mesh."), mdx("p", null, "With a service mesh lite architecture, the ADC shown in green in Figure 5 is responsible for Layer 4-7 load balancing for N-S traffic to handle inbound requests and load balance to the right Kubernetes cluster. The green ADC may carry out SSL termination, web application firewalling, authentication, or other network services. It is managed by the networking team."), mdx("p", null, "Depending on isolation and scale requirements, service mesh lite proxy architecture uses a single or several ADCs (shown in yellow in Figure 5) that proxy communications among microservices pods to manage inter-pod (E-W) traffic rather than using individual sidecars attached to each pod. Proxies can be deployed per node or per namespace and are managed by platform teams."), mdx("strong", null, "Pros of Service Mesh Lite"), mdx("p", null, "Service mesh lite provides many of the same benefits as service mesh but reduces the overall complexity by only having a small set of proxy instances per cluster to manage the inter-pod traffic. Passing all E-W traffic through a small set of proxies provides the same advanced policy control, security, and fine-grained traffic management of a service mesh proxy architecture without all the complexity."), mdx("p", null, "Another advantage of service mesh lite is reduced latency as compared to service mesh because end user request goes through fewer  proxies. The main advantage is reduced complexity and the lower skill set required to implement compared to service mesh. Similar to two-tier ingress, the networking team can manage the green ADC, and the platform team can manage the yellow ADC. With service mesh lite, both teams can work in familiar environments and develop at their own speed."), mdx("strong", null, "Cons of Service Mesh Lite"), mdx("p", null, "Service mesh lite removes the implementation and management associated with service mesh, but the absence of a proxy per pod means that you sacrifice some functionality offload. For example, encryption for E-W must be implemented in each microservice, itself, if required."), mdx("p", null, "Overall, service mesh lite provides most of the service mesh features but with reduced complexity and a lower IT skill set requirement. Many organizations who started with the two-tier ingress architecture find it an easy transition to service mesh lite for the added benefits it brings to their E-W traffic including better observability, enhanced security, better integration with open source tools, and support for continuous deployment."), mdx("p", null, "So after reviewing the four architecture choices, you\u2019re probably wondering: What \u2018s the right architecture choice for my organization? There are no right or wrong answers. Like other architectural choices, proxy deployment models should be selected based on, in part, your application needs and your team structure and your team\u2019s skill set."), mdx("p", null, "Your model of proxy deployment is an important consideration, but just one of many when planning for your application delivery infrastructure. Ensuring that the application delivery components in your deployment are well-integrated into the cloud native ecosystem is your next consideration."), mdx("h2", null, "Openly Integrating with the Cloud Native Ecosystem "), mdx("p", null, "It\u2019s imperative that your various application delivery tools and processes, including your proxy, be well-integrated into commonplace cloud native infrastructure. It\u2019s no secret that much of today\u2019s innovation happens in open source software. And clouds, both public and private, are built upon open source software. So in most cases, your infrastructure will be comprised of popular open source infrastructure and tools that you have picked up on your journey to cloud native. To the extent this is the case, you\u2019ll find common integrations by categories in Figure below:"), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Comparison,
    align: "center",
    alt: ""
  }), mdx("p", null, "Figure - Key categories of consideration for proxy integration with Kubernetes platforms and open source tools")), mdx("p", null, "Cloud native environments make liberal use of open source software projects. Irrespective of which projects you use, suffice it to say that cloud native application delivery can\u2019t be done with just containers. The combination of containers, container orchestration, and a service mesh will get you very far. And alongside a CI/CD system, these components are the most significant and ubiquitously used components of cloud native infrastructure. Integration with each of these categories of cloud native infrastructure is critical so that developers and operators can design and run systems that communicate and inter-operate as a whole. The fact that these bedrocks of cloud native infrastructure are open source unlocks their ability to be integrated."), mdx("p", null, "At the heart of the cloud native ecosystem is the extensible and scalable orchestration infrastructure that is Kubernetes. The cloud native ecosystem (both open source and closed source) extends Kubernetes by writing custom resource definitions (CRDs) and associated controllers. The controllers and CRDs give operators a Kubernetes-native way to manage all parts of their platforms \u2014 both open source and closed source. This integration affords tool unification and powerful composable intent-based primitives that truly enable a software-defined platform."), mdx("p", null, "Critical to the speed of delivery is an early investment in continuous integration/continuous delivery (CI/CD). It\u2019s likely you have already wrangled continuous integration. Continuous deployment pipelines are your next step in seeing that changes to your source code automatically result in a new container being built and a new version of your microservice being tested and deployed to staging and eventually to production."), mdx("p", null, "For many, the notion that CI/CD is an area of early investment is counterintuitive, and they find it hard to swallow the upfront engineering effort required to get a solid pipeline in place. The sooner CI/CD basics are implemented, however, the sooner the dividends start paying out. We will cover advanced continuous delivery considerations later in this white paper."), mdx("p", null, "With cloud native infrastructure\u2019s being inherently dynamic (in contrast to infrastructure not driven by APIs,) the ability to observe cloud native infrastructure and its workloads is also necessary. Software is written with functionality and debugging in mind. Most often, developers use logging as the primary method for debugging their applications. Integration with Elasticsearch and Kibana is key here."), mdx("p", null, "Performance counters are another way to track application behavior and performance. Akin to SNMP for physical and virtual network monitoring, the equivalent cloud native \u201Cstandard\u201D is the use of Prometheus and Grafana, so it\u2019s important that your application delivery solution integrate with these tools. Currently there is no recognized standard for cloud native application performance monitoring metrics."), mdx("div", {
    className: "intro"
  }, mdx("h3", {
    align: "center"
  }, "OpenMetrics"), mdx("p", null, "The cloud native ecosystem needs a common format for the exchange of metrics. Observability pains grow with the release of each newly instrumented service that presents its own metric format. OpenMetrics is an effort to create an open standard for transmitting metrics at scale, with support for both text representation and protocolbBuffers. OpenMetrics builds on Prometheus\u2019s exposition format, popular telemetry formats, and protocols used in infrastructure and application monitoring.")), mdx("p", null, "Irrespective of the metrics format, there are a few metrics that have been identified as key indicators of the health of a cloud native application (that is, the health of a service): latency, traffic, errors, and saturation. Your application delivery solution should assist in producing these signals as well as provide support for the tracing of your distributed, cloud native workloads."), mdx("p", null, "The aforementioned integrations with open source tools enable loosely coupled systems that are resilient, manageable, and observable. Citrix ADC also embodies these characteristics. All of the infrastructure integrations detailed here depend upon APIs for interchange and interoperability. Cloud native applications, too, are centered around declarative APIs to interface with the infrastructure and serve user-facing workloads."), mdx("p", null, "The endpoints that your APIs expose are now being managed by open source service meshes. Service meshes deliver the next generation of networking designed for cloud native applications. At the core of a service mesh is its data plane (its collection of proxies). Proxy selection criteria and deployment model tradeoffs are our next area of consideration."), mdx("p", null, mdx("em", {
    parentName: "p"
  }, mdx("strong", {
    parentName: "em"
  }, " Check out the topic ", mdx(Link, {
    to: "/resources/service-mesh/choosing-the-perfect-proxy",
    mdxType: "Link"
  }, "Choosing the Perfect Proxy"), " to learn more! ")))));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/7-key-considerations-for-microservices-based-application-delivery</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/7-key-considerations-for-microservices-based-application-delivery</guid><enclosure url="https://layer5.io/static/d933a542c39e21f591328eb08d0ce2b2/citrix-path-to-cloud-native.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;h2&gt;The Role of Application Delivery in Your Cloud Native Journey&lt;/h2&gt;&lt;p&gt;As digital transformation is changing how your organization conducts business, so is it changing how your products and services are delivered. The infrastructure and practices by which your software is continuously deployed and operated — your application delivery — is the fulcrum of your organization’s digital transformation. Likely you are progressing on your cloud native journey — that is, transitioning from monolithic to container-based microservices architectures with the goal of achieving agility, portability, and on-demand scalability. Kubernetes is the platform of choice for many, providing the automation and control necessary to manage microservices-based applications at scale and with high velocity.&lt;/p&gt;&lt;p&gt;With the network part and parcel to each and every service request in your microservices-based application, it may come as no surprise that at the core of application delivery is your application delivery controller, an intelligent proxy that accelerates and manages application delivery. With no standard definition of what an application delivery controller does, the capabilities of intelligent proxies vary broadly. And so in this white paper, we’ll explore application delivery controllers as they relate to your architecture choices, your use of Kubernetes platforms, and open source tools.&lt;/p&gt;&lt;h2&gt;7 Key Considerations for Microservices-Based Application Delivery&lt;/h2&gt;&lt;p&gt;Before embarking on your cloud native journey, it is essential to critically assess your organization’s readiness with regard to skill set so that you can choose the solutions that best fit the business objective you are seeking to meet in context of your ability to do so. There are seven key considerations to address when planning your microservices-based application delivery design:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Architecting your foundation the right way &lt;/li&gt;&lt;li&gt;Openly integrating with the cloud native ecosystem&lt;/li&gt;&lt;li&gt;Choosing the perfect proxy&lt;/li&gt;&lt;li&gt;Securing your applications and APIs&lt;/li&gt;&lt;li&gt;Enabling CI/CD and canary deployment with advanced traffic steering &lt;/li&gt;&lt;li&gt;Achieving holistic observability&lt;/li&gt;&lt;li&gt;Managing monoliths and microservices&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;A thorough evaluation of these seven considerations is best done with specific tasks and goals in mind. Depending on the size and diversity of your organization, you may need to account for a variety of stakeholders’ needs — that is, tasks and goals that differ based on role and responsibility. In context of application delivery, let’s survey the most common roles with a generalized view of their responsibilities and needs as stakeholders. To help facilitate a general understanding, we’ve grouped some roles when responsibilities overlap across multiple teams:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;h3&gt;Platform&lt;/h3&gt;&lt;p&gt;Platform teams are responsible for deploying and managing their Kubernetes infrastructure. They are responsible for platform governance, operational efficiency, and developer agility. The platform team is the connective tissue among various teams like DevOps, SREs, developers, and network operations teams and therefore must address and balance the unique needs of a diverse group of stakeholders, or influencers, when choosing cloud native solutions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;DevOps&lt;/h3&gt;&lt;p&gt;DevOps teams are responsible for continuously deploying applications. They care about faster development and release cycles, CI/CD and automation, and canary and progressive rollout.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;SREs&lt;/h3&gt;&lt;p&gt;Site reliability engineers must ensure application availability. They care about observability, incident response, and postmortems. SREs often act as architects for DevOps team and as such are often extensions of or directly belong to DevOps teams.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;Developers&lt;/h3&gt;&lt;p&gt;Development teams are responsible for application performance and are focused on ensuring a seamless end-user experience, including troubleshooting and microservices discovery and routing. Application performance and troubleshooting is shared responsibility among multiple teams.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;NetOps &lt;/h3&gt;&lt;p&gt;Network operations teams are responsible for ensuring stable, high-performing network connectivity, resiliency, security (e.g. web application firewalls and TLS), and are commonly focused on north-south traffic. They care about establishing networking policies and enforcing compliance; achieving management, control, and monitoring of the network; and gaining visibility for the purpose of resources and capacity planning.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;DevSecOps&lt;/h3&gt;&lt;p&gt;DevSecOps teams care about ensuring a strong security posture and rely on automated tools to orchestrate security for infrastructure, applications, containers, and API gateways. DevSecOps works very closley with NetOps team for holistic secure posture.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-6657bcb989b9255c6f56776e21b2b9ee.png&quot; align=&quot;center&quot; alt=&quot;Diverse Stakeholders have different needs&quot;/&gt;&lt;/div&gt;&lt;p&gt;Each role has nuanced responsibilities. Whether you have a single person or teams of people assigned to these roles, each role’s function needs to be accounted for.&lt;/p&gt;&lt;p&gt;It’s important to note that these stakeholders are undergoing a transformation in their responsibilities — or at least a transformation in the way in which they perform their responsibilities. Depending upon your organization’s size and structure, your stakeholders may have clearly defined lines of accountability or not among roles. As you adopt a cloud native approach to application deployment and delivery, you may find that the once-defined lines have blurred or that they are being redrawn. Be aware that the individuals who fill these roles typically go through a period of adjustment that can be unsettling until they adapt to their own and their teams’ new identities.&lt;/p&gt;&lt;p&gt;Your cloud native infrastructure should be as accommodating as possible to you, your team, and your collective responsibilities and process, so we encourage you to seek solutions that address the needs of all your stakeholders. Significantly, this includes evaluating different architectural models for as best fit for purpose. While every organization doesn’t travel the same road to cloud native, every journey starts with initial architectural decisions – decisions which have substantial bearing on your path to cloud native.&lt;/p&gt;&lt;h2&gt;Architecting Your Foundation the Right Way&lt;/h2&gt;&lt;p&gt;Cloud native novices and experts alike find that designing their application delivery architectures is the most challenging part of building microservices. Your architectural choices will have a significant impact on your cloud native journey. Some architectures will provide greater or fewer benefits while others will prove less or more difficult to implement.&lt;/p&gt;&lt;p&gt;Whether you are a cloud native pro or a novice, your selection of the right application delivery architecture will be one that balances the tradeoff between the greatest benefits and the simplicity needed to match your team’s skill set. Figure 1 highlights four common application delivery architecture deployment models:&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/Graph1-922f70168e5eac45ea8da896ca6e827d.png&quot; align=&quot;center&quot; alt=&quot;Graph&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;intro&quot;&gt;&lt;h3 align=&quot;center&quot;&gt;Tip: Traffic Directions&lt;/h3&gt;&lt;p&gt;North-south (N-S) traffic refers to traffic between clients outside the Kubernetes cluster and services inside the cluster, while east-west (E-W) traffic refers to traffic between services inside the Kubernetes cluster.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Each of the deployment models in Figure 1 come with their list of pros and cons and are typically the point of focus of different teams. So how do you choose the right architecture for your deployment? Given the needs of your stakeholders and the many specifics involved in managing both north-south (N-S) and east-west (E-W) traffic, it is critical to assess the four different architectures with respect to the following areas:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Application security &lt;/li&gt;&lt;li&gt;Observability &lt;/li&gt;&lt;li&gt;Continuous deployment &lt;/li&gt;&lt;li&gt;Scalability and performance &lt;/li&gt;&lt;li&gt;Open source tools integration &lt;/li&gt;&lt;li&gt;Service mesh &amp;amp; Istio  integration &lt;/li&gt;&lt;li&gt;IT skill set required &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Let’s examine each of the four deployment models.&lt;/p&gt;&lt;h3&gt;Two-Tier Ingress&lt;/h3&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/citrix-two-tier-ingress-5c271192e7c2aec7e0cc115d2796f66e.svg&quot; align=&quot;centre&quot; alt=&quot;Two Tier Ingress&quot;/&gt;&lt;/div&gt;&lt;p&gt;Two-tier ingress is the simplest architectural model to deploy to get teams up and running quickly. In this deployment model, Tthere are two layers of ADCs for N-S traffic ingress. The external ADC (at Tier 1), shown in green in Figure 2, provides L4 traffic management. Frequently, additional services are assigned to this ADC and can include web application firewall (WAF) and, secure sockets layer/transport layer security offload (SSL/TLS) functionality and authentication. A two-tier ingress deployment model is often managed by the existing network team (which is familiar with internet-facing traffic), and it can also be used as an ADC for other existing applications simultaneously.&lt;/p&gt;&lt;p&gt;The second ADC (Tier 2), shown in yellow in Figure 2, handles L7 load balancing for N-S traffic. It is managed by the platform team and is used within the Kubernetes cluster to direct traffic to the correct node. Layer 7 attributes, like information in the URL and HTTP headers, can be used for traffic load-balancing decisions. The yellow ADC continuously receives updates about the availability and respective IP addresses of the microservices pods within the Kubernetes cluster and can make decisions about which pod is best able to handle the request. Deployed as a container inside the Kubernetes cluster, the yellow ADC can be deployed as a container with Citrix CPX or with another similar product.&lt;/p&gt;&lt;p&gt;The E-W traffic between microservices pods is managed by kube-proxy, an open source, basic L4 load balancer with simple IP address-based round robin or least connection algorithm. kube-proxy lacks advanced features like Layer 7 load balancing, security, and observability, making it a blind spot for E-W traffic.&lt;/p&gt;&lt;b&gt;Pros of Two-Tier Ingress&lt;/b&gt;&lt;p&gt;With the right proxy, SSL termination can be done at the edge, and traffic can be inspected easily. This enables N-S traffic to be comprehensively secured across L3-7. ADC collects and reports telemetry on the N-S application traffic it sees, which means that this architecture provides robust observability for N-S traffic. ADC can also also integrate with CI/CD tools like Spinnaker to provide traffic management to N-S traffic for excellent continuous deployment capabilities.&lt;/p&gt;&lt;p&gt;Two-tier ingress scales very well for N-S traffic, as an example Citrix ADC reach hundreds of Gbps or even Tbps throughput through active-active clustering of ADCs if required. Integration with third-party tools like Prometheus, Grafana and Zipkin are supported out of the box with ADC, so you can continue to use the tools with which you are familiar to collect data and manage your systems for N-S traffic.&lt;/p&gt;&lt;p&gt;The bifurcated design of two-tier ingress makes it relatively simple to implement demarcation points for control. The network team can own and manage the green ADC, and the platform team can work inside the Kubernetes environment. Neither the network team nor the platform team needs extensive retraining, which makes this architecture quick to implement.&lt;/p&gt;&lt;b&gt;Cons of Two-Tier Ingress&lt;/b&gt;&lt;p&gt;The limitations of kube-proxy have made the use of third-party tools like Project Calico necessary to provide network policies, segmentation, and security support for inter-microservices communication. Similarly, kube-proxy&amp;#x27;s lack of detailed telemetry capabilities provides very little observability for E-W traffic. kube-proxy does not have the extensive APIs to integrate with continuous deployment tools, and its basic round-robin load balancing does not provide the granular load balancing needed to incorporate a CI/CD strategy inside the cluster. In general so you lack advanced load balancing tool set required to manage your inter-pod traffic. And kube-proxy does not currently integrate with service meshes, so there is no open source control plane integration for your E-W traffic management.&lt;/p&gt;&lt;p&gt;Overall, two-tier ingress provides excellent services for N-S traffic but lacks control for E-W traffic. It is a popular architecture because it is simple to implement and is frequently a starting point for enterprises on their cloud native journey to microservices adoption.&lt;/p&gt;&lt;div class=&quot;note&quot;&gt;By default, kube-proxy uses iptables (x_tables kernel modules), so it does not perform as well as other proxies. You can configure kube-proxy to run in different modes by setting the --proxy-mode flag. Setting this flag to ipvs enables IPVS mode (netfilter kernel modules), which provides a much improved performance and also enables choice of load balancing algorithm through the --ipvs-scheduler parameter beyond the default round robin algorithm.&lt;/div&gt;&lt;h3&gt;Unified Ingress&lt;/h3&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/citrix-unified-ingress-e24b73fc8f6ed89ecae0a73a8483f8d8.svg&quot; align=&quot;centre&quot; height=&quot;50%&quot; alt=&quot;Unified Ingress&quot;/&gt;&lt;/div&gt;&lt;p&gt;Unified ingress is very similar to the two-tier ingress architecture, except that it unifies two tiers of application delivery controllers (ADCs) for N-S traffic into one. Reducing an ADC tier effectively removes one hop of latency for N-S traffic.&lt;/p&gt;&lt;p&gt;Unified ingress has the same benefits and drawbacks as the two-tier ingress proxy architecture for security, observability, continuous deployment, scale and performance, open source tools support, and service mesh integration. Where it differs is in the skill sets required for implementation. With unified ingress, both the ADCs for N-S traffic and kube-proxy for the E-W traffic are managed by the platform team, who must be very network savvy to implement and manage this architecture.&lt;/p&gt;&lt;p&gt;A unified ingress proxy architecture is capable of participating in the Kubernetes cluster’s overlay network. This allows it to communicate directly with the microservices pods. Therefore, the platform team has to be knowledgeable about layers 3-7 of the network stack to take full advantage of this architecture.&lt;/p&gt;&lt;p&gt;In summary, unified ingress proxy architecture is moderately simple to deploy compared to service mesh (which we will cover next), and it offers robust capabilities for N-S traffic, but has very limited functionality for E-W traffic due to the limitations of kube-proxy. A network-savvy platform team is key for implementing this architecture.&lt;/p&gt;&lt;h3&gt;Service Mesh&lt;/h3&gt;&lt;p&gt;A service mesh is a dedicated infrastructure layer to control how different parts of an application communicate with one another with one another. The service mesh landscape has exploded because service meshes offer the best observability, security, and fine-grained management for traffic among microservices — that is, for E-W traffic. As an additional layer of infrastructure, service meshes do bear additional complexity as a tradeoff to the value they provide.&lt;/p&gt;&lt;div class=&quot;left&quot;&gt;&lt;img src=&quot;static/citrix-service-mesh-9424773542766dde1581086f1363a84b.svg&quot; align=&quot;centre&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;/div&gt;&lt;p&gt;A typical service mesh architecture is similar to the two-tier ingress proxy architecture for N-S traffic and offers the same rich benefits for N-S traffic. The key difference between service mesh and two-tier ingress, and where most of the value lies, is that service mesh employs a lightweight proxy as a sidecar to each microservice pod for E-W traffic. Microservices do not communicate directly: Communication among microservices happens via the sidecar, which enables inter-pod traffic to be inspected and managed as it enters and leaves the pods.&lt;/p&gt;&lt;p&gt;By using proxy sidecars, service mesh offers the highest levels of observability, security, and fine-grained traffic management and control among microservices. Additionally, select repetitive microservice functions like retries and encryption can be offloaded to the sidecars. Despite each sidecar’s being assigned its own memory and CPU resources, sidecars are typically lightweight.&lt;/p&gt;&lt;p&gt;You have the option to use Citrix CPX as a sidecar. Sidecars, which are managed by the platform team and attached to each pod, create a highly scalable, distributed architecture, but they also add complexity because they result in more moving parts.&lt;/p&gt;&lt;strong&gt;Pros of Service Mesh&lt;/strong&gt;&lt;p&gt;The advantages of service mesh for N-S traffic are similar to those for two-tier ingress. Service mesh, however, brings added advantages for E-W traffic.The presence of sidecars enables you to set security policies and control communication among your microservices. You can mandate things like authentication, encryption, and rate limiting for APIs among microservices if required.&lt;/p&gt;&lt;p&gt;Because E-W traffic is seen by the sidecars, there is much more telemetry to provide holistic observability for better insights and improved troubleshooting. Furthermore, Citrix CPX as a sidecar has well-defined APIs that integrate with myriad open source tools, so that you can use the observability tools you&amp;#x27;re used to. Sidecar APIs allow integration with CI/CD tools like Spinnaker.&lt;/p&gt;&lt;p&gt;Similarly, sidecars will integrate with a service mesh control plane like Istio for E-W traffic. Additionally, repetitive functions like retries and encryption can be offloaded to the sidecars. The distributed nature of the sidecar means that the solution is scalable for such features as observability and security.&lt;/p&gt;&lt;strong&gt;Cons of Service Mesh&lt;/strong&gt;&lt;p&gt;The biggest drawback of a service mesh architecture is the complexity of implementation (managing hundreds or thousands of sidecars is not trivial). The learning curve can be steep for the platform team because there are so many moving parts. A sidecar for every pod adds to CPU and memory needs. Similarly, sidecars add latency. Latency, which may affect application performance, varies with proxy implementation and can be easily measured by the open source tool, Meshery. Citrix CPX as a sidecar offers latency as low as 1ms, whereas other solutions can add much more.&lt;/p&gt;&lt;p&gt;Overall, a service mesh architecture provides excellent security, observability, and fine-grained traffic management for all traffic flows. The major downside is that it is complex to implement and manage.&lt;/p&gt;&lt;h3&gt;Service Mesh Lite&lt;/h3&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/citrix-service-mesh-lite-50ff6a2997a34a7d742ad9f5dd996e67.svg&quot; align=&quot;centre&quot; alt=&quot;Service Mesh Lite&quot;/&gt;&lt;/div&gt;&lt;p&gt;What if you want service mesh-like benefits with much less complexity?  The answer is service mesh lite, which is a variant of service mesh.&lt;/p&gt;&lt;p&gt;With a service mesh lite architecture, the ADC shown in green in Figure 5 is responsible for Layer 4-7 load balancing for N-S traffic to handle inbound requests and load balance to the right Kubernetes cluster. The green ADC may carry out SSL termination, web application firewalling, authentication, or other network services. It is managed by the networking team.&lt;/p&gt;&lt;p&gt;Depending on isolation and scale requirements, service mesh lite proxy architecture uses a single or several ADCs (shown in yellow in Figure 5) that proxy communications among microservices pods to manage inter-pod (E-W) traffic rather than using individual sidecars attached to each pod. Proxies can be deployed per node or per namespace and are managed by platform teams.&lt;/p&gt;&lt;strong&gt;Pros of Service Mesh Lite&lt;/strong&gt;&lt;p&gt;Service mesh lite provides many of the same benefits as service mesh but reduces the overall complexity by only having a small set of proxy instances per cluster to manage the inter-pod traffic. Passing all E-W traffic through a small set of proxies provides the same advanced policy control, security, and fine-grained traffic management of a service mesh proxy architecture without all the complexity.&lt;/p&gt;&lt;p&gt;Another advantage of service mesh lite is reduced latency as compared to service mesh because end user request goes through fewer  proxies. The main advantage is reduced complexity and the lower skill set required to implement compared to service mesh. Similar to two-tier ingress, the networking team can manage the green ADC, and the platform team can manage the yellow ADC. With service mesh lite, both teams can work in familiar environments and develop at their own speed.&lt;/p&gt;&lt;strong&gt;Cons of Service Mesh Lite&lt;/strong&gt;&lt;p&gt;Service mesh lite removes the implementation and management associated with service mesh, but the absence of a proxy per pod means that you sacrifice some functionality offload. For example, encryption for E-W must be implemented in each microservice, itself, if required.&lt;/p&gt;&lt;p&gt;Overall, service mesh lite provides most of the service mesh features but with reduced complexity and a lower IT skill set requirement. Many organizations who started with the two-tier ingress architecture find it an easy transition to service mesh lite for the added benefits it brings to their E-W traffic including better observability, enhanced security, better integration with open source tools, and support for continuous deployment.&lt;/p&gt;&lt;p&gt;So after reviewing the four architecture choices, you’re probably wondering: What ‘s the right architecture choice for my organization? There are no right or wrong answers. Like other architectural choices, proxy deployment models should be selected based on, in part, your application needs and your team structure and your team’s skill set.&lt;/p&gt;&lt;p&gt;Your model of proxy deployment is an important consideration, but just one of many when planning for your application delivery infrastructure. Ensuring that the application delivery components in your deployment are well-integrated into the cloud native ecosystem is your next consideration.&lt;/p&gt;&lt;h2&gt;Openly Integrating with the Cloud Native Ecosystem &lt;/h2&gt;&lt;p&gt;It’s imperative that your various application delivery tools and processes, including your proxy, be well-integrated into commonplace cloud native infrastructure. It’s no secret that much of today’s innovation happens in open source software. And clouds, both public and private, are built upon open source software. So in most cases, your infrastructure will be comprised of popular open source infrastructure and tools that you have picked up on your journey to cloud native. To the extent this is the case, you’ll find common integrations by categories in Figure below:&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/citrix-oss-integration-categories-a43533cd84808f3554b20eb4c7b6f1b7.svg&quot; align=&quot;center&quot; alt=&quot;&quot;/&gt;&lt;p&gt;Figure - Key categories of consideration for proxy integration with Kubernetes platforms and open source tools&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Cloud native environments make liberal use of open source software projects. Irrespective of which projects you use, suffice it to say that cloud native application delivery can’t be done with just containers. The combination of containers, container orchestration, and a service mesh will get you very far. And alongside a CI/CD system, these components are the most significant and ubiquitously used components of cloud native infrastructure. Integration with each of these categories of cloud native infrastructure is critical so that developers and operators can design and run systems that communicate and inter-operate as a whole. The fact that these bedrocks of cloud native infrastructure are open source unlocks their ability to be integrated.&lt;/p&gt;&lt;p&gt;At the heart of the cloud native ecosystem is the extensible and scalable orchestration infrastructure that is Kubernetes. The cloud native ecosystem (both open source and closed source) extends Kubernetes by writing custom resource definitions (CRDs) and associated controllers. The controllers and CRDs give operators a Kubernetes-native way to manage all parts of their platforms — both open source and closed source. This integration affords tool unification and powerful composable intent-based primitives that truly enable a software-defined platform.&lt;/p&gt;&lt;p&gt;Critical to the speed of delivery is an early investment in continuous integration/continuous delivery (CI/CD). It’s likely you have already wrangled continuous integration. Continuous deployment pipelines are your next step in seeing that changes to your source code automatically result in a new container being built and a new version of your microservice being tested and deployed to staging and eventually to production.&lt;/p&gt;&lt;p&gt;For many, the notion that CI/CD is an area of early investment is counterintuitive, and they find it hard to swallow the upfront engineering effort required to get a solid pipeline in place. The sooner CI/CD basics are implemented, however, the sooner the dividends start paying out. We will cover advanced continuous delivery considerations later in this white paper.&lt;/p&gt;&lt;p&gt;With cloud native infrastructure’s being inherently dynamic (in contrast to infrastructure not driven by APIs,) the ability to observe cloud native infrastructure and its workloads is also necessary. Software is written with functionality and debugging in mind. Most often, developers use logging as the primary method for debugging their applications. Integration with Elasticsearch and Kibana is key here.&lt;/p&gt;&lt;p&gt;Performance counters are another way to track application behavior and performance. Akin to SNMP for physical and virtual network monitoring, the equivalent cloud native “standard” is the use of Prometheus and Grafana, so it’s important that your application delivery solution integrate with these tools. Currently there is no recognized standard for cloud native application performance monitoring metrics.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;h3 align=&quot;center&quot;&gt;OpenMetrics&lt;/h3&gt;&lt;p&gt;The cloud native ecosystem needs a common format for the exchange of metrics. Observability pains grow with the release of each newly instrumented service that presents its own metric format. OpenMetrics is an effort to create an open standard for transmitting metrics at scale, with support for both text representation and protocolbBuffers. OpenMetrics builds on Prometheus’s exposition format, popular telemetry formats, and protocols used in infrastructure and application monitoring.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Irrespective of the metrics format, there are a few metrics that have been identified as key indicators of the health of a cloud native application (that is, the health of a service): latency, traffic, errors, and saturation. Your application delivery solution should assist in producing these signals as well as provide support for the tracing of your distributed, cloud native workloads.&lt;/p&gt;&lt;p&gt;The aforementioned integrations with open source tools enable loosely coupled systems that are resilient, manageable, and observable. Citrix ADC also embodies these characteristics. All of the infrastructure integrations detailed here depend upon APIs for interchange and interoperability. Cloud native applications, too, are centered around declarative APIs to interface with the infrastructure and serve user-facing workloads.&lt;/p&gt;&lt;p&gt;The endpoints that your APIs expose are now being managed by open source service meshes. Service meshes deliver the next generation of networking designed for cloud native applications. At the core of a service mesh is its data plane (its collection of proxies). Proxy selection criteria and deployment model tradeoffs are our next area of consideration.&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt; Check out the topic &lt;a href=&quot;/resources/service-mesh/choosing-the-perfect-proxy&quot;&gt;Choosing the Perfect Proxy&lt;/a&gt; to learn more! &lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Network Planes]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Network Planes",
  "thumbnail": "./network-planes.png",
  "category": "Network Planes",
  "type": "Case Study",
  "product": "Service Mesh Performance",
  "tags": ["Network Planes"],
  "featured": false,
  "published": true,
  "resource": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, " The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("h2", null, "Data Plane"), mdx("p", null, "Service proxies (gateways) are elements of the data plane. The number of proxies present depends on the number of services you\u2019re running and the design of the service mesh\u2019s deployment model. Some service mesh initiatives create their own proxies, while others rely on existing ones. Envoy is a popular choice as the data plane element."), mdx("strong", null, "BFE"), mdx("p", null, mdx("a", {
    href: "https://github.com/bfenetworks/bfe"
  }, "BFE"), " is a Golang-based modern proxy. HTTP, HTTPS, SPDY, HTTP2, WebSocket, TLS, and FastCGI are among the load balancing algorithms and multiple protocols it supports. Users can configure rule and content-based routing using BFE's own domain-specific language."), mdx("strong", null, "Envoy"), mdx("p", null, "Envoy is a modern proxy developed in C++. Envoy's initial success stemmed from its ability to hot-reload both its configuration and itself (update itself in place while handling connections). API gateways, ingress controllers, service meshes, and managed offerings by Cloud providers are just a few of the projects that have been built on top of Envoy. Istio, App Mesh, Kuma, Open Service Mesh, and other service meshes (discussed in the Control Plane section) have been built on top of Envoy."), mdx("strong", null, "Linkerdv2 "), mdx("p", null, "The linkerd2-proxy is explicitly built for the service mesh sidecar use case, Linkerd, can be significantly smaller and faster than Envoy-based service meshes. Rust was chosen as the implementation language because it is memory-safe and highly performant. This service proxy purports a sub-1ms p99 traffic latency. Open-source.  From Buoyant."), mdx("strong", null, "NGINX"), mdx("p", null, mdx("a", {
    href: "https://github.com/nginxinc/nginmesh"
  }, "nginMesh"), " project deploys NGINX as a sidecar proxy in Istio. Open source. Written primarily in C and Rust. From NGINX. "), mdx("br", null), mdx("p", null, "The following are a couple of early, and now antiquated, service mesh\u2013like projects, forming control planes around existing load-balancers:"), mdx("strong", null, "SmartStack"), mdx("p", null, "Comprising two components: Nerve for health-checking and Synapse for service discovery. Open source. From AirBnB. Written in Ruby."), mdx("strong", null, "Nelson"), mdx("p", null, "Takes advantage of integrations with Envoy, Prometheus, Vault, and Nomad to provide Git-centric, developer-driven deployments with automated build-and-release workflow. Open source. From Verizon Labs. Written in Scala."), mdx("h2", null, "Control Plane"), mdx("strong", null, "Consul "), mdx("p", null, "Announced service mesh capable intention in v1.5. Became a full service mesh in v1.8. Consul uses Envoy as its dataplane, offering multi-cluster federation. Open and closed source. From HashiCorp. Primarily written in Go."), mdx("strong", null, "Linkerd"), mdx("p", null, "Linkerd is hosted by the Cloud Native Computing Foundation (CNCF) and has undergone two major releases with significant architectural changes and an entirely different code base used between the two versions."), mdx("strong", null, "Linkerdv1"), mdx("p", null, "The first version of Linkerd was built on top of Twitter Finagle. Pronounced \u201Clinker-dee\u201D, it includes both a proxying data plane and control plane, Namerd (\u201Cnamer-dee\u201D), all in one package. Open source. Written primarily in Scala."), mdx("li", null, "Data plane can be deployed in a node proxy model (commonly)  or in a proxy sidecar (not common). Proven scale, having served more than one trillion service requests."), mdx("li", null, "Supports services running within container orchestrators and as standalone virtual or physical machines."), mdx("li", null, "Service discovery abstractions to unite multiple systems."), mdx("strong", null, "Linkerdv2"), mdx("p", null, "The second major version of Linkerd is based on a project formerly known as Conduit, a Kubernetes-native and Kubernetes-only service mesh announced as a project in December 2017. In contrast to Istio and in learning from Linkerdv1, Linkerdv2\u2019s design principles revolve around a minimalist architecture and zero configuration philosophy, optimizing for streamlined setup."), mdx("li", null, "Open Source. From Buoyant. Control-plane written in Go. Hosted by the CNCF."), mdx("li", null, "Support for gRPC, HTTP/2, and HTTP/1.x requests plus all TCP traffic. Currently only supports Kubernetes."), mdx("strong", null, "Istio"), mdx("p", null, "Announced as a project in May 2017, Istio is considered to be a \u201Csecond explosion after Kubernetes\u201D given its architecture and surface area of functional aspiration."), mdx("li", null, "Supports services running within container orchestrators and as standalone virtual or physical machines."), mdx("li", null, "Was the first service mesh to promote the model of supporting automatic injection of service proxies as sidecars using Kubernetes Admission controller."), mdx("li", null, "Many projects have been built around Istio. Commercial, closed source offerings built around Istio include: AspenMesh, VMware Tanzu Service Mesh, Octarine (acquired by VMware in 2020). Commercial, closed source offerings built inside of Istio include Citrix Service Mesh To be built \u201Cwithin Istio\u201D means to offer the Istio control plane with an alternative service proxy. Citrix Service Mesh displaces Envoy with CPX. Open source, data plane proxy, MOSN released support for running under Istio as the control plane, while displacing Envoy as the service proxy."), mdx("li", null, "Many projects have been built within Istio."), mdx("li", null, "Mesher. Layer 7 (L7) proxy that runs as a sidecar deployable on Huawei Cloud Service Engine. Open source. Written primarily in Go. From Huawei."), mdx("strong", null, "NGINX Service Mesh "), mdx("p", null, "NGINX Service Mesh is a more recent arrival into the service mesh arena, having released in September 2020. Using an Nginx Plus augmented to interface with Kubernetes natively as its dataplane, supports ingress and egress gateways through NGINX Plus Kubernetes Ingress Controllers. NGINX Service Mesh offers its control plane as a CLI, meshctl, using the Service Mesh Interface (SMI) specification as its API. Both Open and closed source. From NGINX. Primarily written in C."), mdx("strong", null, "Others including Open Service Mesh, Maesh, Kuma, App Mesh..."), mdx("p", null, "This list is meant to give you an idea of the wide range of service meshes that are currently available. A complete list of service meshes and their details may be found in the Layer5 ", mdx(Link, {
    to: "/landscape",
    mdxType: "Link"
  }, "service mesh landscape"), ", maintained by the community."), mdx("h2", null, "Management Plane"), mdx("p", null, "The management plane sits a level above the control plane. It can perform various tasks such as operational patterns, business system integration, and application logic enhancement while functioning across different service meshes. A management plane can perform workload and mesh configuration validation, whether in preparation for onboarding a workload into the mesh or as you upgrade to new versions of components running your control and data planes or new versions of your applications. Management planes help organizations running a service mesh get the most out of their investment. Performance management is one part of maintaining service meshes, a function at which Meshery excels."), mdx("strong", null, "Meshery"), mdx("p", null, "The service mesh management plane for adopting, operating and developing on different service meshes. Meshery integrates business processes and application logic into service meshes by deploying custom WebAssembly (WASM) modules as filters in Envoy-based data planes. It provides governance, policy and performance and configuration management of service meshes with a visual topology for designing service mesh deployments and managing the fine-grained traffic control of a service mesh. - Open source. Created by Layer5. Primarily written in Go."), mdx("div", {
    className: "fact"
  }, "Service Mesh Linguistics", mdx("p", null, "As the lingua franca of the cloud-native ecosystem, Go is certainly prevalent and you might expect most service mesh projects to be written in Go. By the nature of their task, data planes must be highly efficient in the interception, introspection, and rewriting of network traffic. As a data plane component, Envoy is written in C++11 because it provides excellent performance (surprisingly, some say it provides a great developer experience). Rust has found its way into service meshes as a growing language (and something of a C++ competitor). Because of its properties around efficiency (outperforming Go) and memory safety (when written to be so) without garbage collection, Rust has been used for Linkerdv2\u2019s data plane component, for the former nginMesh\u2019s Mixer module (see \u201CHow to customize an Istio service mesh\u201D), and is now being used in WebAssembly programs as data plane filters (see \u201CWrite WASM filters for Envoy in Rust and deploy with Consul\u201D)."))));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/network-planes/network-planes</link><guid isPermaLink="false">https://layer5.io/resources/network-planes/network-planes</guid><enclosure url="https://layer5.io/static/17825725d58d3f0c12d511f863833f64/network-planes.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt; The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Data Plane&lt;/h2&gt;&lt;p&gt;Service proxies (gateways) are elements of the data plane. The number of proxies present depends on the number of services you’re running and the design of the service mesh’s deployment model. Some service mesh initiatives create their own proxies, while others rely on existing ones. Envoy is a popular choice as the data plane element.&lt;/p&gt;&lt;strong&gt;BFE&lt;/strong&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/bfenetworks/bfe&quot;&gt;BFE&lt;/a&gt; is a Golang-based modern proxy. HTTP, HTTPS, SPDY, HTTP2, WebSocket, TLS, and FastCGI are among the load balancing algorithms and multiple protocols it supports. Users can configure rule and content-based routing using BFE&amp;#x27;s own domain-specific language.&lt;/p&gt;&lt;strong&gt;Envoy&lt;/strong&gt;&lt;p&gt;Envoy is a modern proxy developed in C++. Envoy&amp;#x27;s initial success stemmed from its ability to hot-reload both its configuration and itself (update itself in place while handling connections). API gateways, ingress controllers, service meshes, and managed offerings by Cloud providers are just a few of the projects that have been built on top of Envoy. Istio, App Mesh, Kuma, Open Service Mesh, and other service meshes (discussed in the Control Plane section) have been built on top of Envoy.&lt;/p&gt;&lt;strong&gt;Linkerdv2 &lt;/strong&gt;&lt;p&gt;The linkerd2-proxy is explicitly built for the service mesh sidecar use case, Linkerd, can be significantly smaller and faster than Envoy-based service meshes. Rust was chosen as the implementation language because it is memory-safe and highly performant. This service proxy purports a sub-1ms p99 traffic latency. Open-source.  From Buoyant.&lt;/p&gt;&lt;strong&gt;NGINX&lt;/strong&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/nginxinc/nginmesh&quot;&gt;nginMesh&lt;/a&gt; project deploys NGINX as a sidecar proxy in Istio. Open source. Written primarily in C and Rust. From NGINX. &lt;/p&gt;&lt;br/&gt;&lt;p&gt;The following are a couple of early, and now antiquated, service mesh–like projects, forming control planes around existing load-balancers:&lt;/p&gt;&lt;strong&gt;SmartStack&lt;/strong&gt;&lt;p&gt;Comprising two components: Nerve for health-checking and Synapse for service discovery. Open source. From AirBnB. Written in Ruby.&lt;/p&gt;&lt;strong&gt;Nelson&lt;/strong&gt;&lt;p&gt;Takes advantage of integrations with Envoy, Prometheus, Vault, and Nomad to provide Git-centric, developer-driven deployments with automated build-and-release workflow. Open source. From Verizon Labs. Written in Scala.&lt;/p&gt;&lt;h2&gt;Control Plane&lt;/h2&gt;&lt;strong&gt;Consul &lt;/strong&gt;&lt;p&gt;Announced service mesh capable intention in v1.5. Became a full service mesh in v1.8. Consul uses Envoy as its dataplane, offering multi-cluster federation. Open and closed source. From HashiCorp. Primarily written in Go.&lt;/p&gt;&lt;strong&gt;Linkerd&lt;/strong&gt;&lt;p&gt;Linkerd is hosted by the Cloud Native Computing Foundation (CNCF) and has undergone two major releases with significant architectural changes and an entirely different code base used between the two versions.&lt;/p&gt;&lt;strong&gt;Linkerdv1&lt;/strong&gt;&lt;p&gt;The first version of Linkerd was built on top of Twitter Finagle. Pronounced “linker-dee”, it includes both a proxying data plane and control plane, Namerd (“namer-dee”), all in one package. Open source. Written primarily in Scala.&lt;/p&gt;&lt;li&gt;Data plane can be deployed in a node proxy model (commonly)  or in a proxy sidecar (not common). Proven scale, having served more than one trillion service requests.&lt;/li&gt;&lt;li&gt;Supports services running within container orchestrators and as standalone virtual or physical machines.&lt;/li&gt;&lt;li&gt;Service discovery abstractions to unite multiple systems.&lt;/li&gt;&lt;strong&gt;Linkerdv2&lt;/strong&gt;&lt;p&gt;The second major version of Linkerd is based on a project formerly known as Conduit, a Kubernetes-native and Kubernetes-only service mesh announced as a project in December 2017. In contrast to Istio and in learning from Linkerdv1, Linkerdv2’s design principles revolve around a minimalist architecture and zero configuration philosophy, optimizing for streamlined setup.&lt;/p&gt;&lt;li&gt;Open Source. From Buoyant. Control-plane written in Go. Hosted by the CNCF.&lt;/li&gt;&lt;li&gt;Support for gRPC, HTTP/2, and HTTP/1.x requests plus all TCP traffic. Currently only supports Kubernetes.&lt;/li&gt;&lt;strong&gt;Istio&lt;/strong&gt;&lt;p&gt;Announced as a project in May 2017, Istio is considered to be a “second explosion after Kubernetes” given its architecture and surface area of functional aspiration.&lt;/p&gt;&lt;li&gt;Supports services running within container orchestrators and as standalone virtual or physical machines.&lt;/li&gt;&lt;li&gt;Was the first service mesh to promote the model of supporting automatic injection of service proxies as sidecars using Kubernetes Admission controller.&lt;/li&gt;&lt;li&gt;Many projects have been built around Istio. Commercial, closed source offerings built around Istio include: AspenMesh, VMware Tanzu Service Mesh, Octarine (acquired by VMware in 2020). Commercial, closed source offerings built inside of Istio include Citrix Service Mesh To be built “within Istio” means to offer the Istio control plane with an alternative service proxy. Citrix Service Mesh displaces Envoy with CPX. Open source, data plane proxy, MOSN released support for running under Istio as the control plane, while displacing Envoy as the service proxy.&lt;/li&gt;&lt;li&gt;Many projects have been built within Istio.&lt;/li&gt;&lt;li&gt;Mesher. Layer 7 (L7) proxy that runs as a sidecar deployable on Huawei Cloud Service Engine. Open source. Written primarily in Go. From Huawei.&lt;/li&gt;&lt;strong&gt;NGINX Service Mesh &lt;/strong&gt;&lt;p&gt;NGINX Service Mesh is a more recent arrival into the service mesh arena, having released in September 2020. Using an Nginx Plus augmented to interface with Kubernetes natively as its dataplane, supports ingress and egress gateways through NGINX Plus Kubernetes Ingress Controllers. NGINX Service Mesh offers its control plane as a CLI, meshctl, using the Service Mesh Interface (SMI) specification as its API. Both Open and closed source. From NGINX. Primarily written in C.&lt;/p&gt;&lt;strong&gt;Others including Open Service Mesh, Maesh, Kuma, App Mesh...&lt;/strong&gt;&lt;p&gt;This list is meant to give you an idea of the wide range of service meshes that are currently available. A complete list of service meshes and their details may be found in the Layer5 &lt;a href=&quot;/landscape&quot;&gt;service mesh landscape&lt;/a&gt;, maintained by the community.&lt;/p&gt;&lt;h2&gt;Management Plane&lt;/h2&gt;&lt;p&gt;The management plane sits a level above the control plane. It can perform various tasks such as operational patterns, business system integration, and application logic enhancement while functioning across different service meshes. A management plane can perform workload and mesh configuration validation, whether in preparation for onboarding a workload into the mesh or as you upgrade to new versions of components running your control and data planes or new versions of your applications. Management planes help organizations running a service mesh get the most out of their investment. Performance management is one part of maintaining service meshes, a function at which Meshery excels.&lt;/p&gt;&lt;strong&gt;Meshery&lt;/strong&gt;&lt;p&gt;The service mesh management plane for adopting, operating and developing on different service meshes. Meshery integrates business processes and application logic into service meshes by deploying custom WebAssembly (WASM) modules as filters in Envoy-based data planes. It provides governance, policy and performance and configuration management of service meshes with a visual topology for designing service mesh deployments and managing the fine-grained traffic control of a service mesh. - Open source. Created by Layer5. Primarily written in Go.&lt;/p&gt;&lt;div class=&quot;fact&quot;&gt;Service Mesh Linguistics&lt;p&gt;As the lingua franca of the cloud-native ecosystem, Go is certainly prevalent and you might expect most service mesh projects to be written in Go. By the nature of their task, data planes must be highly efficient in the interception, introspection, and rewriting of network traffic. As a data plane component, Envoy is written in C++11 because it provides excellent performance (surprisingly, some say it provides a great developer experience). Rust has found its way into service meshes as a growing language (and something of a C++ competitor). Because of its properties around efficiency (outperforming Go) and memory safety (when written to be so) without garbage collection, Rust has been used for Linkerdv2’s data plane component, for the former nginMesh’s Mixer module (see “How to customize an Istio service mesh”), and is now being used in WebAssembly programs as data plane filters (see “Write WASM filters for Envoy in Rust and deploy with Consul”).&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh Architecture and Components]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Service Mesh Architecture and Components",
  "thumbnail": "./figure2.png",
  "category": "Service Mesh",
  "tags": ["Service mesh", "Network Planes"],
  "featured": false,
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("p", null, "Service mesh architectures typically consist of three planes: a management plane, a control plane, and a data plane. The analogy between how physical networks (and their equipment) are designed and managed along with\xA0the concept of these three planes immediately resonates with network engineers.\xA0 The OSI model is another type of training that network engineers receive. For those who haven't seen the OSI model in a while, Figure 1 serves as a refresher."), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Planes,
    align: "right",
    alt: "Network Planes"
  }), mdx("p", null, "Figure 1: Physical networking versus software-defined networking planes")), mdx("p", null, "Let\u2019s contrast physical networking planes and network topologies with those of service meshes:"), mdx("h3", null, "Physical network planes"), mdx("p", null, "The application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). A forwarding information base (FIB) is a basic, dynamic table that maps a media access control address (MAC address) to a physical network port, allowing traffic to be transmitted at wire speed (using ASICs) to the next device."), mdx("p", null, "The physical networking control plane is the\xA0logical entity that is linked to router processes and functions and is responsible for generating and maintaining necessary intelligence about the state of the network (topology) and the router's interfaces. The control plane includes network protocols, such as routing, signaling, and link-state protocols that are used to build and maintain the operational state of the network and provide IP connectivity between IP hosts.\xA0\xA0 As physical network control planes run in-band with network traffic, they are vulnerable to Denial of service (DoS) attacks, which can result in:"), mdx("ul", null, mdx("li", null, "Exhaustion of memory and/or buffer resources."), mdx("li", null, "Loss of routing protocol updates and keepalives."), mdx("li", null, "Slow or blocked access to interactive management sessions."), mdx("li", null, "High CPU utilization."), mdx("li", null, "Routing instability, interrupted network reachability, or inconsistent packet delivery.")), mdx("p", null, "The physical networking management plane is a logical entity that specifies the traffic used to access, manage, and monitor all network elements via protocols such as SNMP, SSH, HTTPS, and\xA0Telnet. All network provisioning, maintenance, and monitoring operations are supported by the management plane. Although control plane network traffic is handled in-band with all other data plane traffic, management plane traffic\xA0can be carried over an out-of-band (OOB) management network to enable separate reachability if the primary in-band IP path is unavailable (and create a security boundary). Restricting management plane access to devices on trusted networks is critical."), mdx("p", null, "Physical networking control and data planes are tightly coupled and generally vendor-provided as a proprietary integration of hardware and firmware. Software-defined networking (SDN) has done much to standardize and decouple. OpenvSwitch and OpenDaylight are two examples of SDN projects. We\u2019ll see that control and data planes of service meshes are not necessarily tightly coupled."), mdx("div", {
    className: "left"
  }, mdx("img", {
    src: Topology,
    align: "right",
    alt: "Mesh Topology"
  }), mdx("p", null, "Figure 2: Mesh topology\u2014fully connected network nodes")), mdx("h3", null, "Physical network topologies"), mdx("p", null, "Star, spoke-and-hub, tree (also called\xA0hierarchical), and mesh are some of the most used physical networking topologies. Nodes in mesh networks connect directly and non-hierarchically, such that each node is connected to an indefinite number (typically as many as possible or as needed dynamically) of neighbour nodes, allowing at least one path from a given node to any other node to route data efficiently ."), mdx("p", null, "Wireless is the canonical use case for physical mesh networks in which the networking medium is sensitive to line-of-sight, weather-induced, or other disruptions, and so reliability is a top priority. Mesh networks typically self-configure, allowing\xA0dynamic task distribution. This ability is especially important to mitigate\xA0the risk of failure (improving resiliency) and reacting to continuously changing topologies. It's easy to see why this network topology\xA0is the preferred design for service mesh architectures."), mdx("h3", null, "Service mesh network planes"), mdx("p", null, "Service mesh architectures typically employ the same three networking planes: data, control, and management. "), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Architecture,
    align: "right",
    alt: "Service mesh architecture"
  }), mdx("p", null, "Figure 3: An example of service mesh architecture. In Conduit\u2019s architecture, control and data planes divide in-band and out-of-band responsibility for service traffic")), mdx("p", null, "A service mesh data plane (also known as the proxying layer) intercepts all packets in a request and performs health checks, routing, load balancing, authentication, authorization, and generation of observable signals. Service proxies are transparently inserted, and applications are oblivious of the data plane's existence when they conduct service-to-service calls. Intra-service communication, as well as inbound (ingress) and outbound (egress) service mesh traffic, are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling prior to sending (or not sending) along to the application.\xA0 Traffic is transparently intercepted and redirected to the service proxy in order to reroute traffic from the service proxy to the service application. The service proxy intercepts and redirects traffic between\xA0the service proxy and service application places the service application\u2019s container onto a network it would otherwise not be on.\xA0All traffic to and from the service application is seen by the service proxy.\xA0 Service proxies are the building blocks of service mesh data planes."), mdx("div", {
    className: "fact"
  }, "Traffic Interception and Redirection:", mdx("p", null, "The technology utilised to intercept and redirect traffic varies between service meshes. Some meshes allow you the option of using iptables, IPVS, or eBPF to transparently proxy requests between clients and service applications. Other service mesh proxies operate in a less transparent manner, requiring application traffic to be configured to direct their traffic to the proxy. The operating system type and kernel version used for the service mesh deployment are constrained by the choice of each of these technologies, which influences the speed with which packets are processed.")), mdx("p", null, "Envoy is one of the most widely used proxy in service mesh data planes. It's also common to see it deployed\xA0as a load balancer or ingress gateway. The proxies used in service mesh data planes are highly intelligent.\xA0 In order to manipulate network packets\xA0(including application level data), they\xA0may include any number of protocol-specific filters . Extending data plane capabilities with technology advancements like WebAssembly allows service meshes to inject additional logic into requests while simultaneously handling large traffic loads."), mdx("p", null, "When the number of proxies becomes unmanageable or when a single point of visibility and control is required, a service mesh control plane is essential. Control planes offer policy and configuration for the services in the mesh, transforming a set of isolated, stateless proxies into a service mesh. Control planes run out-of-band and do not directly touch any network packets in the mesh. Control planes usually include a command-line interface (CLI) and a user interface to interact with, both of which provide access to a centralised API for regulating proxy behaviour holistically.\xA0You can use the control plane's APIs to automate changes to its configuration (for example, using a continuous integration/continuous deployment pipeline), where configuration is generally version controlled and updated."), mdx("div", {
    className: "fact"
  }, "Proxies are generally considered stateless, but this is a thought-provoking concept. In the way in which proxies are generally informed by the control plane of the presence of services, mesh topology updates, traffic and authorization policy, and so on, proxies cache the state of the mesh but aren\u2019t regarded as the source of truth for the state of the mesh."), mdx("p", null, "We can see how the data and control planes are packaged and deployed in Linkerd (pronounced \"linker-dee\") and Istio (pronounced \"Ist-tee-oh\"), two prominent open source service meshes. In terms of packaging, Linkerdv1 contains both its proxying components (linkerd) and its control plane (namerd) packaged together simply as \u201CLinkerd,\u201D and Istio brings a collection of control plane components (Galley, Pilot, and Citadel) to pair by default with Envoy (a data plane) packaged together as \u201CIstio.\u201D Envoy is often labeled a service mesh, inappropriately so, because it takes packaging with a control plane to form a service mesh."), mdx("p", null, "A service mesh management plane is a higher order level of control as shown in Figure 4. A management plane may provide a variety of functions. As such, implementations vary in their functionality: some focusing on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, providing insight across a collection of diverse meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control."), mdx("div", {
    className: "left"
  }, mdx("img", {
    src: Meshery,
    align: "right",
    alt: "Meshery"
  }), mdx("p", null, "Figure 4: Meshery, the service mesh management plane\u2019s architecture.")), mdx("p", null, "A service mesh management plane is a higher order level of control. A management plane can provide\xA0various functions. As a result, implementations differ in functionality, with some focused on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, which provides insight across a set of meshes.\xA0Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control."), mdx("p", null, "In terms of deployments, data planes, such as Linkerdv2, contain proxies that are created as part of the project and are not designed to be configured by hand, but rather to have their behaviour completely controlled by the control plane. Other service meshes, such as Istio, prefer not to develop their own proxy and instead ingest and utilise independent proxies (separate projects), simplifying proxy selection and deployment outside of the mesh(standalone). Control planes are often deployed in a separate \"system\" namespace,\xA0using\xA0Kubernetes as the example infrastructure. Depending on how closely they integrate with non-containerized workloads and a business's backend systems, management planes are deployed both on and off cluster.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-architecture-and-components</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-architecture-and-components</guid><enclosure url="https://layer5.io/static/bed9d3fcfe69a84ae0787ff2ca8845aa/figure2.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Service mesh architectures typically consist of three planes: a management plane, a control plane, and a data plane. The analogy between how physical networks (and their equipment) are designed and managed along with the concept of these three planes immediately resonates with network engineers.  The OSI model is another type of training that network engineers receive. For those who haven&amp;#x27;t seen the OSI model in a while, Figure 1 serves as a refresher.&lt;/p&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/figure1-6e4093aff217b5c671eada947906c711.png&quot; align=&quot;right&quot; alt=&quot;Network Planes&quot;/&gt;&lt;p&gt;Figure 1: Physical networking versus software-defined networking planes&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Let’s contrast physical networking planes and network topologies with those of service meshes:&lt;/p&gt;&lt;h3&gt;Physical network planes&lt;/h3&gt;&lt;p&gt;The application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB). A forwarding information base (FIB) is a basic, dynamic table that maps a media access control address (MAC address) to a physical network port, allowing traffic to be transmitted at wire speed (using ASICs) to the next device.&lt;/p&gt;&lt;p&gt;The physical networking control plane is the logical entity that is linked to router processes and functions and is responsible for generating and maintaining necessary intelligence about the state of the network (topology) and the router&amp;#x27;s interfaces. The control plane includes network protocols, such as routing, signaling, and link-state protocols that are used to build and maintain the operational state of the network and provide IP connectivity between IP hosts.   As physical network control planes run in-band with network traffic, they are vulnerable to Denial of service (DoS) attacks, which can result in:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Exhaustion of memory and/or buffer resources.&lt;/li&gt;&lt;li&gt;Loss of routing protocol updates and keepalives.&lt;/li&gt;&lt;li&gt;Slow or blocked access to interactive management sessions.&lt;/li&gt;&lt;li&gt;High CPU utilization.&lt;/li&gt;&lt;li&gt;Routing instability, interrupted network reachability, or inconsistent packet delivery.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The physical networking management plane is a logical entity that specifies the traffic used to access, manage, and monitor all network elements via protocols such as SNMP, SSH, HTTPS, and Telnet. All network provisioning, maintenance, and monitoring operations are supported by the management plane. Although control plane network traffic is handled in-band with all other data plane traffic, management plane traffic can be carried over an out-of-band (OOB) management network to enable separate reachability if the primary in-band IP path is unavailable (and create a security boundary). Restricting management plane access to devices on trusted networks is critical.&lt;/p&gt;&lt;p&gt;Physical networking control and data planes are tightly coupled and generally vendor-provided as a proprietary integration of hardware and firmware. Software-defined networking (SDN) has done much to standardize and decouple. OpenvSwitch and OpenDaylight are two examples of SDN projects. We’ll see that control and data planes of service meshes are not necessarily tightly coupled.&lt;/p&gt;&lt;div class=&quot;left&quot;&gt;&lt;img src=&quot;static/figure2-1a9f1b412652dfd917052e9ac2854c73.png&quot; align=&quot;right&quot; alt=&quot;Mesh Topology&quot;/&gt;&lt;p&gt;Figure 2: Mesh topology—fully connected network nodes&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Physical network topologies&lt;/h3&gt;&lt;p&gt;Star, spoke-and-hub, tree (also called hierarchical), and mesh are some of the most used physical networking topologies. Nodes in mesh networks connect directly and non-hierarchically, such that each node is connected to an indefinite number (typically as many as possible or as needed dynamically) of neighbour nodes, allowing at least one path from a given node to any other node to route data efficiently .&lt;/p&gt;&lt;p&gt;Wireless is the canonical use case for physical mesh networks in which the networking medium is sensitive to line-of-sight, weather-induced, or other disruptions, and so reliability is a top priority. Mesh networks typically self-configure, allowing dynamic task distribution. This ability is especially important to mitigate the risk of failure (improving resiliency) and reacting to continuously changing topologies. It&amp;#x27;s easy to see why this network topology is the preferred design for service mesh architectures.&lt;/p&gt;&lt;h3&gt;Service mesh network planes&lt;/h3&gt;&lt;p&gt;Service mesh architectures typically employ the same three networking planes: data, control, and management. &lt;/p&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/figure3-58e1728df81b55a288fc15de629455ce.png&quot; align=&quot;right&quot; alt=&quot;Service mesh architecture&quot;/&gt;&lt;p&gt;Figure 3: An example of service mesh architecture. In Conduit’s architecture, control and data planes divide in-band and out-of-band responsibility for service traffic&lt;/p&gt;&lt;/div&gt;&lt;p&gt;A service mesh data plane (also known as the proxying layer) intercepts all packets in a request and performs health checks, routing, load balancing, authentication, authorization, and generation of observable signals. Service proxies are transparently inserted, and applications are oblivious of the data plane&amp;#x27;s existence when they conduct service-to-service calls. Intra-service communication, as well as inbound (ingress) and outbound (egress) service mesh traffic, are handled by data planes. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling prior to sending (or not sending) along to the application.  Traffic is transparently intercepted and redirected to the service proxy in order to reroute traffic from the service proxy to the service application. The service proxy intercepts and redirects traffic between the service proxy and service application places the service application’s container onto a network it would otherwise not be on. All traffic to and from the service application is seen by the service proxy.  Service proxies are the building blocks of service mesh data planes.&lt;/p&gt;&lt;div class=&quot;fact&quot;&gt;Traffic Interception and Redirection:&lt;p&gt;The technology utilised to intercept and redirect traffic varies between service meshes. Some meshes allow you the option of using iptables, IPVS, or eBPF to transparently proxy requests between clients and service applications. Other service mesh proxies operate in a less transparent manner, requiring application traffic to be configured to direct their traffic to the proxy. The operating system type and kernel version used for the service mesh deployment are constrained by the choice of each of these technologies, which influences the speed with which packets are processed.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Envoy is one of the most widely used proxy in service mesh data planes. It&amp;#x27;s also common to see it deployed as a load balancer or ingress gateway. The proxies used in service mesh data planes are highly intelligent.  In order to manipulate network packets (including application level data), they may include any number of protocol-specific filters . Extending data plane capabilities with technology advancements like WebAssembly allows service meshes to inject additional logic into requests while simultaneously handling large traffic loads.&lt;/p&gt;&lt;p&gt;When the number of proxies becomes unmanageable or when a single point of visibility and control is required, a service mesh control plane is essential. Control planes offer policy and configuration for the services in the mesh, transforming a set of isolated, stateless proxies into a service mesh. Control planes run out-of-band and do not directly touch any network packets in the mesh. Control planes usually include a command-line interface (CLI) and a user interface to interact with, both of which provide access to a centralised API for regulating proxy behaviour holistically. You can use the control plane&amp;#x27;s APIs to automate changes to its configuration (for example, using a continuous integration/continuous deployment pipeline), where configuration is generally version controlled and updated.&lt;/p&gt;&lt;div class=&quot;fact&quot;&gt;Proxies are generally considered stateless, but this is a thought-provoking concept. In the way in which proxies are generally informed by the control plane of the presence of services, mesh topology updates, traffic and authorization policy, and so on, proxies cache the state of the mesh but aren’t regarded as the source of truth for the state of the mesh.&lt;/div&gt;&lt;p&gt;We can see how the data and control planes are packaged and deployed in Linkerd (pronounced &amp;quot;linker-dee&amp;quot;) and Istio (pronounced &amp;quot;Ist-tee-oh&amp;quot;), two prominent open source service meshes. In terms of packaging, Linkerdv1 contains both its proxying components (linkerd) and its control plane (namerd) packaged together simply as “Linkerd,” and Istio brings a collection of control plane components (Galley, Pilot, and Citadel) to pair by default with Envoy (a data plane) packaged together as “Istio.” Envoy is often labeled a service mesh, inappropriately so, because it takes packaging with a control plane to form a service mesh.&lt;/p&gt;&lt;p&gt;A service mesh management plane is a higher order level of control as shown in Figure 4. A management plane may provide a variety of functions. As such, implementations vary in their functionality: some focusing on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, providing insight across a collection of diverse meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.&lt;/p&gt;&lt;div class=&quot;left&quot;&gt;&lt;img src=&quot;static/figure4-b3eeda7dcac8dcf72d83a4cc33156ded.png&quot; align=&quot;right&quot; alt=&quot;Meshery&quot;/&gt;&lt;p&gt;Figure 4: Meshery, the service mesh management plane’s architecture.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;A service mesh management plane is a higher order level of control. A management plane can provide various functions. As a result, implementations differ in functionality, with some focused on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, which provides insight across a set of meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.&lt;/p&gt;&lt;p&gt;In terms of deployments, data planes, such as Linkerdv2, contain proxies that are created as part of the project and are not designed to be configured by hand, but rather to have their behaviour completely controlled by the control plane. Other service meshes, such as Istio, prefer not to develop their own proxy and instead ingest and utilise independent proxies (separate projects), simplifying proxy selection and deployment outside of the mesh(standalone). Control planes are often deployed in a separate &amp;quot;system&amp;quot; namespace, using Kubernetes as the example infrastructure. Depending on how closely they integrate with non-containerized workloads and a business&amp;#x27;s backend systems, management planes are deployed both on and off cluster.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh Fundamentals]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Service Mesh Fundamentals",
  "thumbnail": "../service-mesh.svg",
  "category": "Service Mesh",
  "tags": ["Service mesh"],
  "featured": false,
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("p", null, "Many emerging technologies are based on or reincarnated from prior thinking and approaches to computing and networking paradigms. Why is this phenomenon required? We'll look to the microservices and containers movement for service meshes, a cloud-native approach to design scalable, independently supplied services. What was previously internal application communications have become a mesh of service-to-service remote procedure calls (RPCs) transported via networks thanks to microservices. Microservices democratize language and technology choice across independent service teams that generate new features quickly as they iteratively and continuously provide software(typically as a service). The most crucial driver of microservices as an architectural model is the decoupling of engineering teams and their enhanced speed."), mdx("h3", null, "Operating Many Services"), mdx("p", null, "The initial couple of microservices are relatively simple to deliver and operate\u2014at least in comparison to organizations' challenges when they first use many microservices. Whether that \"many\" is three or one hundred, a major technological issue will inevitably arise. To relieve microservices headaches, several remedies are prescribed; one notable example is the use of client libraries. In microservices environments, language and framework-specific client libraries, whether pre-existing or generated, are utilized to address distributed systems challenges. Many teams first explore their path to a service mesh in these situations. The sheer volume of services that must be managed on an individual, distributed basis (rather than centrally as with monoliths) and the challenges of ensuring their reliability, observability, and security cannot be met with outmoded paradigms, necessitating the need to reincarnate prior thinking and approaches. It is necessary to adapt new tools and techniques."), mdx("p", null, "Since microservices are distributed (often ephemeral) by nature, and the network is critical to their functioning, we should consider the fallacy that networks are reliable, have no latency, have infinite bandwidth, and that communication is guaranteed. When you consider how important it is to be able to control and secure service communication in distributed systems that rely on network calls with every transaction, every time an application is invoked, you can see why you are under tooled and why running more than a few microservices on a network topology that is in constant flux is so difficult. In the age of microservices, a new layer of tooling for the caretaking of services is needed\u2014a service mesh is needed."), mdx("h3", null, "What Is a Service Mesh?"), mdx("p", null, "Service meshes provide intent-based networking for microservices describing desired behavior of the network in the face of constantly changing conditions and network topology. At their core, service meshes provide:"), mdx("ul", null, mdx("li", null, "A services-first network;"), mdx("li", null, "A developer-driven network;"), mdx("li", null, "A network that is primarily concerned with alleviating application developers from building infrastructure concerns into their application code; "), mdx("li", null, "A network that empowers operators with the ability to declaratively define network behavior, node identity, and traffic flow through policy; "), mdx("li", null, "A network that enables service owners to control application logic without engaging developers to change its code.")), mdx("p", null, "Value derived from the layer of tooling that service meshes provide is most evident in the land of microservices. The more services, the more value derived from the mesh. In subsequent chapters, I show how service meshes provide value outside of the use of microservices and containers and help modernize existing services (running on virtual or bare metal servers) as well."), mdx("p", null, "Many of you will find yourself working in organizations that have more than one sort of service mesh. Diversity is driven by a broad set of workload requirements varying from process-based to event-driven in their design, from those running on bare metal to executing in functions and those representing every style of deployment artifact in-between. The scope of service mesh capability required by different organizations varies. As a result, different service meshes are created with slightly different use cases in mind, resulting in differences in service mesh architecture and deployment models. Service meshes, which are driven by Cloud, Hybrid, On-Prem, and Edge, can enable each of these. With the requirements of different edge devices and their functions, along with ephemeral cloud-based workloads, microservice patterns and technologies give a plethora of opportunities for service mesh differentiation and specialization. Cloud vendors produce and collaborate as they provide service mesh as a managed service on their platforms."), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Differences,
    align: "center",
    alt: "comparative spectrum"
  }), mdx("p", null, "Figure 1: A comparative spectrum of the difference between some of the service meshes based on their individual strengths.")), mdx("p", null, "The demand for service meshes, including meshes native to specific cloud platforms, is growing in tandem with the number of microservices. As a result, many enterprises now use various service mesh products, either separately or together."), mdx("h3", null, "Service Mesh Abstractions"), mdx("p", null, "Because there are any number of service meshes available, independent specifications have cropped up to provide abstraction and standardization across them. Three service mesh abstractions exist today:"), mdx("ul", null, mdx("li", null, mdx(Link, {
    to: "/projects/service-mesh-performance",
    mdxType: "Link"
  }, "Service Mesh Performance"), " (SMP) is a format for describing and capturing service mesh performance. Created by Layer5; Meshery is the canonical implementation of this specification."), mdx("li", null, "Multi-Vendor Service Mesh Interoperation (Hamlet) is a set of API standards for enabling service mesh federation. Created by VMware."), mdx("li", null, mdx(Link, {
    to: "/projects/service-mesh-interface-conformance",
    mdxType: "Link"
  }, "Service Mesh Interface"), " (SMI) is a standard interface for service meshes on Kubernetes. Created by Microsoft; Meshery is the official SMI conformance tool used to ensure that a cluster is properly configured and that its behavior conforms to official SMI specifications.")), mdx("h3", null, "Service Mesh Landscape"), mdx("p", null, "Let's start characterizing different service meshes now that we better understand why we live in a multi-mesh world. Some service meshes support non-containerized workloads (services operating on a VM or on bare metal), while others specialize in layering on top of container orchestrators, such as Kubernetes. All service meshes support integration with service discovery systems. The subsections that follow provide a very brief survey of service mesh offerings within the current technology landscape."), mdx("div", {
    className: "fact-left"
  }, mdx("p", null, "See the Layer5 ", mdx(Link, {
    to: "//service-mesh-landscape",
    mdxType: "Link"
  }, "service mesh landscape"), " for a comprehensive overview and characterizing of all of the service meshes, service proxies, and related tools available today. This landscape is community-maintained and places service meshes in contrast with one another so that the reader might make the most informed decision about which service mesh best suits their needs.")), mdx("h3", null, "Why Do I Need One?"), mdx("p", null, "\"I have a container orchestrator; why do I need another infrastructure layer?\" you might wonder. Container orchestrators provide most of what the cluster (nodes and containers) requires.\xA0 Container orchestrators' primary focus is on scheduling, discovery, and health, mainly at the infrastructure level (networking being a Layer 4 and below focus). As a result, microservices have unmet service-level\xA0needs. A service mesh is a specialized infrastructure layer that makes service-to-service communication safe, fast, and reliable. Its operation is typically based on a container orchestrator or integration\xA0with another service discovery system. Although service meshes are frequently deployed as a separate layer on top of container orchestrators, they do\xA0not require one\xA0because control and data plane components could be deployed independently of containerized infrastructure."), mdx("p", null, "As stated previously, the network is directly and critically involved in every transaction, every execution of business logic, and every request made to the application in microservices deployments. For modern, cloud-native applications, network stability and latency are top priorities. A cloud native application may be made up of hundreds of microservices, each of which could have several instances, and each of those ephemeral instances could be rescheduled by a container orchestrator as needed."), mdx("p", null, "What would you want from a network that connects your microservices, given the network's criticality? You want your network to be as intelligent and resilient as possible. To improve the aggregate reliability\xA0of your cluster, you want your network to route traffic around from\xA0failures. You want to avoid overhead\xA0like high-latency routes or servers with cold caches in your network. You want your network to protect the traffic that flows between services against trivial attacks. You want your network to provide insight into service communication failures by exposing unforeseen dependencies and root causes. You want your network to let you impose policies at the granularity of service behaviors, not just at the connection level. You also don\u2019t want to write all this logic into your application."), mdx("p", null, "You want Layer 5 management. You want a services-first network. You want a service mesh!")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-fundamentals</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-fundamentals</guid><enclosure url="https://layer5.io/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Many emerging technologies are based on or reincarnated from prior thinking and approaches to computing and networking paradigms. Why is this phenomenon required? We&amp;#x27;ll look to the microservices and containers movement for service meshes, a cloud-native approach to design scalable, independently supplied services. What was previously internal application communications have become a mesh of service-to-service remote procedure calls (RPCs) transported via networks thanks to microservices. Microservices democratize language and technology choice across independent service teams that generate new features quickly as they iteratively and continuously provide software(typically as a service). The most crucial driver of microservices as an architectural model is the decoupling of engineering teams and their enhanced speed.&lt;/p&gt;&lt;h3&gt;Operating Many Services&lt;/h3&gt;&lt;p&gt;The initial couple of microservices are relatively simple to deliver and operate—at least in comparison to organizations&amp;#x27; challenges when they first use many microservices. Whether that &amp;quot;many&amp;quot; is three or one hundred, a major technological issue will inevitably arise. To relieve microservices headaches, several remedies are prescribed; one notable example is the use of client libraries. In microservices environments, language and framework-specific client libraries, whether pre-existing or generated, are utilized to address distributed systems challenges. Many teams first explore their path to a service mesh in these situations. The sheer volume of services that must be managed on an individual, distributed basis (rather than centrally as with monoliths) and the challenges of ensuring their reliability, observability, and security cannot be met with outmoded paradigms, necessitating the need to reincarnate prior thinking and approaches. It is necessary to adapt new tools and techniques.&lt;/p&gt;&lt;p&gt;Since microservices are distributed (often ephemeral) by nature, and the network is critical to their functioning, we should consider the fallacy that networks are reliable, have no latency, have infinite bandwidth, and that communication is guaranteed. When you consider how important it is to be able to control and secure service communication in distributed systems that rely on network calls with every transaction, every time an application is invoked, you can see why you are under tooled and why running more than a few microservices on a network topology that is in constant flux is so difficult. In the age of microservices, a new layer of tooling for the caretaking of services is needed—a service mesh is needed.&lt;/p&gt;&lt;h3&gt;What Is a Service Mesh?&lt;/h3&gt;&lt;p&gt;Service meshes provide intent-based networking for microservices describing desired behavior of the network in the face of constantly changing conditions and network topology. At their core, service meshes provide:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A services-first network;&lt;/li&gt;&lt;li&gt;A developer-driven network;&lt;/li&gt;&lt;li&gt;A network that is primarily concerned with alleviating application developers from building infrastructure concerns into their application code; &lt;/li&gt;&lt;li&gt;A network that empowers operators with the ability to declaratively define network behavior, node identity, and traffic flow through policy; &lt;/li&gt;&lt;li&gt;A network that enables service owners to control application logic without engaging developers to change its code.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Value derived from the layer of tooling that service meshes provide is most evident in the land of microservices. The more services, the more value derived from the mesh. In subsequent chapters, I show how service meshes provide value outside of the use of microservices and containers and help modernize existing services (running on virtual or bare metal servers) as well.&lt;/p&gt;&lt;p&gt;Many of you will find yourself working in organizations that have more than one sort of service mesh. Diversity is driven by a broad set of workload requirements varying from process-based to event-driven in their design, from those running on bare metal to executing in functions and those representing every style of deployment artifact in-between. The scope of service mesh capability required by different organizations varies. As a result, different service meshes are created with slightly different use cases in mind, resulting in differences in service mesh architecture and deployment models. Service meshes, which are driven by Cloud, Hybrid, On-Prem, and Edge, can enable each of these. With the requirements of different edge devices and their functions, along with ephemeral cloud-based workloads, microservice patterns and technologies give a plethora of opportunities for service mesh differentiation and specialization. Cloud vendors produce and collaborate as they provide service mesh as a managed service on their platforms.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-624b7da78797752b7cf79ce222606415.png&quot; align=&quot;center&quot; alt=&quot;comparative spectrum&quot;/&gt;&lt;p&gt;Figure 1: A comparative spectrum of the difference between some of the service meshes based on their individual strengths.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The demand for service meshes, including meshes native to specific cloud platforms, is growing in tandem with the number of microservices. As a result, many enterprises now use various service mesh products, either separately or together.&lt;/p&gt;&lt;h3&gt;Service Mesh Abstractions&lt;/h3&gt;&lt;p&gt;Because there are any number of service meshes available, independent specifications have cropped up to provide abstraction and standardization across them. Three service mesh abstractions exist today:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance&lt;/a&gt; (SMP) is a format for describing and capturing service mesh performance. Created by Layer5; Meshery is the canonical implementation of this specification.&lt;/li&gt;&lt;li&gt;Multi-Vendor Service Mesh Interoperation (Hamlet) is a set of API standards for enabling service mesh federation. Created by VMware.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/projects/service-mesh-interface-conformance&quot;&gt;Service Mesh Interface&lt;/a&gt; (SMI) is a standard interface for service meshes on Kubernetes. Created by Microsoft; Meshery is the official SMI conformance tool used to ensure that a cluster is properly configured and that its behavior conforms to official SMI specifications.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Service Mesh Landscape&lt;/h3&gt;&lt;p&gt;Let&amp;#x27;s start characterizing different service meshes now that we better understand why we live in a multi-mesh world. Some service meshes support non-containerized workloads (services operating on a VM or on bare metal), while others specialize in layering on top of container orchestrators, such as Kubernetes. All service meshes support integration with service discovery systems. The subsections that follow provide a very brief survey of service mesh offerings within the current technology landscape.&lt;/p&gt;&lt;div class=&quot;fact-left&quot;&gt;&lt;p&gt;See the Layer5 &lt;a href=&quot;//service-mesh-landscape&quot;&gt;service mesh landscape&lt;/a&gt; for a comprehensive overview and characterizing of all of the service meshes, service proxies, and related tools available today. This landscape is community-maintained and places service meshes in contrast with one another so that the reader might make the most informed decision about which service mesh best suits their needs.&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Why Do I Need One?&lt;/h3&gt;&lt;p&gt;&amp;quot;I have a container orchestrator; why do I need another infrastructure layer?&amp;quot; you might wonder. Container orchestrators provide most of what the cluster (nodes and containers) requires.  Container orchestrators&amp;#x27; primary focus is on scheduling, discovery, and health, mainly at the infrastructure level (networking being a Layer 4 and below focus). As a result, microservices have unmet service-level needs. A service mesh is a specialized infrastructure layer that makes service-to-service communication safe, fast, and reliable. Its operation is typically based on a container orchestrator or integration with another service discovery system. Although service meshes are frequently deployed as a separate layer on top of container orchestrators, they do not require one because control and data plane components could be deployed independently of containerized infrastructure.&lt;/p&gt;&lt;p&gt;As stated previously, the network is directly and critically involved in every transaction, every execution of business logic, and every request made to the application in microservices deployments. For modern, cloud-native applications, network stability and latency are top priorities. A cloud native application may be made up of hundreds of microservices, each of which could have several instances, and each of those ephemeral instances could be rescheduled by a container orchestrator as needed.&lt;/p&gt;&lt;p&gt;What would you want from a network that connects your microservices, given the network&amp;#x27;s criticality? You want your network to be as intelligent and resilient as possible. To improve the aggregate reliability of your cluster, you want your network to route traffic around from failures. You want to avoid overhead like high-latency routes or servers with cold caches in your network. You want your network to protect the traffic that flows between services against trivial attacks. You want your network to provide insight into service communication failures by exposing unforeseen dependencies and root causes. You want your network to let you impose policies at the granularity of service behaviors, not just at the connection level. You also don’t want to write all this logic into your application.&lt;/p&gt;&lt;p&gt;You want Layer 5 management. You want a services-first network. You want a service mesh!&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Swappable Sidecars]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Swappable Sidecars",
  "thumbnail": "./figure1.png",
  "category": "Service Mesh",
  "type": "Article",
  "tags": ["Service Mesh"],
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about WebAssembly's use within service mesh data planes in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.")), mdx("p", null, "One of the most significant\xA0considerations to make when establishing a service mesh is the proxy's functionality. From the standpoint of a developer, a proxy's cloud native integrations (e.g., with OpenTelemetry / OpenTracing, Prometheus, and so on) are extremely important. Surprisingly, a developer may be uninterested in the APIs of a proxy. The control plane for the service mesh is the point of control for managing proxy settings. A developer, however, will be interested in the APIs of a management plane. Protocol support is at the top of the developers' wish list for proxies. Protocol considerations can be divided into two categories:"), mdx("ul", null, mdx("li", null, "TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing."), mdx("li", null, "gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.")), mdx("p", null, "The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:"), mdx("ul", null, mdx("li", null, "High performance and low latency"), mdx("li", null, "High scalability and small memory footprint"), mdx("li", null, "Deep observability at all layers of the network stack"), mdx("li", null, "Programmatic configuration and ecosystem integration"), mdx("li", null, "Thorough documentation to facilitate an understanding of expected proxy behavior")), mdx("p", null, "Envoy is used as a service proxy by a variety of service meshes. Within Istio, Envoy is the default service proxy. Using Envoy\u2019s APIs, various projects have demonstrated the ability to displace Envoy as the default service proxy with the choice of an alternative."), mdx("div", {
    className: "intro"
  }, mdx("h3", {
    align: "center"
  }, "Standardizing Data Plane APIs"), mdx("p", null, "The xDS APIs are a collection of Envoy's APIs. The Universal Data Plane API (UDPA) working group attempts to create a set of APIs that will serve as the de facto standard for L4/L7 data plane configuration (similar to OpenFlow's role in SDN at L2/L3/L4). The Envoy xDS APIs are being evolved to address service discovery, load balancing assignments, routing discovery, listener configuration, secret discovery, load reporting, health check delegation, and more, in combination with a well-defined, stable API versioning policy.")), mdx("p", null, "In early versions of Istio, Linkerd exhibited an integration in which Istio was the control plane, supplying configuration to Linkerd proxies.\xA0 NGINX also hosted a project called nginMesh, in which Istio served as the control plane and NGINX proxies operated as the data plane."), mdx("p", null, "With many service proxies in the ecosystem, outside of Envoy, only two have currently demonstrated integration with Istio . Linkerd is not yet intended to be a general-purpose proxy; instead, it is focused on being lightweight, placing extensibility as a secondary concern by offering extensions via gRPC plug-in.\xA0 Consul makes use of Envoy as a proxy. Why would you want to use another\xA0service proxy?"), mdx("strong", null, "NGINX"), mdx("p", null, "While you won't be able to use NGINX as a proxy to replace Envoy, you could wish to employ NGINX based on your operational expertise, the necessity for a battle-tested proxy, or the integration of an F5 load balancer. You might also be looking for caching, a web application firewall (WAF), or other features in NGINX Plus. The service proxy used in the NGINX Service Mesh data plane is an enhanced version of NGINX Plus that interfaces natively with Kubernetes."), mdx("strong", null, "CPX"), mdx("p", null, "If you already have Citrix Application Delivery Controllers and want to use them across your diverse infrastructure, you might choose to use the Citrix Service Mesh (which is an Istio control plane with a CPX data plane).With infrastructure diversity, holistic control, and monitoring for operational consistency across all your workloads (new microservices and existing monoliths)."), mdx("strong", null, "MOSN"), mdx("p", null, "MOSN can deploy as an Istio data plane. You might choose to deploy MOSN if you need to highly customize your service proxy and are a Golang shop. MOSN supports a multi-protocol framework, and you access private protocols with a unified routing framework. It has a multi-process plug-in mechanism, which can easily extend the plug-ins of independent MOSN processes through the plug-in framework, and do some other management, bypass and other functional module extensions."), mdx("div", {
    className: "fact"
  }, "You might find this article on ", mdx("a", {
    href: "https://www.oreilly.com/content/how-to-customize-an-istio-service-mesh/"
  }, "How to customize an Istio service mesh and its adjoining webcast"), " helpful in further understanding Istio\u2019s extensibility with respect to swappable service proxies."), mdx("p", null, "Without configuration, proxies are without instructions to perform their tasks. Pilot is the head of the ship in an Istio mesh, keeping synchronized with the underlying platform by tracking and representing its services to istio-proxy. istio-proxy contains the proxy of choice (e.g. Envoy). Typically, the same istio-proxy Docker image is used by Istio sidecar and Istio ingress gateway, which contains not only the service proxy but also the Istio Pilot agent.  At regular intervals, the Istio Pilot agent pulls configuration from Pilot to the service proxy, so that each proxy knows where to route traffic."), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Swappingproxy,
    align: "center",
    alt: "Swapping Proxy"
  }), mdx("p", null, "Figure 1: Example of swapping proxies\u2014Istio + nginMesh."))));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/swappable-sidecars</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/swappable-sidecars</guid><enclosure url="https://layer5.io/static/cfb74577108949bc2ca373257e95e16c/figure1.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about WebAssembly&amp;#x27;s use within service mesh data planes in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;One of the most significant considerations to make when establishing a service mesh is the proxy&amp;#x27;s functionality. From the standpoint of a developer, a proxy&amp;#x27;s cloud native integrations (e.g., with OpenTelemetry / OpenTracing, Prometheus, and so on) are extremely important. Surprisingly, a developer may be uninterested in the APIs of a proxy. The control plane for the service mesh is the point of control for managing proxy settings. A developer, however, will be interested in the APIs of a management plane. Protocol support is at the top of the developers&amp;#x27; wish list for proxies. Protocol considerations can be divided into two categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TCP, UDP, HTTP: Network team-centric consideration in which efficiency, performance, offload, and load balancing algorithm support are evaluated. Support for HTTP2 often takes top billing.&lt;/li&gt;&lt;li&gt;gRPC, NATS, Kafka: A developer-centric consideration in which the top item on the list is application-level protocols, specifically those commonly used in modern distributed application designs.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The reality is that selecting the perfect proxy involves more than protocol support. Your proxy should meet all key criteria:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;High performance and low latency&lt;/li&gt;&lt;li&gt;High scalability and small memory footprint&lt;/li&gt;&lt;li&gt;Deep observability at all layers of the network stack&lt;/li&gt;&lt;li&gt;Programmatic configuration and ecosystem integration&lt;/li&gt;&lt;li&gt;Thorough documentation to facilitate an understanding of expected proxy behavior&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Envoy is used as a service proxy by a variety of service meshes. Within Istio, Envoy is the default service proxy. Using Envoy’s APIs, various projects have demonstrated the ability to displace Envoy as the default service proxy with the choice of an alternative.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;h3 align=&quot;center&quot;&gt;Standardizing Data Plane APIs&lt;/h3&gt;&lt;p&gt;The xDS APIs are a collection of Envoy&amp;#x27;s APIs. The Universal Data Plane API (UDPA) working group attempts to create a set of APIs that will serve as the de facto standard for L4/L7 data plane configuration (similar to OpenFlow&amp;#x27;s role in SDN at L2/L3/L4). The Envoy xDS APIs are being evolved to address service discovery, load balancing assignments, routing discovery, listener configuration, secret discovery, load reporting, health check delegation, and more, in combination with a well-defined, stable API versioning policy.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;In early versions of Istio, Linkerd exhibited an integration in which Istio was the control plane, supplying configuration to Linkerd proxies.  NGINX also hosted a project called nginMesh, in which Istio served as the control plane and NGINX proxies operated as the data plane.&lt;/p&gt;&lt;p&gt;With many service proxies in the ecosystem, outside of Envoy, only two have currently demonstrated integration with Istio . Linkerd is not yet intended to be a general-purpose proxy; instead, it is focused on being lightweight, placing extensibility as a secondary concern by offering extensions via gRPC plug-in.  Consul makes use of Envoy as a proxy. Why would you want to use another service proxy?&lt;/p&gt;&lt;strong&gt;NGINX&lt;/strong&gt;&lt;p&gt;While you won&amp;#x27;t be able to use NGINX as a proxy to replace Envoy, you could wish to employ NGINX based on your operational expertise, the necessity for a battle-tested proxy, or the integration of an F5 load balancer. You might also be looking for caching, a web application firewall (WAF), or other features in NGINX Plus. The service proxy used in the NGINX Service Mesh data plane is an enhanced version of NGINX Plus that interfaces natively with Kubernetes.&lt;/p&gt;&lt;strong&gt;CPX&lt;/strong&gt;&lt;p&gt;If you already have Citrix Application Delivery Controllers and want to use them across your diverse infrastructure, you might choose to use the Citrix Service Mesh (which is an Istio control plane with a CPX data plane).With infrastructure diversity, holistic control, and monitoring for operational consistency across all your workloads (new microservices and existing monoliths).&lt;/p&gt;&lt;strong&gt;MOSN&lt;/strong&gt;&lt;p&gt;MOSN can deploy as an Istio data plane. You might choose to deploy MOSN if you need to highly customize your service proxy and are a Golang shop. MOSN supports a multi-protocol framework, and you access private protocols with a unified routing framework. It has a multi-process plug-in mechanism, which can easily extend the plug-ins of independent MOSN processes through the plug-in framework, and do some other management, bypass and other functional module extensions.&lt;/p&gt;&lt;div class=&quot;fact&quot;&gt;You might find this article on &lt;a href=&quot;https://www.oreilly.com/content/how-to-customize-an-istio-service-mesh/&quot;&gt;How to customize an Istio service mesh and its adjoining webcast&lt;/a&gt; helpful in further understanding Istio’s extensibility with respect to swappable service proxies.&lt;/div&gt;&lt;p&gt;Without configuration, proxies are without instructions to perform their tasks. Pilot is the head of the ship in an Istio mesh, keeping synchronized with the underlying platform by tracking and representing its services to istio-proxy. istio-proxy contains the proxy of choice (e.g. Envoy). Typically, the same istio-proxy Docker image is used by Istio sidecar and Istio ingress gateway, which contains not only the service proxy but also the Istio Pilot agent.  At regular intervals, the Istio Pilot agent pulls configuration from Pilot to the service proxy, so that each proxy knows where to route traffic.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-4af4feafa8c502823390ae35112b891f.png&quot; align=&quot;center&quot; alt=&quot;Swapping Proxy&quot;/&gt;&lt;p&gt;Figure 1: Example of swapping proxies—Istio + nginMesh.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Value of a Service Mesh]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Value of a Service Mesh",
  "thumbnail": "./service-mesh.svg",
  "category": "Service Mesh",
  "tags": ["Service mesh"],
  "featured": false,
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about service mesh fundamentals in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, " The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource which addresses how to evaluate your organization\u2019s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.")), mdx("p", null, "Service meshes provide visibility, resiliency, traffic, and security control of distributed application services."), mdx("h3", null, "Observability"), mdx("p", null, "Many organisations are attracted to the uniform observability that service meshes provide. There is no such thing as a fully healthy complex system. Service-level\xA0 t elemetry\xA0sheds light on difficult-to-answer questions like why your requests are slow\xA0to respond. It's quite simple to figure out when a service is down, but figuring out where it's slow and why is a different story."), mdx("p", null, "Service meshes allow both black-box (observing a system from the outside) and white-box (monitoring a system from the inside)\xA0monitoring of service-to-service communication. To provide white-box monitoring, some service meshes combine with a distributed tracing library. In contrast, other service meshes\xA0use protocol-specific filters as a capability of their proxies to provide a deeper level of visibility. The components of the data plane are well-positioned (transparently, in-band) to create metrics, logs, and traces, ensuring uniform and thorough observability across the mesh."), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Mixer,
    align: "right",
    alt: "Istio Mixer"
  }), mdx("p", null, "Figure 1: Istio\u2019s Mixer is capable of collecting multiple telemetric signals and sending those signals to backend monitoring, authentication, and quota systems via adapters")), mdx("p", null, "Service meshes centralize and assist in solving these observability challenges by providing the following:"), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Metrics,
    align: "right",
    alt: "Request Metrics"
  }), mdx("p", null, "Figure 2: Request metrics generated by Istio and visible in Meshery")), mdx("ul", null, mdx("li", null, mdx("strong", null, "Logging"), mdx("p", null, "Logs are used to baseline visibility for access requests to your entire fleet of services. Figure 1 illustrates how telemetry transmitted through service mesh logs include source and destination, request protocol, endpoint (URL), response time, size, and associated response code.")), mdx("li", null, mdx("strong", null, "Metrics"), mdx("p", null, "Metrics are used to eliminate the need for the development process to instrument code in order to emit metrics. When metrics are ubiquitous\xA0across your cluster, additional insights become available. Consistent metrics allow for things like autoscaling to be automated. Telemetry emitted by service mesh metrics include global request volume, global success rate, individual service responses by version, source and time.")), mdx("li", null, mdx("strong", null, "Tracing"), mdx("p", null, "Slow services (as opposed to services that simply fail) are the most difficult to debug without tracing. Imagine manually enumerating and tracking all of your service dependencies in a spreadsheet. Dependencies, request volumes, and failure rates are visualised using traces. Service meshes enable incorporating tracing functionality extremely simple with the help of\xA0automatically generated span identifiers. The mesh's individual services still must forward context headers.\xA0 Many application performance management (APM) solutions, on the other hand, need manual instrumentation to extract traces from your services."))), mdx("h3", null, "Traffic control"), mdx("p", null, "Service meshes provide for granular, declarative control over network traffic, such as determining where a request should be routed to perform\xA0canary release. Circuit breaking, latency-aware load balancing, eventually consistent service discovery, timeouts, deadlines, and retries are all common resiliency features."), mdx("p", null, "When a request does not return to the client within a certain amount of predefined\xA0time, a  ", mdx("strong", null, "timeout"), " is used to terminate it. They provide a time restriction on how much time can be spent on an individual\xA0request and are enforced at a point after which a response is considered invalid. ", mdx("strong", null, "Deadlines"), " are an advanced service mesh feature that helps minimise retry storms by facilitating feature-level timeouts rather than independent service timeouts. As a request travels through the mesh, deadlines deduct time remaining to handle it at each stage, propagating elapsed time with each downstream service call.\xA0 Timeouts and deadlines\xA0might be considered enforcers of your Service-Level Objectives (SLOs)."), mdx("p", null, "You can choose to retry a request if a service\xA0times out or is unsuccessfully returned. Retrying the same call to a service that is already under water (retry three times = 300 percent additional service load) can make things worse. Retry budgets (aka\xA0maximum retries) offer the benefit of multiple tries but come with a limit to avoid overloading an already a load-challenged\xA0service. Some service meshes go even further to reduce client contention by using jitter and an exponential back-off algorithm to calculate the timing of the\xA0next retry attempt."), mdx("div", {
    className: "left"
  }, mdx("img", {
    src: Timeouts,
    align: "right",
    alt: "Deadlines"
  }), mdx("p", null, "Figure 3:Deadlines, not ubiquitously supported by different service meshes, set feature-level timeouts")), mdx("p", null, "You can choose to fail fast and disconnect the service, prohibiting calls to it, rather than retrying and putting more load to the service. ", mdx("strong", null, "Circuit breaking"), " allows users to set\xA0configurable\xA0timeouts (or failure thresholds) to assure safe maximums and graceful failure, which is common for slow-responding services. When applications (services) are oversubscribed, using a service mesh as a distinct layer to implement circuit breaking minimises undue overhead."), mdx("p", null, mdx("strong", null, "Rate limiting"), "(throttling) is implemented to\xA0ensure service stability. When requests by\xA0one client\xA0surge, the service continues to function smoothly for others. The rate limits are calculated over a period of time. You can also utilise various algorithms, such as a fixed or sliding window, a sliding log, etc. The purpose of rate limits is to ensure that your services are not oversubscribed."), mdx("p", null, "When a limit is reached, well-implemented services commonly adhere to IETF RFC 6585, sending 429 Too Many Requests as the response code, including headers, such as the following, describing the request limit, number of requests remaining, and amount of time remaining until the request counter is reset:"), mdx("div", {
    className: "fact-left"
  }, mdx("p", null, "X-RateLimit-Limit: 60"), mdx("p", null, "X-RateLimit-Remaining: 0"), mdx("p", null, "X-RateLimit-Reset: 1372016266")), mdx("p", null, mdx("strong", null, "Quota management"), " (or conditional rate-limiting) accounts for requests based on business requirements instead of limiting rates based on operational concerns. It can be difficult to tell the difference between rate limiting and quota management because both features are handled by the same service mesh capability but are exposed to users in different ways."), mdx("p", null, "Configuring a policy setting a threshold for the number of client requests allowed to a service over time is the canonical example of quota management. User Lee, for example, is on the Free service plan and is allowed upto\xA010 requests per day. Quota policy imposes consumption limitations on services by keeping track of incoming requests in a distributed counter,often using\xA0an in-memory datastore like Redis\xA0 Conditional rate limits are a powerful service mesh capability when applied based on a user-defined set of arbitrary attributes."), mdx("h3", null, "Security"), mdx("div", {
    className: "right"
  }, mdx("img", {
    src: Communication,
    align: "right",
    alt: "Communication Paths"
  }), mdx("p", null, "Figure 4: An example of service mesh architecture. Secure communication paths in Istio")), mdx("p", null, "For securing service-to-service communication, most service meshes include a certificate authority that manages keys and certificates. Certificates are generated for each service and serve as the service's unique identifier. When sidecar proxies are employed, they assume the identity of the service and perform lifecycle management\xA0of certificates (creation, distribution, refresh, and revocation) on its behalf.\xA0\xA0 Local TCP connections are often established between the service and the sidecar proxy, whereas mutual Transport Layer Security (mTLS) connections are typically established between proxies in sidecar proxy deployments."), mdx("p", null, "Internal traffic within your application should be encrypted as a matter of security. The service calls in your application are no longer contained within a single monolith via localhost; they are now exposed over the network. Allowing service calls without TLS on the transport is a recipe for disaster in terms of security. When two mesh-enabled services communicate, they have strong cryptographic proof of their peers.\xA0\xA0 After identities have been established, they are used to create access control policies that determine whether or not a request should be serviced. Policy controls configuration of the key management system (e.g., certificate refresh interval) and operational access control are used to determine whether a request is accepted, based on service mesh employed. Approved and unapproved connection requests, as well as more granular access control parameters like time of day, are identified using white and blacklists."), mdx("h3", null, "Delay and fault injection"), mdx("p", null, "It's important to accept that your networks and/or systems will fail. Why not introduce failure and verify behaviour ahead of time? As proxies sit in line to service\xA0traffic, they frequently support protocol-specific fault injection, which allows you to configure\xA0the percentage of requests that should be subjected to faults or network delays. For example, generating HTTP 500 errors might be used to test the robustness of your distributed application's response behaviour."), mdx("p", null, "Injecting latency into requests without a service mesh is a time-consuming procedure, but it is probably a more prevalent problem encountered during\xA0 operation of an\xA0application. Users are far more irritated by slow replies that result in an HTTP 503 after a minute of waiting than by a 503 after a few seconds. The finest element of these resilience testing capabilities\xA0is that no application code needs to be changed to make these tests possible. The results of the tests, on the other hand, may prompt you to make changes to the application code."), mdx("p", null, "Using a service mesh, developers spend far less time creating code to cope with infrastructure issues\u2014code\xA0that could be commoditized by service meshes in the future. The separation of service and session-layer concerns from application code is manifested as a phenomenon I refer to as decoupling at Layer 5."), mdx("p", null, "A service mesh can be regarded of as surfacing the OSI model's session layer as a separately addressable, first-class citizen in your modern architecture. They are a secret weapon of cloud native systems, waiting to be exploited as a highly configurable work horse.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/service-mesh/value-of-a-service-mesh</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/value-of-a-service-mesh</guid><enclosure url="https://layer5.io/static/cb310234b6631abcabb632a85974a3dd/service-mesh.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about service mesh fundamentals in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt; The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Service meshes provide visibility, resiliency, traffic, and security control of distributed application services.&lt;/p&gt;&lt;h3&gt;Observability&lt;/h3&gt;&lt;p&gt;Many organisations are attracted to the uniform observability that service meshes provide. There is no such thing as a fully healthy complex system. Service-level  t elemetry sheds light on difficult-to-answer questions like why your requests are slow to respond. It&amp;#x27;s quite simple to figure out when a service is down, but figuring out where it&amp;#x27;s slow and why is a different story.&lt;/p&gt;&lt;p&gt;Service meshes allow both black-box (observing a system from the outside) and white-box (monitoring a system from the inside) monitoring of service-to-service communication. To provide white-box monitoring, some service meshes combine with a distributed tracing library. In contrast, other service meshes use protocol-specific filters as a capability of their proxies to provide a deeper level of visibility. The components of the data plane are well-positioned (transparently, in-band) to create metrics, logs, and traces, ensuring uniform and thorough observability across the mesh.&lt;/p&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-dcc279844f5e980cd2e4eea5f8388b1a.png&quot; align=&quot;right&quot; alt=&quot;Istio Mixer&quot;/&gt;&lt;p&gt;Figure 1: Istio’s Mixer is capable of collecting multiple telemetric signals and sending those signals to backend monitoring, authentication, and quota systems via adapters&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Service meshes centralize and assist in solving these observability challenges by providing the following:&lt;/p&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/figure2-390054d17df7bf42260a8df2f09c78f4.png&quot; align=&quot;right&quot; alt=&quot;Request Metrics&quot;/&gt;&lt;p&gt;Figure 2: Request metrics generated by Istio and visible in Meshery&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Logging&lt;/strong&gt;&lt;p&gt;Logs are used to baseline visibility for access requests to your entire fleet of services. Figure 1 illustrates how telemetry transmitted through service mesh logs include source and destination, request protocol, endpoint (URL), response time, size, and associated response code.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt;&lt;p&gt;Metrics are used to eliminate the need for the development process to instrument code in order to emit metrics. When metrics are ubiquitous across your cluster, additional insights become available. Consistent metrics allow for things like autoscaling to be automated. Telemetry emitted by service mesh metrics include global request volume, global success rate, individual service responses by version, source and time.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Tracing&lt;/strong&gt;&lt;p&gt;Slow services (as opposed to services that simply fail) are the most difficult to debug without tracing. Imagine manually enumerating and tracking all of your service dependencies in a spreadsheet. Dependencies, request volumes, and failure rates are visualised using traces. Service meshes enable incorporating tracing functionality extremely simple with the help of automatically generated span identifiers. The mesh&amp;#x27;s individual services still must forward context headers.  Many application performance management (APM) solutions, on the other hand, need manual instrumentation to extract traces from your services.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Traffic control&lt;/h3&gt;&lt;p&gt;Service meshes provide for granular, declarative control over network traffic, such as determining where a request should be routed to perform canary release. Circuit breaking, latency-aware load balancing, eventually consistent service discovery, timeouts, deadlines, and retries are all common resiliency features.&lt;/p&gt;&lt;p&gt;When a request does not return to the client within a certain amount of predefined time, a  &lt;strong&gt;timeout&lt;/strong&gt; is used to terminate it. They provide a time restriction on how much time can be spent on an individual request and are enforced at a point after which a response is considered invalid. &lt;strong&gt;Deadlines&lt;/strong&gt; are an advanced service mesh feature that helps minimise retry storms by facilitating feature-level timeouts rather than independent service timeouts. As a request travels through the mesh, deadlines deduct time remaining to handle it at each stage, propagating elapsed time with each downstream service call.  Timeouts and deadlines might be considered enforcers of your Service-Level Objectives (SLOs).&lt;/p&gt;&lt;p&gt;You can choose to retry a request if a service times out or is unsuccessfully returned. Retrying the same call to a service that is already under water (retry three times = 300 percent additional service load) can make things worse. Retry budgets (aka maximum retries) offer the benefit of multiple tries but come with a limit to avoid overloading an already a load-challenged service. Some service meshes go even further to reduce client contention by using jitter and an exponential back-off algorithm to calculate the timing of the next retry attempt.&lt;/p&gt;&lt;div class=&quot;left&quot;&gt;&lt;img src=&quot;static/figure3-d1eb6e4c19a25c29b8e465646eaa644b.png&quot; align=&quot;right&quot; alt=&quot;Deadlines&quot;/&gt;&lt;p&gt;Figure 3:Deadlines, not ubiquitously supported by different service meshes, set feature-level timeouts&lt;/p&gt;&lt;/div&gt;&lt;p&gt;You can choose to fail fast and disconnect the service, prohibiting calls to it, rather than retrying and putting more load to the service. &lt;strong&gt;Circuit breaking&lt;/strong&gt; allows users to set configurable timeouts (or failure thresholds) to assure safe maximums and graceful failure, which is common for slow-responding services. When applications (services) are oversubscribed, using a service mesh as a distinct layer to implement circuit breaking minimises undue overhead.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Rate limiting&lt;/strong&gt;(throttling) is implemented to ensure service stability. When requests by one client surge, the service continues to function smoothly for others. The rate limits are calculated over a period of time. You can also utilise various algorithms, such as a fixed or sliding window, a sliding log, etc. The purpose of rate limits is to ensure that your services are not oversubscribed.&lt;/p&gt;&lt;p&gt;When a limit is reached, well-implemented services commonly adhere to IETF RFC 6585, sending 429 Too Many Requests as the response code, including headers, such as the following, describing the request limit, number of requests remaining, and amount of time remaining until the request counter is reset:&lt;/p&gt;&lt;div class=&quot;fact-left&quot;&gt;&lt;p&gt;X-RateLimit-Limit: 60&lt;/p&gt;&lt;p&gt;X-RateLimit-Remaining: 0&lt;/p&gt;&lt;p&gt;X-RateLimit-Reset: 1372016266&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Quota management&lt;/strong&gt; (or conditional rate-limiting) accounts for requests based on business requirements instead of limiting rates based on operational concerns. It can be difficult to tell the difference between rate limiting and quota management because both features are handled by the same service mesh capability but are exposed to users in different ways.&lt;/p&gt;&lt;p&gt;Configuring a policy setting a threshold for the number of client requests allowed to a service over time is the canonical example of quota management. User Lee, for example, is on the Free service plan and is allowed upto 10 requests per day. Quota policy imposes consumption limitations on services by keeping track of incoming requests in a distributed counter,often using an in-memory datastore like Redis  Conditional rate limits are a powerful service mesh capability when applied based on a user-defined set of arbitrary attributes.&lt;/p&gt;&lt;h3&gt;Security&lt;/h3&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/figure4-42e3faa6d38a8c21b7584ee807ee0dec.png&quot; align=&quot;right&quot; alt=&quot;Communication Paths&quot;/&gt;&lt;p&gt;Figure 4: An example of service mesh architecture. Secure communication paths in Istio&lt;/p&gt;&lt;/div&gt;&lt;p&gt;For securing service-to-service communication, most service meshes include a certificate authority that manages keys and certificates. Certificates are generated for each service and serve as the service&amp;#x27;s unique identifier. When sidecar proxies are employed, they assume the identity of the service and perform lifecycle management of certificates (creation, distribution, refresh, and revocation) on its behalf.   Local TCP connections are often established between the service and the sidecar proxy, whereas mutual Transport Layer Security (mTLS) connections are typically established between proxies in sidecar proxy deployments.&lt;/p&gt;&lt;p&gt;Internal traffic within your application should be encrypted as a matter of security. The service calls in your application are no longer contained within a single monolith via localhost; they are now exposed over the network. Allowing service calls without TLS on the transport is a recipe for disaster in terms of security. When two mesh-enabled services communicate, they have strong cryptographic proof of their peers.   After identities have been established, they are used to create access control policies that determine whether or not a request should be serviced. Policy controls configuration of the key management system (e.g., certificate refresh interval) and operational access control are used to determine whether a request is accepted, based on service mesh employed. Approved and unapproved connection requests, as well as more granular access control parameters like time of day, are identified using white and blacklists.&lt;/p&gt;&lt;h3&gt;Delay and fault injection&lt;/h3&gt;&lt;p&gt;It&amp;#x27;s important to accept that your networks and/or systems will fail. Why not introduce failure and verify behaviour ahead of time? As proxies sit in line to service traffic, they frequently support protocol-specific fault injection, which allows you to configure the percentage of requests that should be subjected to faults or network delays. For example, generating HTTP 500 errors might be used to test the robustness of your distributed application&amp;#x27;s response behaviour.&lt;/p&gt;&lt;p&gt;Injecting latency into requests without a service mesh is a time-consuming procedure, but it is probably a more prevalent problem encountered during  operation of an application. Users are far more irritated by slow replies that result in an HTTP 503 after a minute of waiting than by a 503 after a few seconds. The finest element of these resilience testing capabilities is that no application code needs to be changed to make these tests possible. The results of the tests, on the other hand, may prompt you to make changes to the application code.&lt;/p&gt;&lt;p&gt;Using a service mesh, developers spend far less time creating code to cope with infrastructure issues—code that could be commoditized by service meshes in the future. The separation of service and session-layer concerns from application code is manifested as a phenomenon I refer to as decoupling at Layer 5.&lt;/p&gt;&lt;p&gt;A service mesh can be regarded of as surfacing the OSI model&amp;#x27;s session layer as a separately addressable, first-class citizen in your modern architecture. They are a secret weapon of cloud native systems, waiting to be exploited as a highly configurable work horse.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Comparing Lua and WebAssembly]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Comparing Lua and WebAssembly",
  "thumbnail": "./webassembly-logo-horizontal.png",
  "category": "WebAssembly Filters",
  "type": "Article",
  "technology": "WebAssembly",
  "tags": ["WebAssembly", "Envoy"],
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about WebAssembly's use within service mesh data planes in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.")), mdx("h3", null, "The Power of the Data Plane"), mdx("p", null, "Operators benefit from control planes because they provide much-needed element management. Data planes require control planes to apply service mesh-specific use cases to their fleet of service proxies. A control plane performs activities like configuration management, telemetry collecting, infrastructure-centric authorization, identity, etc. However, the service proxy is a massive source of power for them. Users frequently require customizing the chain of traffic filters (modules) that service proxies employ to perform much of their heavy lifting. Different technologies are used to provide data plane extensibility, and consequently, additional custom data plane intelligence, including:"), mdx("ul", null, mdx("li", null, "Lua - a scripting language for execution inside a Just-In-Time compiler, LuaJIT."), mdx("li", null, "WebAssembly (WASM) - a virtual stack machine as a compilation target for different languages to use as an execution environment.")), mdx("h3", null, "Lua and WebAssembly"), mdx("p", null, "People are discussing the merits of using a WebAssembly runtime since the introduction of WASM into service meshes. A\xA0 Lua runtime\xA0can be as little as 4 kb, with LuaJIT being surprisingly fast, having a runtime of only ~200 kb."), mdx("p", null, "The WebAssembly loader, not the runtime, is the source of complexity for the host software. When comparing the two, how do you weigh GCC or LLVM in terms of making optimized C or C++ faster or slower than LuaJIT?"), mdx("p", null, "The complexity of a WebAssembly runtime stems from the fact that it contains arch-specific optimizers as well as an Intermediate Representation to machine code translation stage that would usually be executed inside GCC or LLVM. Machine code can be created once and then cached on non-volatile storage until the input WASM file's hash changes (like the extracted contents of a Zip file). Since WASM has a similar approach to sandboxing (making the language/bytecode unable to describe accessing resources outside of what is granted), the result is lighter than Lua once the machine code is generated. However, WASM's compiled machine code does not require a garbage collector or JIT engine."), mdx("p", null, "WebAssembly follows the same flat, garbage-collected memory model as malloc and free. Suppose you want a garbage collector in a WebAssembly application. In that case, you can either compile it to WebAssembly and run it inside the sandbox or wait for extensions currently developing, such as \"opaque reference types,\" which allows WebAssembly applications to interact with objects managed by a Garbage Collector outside the sandbox."), mdx("h3", null, "NGINX and Lua"), mdx("p", null, "NGINX allows you to write\xA0dynamic modules that can be loaded at runtime based on\xA0configuration files. By modifying the configuration files and reloading NGINX, these modules can be unloaded. NGINX enables you to use Lua to embed custom logic into dynamic modules."), mdx("p", null, "Lua is a lightweight, embeddable scripting language that supports procedural, functional, and object-oriented programming. Lua is dynamically typed, and runs by interpreting bytecode with a register-based virtual machine."), mdx("p", null, "NGINX provides the ability to integrate dynamic Lua scripts using the ngx_lua module. Using NGINX with ngx_lua helps you offload logic from your services and hand their concerns off to an intelligent data plane. Leveraging NGINX's subrequests, the ngx_lua module allows the integration of Lua threads (or coroutines into the NGINX event model. Instead of passing logic to an upstream server, the Lua script can inspect and process service traffic. ngx_lua modules can be chained to be invoked at different phases of NGINX request processing.")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/webassembly-filters/comparing-lua-and-webassembly</link><guid isPermaLink="false">https://layer5.io/resources/webassembly-filters/comparing-lua-and-webassembly</guid><enclosure url="https://layer5.io/static/06e071d3040728c69145f5d670854c6d/webassembly-logo-horizontal.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about WebAssembly&amp;#x27;s use within service mesh data planes in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;The Power of the Data Plane&lt;/h3&gt;&lt;p&gt;Operators benefit from control planes because they provide much-needed element management. Data planes require control planes to apply service mesh-specific use cases to their fleet of service proxies. A control plane performs activities like configuration management, telemetry collecting, infrastructure-centric authorization, identity, etc. However, the service proxy is a massive source of power for them. Users frequently require customizing the chain of traffic filters (modules) that service proxies employ to perform much of their heavy lifting. Different technologies are used to provide data plane extensibility, and consequently, additional custom data plane intelligence, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Lua - a scripting language for execution inside a Just-In-Time compiler, LuaJIT.&lt;/li&gt;&lt;li&gt;WebAssembly (WASM) - a virtual stack machine as a compilation target for different languages to use as an execution environment.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Lua and WebAssembly&lt;/h3&gt;&lt;p&gt;People are discussing the merits of using a WebAssembly runtime since the introduction of WASM into service meshes. A  Lua runtime can be as little as 4 kb, with LuaJIT being surprisingly fast, having a runtime of only ~200 kb.&lt;/p&gt;&lt;p&gt;The WebAssembly loader, not the runtime, is the source of complexity for the host software. When comparing the two, how do you weigh GCC or LLVM in terms of making optimized C or C++ faster or slower than LuaJIT?&lt;/p&gt;&lt;p&gt;The complexity of a WebAssembly runtime stems from the fact that it contains arch-specific optimizers as well as an Intermediate Representation to machine code translation stage that would usually be executed inside GCC or LLVM. Machine code can be created once and then cached on non-volatile storage until the input WASM file&amp;#x27;s hash changes (like the extracted contents of a Zip file). Since WASM has a similar approach to sandboxing (making the language/bytecode unable to describe accessing resources outside of what is granted), the result is lighter than Lua once the machine code is generated. However, WASM&amp;#x27;s compiled machine code does not require a garbage collector or JIT engine.&lt;/p&gt;&lt;p&gt;WebAssembly follows the same flat, garbage-collected memory model as malloc and free. Suppose you want a garbage collector in a WebAssembly application. In that case, you can either compile it to WebAssembly and run it inside the sandbox or wait for extensions currently developing, such as &amp;quot;opaque reference types,&amp;quot; which allows WebAssembly applications to interact with objects managed by a Garbage Collector outside the sandbox.&lt;/p&gt;&lt;h3&gt;NGINX and Lua&lt;/h3&gt;&lt;p&gt;NGINX allows you to write dynamic modules that can be loaded at runtime based on configuration files. By modifying the configuration files and reloading NGINX, these modules can be unloaded. NGINX enables you to use Lua to embed custom logic into dynamic modules.&lt;/p&gt;&lt;p&gt;Lua is a lightweight, embeddable scripting language that supports procedural, functional, and object-oriented programming. Lua is dynamically typed, and runs by interpreting bytecode with a register-based virtual machine.&lt;/p&gt;&lt;p&gt;NGINX provides the ability to integrate dynamic Lua scripts using the ngx_lua module. Using NGINX with ngx_lua helps you offload logic from your services and hand their concerns off to an intelligent data plane. Leveraging NGINX&amp;#x27;s subrequests, the ngx_lua module allows the integration of Lua threads (or coroutines into the NGINX event model. Instead of passing logic to an upstream server, the Lua script can inspect and process service traffic. ngx_lua modules can be chained to be invoked at different phases of NGINX request processing.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Envoy and WebAssembly]]></title><description><![CDATA[function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

/* @jsxRuntime classic */

/* @jsx mdx */
var _frontmatter = {
  "title": "Envoy and WebAssembly",
  "thumbnail": "./envoy-icon-color.svg",
  "category": "WebAssembly Filters",
  "type": "Article",
  "technology": "WebAssembly",
  "tags": ["WebAssembly", "Envoy"],
  "published": true
};
var layoutProps = {
  _frontmatter: _frontmatter
};
var MDXLayout = "wrapper";
return function MDXContent(_ref) {
  var components = _ref.components,
      props = _objectWithoutProperties(_ref, ["components"]);

  return mdx(MDXLayout, _extends({}, layoutProps, props, {
    components: components,
    mdxType: "MDXLayout"
  }), mdx(ResourcesWrapper, {
    mdxType: "ResourcesWrapper"
  }, mdx("div", {
    className: "intro"
  }, mdx("p", null, "Learn more about WebAssembly's use within service mesh data planes in", mdx(Link, {
    className: "blog",
    to: "/learn/books",
    mdxType: "Link"
  }, "The Enterprise Path to Service Mesh Archictures (2nd Edition)"), " -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.")), mdx("p", null, "WASM stands for WebAssembly, which is an open standard for defining a binary format for executable programs. It also defines Interfaces for interacting with host environments through the WebAssembly System Interface (WASI). Browsers and large web applications were the primary focus of these host environments, with the goal of securely running programmes to enhance performance. The W3C maintains WASM as an open standard, and all modern browsers have adopted it. WebAssembly is the fourth language that can run natively in web browsers, following HTML, CSS, and Javascript."), mdx("p", null, "Google's open-source high-performance JavaScript and WebAssembly engine, V8, is being embedded into Envoy, bringing WASM support to the platform. Envoy exposes an Application Binary Interface (ABI) to WASM modules via the WebAssembly System Interface, allowing them to function as Envoy filters. WASI operates effortlessly. Your application is written in one of your favorite languages, such as Rust, C++, or C. Then, for the host environment, build and compile them into a WebAssembly binary. For the resulting binary to execute, the WebAssembly runtime must offer the necessary interfaces to system calls. Conceptually, this is similar to JVM. If you have a JVM installed, then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary."), mdx("p", null, "Additional filters can be added to Envoy in one of two ways:", mdx("ul", null, mdx("li", null, "By incorporating your custom filter into Envoy's C++ source code and building a new version of Envoy natively. The disadvantage is that you'll have to maintain your own version of Envoy, but the advantage is that your custom filter will run at native speed."), mdx("li", null, "Via WASM, by developing your custom filter in C++, Rust, AssemblyScript, or Go and integrating it as a WebAssembly binary. The disadvantage is that WASM-based filters have considerable overhead, but the advantage is that WASM-based filters may be dynamically loaded and reloaded in Envoy at runtime."))), mdx("p", null, "On startup, Envoy's configuration is initialised using bootstrap. The xDS APIs in Envoy enable\xA0dynamic configuration loading and reloading during runtime. There are several sections in the Envoy configuration (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). WASM plugins can be configured in each section (programs)."), mdx("h3", null, "Dynamically (Re)loadable Intelligence"), mdx("p", null, " Data planes are powerful because they can dynamically load WASM programs to inspect, rewrite, and reroute packets carrying application requests. WASM applications can integrate business logic considerations when filtering application requests when using a management plane. The service mesh can implement business logic, as well as common application infrastructure logic: "), mdx("ul", null, mdx("li", null, "Subscription plan enforcement: rate limiting requests based on user\u2019s subscription plan"), mdx("li", null, "Class of Service: directing requests to high performance clusters based on user demographics or activity"), mdx("li", null, "Multivariate testing: facilitating comparison a of high number of variables between deployments (service versions) and users")), mdx("div", {
    className: "fact"
  }, mdx("p", null, "To get a feel of these\xA0capabilities, try experimenting with the ", mdx(Link, {
    to: "/projects/image-hub",
    mdxType: "Link"
  }, "Image Hub"), ",a prototype application developed in Rust that runs on Consul and allows you to explore WebAssembly modules used as Envoy filters.")), mdx("div", {
    className: "center"
  }, mdx("img", {
    src: Infrastructure,
    align: "center",
    alt: "application infrastructure logic"
  }), mdx("p", null, "Figure 1:. How the intelligence of the service mesh management plane and the power of the service mesh data plane combine to deliver application infrastructure logic.  ")), mdx("p", null, "WebAssembly is intriguing in part because of its performance characteristics, which vary depending on the program/filter used. For network filtering use cases, some have a 10% to 20% overhead as compared to natively executed code.\xA0 Given its high degree of portability, WebAssembly resembles Docker in certain ways. WASM's virtual stack machine, like the Java Virtual Machine (JVM), is evolving into a write once, run anywhere system (WORA). WASM executables are precompiled with a wide range of languages that support it as a compilation target (currently around 40 languages).")));
}
;
MDXContent.isMDXComponent = true;]]></description><link>https://layer5.io/resources/webassembly-filters/envoy-and-webassembly</link><guid isPermaLink="false">https://layer5.io/resources/webassembly-filters/envoy-and-webassembly</guid><enclosure url="https://layer5.io/static/ef8ca37dab5018498438c17e69966940/envoy-icon-color.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about WebAssembly&amp;#x27;s use within service mesh data planes in&lt;a class=&quot;blog&quot; href=&quot;/learn/books&quot;&gt;The Enterprise Path to Service Mesh Archictures (2nd Edition)&lt;/a&gt; -  free book and excellent resource for anyone looking to understand WASM filters, Lua scripts, and other options available for extending the data plane.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;WASM stands for WebAssembly, which is an open standard for defining a binary format for executable programs. It also defines Interfaces for interacting with host environments through the WebAssembly System Interface (WASI). Browsers and large web applications were the primary focus of these host environments, with the goal of securely running programmes to enhance performance. The W3C maintains WASM as an open standard, and all modern browsers have adopted it. WebAssembly is the fourth language that can run natively in web browsers, following HTML, CSS, and Javascript.&lt;/p&gt;&lt;p&gt;Google&amp;#x27;s open-source high-performance JavaScript and WebAssembly engine, V8, is being embedded into Envoy, bringing WASM support to the platform. Envoy exposes an Application Binary Interface (ABI) to WASM modules via the WebAssembly System Interface, allowing them to function as Envoy filters. WASI operates effortlessly. Your application is written in one of your favorite languages, such as Rust, C++, or C. Then, for the host environment, build and compile them into a WebAssembly binary. For the resulting binary to execute, the WebAssembly runtime must offer the necessary interfaces to system calls. Conceptually, this is similar to JVM. If you have a JVM installed, then you can run any Java-like languages on it. Similarly, with a runtime, you can run the WebAssembly binary.&lt;/p&gt;&lt;p&gt;Additional filters can be added to Envoy in one of two ways:&lt;ul&gt;&lt;li&gt;By incorporating your custom filter into Envoy&amp;#x27;s C++ source code and building a new version of Envoy natively. The disadvantage is that you&amp;#x27;ll have to maintain your own version of Envoy, but the advantage is that your custom filter will run at native speed.&lt;/li&gt;&lt;li&gt;Via WASM, by developing your custom filter in C++, Rust, AssemblyScript, or Go and integrating it as a WebAssembly binary. The disadvantage is that WASM-based filters have considerable overhead, but the advantage is that WASM-based filters may be dynamically loaded and reloaded in Envoy at runtime.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;p&gt;On startup, Envoy&amp;#x27;s configuration is initialised using bootstrap. The xDS APIs in Envoy enable dynamic configuration loading and reloading during runtime. There are several sections in the Envoy configuration (e.g. LDS which is for configuring Listeners and CDS which is for configuring clusters). WASM plugins can be configured in each section (programs).&lt;/p&gt;&lt;h3&gt;Dynamically (Re)loadable Intelligence&lt;/h3&gt;&lt;p&gt; Data planes are powerful because they can dynamically load WASM programs to inspect, rewrite, and reroute packets carrying application requests. WASM applications can integrate business logic considerations when filtering application requests when using a management plane. The service mesh can implement business logic, as well as common application infrastructure logic: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Subscription plan enforcement: rate limiting requests based on user’s subscription plan&lt;/li&gt;&lt;li&gt;Class of Service: directing requests to high performance clusters based on user demographics or activity&lt;/li&gt;&lt;li&gt;Multivariate testing: facilitating comparison a of high number of variables between deployments (service versions) and users&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;fact&quot;&gt;&lt;p&gt;To get a feel of these capabilities, try experimenting with the &lt;a href=&quot;/projects/image-hub&quot;&gt;Image Hub&lt;/a&gt;,a prototype application developed in Rust that runs on Consul and allows you to explore WebAssembly modules used as Envoy filters.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;center&quot;&gt;&lt;img src=&quot;static/figure1-8ca07464d8d5a4cb657bed3daa70716e.png&quot; align=&quot;center&quot; alt=&quot;application infrastructure logic&quot;/&gt;&lt;p&gt;Figure 1:. How the intelligence of the service mesh management plane and the power of the service mesh data plane combine to deliver application infrastructure logic.  &lt;/p&gt;&lt;/div&gt;&lt;p&gt;WebAssembly is intriguing in part because of its performance characteristics, which vary depending on the program/filter used. For network filtering use cases, some have a 10% to 20% overhead as compared to natively executed code.  Given its high degree of portability, WebAssembly resembles Docker in certain ways. WASM&amp;#x27;s virtual stack machine, like the Java Virtual Machine (JVM), is evolving into a write once, run anywhere system (WORA). WASM executables are precompiled with a wide range of languages that support it as a compilation target (currently around 40 languages).&lt;/p&gt;&lt;/div&gt;</content:encoded></item></channel></rss>