<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Layer5 Contributor Feed]]></title><description><![CDATA[Expect more from your infrastructure. Cloud native, open source software for your cloud native infrastructure and applications. Allowing developers to focus on business logic, not infrastructure concerns. Empowering operators to confidently run modern infrastructure.]]></description><link>https://layer5.io</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 25 Nov 2025 11:37:27 GMT</lastBuildDate><item><title><![CDATA[Kanvas: Like Miro, But Much, Much More]]></title><description><![CDATA[Discover how Kanvas goes beyond traditional collaborative design tools like Miro to provide engineers with a comprehensive platform for designing, deploying, and managing cloud-native infrastructure.]]></description><link>https://layer5.io/blog/kanvas/kanvas-like-miro-but-much-much-more</link><guid isPermaLink="false">https://layer5.io/blog/kanvas/kanvas-like-miro-but-much-much-more</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Wed, 19 Nov 2025 16:30:05 GMT</pubDate><enclosure url="https://layer5.io/static/7b643017b888e339b099aa6f9ed83acd/kanvas-icon-color.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;If you&amp;#x27;ve ever used Miro, you know the appeal of a collaborative visual workspace. Sticky notes, diagrams, infinite canvases—it&amp;#x27;s a designer&amp;#x27;s playground. But what happens when engineers need more than just pretty diagrams? What happens when those boxes and arrows need to actually &lt;strong&gt;do something&lt;/strong&gt;?&lt;/p&gt;&lt;p&gt;That&amp;#x27;s where &lt;a href=&quot;/cloud-native-management/kanvas&quot;&gt;Kanvas&lt;/a&gt; comes in.&lt;/p&gt;&lt;p&gt;Kanvas is what you get when you take the collaborative visual thinking of Miro and infuse it with the power of infrastructure-as-code, Kubernetes orchestration, and GitOps workflows. It&amp;#x27;s not just a whiteboard—it&amp;#x27;s a &lt;strong&gt;complete engineering platform&lt;/strong&gt; for cloud-native infrastructure.&lt;/p&gt;&lt;h2&gt;The Miro Experience (And Its Limits)&lt;/h2&gt;&lt;p&gt;Let&amp;#x27;s be fair: Miro is excellent at what it does. Teams use it to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Brainstorm ideas with virtual sticky notes&lt;/li&gt;&lt;li&gt;Map out user journeys and customer experiences&lt;/li&gt;&lt;li&gt;Create wireframes and mockups&lt;/li&gt;&lt;li&gt;Run design thinking workshops&lt;/li&gt;&lt;li&gt;Collaborate asynchronously across time zones&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For product designers, UX researchers, and agile teams, Miro is invaluable. The problem emerges when you try to move from &lt;strong&gt;design to deployment&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Picture this: Your team has just spent two hours mapping out your microservices architecture in Miro. Beautiful diagram. Everyone&amp;#x27;s aligned. Great meeting. &lt;/p&gt;&lt;p&gt;Now what?&lt;/p&gt;&lt;p&gt;Someone has to translate that diagram into YAML. Someone has to configure the ingress controllers. Someone has to set up the service mesh. Someone has to ensure the production deployment actually matches what&amp;#x27;s on the whiteboard.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The diagram and reality immediately diverge.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;The Infrastructure Gap&lt;/h2&gt;&lt;p&gt;This gap between design and reality is what we call the &lt;strong&gt;infrastructure gap&lt;/strong&gt;. Traditional diagramming tools create a one-way street: you design, then you implement separately. There&amp;#x27;s no connection between the visual representation and the actual infrastructure.&lt;/p&gt;&lt;p&gt;This leads to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Drift&lt;/strong&gt;: Your diagrams become outdated the moment infrastructure changes&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Manual Translation&lt;/strong&gt;: Engineers spend hours converting boxes and arrows into YAML manifests&lt;/li&gt;&lt;li&gt;&lt;strong&gt;No Single Source of Truth&lt;/strong&gt;: Is the diagram right? Is the code right? Who knows?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Limited Collaboration&lt;/strong&gt;: DevOps engineers can&amp;#x27;t &amp;quot;play&amp;quot; in the same visual space as the rest of the team because the tool doesn&amp;#x27;t speak their language&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Enter Kanvas: Where Design Meets Deployment&lt;/h2&gt;&lt;p&gt;Kanvas is fundamentally different. It&amp;#x27;s built on the principle of &lt;strong&gt;Infrastructure as Design&lt;/strong&gt;—the idea that your visual representation and your actual infrastructure should be the same thing.&lt;/p&gt;&lt;p&gt;When you drag a Kubernetes Deployment onto the Kanvas canvas, you&amp;#x27;re not drawing a picture of a deployment. You&amp;#x27;re &lt;strong&gt;creating an actual Kubernetes deployment manifest&lt;/strong&gt;. When you connect two services, you&amp;#x27;re not sketching a relationship—you&amp;#x27;re &lt;strong&gt;defining network policies and service meshes&lt;/strong&gt;.&lt;/p&gt;&lt;h3&gt;What Makes Kanvas an Engineer&amp;#x27;s Tool&lt;/h3&gt;&lt;h4&gt;1. &lt;strong&gt;Live Infrastructure Integration&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Kanvas operates in two modes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Designer Mode&lt;/strong&gt;: Create and design infrastructure patterns, applications, and deployments&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Operator Mode&lt;/strong&gt;: Visualize and manage your live, running infrastructure in real-time&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In Operator mode, Kanvas connects directly to your Kubernetes clusters. You can see what&amp;#x27;s actually running, what&amp;#x27;s healthy, what&amp;#x27;s failing—all visually. No more &lt;code&gt;kubectl get pods&lt;/code&gt; in 47 terminal windows.&lt;/p&gt;&lt;h4&gt;2. &lt;strong&gt;Import Existing Infrastructure&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Already have Kubernetes manifests? Helm charts? Docker Compose files? Kustomize configurations?&lt;/p&gt;&lt;p&gt;Import them directly into Kanvas. The platform automatically converts them into visual components on the canvas, giving you instant visual insight into what you&amp;#x27;ve already built. This is crucial for teams inheriting complex infrastructure or working with legacy systems.&lt;/p&gt;&lt;h4&gt;3. &lt;strong&gt;GitOps-Native Workflow&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Kanvas integrates seamlessly with GitOps workflows. Every change you make in the visual designer can be tracked, versioned, and managed through Git. Your infrastructure-as-design becomes infrastructure-as-code automatically.&lt;/p&gt;&lt;p&gt;This means:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Full audit trail of who changed what and when&lt;/li&gt;&lt;li&gt;Ability to roll back to previous infrastructure states&lt;/li&gt;&lt;li&gt;Collaboration through pull requests and code reviews&lt;/li&gt;&lt;li&gt;Consistency with your existing CI/CD pipelines&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;4. &lt;strong&gt;Multi-Cluster, Multi-Cloud Management&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Built on top of &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery&lt;/a&gt;, Kanvas supports managing infrastructure across:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Multiple Kubernetes clusters&lt;/li&gt;&lt;li&gt;Different cloud providers (AWS, GCP, Azure)&lt;/li&gt;&lt;li&gt;Various service meshes (Istio, Linkerd, Consul, etc.)&lt;/li&gt;&lt;li&gt;Hundreds of cloud-native technologies&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You can design once and deploy everywhere, or visualize your entire distributed infrastructure in a single pane of glass.&lt;/p&gt;&lt;h4&gt;5. &lt;strong&gt;Component Library with Real Infrastructure&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Where Miro gives you shapes and connector lines, Kanvas gives you &lt;strong&gt;actual infrastructure components&lt;/strong&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Kubernetes Deployments, Services, ConfigMaps, and Secrets&lt;/li&gt;&lt;li&gt;Istio VirtualServices and DestinationRules&lt;/li&gt;&lt;li&gt;Prometheus monitoring configurations&lt;/li&gt;&lt;li&gt;Database operators&lt;/li&gt;&lt;li&gt;Custom Resource Definitions (CRDs)&lt;/li&gt;&lt;li&gt;And thousands more from the ecosystem&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Each component comes with its full configuration exposed, not just a pretty icon.&lt;/p&gt;&lt;h4&gt;6. &lt;strong&gt;Collaboration That Scales&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Like Miro, Kanvas supports multi-user collaboration. But unlike Miro, when multiple engineers are working together in Kanvas, they&amp;#x27;re not just moving sticky notes around—they&amp;#x27;re &lt;strong&gt;co-authoring production infrastructure&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Changes are collaborative, but also controlled. You can share designs, publish them to the &lt;a href=&quot;/cloud-native-management/catalog&quot;&gt;Kanvas Catalog&lt;/a&gt; for others to clone, and standardize deployment patterns across your organization.&lt;/p&gt;&lt;h2&gt;Real-World Use Cases&lt;/h2&gt;&lt;h3&gt;Scenario 1: Onboarding New Team Members&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;With Miro:&lt;/strong&gt; &amp;quot;Here&amp;#x27;s a diagram of our infrastructure. Good luck figuring out what&amp;#x27;s actually deployed.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;With Kanvas:&lt;/strong&gt; Import your production Kubernetes manifests, visualize them on the canvas, and let new engineers explore the actual infrastructure visually. They can see relationships, configurations, and dependencies—all mapped to real resources.&lt;/p&gt;&lt;h3&gt;Scenario 2: Designing a New Microservice&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;With Miro:&lt;/strong&gt; Sketch the architecture, export a PNG, hand it off to DevOps to implement.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;With Kanvas:&lt;/strong&gt; Design the service architecture visually, configure the Kubernetes resources, define the service mesh policies, set up observability, and deploy—all from the same canvas.&lt;/p&gt;&lt;h3&gt;Scenario 3: Troubleshooting Production Issues&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;With Miro:&lt;/strong&gt; Diagrams are useless. Back to the terminal.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;With Kanvas:&lt;/strong&gt; Switch to Operator mode, see the live state of your infrastructure, identify failing components visually, and drill down into logs and metrics—without leaving the visual context.&lt;/p&gt;&lt;h3&gt;Scenario 4: Standardizing Deployment Patterns&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;With Miro:&lt;/strong&gt; Copy-paste diagrams and hope teams implement them correctly.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;With Kanvas:&lt;/strong&gt; Create a design pattern, publish it to the Catalog, and teams can clone and deploy it exactly as designed. Consistency guaranteed.&lt;/p&gt;&lt;h2&gt;The Best of Both Worlds&lt;/h2&gt;&lt;p&gt;Here&amp;#x27;s the thing: &lt;strong&gt;Kanvas doesn&amp;#x27;t replace the brainstorming aspect of Miro&lt;/strong&gt;. You can still sketch, annotate, and collaborate visually. The difference is that when you&amp;#x27;re ready to move from idea to implementation, Kanvas goes with you.&lt;/p&gt;&lt;p&gt;You can start with high-level architecture diagrams and progressively add detail, configuration, and deployment logic—all in the same tool. The barrier between &amp;quot;design time&amp;quot; and &amp;quot;runtime&amp;quot; dissolves.&lt;/p&gt;&lt;h2&gt;Who Should Use Kanvas?&lt;/h2&gt;&lt;p&gt;Kanvas is ideal for:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Platform Engineers&lt;/strong&gt; building internal developer platforms&lt;/li&gt;&lt;li&gt;&lt;strong&gt;DevOps and SRE Teams&lt;/strong&gt; managing complex infrastructure&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Cloud Architects&lt;/strong&gt; designing multi-cloud strategies&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Infrastructure Teams&lt;/strong&gt; migrating to Kubernetes&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Anyone&lt;/strong&gt; tired of YAML hell&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you&amp;#x27;re working with cloud-native infrastructure and you&amp;#x27;ve wished for a better way to visualize, design, and operate it—Kanvas is your tool.&lt;/p&gt;&lt;h2&gt;Beyond the Whiteboard: Infrastructure That Works&lt;/h2&gt;&lt;p&gt;Miro is fantastic for what it does. But when you need to design infrastructure that actually runs, deploys, scales, and operates—you need more than a whiteboard.&lt;/p&gt;&lt;p&gt;You need Kanvas.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Infrastructure as Design.&lt;/strong&gt; Not infrastructure as an afterthought.&lt;/p&gt;&lt;p&gt;Ready to see the difference? &lt;a href=&quot;/cloud-native-management/kanvas&quot;&gt;Try Kanvas today&lt;/a&gt; and experience what it&amp;#x27;s like to work with a tool built for engineers, by engineers.&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;em&gt;Want to learn more? Check out the &lt;a href=&quot;/cloud-native-management/catalog&quot;&gt;Kanvas Catalog&lt;/a&gt; for ready-to-use infrastructure patterns, or dive into the &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery documentation&lt;/a&gt; to understand the powerful engine behind Kanvas.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[CNCF Honors Innovators and Defenders with 2025 Community Awards at KubeCon + CloudNativeCon North America]]></title><description><![CDATA[CNCF’s 2025 Community Awards at KubeCon + CloudNativeCon North America spotlights contributors, end users, mentors, and community heroes, with Layer5 founder Lee Calcote honored for his mentorship leadership.]]></description><link>https://layer5.io/company/news/cncf-honors-innovators-and-defenders-with-2025-community-awards-at-kubecon-cloudnativecon-north-america</link><guid isPermaLink="false">https://layer5.io/company/news/cncf-honors-innovators-and-defenders-with-2025-community-awards-at-kubecon-cloudnativecon-north-america</guid><dc:creator><![CDATA[The Newsroom]]></dc:creator><pubDate>Sun, 16 Nov 2025 13:30:00 GMT</pubDate><enclosure url="https://layer5.io/static/5c1bd25e7d1d30f18eb73288f35442e8/kubecon-2025.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 bzJNOf&quot;&gt;&lt;p&gt;[Atlanta, GA][KubeCon + CloudNativeCon North America] – November 12, 2025 —
The Cloud Native Computing Foundation (CNCF) has announced the winners of its 2025 Community Awards, celebrating contributors, mentors, end users, and long-time ecosystem champions. Among this year’s honorees is &lt;strong&gt;Layer5 founder Lee Calcote&lt;/strong&gt;, recipient of the &lt;strong&gt;inaugural Outstanding Mentor Award&lt;/strong&gt; for his deep and consistent commitment to growing community talent across CNCF and Linux Foundation programs.&lt;/p&gt;&lt;a href=&quot;https://www.cncf.io/announcements/2025/11/12/cncf-honors-innovators-and-defenders-with-2025-community-awards-at-kubecon-cloudnativecon-north-america/&quot;&gt;Read the official CNCF announcement&lt;/a&gt;&lt;h2&gt;&lt;strong&gt;Recognizing Leaders Shaping the Cloud Native Ecosystem&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The CNCF Community Awards spotlight individuals whose work strengthens the global cloud native community. This year’s recognitions included:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Lifetime Achievement Award&lt;/strong&gt;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Top End User Award&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Top Committer Award&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Chop Wood, Carry Water Award&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Outstanding Mentor Award&lt;/strong&gt; (first-ever)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Cloud Native Hero Award&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;TAGGIE Award&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;End User Case Study Contest&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Lorem Ipsum (Top Documentarian) Award&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These awards highlight the diverse technical, organizational, and community-driven efforts that contribute to the sustained health of the CNCF ecosystem.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Lee Calcote Receives the Outstanding Mentor Award&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;CNCF honored &lt;strong&gt;Lee Calcote&lt;/strong&gt; for mentoring more than &lt;strong&gt;60 times&lt;/strong&gt; over the past five years, across programs including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The Linux Foundation’s LFX Mentorship Program  &lt;/li&gt;&lt;li&gt;Google Summer of Code (GSoC)  &lt;/li&gt;&lt;li&gt;CNCF TAG initiatives  &lt;/li&gt;&lt;li&gt;Meshery and Layer5 community programs  &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Many of his mentees have gone on to become active contributors and maintainers within CNCF projects, reflecting the long-term impact of his mentorship.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 evseNu blockquote&quot; quote=&quot;This year’s award recipients reflect what it really takes to sustain the cloud native community.&quot; person=&quot;Chris Aniszczyk&quot; title=&quot;CTO, CNCF&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;This year’s award recipients reflect what it really takes to sustain the cloud native community.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Chris Aniszczyk&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;CTO, CNCF&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;Strengthening the Global Open Source Community&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;With over &lt;strong&gt;270,000 contributors&lt;/strong&gt; and &lt;strong&gt;728 member organizations&lt;/strong&gt;, the CNCF ecosystem thrives on collaboration, documentation, mentorship, and sustained contributions. This year’s awardees exemplify the dedication required to keep cloud native innovation moving forward.&lt;/p&gt;&lt;p&gt;Layer5 congratulates all recipients and celebrates the community-driven spirit that continues to move open source infrastructure forward.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;About Layer5&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Layer5 is the cloud native management company behind &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt;, the extensible cloud native manager enabling teams to build and operate modern distributed systems with confidence. With a global open source community of more than 10,000 members, Layer5 empowers engineers to collaborate across multi-cluster and multi-cloud environments.&lt;/p&gt;&lt;p&gt;Learn more at &lt;a href=&quot;https://layer5.io&quot;&gt;layer5.io&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Layer5 Debuts Enterprise Edition of Meshery for Configuring Kubernetes]]></title><description><![CDATA[Announced at KubeCon + CloudNativeCon North America 2025, Kanvas extends the Meshery framework with visual tools, collaborative workspaces, and role-based access control for managing Kubernetes environments]]></description><link>https://layer5.io/company/news/layer5-debuts-enterprise-edition-of-meshery-for-configuring-kubernetes</link><guid isPermaLink="false">https://layer5.io/company/news/layer5-debuts-enterprise-edition-of-meshery-for-configuring-kubernetes</guid><dc:creator><![CDATA[Cloud Native Now]]></dc:creator><pubDate>Wed, 12 Nov 2025 13:30:00 GMT</pubDate><enclosure url="https://layer5.io/static/d51507c39d2e8e8618e5fe51a8c368fc/Layer5-Kanvas-Designer-img.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 bzJNOf&quot;&gt;&lt;p&gt;Layer5 today revealed it has made available Kanvas, an enterprise grade distribution of the open source Meshery framework for declaratively managing Kubernetes environments.&lt;/p&gt;&lt;p&gt;Announced at the KubeCon + CloudNativeCon North America 2025 conference, Kanvas adds additional graphical tools to visualize and edit, along with functionality such as the ability to store snapshots in GitHub repositories to a core Meshery platform that provides workspaces that enable IT teams to collaborate more easily. It also provides access to a catalog of hundreds of pre-built, best-practice design patterns and reference architectures that IT teams can extend.&lt;/p&gt;&lt;p&gt;Additionally, Kanvas also makes available role-based access controls (RBAC) and an ability to import existing Kubernetes manifests, Helm charts, Kustomize configuration and Docker Compose files.&lt;/p&gt;&lt;p&gt;Available to be deployed by an internal IT team or access as a managed service, Kanvas today provides a drag-and-drop interface for designing and visualizing complex infrastructure and application architectures using Meshery.&lt;/p&gt;&lt;p&gt;Layer5 is also making available in beta a Kanvas Operator for managing live infrastructure in real-time using a Meshery framework that is currently being advanced under the auspices of the Cloud Native Computing Foundation (CNCF).&lt;/p&gt;&lt;p&gt;Layer5 CEO Lee Calcote said at its core Meshery provides a platform that fosters collaboration in a way that makes it simpler for IT teams to retain tribal knowledge. It allows engineers to see, collaborate on, and approve suggestions on a visual canvas, and even conduct a dry run to validate changes.&lt;/p&gt;&lt;p&gt;In addition to making it simpler to manage Kubernetes clusters at scale, Kanvas also makes it simpler to onboard additional engineers to a team, noted Calcote.&lt;/p&gt;&lt;p&gt;It’s not clear how many Kubernetes clusters are deployed in production environments, but as the number increases, the need for finding ways to manage one of the most complex IT platforms ever created is becoming more acute. There simply are not enough engineers to manage those clusters, so platforms such as Kanvas that make it simpler for small teams to consistently manage the configuration of Kubernetes clusters is crucial, said Calcote.&lt;/p&gt;&lt;p&gt;Hopefully, as various tools make Kubernetes more accessible, organizations will be able to rely more on IT administrators rather than DevOps engineers to manage them. The need for DevOps engineers isn’t likely to be eliminated any time soon, but it should become easier for IT teams to reuse configurations that have already been validated by a DevOps team. In effect, Meshery and Kanvas are making it simpler for IT teams to embrace infrastructure by design principles, noted Calcote.&lt;/p&gt;&lt;p&gt;In the meantime, IT organizations should expect the total number of workloads running on Kubernetes clusters to continue to steadily increase, especially as more artificial intelligence (AI) applications are built and deployed. The challenge, as always, is finding a way to manage large numbers of Kubernetes clusters at higher levels of scale. In fact, arguably there would many more Kubernetes clusters already deployed in the platform if the platform was easier to manage.&lt;/p&gt;&lt;p&gt;Hopefully, there will come a day soon when the inherent complexity of Kubernetes is no longer an issue, but until then, the next best thing is to adopt tools that enable IT teams to manage clusters at a much higher level of abstraction.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Read the original article on &lt;a href=&quot;https://cloudnativenow.com/features/layer5-debuts-enterprise-edition-of-meshery-for-configuring-kubernetes/&quot;&gt;https://cloudnativenow.com/features/layer5-debuts-enterprise-edition-of-meshery-for-configuring-kubernetes/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Layer5 Unveils Kanvas]]></title><description><![CDATA[Empowering Platform and Operations Teams with Intuitive Tools to Design, Deploy, and Operate Kubernetes and Multi-Cloud Infrastructure]]></description><link>https://layer5.io/company/news/layer5-unveils-kanvas</link><guid isPermaLink="false">https://layer5.io/company/news/layer5-unveils-kanvas</guid><dc:creator><![CDATA[The Newsroom]]></dc:creator><pubDate>Tue, 11 Nov 2025 13:30:00 GMT</pubDate><enclosure url="https://layer5.io/static/72106b16d634bf9bfc689071f4aba4ce/Layer5-Kanvas-Designer.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 bzJNOf&quot;&gt;&lt;p&gt;&lt;strong&gt;ATLANTA, GA&lt;/strong&gt; - November 11th, 2025 – &lt;a href=&quot;https://layer5.io&quot;&gt;Layer5&lt;/a&gt;, the company behind the popular &lt;a href=&quot;https://meshery.io&quot;&gt;Meshery&lt;/a&gt; project, today announced the general availability (GA) of Kanvas. As an enterprise-grade distribution of Meshery, Kanvas is a critical platform engineering tool that unifies infrastructure design, operation, and collaboration for teams managing complex cloud native environments.&lt;/p&gt;&lt;p&gt;Kanvas directly addresses the persistent challenges that platform engineers, SREs, and architects face: the unmanageable cognitive load of highly distributed systems, critical security gaps arising from mismanaged secrets and insecure network configurations, and fragmented workflows that silo teams and slow innovation.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;The rise of AI is about to amplify that complexity tenfold as it brings an onslaught of suggested infrastructure changes from non-deterministic LLMs, whose inherent risk of hallucination only exacerbates the cognitive overload of engineers.&quot; person=&quot;Lee Calcote&quot; title=&quot;CEO of Layer5&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;The rise of AI is about to amplify that complexity tenfold as it brings an onslaught of suggested infrastructure changes from non-deterministic LLMs, whose inherent risk of hallucination only exacerbates the cognitive overload of engineers.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Lee Calcote&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;CEO of Layer5&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Kanvas functions as a &amp;quot;Google Workspace for engineers,&amp;quot; providing a unified, multi-modal collaboration suite built atop one of the Cloud Native Computing Foundation’s (CNCF) most dynamic open source projects, Meshery. Kanvas also tackles the high cost of turnover by facilitating the retention of tribal knowledge and significantly reducing the time to productivity for new engineers by streamlining the onboarding process for shipping code and managing infrastructure.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 evseNu blockquote&quot; quote=&quot;Teams simply cannot be expected to approve a black box of LLM-generated changes. The way to safely harness the power of AI is to combat cognitive load ‘head-on’. This means visually representing *all* changes—whether from a human or an AI—in a way the mind can readily digest. A picture is worth a thousand words, as they say. In Kanvas, we call this &amp;#x27;infrastructure as design.&amp;#x27;&quot; person=&quot;Lee Calcote&quot; title=&quot;CEO of Layer5&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Teams simply cannot be expected to approve a black box of LLM-generated changes. The way to safely harness the power of AI is to combat cognitive load ‘head-on’. This means visually representing *all* changes—whether from a human or an AI—in a way the mind can readily digest. A picture is worth a thousand words, as they say. In Kanvas, we call this &amp;#x27;infrastructure as design.&amp;#x27;&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Lee Calcote&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;CEO of Layer5&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Kanvas allows engineers to see, collaborate on, and approve suggestions on a visual canvas, and even perform &amp;#x27;dry runs&amp;#x27; of their designs through GitOps-infused visual diffs &lt;em&gt;before&lt;/em&gt; a single change is committed to production. &lt;a href=&quot;https://docs.layer5.io/videos/getting-started/comments/design-reviews-full/&quot;&gt;Peer reviews in Kanvas restore human oversight&lt;/a&gt; and collaboration to an increasingly complex, AI-driven world.&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;Kanvas has two powerful, integrated modes:&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Kanvas Designer&lt;/strong&gt; (GA): Offers an intuitive, declarative, drag-and-drop interface for designing and visualizing complex infrastructure and application architectures.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Kanvas Operator&lt;/strong&gt; (beta): Provides an imperative, hands-on mode for managing and operating live infrastructure in real-time.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This dual-mode approach allows platform engineers to curate a catalog of design patterns, solution architects to design multi-cloud infrastructure, and SREs to collaborate on incident resolution, all within a single platform.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;/static/Layer5-Kanvas-Designer-img-8166db031c00aabddcdf0542d106cba4.png&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/Layer5-Kanvas-Designer-img-8166db031c00aabddcdf0542d106cba4.png&quot; alt=&quot;Layer5 Kanvas Designer&quot; width=&quot;100%&quot; class=&quot;block-display align-center&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;&lt;/a&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;strong&gt;Driven by Community, Ready for the Enterprise&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The power of Kanvas stems from its foundation in Meshery, which was recently recognized as the &lt;a href=&quot;https://meshery.io/blog/sixth-highest-velocity-cncf-project&quot;&gt;sixth highest-velocity project out of more than 240 projects&lt;/a&gt; in the CNCF. This incredible momentum, driven by over 3,000 global contributors, underscores the platform&amp;#x27;s stability, rich feature set, and the vibrant community driving its innovation.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;Kanvas has me rethinking how I approach interactions with team members. The ability to visually design, import existing Helm charts, and collaborate on changes in a single GitOps workflow might just eliminate my cross-team friction. Workspaces in Kanvas are my new Google Drive for infrastructure work.&quot; person=&quot;Venil Noronha&quot; title=&quot;Tech Lead at Stripe&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;Kanvas has me rethinking how I approach interactions with team members. The ability to visually design, import existing Helm charts, and collaborate on changes in a single GitOps workflow might just eliminate my cross-team friction. Workspaces in Kanvas are my new Google Drive for infrastructure work.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Venil Noronha&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Tech Lead at Stripe&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;This enterprise readiness is further validated by the project&amp;#x27;s recent maturity, including &lt;a href=&quot;https://meshery.io/blog/2025/meshery-ecosystem-expansion&quot;&gt;a strategic governance shift to scale its growing ecosystem of extensions&lt;/a&gt; and the &lt;a href=&quot;https://www.cncf.io/blog/2025/10/27/announcing-the-certified-meshery-contributor-cmc/&quot;&gt;launch of the new Certified Meshery Contributor (CMC) program&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Kanvas caters to a wide range of users, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Engineering teams and managers&lt;/strong&gt; for brainstorming, diagramming, wireframing, and interviewing.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Platform engineers&lt;/strong&gt; for underpinning self-service and developer empowerment.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Site reliability engineers&lt;/strong&gt; for curating a catalog of design patterns as a center of excellence, operators.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Solution architects&lt;/strong&gt; designing infrastructure across multiple cloud providers from a single canvas.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Developer advocates and educators&lt;/strong&gt; for facilitating real-time exploration and asynchronous study of any cloud native technology.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Developers and product engineers&lt;/strong&gt; for ease of understanding and of design of their application infrastructure.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;System integrators and consultants&lt;/strong&gt; for a service provider-grade organization hierarchy, multi-tenant, white-labelable, highly extensible delivery platform.&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 evseNu blockquote&quot; quote=&quot;Particularly as AI has entered our field, the trend of platform engineers leveraging Kubernetes Operators to automate application and infrastructure lifecycle management has grown stronger. What&amp;#x27;s exciting about Kanvas is how it builds on this evolution by introducing &amp;#x27;infrastructure as design&amp;#x27;. This is an innovative abstraction that finally simplifies the underlying complexities we deal with daily—like Kubernetes CRDs and Terraform modules. This approach is transformative; it empowers us to visually design, deploy, and manage our infrastructure with unprecedented ease and clarity.&quot; person=&quot;Dhruv Sharma&quot; title=&quot;Principal Platform Product Manager at GuideWire&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Particularly as AI has entered our field, the trend of platform engineers leveraging Kubernetes Operators to automate application and infrastructure lifecycle management has grown stronger. What&amp;#x27;s exciting about Kanvas is how it builds on this evolution by introducing &amp;#x27;infrastructure as design&amp;#x27;. This is an innovative abstraction that finally simplifies the underlying complexities we deal with daily—like Kubernetes CRDs and Terraform modules. This approach is transformative; it empowers us to visually design, deploy, and manage our infrastructure with unprecedented ease and clarity.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Dhruv Sharma&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Principal Platform Product Manager at GuideWire&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;hr/&gt;&lt;h2&gt;&lt;strong&gt;Key Features Now Generally Available:&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Unified Visual Design &amp;amp; Operation&lt;/strong&gt;: Toggle between the declarative designer for visual architecture and the imperative Operator for live cluster management, including interactive terminals and live resource views.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;GitOps-Infused Workflows&lt;/strong&gt;: Go beyond basic integration with &lt;a href=&quot;https://docs.layer5.io/cloud/tutorials/gitops-snapshots/&quot;&gt;Kanvas Snapshots&lt;/a&gt;, providing visual infrastructure diffs directly in GitHub pull requests.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enterprise Identity &amp;amp; Governance&lt;/strong&gt;: Manage access with a robust hierarchy of Organizations, Teams, and Users governed by role-based access control (RBAC).  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Comprehensive Import Engine&lt;/strong&gt;: Visualize brownfield environments by importing existing Kubernetes manifests, Helm charts, Kustomize, and Docker Compose files into editable and deployable designs.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Collaborative Workspaces&lt;/strong&gt;: Utilize Workspaces (like a Google Drive for infrastructure) to organize designs, environments, and team access in one place.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Rich, Real-time Collaboration&lt;/strong&gt;: Work with teammates simultaneously, using visual whiteboarding tools and inline commenting to review designs.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Extensive Design Catalog&lt;/strong&gt;: Accelerate projects by leveraging a rich catalog of hundreds of pre-built, best-practice design patterns and modern reference architectures. This enables teams to adopt vetted configurations with one click, ensuring consistency and best practices from the start.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Flexible Deployment&lt;/strong&gt;: Available as a fully managed service or as a self-hosted solution with support for white-labeling and custom domains.&lt;/li&gt;&lt;/ul&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;/static/Kanvas-Catalog-43a1dc1d24370167c08a66fe7c3f2f00.png&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/Kanvas-Catalog-43a1dc1d24370167c08a66fe7c3f2f00.png&quot; alt=&quot;Kanvas Catalog&quot; width=&quot;100%&quot; class=&quot;block-display align-center&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;&lt;/a&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Layer5 Kanvas is available today as both a self-hosted solution and a managed service. Get started by visiting &lt;a href=&quot;https://kanvas.new&quot;&gt;https://kanvas.new&lt;/a&gt;.&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;strong&gt;About Layer5&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Layer5&amp;#x27;s mission is to simplify the adoption and operation of cloud native infrastructure, enabling organizations to innovate faster and engineers to do so collaboratively. Layer5’s award-winning open source community has over 10,000 members. Visit &lt;a href=&quot;https://layer5.io&quot;&gt;https://layer5.io&lt;/a&gt;.&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;strong&gt;About Kanvas&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Kanvas is a web-based, enterprise-grade collaboration platform that allows platform, operations, and development teams to create, review, and operate highly-detailed architecture diagrams of their cloud and cloud native infrastructure. Kanvas is the definitive tool for productive, collaborative infrastructure management. Learn more about Kanvas at &lt;a href=&quot;https://layer5.io/kanvas&quot;&gt;https://layer5.io/kanvas&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Meshery Ranks 6th Highest-Velocity Project in CNCF, Announces Major Governance Shift]]></title><description><![CDATA[Riding top-tier CNCF velocity, Meshery unveils a new, expanded project structure at KubeCon to accelerate its 300+ community-driven integrations.]]></description><link>https://layer5.io/company/news/meshery-ranks-6th-highest-velocity-project-in-cncf-announces-major-governance-shift</link><guid isPermaLink="false">https://layer5.io/company/news/meshery-ranks-6th-highest-velocity-project-in-cncf-announces-major-governance-shift</guid><dc:creator><![CDATA[The Newsroom]]></dc:creator><pubDate>Wed, 05 Nov 2025 13:30:00 GMT</pubDate><enclosure url="https://layer5.io/static/409acc604106a93fbfb4e73072112c3b/sixth-highest-velocity-project-out-of-237-CNCF-projects.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 bzJNOf&quot;&gt;&lt;p&gt;[Austin, TX][KubeCon + CloudNativeCon] - November 5th, 2025 –- &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt;, the extensible cloud native management platform, today announced that it has achieved the status of the sixth highest-velocity project within the Cloud Native Computing Foundation (CNCF), a significant acceleration considering its Sandbox maturity level and position among 237 CNCF projects&lt;sup&gt;&lt;a href=&quot;#references&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. This news precedes Meshery’s robust presence at KubeCon + CloudNativeCon North America 2025 in Atlanta.&lt;/p&gt;&lt;h2&gt;The Rocket Ship: Surging Velocity and Community Growth&lt;/h2&gt;&lt;p&gt;Meshery’s climb to the 6th highest-velocity project marks a rapid progression, jumping three ranks since its 9th-place announcement in April 2025. This trajectory reflects consistent growth, improving steadily from 33rd highest velocity in 2020-2021 to 6th by July 2025.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;These achievements underscore the dedication of our global community and Meshery&amp;#x27;s growing impact in the cloud native ecosystem.&quot; person=&quot;Sangram Rath&quot; title=&quot;Meshery Maintainer&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;These achievements underscore the dedication of our global community and Meshery&amp;#x27;s growing impact in the cloud native ecosystem.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Sangram Rath&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Meshery Maintainer&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;These achievements underscore the dedication of our global community and Meshery&amp;#x27;s growing impact in the cloud native ecosystem.&lt;/p&gt;&lt;p&gt;This momentum is sustained by Meshery’s expanding global community, which now boasts more than 10,000 members. Over the past year, the project has seen a 350% increase in code commits, contributions from over 3,000 open source contributors, and has surpassed 10,000 GitHub stars.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;/static/sixth-highest-velocity-project-out-of-237-CNCF-projects-4dfb3f4fd3c9a22853dacf3a24b8b602.png&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/sixth-highest-velocity-project-out-of-237-CNCF-projects-4dfb3f4fd3c9a22853dacf3a24b8b602.png&quot; alt=&quot;Meshery achieved the status of the sixth highest-velocity project within the Cloud Native Computing Foundation (CNCF).&quot; width=&quot;100%&quot; class=&quot;block-display align-center&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Meshery empowers DevOps, Platform, SRE, and Application teams by providing collaborative GitOps, distributed performance management, and a visual designer for deployments, simplifying cloud native infrastructure management and accelerating learning and experimentation across CNCF projects.&lt;/p&gt;&lt;h2&gt;The Meshery Umbrella Expands: Strategic Partitioning for Scale&lt;/h2&gt;&lt;p&gt;Driven by this high project velocity and growing complexity, Meshery maintainers have implemented a &lt;a href=&quot;https://meshery.io/blog/2025/meshery-ecosystem-expansion&quot;&gt;critical revision to its governance and organizational structure&lt;/a&gt;: the partitioning of its repositories into two distinct GitHub organizations. This strategic move aims to enhance modularity, scalability, and community engagement.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;/static/meshery-extensions-github-dark-44640be2e81a471bf0239e5965a1ce9e.png&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/meshery-extensions-github-dark-44640be2e81a471bf0239e5965a1ce9e.png&quot; alt=&quot;This restructuring comes as Meshery celebrates a milestone of unprecedented growth.&quot; width=&quot;100%&quot; class=&quot;block-display align-center&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;&lt;/a&gt;&lt;br/&gt;This restructuring comes as Meshery celebrates a milestone of unprecedented growth.&lt;/p&gt;&lt;p&gt;The new structure divides the ecosystem into:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/meshery&quot;&gt;github.com/meshery&lt;/a&gt;: Dedicated to the core platform and foundational projects, including critical components like Meshery Operator and MeshSync. The core Meshery maintainers govern this organization, ensuring stability and alignment with CNCF standards.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/meshery-extensions&quot;&gt;github.com/meshery-extensions&lt;/a&gt;: A dedicated, community-centric space for extensions, integrations, and tooling. This organization fosters community ownership, allows for rapid iteration on independent release cycles, and acts as an incubator for new ideas and less common cloud service providers.&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 evseNu blockquote&quot; quote=&quot;This new structure isn&amp;#x27;t just a response to our success; it&amp;#x27;s our strategy for scaling it.&quot; person=&quot;Lee Calcote&quot; title=&quot;Meshery Maintainer&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;This new structure isn&amp;#x27;t just a response to our success; it&amp;#x27;s our strategy for scaling it.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Lee Calcote&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Meshery Maintainer&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&amp;quot;This incredible growth to the #6 highest velocity project in the CNCF is a testament to our amazing community,&amp;quot; said Lee Calcote, Meshery maintainer. &amp;quot;This new structure isn&amp;#x27;t just a response to our success; it&amp;#x27;s our strategy for scaling it. By partitioning into core and extensions, we are empowering our community to innovate faster than ever while ensuring a stable, robust platform for the enterprise.&amp;quot;&lt;/p&gt;&lt;p&gt;This scalable structure currently &lt;a href=&quot;https://meshery.io/integrations&quot;&gt;supports over 300 out-of-the-box integrations&lt;/a&gt; with Cloud and cloud nativ infrastructure, enabling seamless lifecycle, configuration, and performance management across multi-cluster and multi-cloud environments. This approach draws inspiration from successful, graduated CNCF projects for clear core vs. extensions distinction, team autonomy, and a working group-like model for governance.&lt;/p&gt;&lt;h2&gt;A Commitment to Mentorship and Inclusion&lt;/h2&gt;&lt;p&gt;Meshery’s success is deeply rooted in its vibrant and inclusive community, evidenced by its leading role in mentorship programs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;#1 Most Popular Internship in the Linux Foundation: Meshery is the top choice for aspiring developers in the Linux Foundation’s LFX Mentorship program, offering hands-on projects in areas like cloud service model relationships and end-to-end testing across Spring, Summer, and Fall terms.&lt;/li&gt;&lt;li&gt;Marquee Project in Google Summer of Code (GSoC): As a flagship participant in GSoC, Meshery provides mentees with opportunities to tackle real-world challenges in distributed systems, with projects for 2025 including support for Azure, shared workspaces, and kubectl plugins.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These initiatives embody a pay-it-forward mentality, where maintainers and MeshMates actively guide newcomers.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;I&amp;#x27;ve consistently been impressed by the top-tier cloud native talent coming from the Meshery community. It&amp;#x27;s clear that their focus on real-world challenges through programs like LFX Mentorship and GSoC isn&amp;#x27;t just building a high-velocity tool—it&amp;#x27;s building high-velocity engineers ready to solve complex problems from day one.&quot; person=&quot;Marcus Blom&quot; title=&quot;Senior Technical Recruiter at Amazon Web Services (AWS)&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;I&amp;#x27;ve consistently been impressed by the top-tier cloud native talent coming from the Meshery community. It&amp;#x27;s clear that their focus on real-world challenges through programs like LFX Mentorship and GSoC isn&amp;#x27;t just building a high-velocity tool—it&amp;#x27;s building high-velocity engineers ready to solve complex problems from day one.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Marcus Blom&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Senior Technical Recruiter at Amazon Web Services (AWS)&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;Join Meshery at KubeCon + CloudNativeCon NA 2025&lt;/h2&gt;&lt;p&gt;The Meshery project invites the community to &lt;a href=&quot;/community/events/kubecon-cloudnativecon-north-america-2025&quot;&gt;join its maintainers at KubeCon + CloudNativeCon NA 2025&lt;/a&gt; in Atlanta from November 10th to 13th. Key sessions include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Project Lightning Talk: Beyond YAML: Visualizing Kubernetes Ontologies With Meshery
Attendees will learn how Meshery&amp;#x27;s intuitive visual interface, Kanvas, reduces cognitive load by aligning with users&amp;#x27; mental models, making Kubernetes configuration less daunting.
Date: November 10, 2025, 1:52 am - 1:57 pm EST&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Session: &amp;quot;Do You Even Merge?&amp;quot; - Welcome To Maintainers Life, Please Bring Snacks and Boundaries
This talk will share the human side of maintaining high-velocity CNCF projects, discussing how the team manages growth, prioritizes responsibilities, and uses governance structures like SIGs to scale.
Date: November 12, 2025, 11:00 am - 11:30 am EST&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Contribfest: Dive Deep Into Extending Cloud Native Management with Meshery
This in-depth, hands-on session allows participants to understand and create Meshery Models - a blueprint characterizing managed resources and their relationships, enabling consistent infrastructure and workload deployment, management, and automation. No prior experience is needed.
Date: November 13th, 2025, 1:45 pm - 3:00 pm EST&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Meshery invites developers, operators, and enthusiasts to try Meshery from the convenience of their web browser today at &lt;a href=&quot;https://play.meshery.io&quot;&gt;https://play.meshery.io&lt;/a&gt; and be part of the movement that is redefining cloud native management.&lt;/p&gt;&lt;h4&gt;About Meshery&lt;/h4&gt;&lt;p&gt;Meshery is the open source, cloud native manager and extensible engineering platform that enables collaborative cloud native management. It accelerates learning and experimentation, empowering users to seamlessly handle lifecycle, configuration, and performance management across multi-cluster and multi-cloud environments. &lt;a href=&quot;https://meshery.io&quot;&gt;Meshery&lt;/a&gt; is a project hosted under the Cloud Native Computing Foundation (CNCF).&lt;/p&gt;&lt;h5&gt;About Layer5, Inc.&lt;/h5&gt;&lt;p style=&quot;font-size:1rem&quot;&gt;Layer5 empowers organizations to confidently embrace the power of cloud native technologies through its open source and commercial products. The company’s mission is to simplify the adoption and operation of cloud native infrastructure, enabling organizations to innovate faster and engineers to collaborate more effectively. Layer5’s award-winning open source community includes more than 10,000 members. For more information, visit &lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt;https://layer5.io&lt;/a&gt;&lt;/p&gt;&lt;a id=&quot;references&quot;&gt;&lt;/a&gt;&lt;h4&gt;References&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/116ZU_ltVkJip7G073ocULHxKhy4F1OgWjNjtZ1IPBWk/edit?gid=0#gid=0&quot;&gt;Google Sheets — All CNCF Projects for Jan 2024–Jan 2025&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[How can you tell what kind of Kubernetes Configmap you have?]]></title><link>https://layer5.io/blog/kubernetes/how-can-you-tell-what-kind-of-kubernetes-configmap-you-have</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/how-can-you-tell-what-kind-of-kubernetes-configmap-you-have</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Mon, 03 Nov 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/88427231d61b05cc39b0208166c642ea/image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;A common point of confusion when working with Kubernetes is understanding how &lt;code&gt;ConfigMap&lt;/code&gt; updates are handled. You’ve pushed a change to your ConfigMap, but your application isn&amp;#x27;t seeing the new values. What&amp;#x27;s going on?&lt;/p&gt;&lt;p&gt;The answer depends entirely on &lt;strong&gt;how your application consumes the ConfigMap&lt;/strong&gt;. There isn&amp;#x27;t a &amp;quot;type&amp;quot; of ConfigMap object itself, but rather two distinct &lt;em&gt;methods of consumption&lt;/em&gt; by a Pod, and each has drastically different behavior regarding updates.&lt;/p&gt;&lt;p&gt;To tell what &amp;quot;kind&amp;quot; you have, you need to look at your Pod or Deployment&amp;#x27;s YAML definition.&lt;/p&gt;&lt;h2&gt;How to Check Your Pod&amp;#x27;s ConfigMap Consumption&lt;/h2&gt;&lt;p&gt;You can find out how a Pod is using a ConfigMap by inspecting its YAML definition. 🧐  Run this command to get the running YAML for a specific pod:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kubectl get pod &amp;lt;your-pod-name&amp;gt; -o yaml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Now, look for two key sections in the &lt;code&gt;spec.containers&lt;/code&gt; list:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Environment Variables:&lt;/strong&gt; Look for &lt;code&gt;env&lt;/code&gt; or &lt;code&gt;envFrom&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Mounted Volumes:&lt;/strong&gt; Look for &lt;code&gt;volumeMounts&lt;/code&gt; and the corresponding &lt;code&gt;volumes&lt;/code&gt; section at the Pod spec level.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Let&amp;#x27;s break down what each one means for reloading.&lt;/p&gt;&lt;h2&gt;1. Consumed as Environment Variables&lt;/h2&gt;&lt;p&gt;This is when your Pod&amp;#x27;s YAML injects ConfigMap data directly as environment variables for the container.&lt;/p&gt;&lt;h3&gt;How to Identify It&lt;/h3&gt;&lt;p&gt;In your Pod spec, you&amp;#x27;ll see blocks like this:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# ...&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;container&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;app&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# &amp;lt;-- Look here&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; MY_CONFIG_KEY&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;valueFrom&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# &amp;lt;-- Or here&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;configMapKeyRef&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;special&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;config&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; some.config.key&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;envFrom&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# &amp;lt;-- Or here&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;configMapRef&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;special&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;config&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# ...&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If you see &lt;code&gt;env&lt;/code&gt; or &lt;code&gt;envFrom&lt;/code&gt; pointing to a &lt;code&gt;configMapKeyRef&lt;/code&gt; or &lt;code&gt;configMapRef&lt;/code&gt;, your application is consuming the ConfigMap as environment variables.&lt;/p&gt;&lt;h3&gt;Reload Behavior: 🛑 No Hot-Reload&lt;/h3&gt;&lt;p&gt;This is the most critical difference: &lt;strong&gt;Changes to a ConfigMap are NOT reflected in running Pods that use them as environment variables.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Environment variables are set by the container runtime &lt;em&gt;only when the container is created&lt;/em&gt;. They are immutable for the life of that running process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How to Apply Changes:&lt;/strong&gt; To make the application see the new ConfigMap values, you &lt;strong&gt;must restart the Pod&lt;/strong&gt;. The simplest way to do this for a &lt;code&gt;Deployment&lt;/code&gt; is with a rolling restart:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kubectl rollout restart deployment &amp;lt;your-deployment-name&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;When the new Pods are created, they will read the &lt;em&gt;updated&lt;/em&gt; ConfigMap data and set the new environment variables.&lt;/p&gt;&lt;h2&gt;2. Consumed as a Mounted Volume&lt;/h2&gt;&lt;p&gt;This method mounts your ConfigMap as one or more files inside your Pod&amp;#x27;s filesystem. Your application is programmed to read its configuration from these files (e.g., &lt;code&gt;/app/config/settings.properties&lt;/code&gt;).&lt;/p&gt;&lt;h3&gt;How to Identify It&lt;/h3&gt;&lt;p&gt;You&amp;#x27;ll see two corresponding sections in your Pod spec:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;spec.containers.volumeMounts&lt;/code&gt;: This tells the container where to mount the volume.&lt;/li&gt;&lt;li&gt;&lt;code&gt;spec.volumes&lt;/code&gt;: This defines the volume itself and links it to the ConfigMap.&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# ...&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;container&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;app&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;volumeMounts&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# &amp;lt;-- Look here&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; config&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;volume&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; /etc/config&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# &amp;lt;-- And here&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; config&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;volume&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;configMap&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;special&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;config&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# ...&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If you see this &lt;code&gt;volumes&lt;/code&gt; and &lt;code&gt;volumeMounts&lt;/code&gt; pairing, your application is consuming the ConfigMap as files.&lt;/p&gt;&lt;h3&gt;Reload Behavior: ✅ Automatic... With a Catch&lt;/h3&gt;&lt;p&gt;This method &lt;strong&gt;does support hot-reloading&lt;/strong&gt;, but with two important caveats:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;There is a delay.&lt;/strong&gt; When you update the ConfigMap object, the &lt;code&gt;kubelet&lt;/code&gt; on the node is responsible for updating the mounted files. This is not instantaneous. It relies on a periodic sync cycle, and the total delay can be &lt;strong&gt;60 to 90 seconds (or even longer)&lt;/strong&gt; before the files at &lt;code&gt;mountPath&lt;/code&gt; are actually updated.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Your application must support it.&lt;/strong&gt; Kubernetes &lt;em&gt;only&lt;/em&gt; updates the files on disk. It does &lt;strong&gt;not&lt;/strong&gt; send a signal (like &lt;code&gt;SIGHUP&lt;/code&gt;) to the process or restart the container. Your application must be built to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Watch the configuration files for changes (using a library like &lt;code&gt;fsnotify&lt;/code&gt;).&lt;/li&gt;&lt;li&gt;Periodically re-read the configuration files on its own timer.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;If your application only reads its config files on startup, it will behave just like the environment variable method: &lt;strong&gt;it will not see the changes until it is restarted.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;ConfigMap Reload Behavior Summary&lt;/h2&gt;&lt;p&gt;Here’s a simple table to remember the differences:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Consumption Method&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;How to Identify in Pod YAML&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Are Changes Updated in Running Pod?&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;How Are Changes Seen?&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;code&gt;spec.containers.env&lt;/code&gt; &lt;code&gt;spec.containers.envFrom&lt;/code&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;strong&gt;No&lt;/strong&gt; ❌&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Pod must be &lt;strong&gt;restarted&lt;/strong&gt;.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;&lt;strong&gt;Mounted Volume&lt;/strong&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;code&gt;spec.containers.volumeMounts&lt;/code&gt; &lt;code&gt;spec.volumes&lt;/code&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;strong&gt;Yes&lt;/strong&gt; ✅ (with delay)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Kubelet updates files. &lt;strong&gt;Application must be coded&lt;/strong&gt; to reload the updated file.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3&gt;What If I Need Automatic Restarts?&lt;/h3&gt;&lt;p&gt;If you are using the volume mount method but your application doesn&amp;#x27;t support live reloading, you can use a &amp;quot;reloader&amp;quot; tool. A popular open-source controller like &lt;a href=&quot;https://github.com/stakater/Reloader&quot;&gt;&lt;strong&gt;Stakater&amp;#x27;s Reloader&lt;/strong&gt;&lt;/a&gt; can watch for ConfigMap changes and automatically trigger a rolling restart of any Deployment that uses it. This gives you the best of both worlds: configuration in files and automatic updates for apps that can&amp;#x27;t reload on their own.&lt;/p&gt;&lt;br/&gt;&lt;hr/&gt;&lt;br/&gt;&lt;h2&gt;Skip the CLI. Power up with Kanvas&lt;/h2&gt;&lt;p&gt;Alternatively, you can skip the YAML editing and make these changes visually. That is, if you&amp;#x27;re managing your Kubernetes cluster using Kanvas. Let&amp;#x27;s break down how to use it to manage your resources, like a &lt;code&gt;ConfigMap&lt;/code&gt;. &lt;/p&gt;&lt;h2&gt;🤔 What is Kanvas Designer?&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://layer5.io/kanvas&quot;&gt;Layer5&amp;#x27;s Kanvas&lt;/a&gt; is a powerful tool for designing, deploying, and managing your Kubernetes and Cloud infrastructure and workloads from a visual interface. Instead of writing hundreds of lines of YAML by hand, you build a &lt;strong&gt;Design&lt;/strong&gt;. This design is a visual representation of your components (&lt;code&gt;Deployment&lt;/code&gt;, &lt;code&gt;Service&lt;/code&gt;, &lt;code&gt;ConfigMap&lt;/code&gt;, etc.) and their relationships.&lt;/p&gt;&lt;h2&gt;🎨 How to Update a ConfigMap in Kanvas Designer&lt;/h2&gt;&lt;p&gt;Updating a &lt;code&gt;ConfigMap&lt;/code&gt; through the Designer follows this &amp;quot;design-first&amp;quot; workflow. You don&amp;#x27;t just &amp;quot;edit&amp;quot; the live resource in the cluster; you &lt;strong&gt;update your design&lt;/strong&gt; and then &lt;strong&gt;(re-)deploy it&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Here is the step-by-step process:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Open Kanvas Designer:&lt;/strong&gt; Log in to your Kanvas UI and navigate to Designer mode (the default mode).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Load Your Design:&lt;/strong&gt; Open the design file that contains the &lt;code&gt;ConfigMap&lt;/code&gt; you want to edit. If you don&amp;#x27;t have a design yet, you can import your existing &lt;code&gt;ConfigMap&lt;/code&gt; from your cluster directly onto the canvas.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Find the ConfigMap Component:&lt;/strong&gt; On the visual canvas, find the block representing your &lt;code&gt;ConfigMap&lt;/code&gt;. It will have the Kubernetes icon and the &amp;quot;ConfigMap&amp;quot; kind.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Edit the Configuration:&lt;/strong&gt; Click on the component. A configuration panel will slide out, often with a &amp;#x27;Configure&amp;#x27; tab or an editor icon. This will show you the key/value pairs for that &lt;em&gt;specific&lt;/em&gt; &lt;code&gt;ConfigMap&lt;/code&gt; resource.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Deploy the Design:&lt;/strong&gt; Changes are automatically saved in your design as you make them. Use the &lt;strong&gt;Deploy&lt;/strong&gt; button to send your entire design to your target Kubernetes or Cloud environment. Kanvas will calculate the difference (a &amp;quot;diff&amp;quot;) and apply the updated &lt;code&gt;ConfigMap&lt;/code&gt; manifest to your cluster. This action is the equivalent of running &lt;code&gt;kubectl&lt;/code&gt; server-side apply using your design.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;🛑 The Most Important Part: Reload Behavior&lt;/h2&gt;&lt;p&gt;This is critical: &lt;strong&gt;Using Kanvas Designer to update a ConfigMap does NOT change how your application reloads it.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Deploying from Kanvas is just a friendly, visual way to run &lt;code&gt;kubectl apply&lt;/code&gt;. The rules we discussed in our previous post about ConfigMap behavior still apply completely:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;If your Pod consumes the ConfigMap as Environment Variables:&lt;/strong&gt; Your running Pods &lt;strong&gt;will not&lt;/strong&gt; see the change. You must still restart them (e.g., &lt;code&gt;kubectl rollout restart deployment ...&lt;/code&gt;).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;If your Pod consumes the ConfigMap as a Mounted Volume:&lt;/strong&gt; The files inside the Pod &lt;strong&gt;will&lt;/strong&gt; be updated (after the kubelet sync delay), but your application &lt;em&gt;still&lt;/em&gt; needs to be smart enough to re-read that file from disk.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Kanvas Designer simplifies the &lt;em&gt;applying&lt;/em&gt; of the change and helps you visually manage your application&amp;#x27;s state, but it doesn&amp;#x27;t change the fundamental Kubernetes behavior of &lt;em&gt;how&lt;/em&gt; that change is consumed by your workloads.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[AGENTS.md: One File to Guide Them All]]></title><link>https://layer5.io/blog/ai/agentsmd-one-file-to-guide-them-all</link><guid isPermaLink="false">https://layer5.io/blog/ai/agentsmd-one-file-to-guide-them-all</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 10 Oct 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/76c19b76901449806f78915cf47038aa/readme-agents.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;AI coding assistants are everywhere. They live in our terminals, they&amp;#x27;re built into our IDEs, and they&amp;#x27;ve fundamentally changed how we write software. From Codex and Copilot to Gemini and Claude, developers now have a powerful new collaborator.&lt;/p&gt;&lt;p&gt;But, there&amp;#x27;s a problem. To be effective, these AI agents need context. They need to understand your project&amp;#x27;s architecture, coding standards, and specific rules. This guidance lives in configuration files, but every agent speaks a different language.&lt;/p&gt;&lt;p&gt;You might have a &lt;code&gt;CLAUDE.md&lt;/code&gt; for Claude, a &lt;code&gt;.cursor/rules/&lt;/code&gt; directory for Cursor, and &lt;code&gt;.github/copilot-instructions.md&lt;/code&gt; for Copilot, and a &lt;code&gt;JULES.md&lt;/code&gt; for Google Jules. This fragmentation creates a digital Tower of Babel in your repository. When you switch tools or collaborate with a team using different agents, you&amp;#x27;re stuck translating the same core instructions into multiple formats.&lt;/p&gt;&lt;p&gt;What if there was a universal translator? A single, standardized file to provide context to &lt;em&gt;any&lt;/em&gt; AI coding agent?&lt;/p&gt;&lt;p&gt;That’s the idea behind &lt;strong&gt;AGENTS.md&lt;/strong&gt;: an open standard for guiding AI coding agents.&lt;/p&gt;&lt;h3&gt;What We&amp;#x27;ll Cover&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;What is AGENTS.md?&lt;/strong&gt; The &amp;quot;README for AI.&amp;quot;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Why Do We Need It?&lt;/strong&gt; Taming the chaos of configuration files.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;What Goes Inside?&lt;/strong&gt; A practical guide to crafting your own AGENTS.md.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Making It Work Today:&lt;/strong&gt; Bridging AGENTS.md with your current tools.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Future is Unified:&lt;/strong&gt; What&amp;#x27;s next for AI-native development.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;What is AGENTS.md?&lt;/h3&gt;&lt;p&gt;Think of it this way: README.md is the front door for human developers. It&amp;#x27;s the first place you look to understand a project&amp;#x27;s purpose, setup, and contribution guidelines.&lt;/p&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/readme-agents-d0345ace18491c3f7fb5021933bf5c83.webp&quot; width=&quot;50%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;AGENTS.md is the front door for AI agents.&lt;/strong&gt; It’s a single, standardized markdown file in the root of your project where AI assistants can get all the context they need to become a high-performing teammate.&lt;/p&gt;&lt;p&gt;This simple idea is already gaining traction. With support from tools like Codex, Cursor, and Gemini CLI, AGENTS.md has been adopted by over 40,000 open-source projects.&lt;/p&gt;&lt;h3&gt;Why AGENTS.md? The Case for a Universal Standard&lt;/h3&gt;&lt;p&gt;Developers are already feeling the pain of config fragmentation. On GitHub, users of tools like Claude Code and Cline have opened issues asking for a unified standard, specifically pointing to AGENTS.md.&lt;/p&gt;&lt;p&gt;Here’s the problem without a standard:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Tool Lock-in:&lt;/strong&gt; Switching to a new, better AI agent means rewriting your project&amp;#x27;s context from scratch in a new format.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Team Friction:&lt;/strong&gt; When your team members use different agents, your repository gets cluttered with redundant config files (.cursor/, claude.md, gemini.md), all containing slight variations of the same information.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Maintenance Nightmare:&lt;/strong&gt; Every time a rule changes—like updating your deployment command or linting standard—you have to update it in multiple places, hoping you don&amp;#x27;t miss one.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;AGENTS.md solves this by creating a single source of truth.&lt;/p&gt;&lt;p&gt;Instead of a tangled mess of agent-specific files, you have one clean, universal file that works across all tools, which can come with its own drawbacks.&lt;/p&gt;&lt;h3&gt;Why you might want to use multiple AI code assistant configuration files&lt;/h3&gt;&lt;p&gt;Using multiple configuration files for an AI code assistant can offer a few benefits, most noteably is that of allowing for specialization, consistency, and tighter control in more complex projects. &lt;/p&gt;&lt;h4&gt;Improved project-specific customization&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Tailored behavior: A configuration file can be set up for a specific project or microservice to guide the AI with project-specific settings. This ensures the AI understands the unique context, coding style, and framework of that codebase, providing more accurate and relevant suggestions.&lt;/li&gt;&lt;li&gt;Contextual awareness: For large codebases, AI assistants perform better when the code is organized into modular files. This allows the AI to process each file&amp;#x27;s context more effectively without being overloaded, leading to faster and more accurate suggestions.&lt;/li&gt;&lt;li&gt;Optimized performance: You can create lightweight configurations for smaller tasks or projects that don&amp;#x27;t require the AI to have a deep understanding of the entire codebase. This can reduce processing time and resource consumption. &lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Enhanced flexibility and control&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Switching models: By having multiple configurations, you can easily switch between different AI models, like Claude, GitHub Copilot, or a self-hosted model, to determine which is best for a specific task. This prevents vendor lock-in and allows you to always use the most effective tool.&lt;/li&gt;&lt;li&gt;Experimentation: Developers can experiment with different prompts, settings, and AI models by creating separate, isolated configuration files. This allows for testing and fine-tuning without disrupting the main project workflow. &lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Streamlined team collaboration&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Consistent guidance: A team can share a standard configuration file to ensure all members receive the same AI guidance. This helps enforce consistent coding practices, security rules, and tool usage across the entire development workflow.&lt;/li&gt;&lt;li&gt;Centralized management: Centralizing API keys and other secrets within managed configurations allows for secure collaboration. Teams can roll out pre-approved AI models and workflows while retaining oversight of their data.&lt;/li&gt;&lt;li&gt;Reduced inconsistency: A standard configuration file prevents inconsistent AI outputs that can arise when different team members use different settings or prompts, which is a major headache for Python projects and others&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;What&amp;#x27;s the difference between AI code assistant configuration files?&lt;/h3&gt;&lt;p&gt;To improve the AI&amp;#x27;s relevance and prevent security issues, developers can explicitly control which parts of a codebase the AI should focus on or ignore.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;.aiignore&lt;/code&gt;: Similar to a &lt;code&gt;.gitignore&lt;/code&gt; file, this file tells the AI which files and folders to exclude from its analysis. This is critical for security, as it prevents the AI from being exposed to sensitive information.&lt;/li&gt;&lt;li&gt;&lt;code&gt;.github/copilot-instructions.md&lt;/code&gt;: This file contains custom instructions specifically for GitHub Copilot, guiding its behavior and code generation according to project standards or user preferences.&lt;/li&gt;&lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt;: These files are associated with the concept of &amp;quot;agents&amp;quot; in AI coding, particularly with tools like GitHub Copilot&amp;#x27;s coding agent. They can define behaviors and instructions for these agents, potentially at a more granular level than the general copilot-instructions.md. AGENTS.md suggests a collection of agent definitions.&lt;/li&gt;&lt;li&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;: This file serves a similar purpose to copilot-instructions.md but is specifically designed for the Claude AI model, allowing users to provide custom instructions for its interactions and code generation.&lt;/li&gt;&lt;li&gt;&lt;code&gt;.cursorrules&lt;/code&gt;, &lt;code&gt;.windsurfrules&lt;/code&gt;, &lt;code&gt;.clinerules&lt;/code&gt;: These files, and their directory counterparts, contain configuration or rule sets for specific AI coding tools.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;README.md: This is a standard Markdown file used in most software projects to provide an overview, instructions, and other essential information about the project. While not directly tied to AI assistant configuration, it can implicitly guide AI tools by providing context about the codebase.&lt;/p&gt;&lt;p&gt;The key distinction is between files designed to configure and instruct specific AI coding assistants (e.g., Copilot, Claude, Cursor, Windsurf) and general project documentation (README.md) that provides human-readable information about the project. The AI configuration files differ based on the particular AI tool they target and the specific instructions or rules they convey to that tool.&lt;/p&gt;&lt;h3&gt;What Goes Inside an AGENTS.md File?&lt;/h3&gt;&lt;p&gt;AGENTS.md consolidates the essential knowledge required to contribute to your project effectively. It&amp;#x27;s a living document that captures your team&amp;#x27;s conventions, architectural decisions, and operational knowledge.&lt;/p&gt;&lt;p&gt;Here’s a practical example of what a robust AGENTS.md might look like:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-markdown&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; AGENTS.md: Project Constitution for AI Assistants&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 1. Project Overview &amp;amp; Core Purpose  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Purpose:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; This is a customer support ticketing system built with a React frontend and a Node.js (Express) backend.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Tech Stack:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; TypeScript, React, Tailwind CSS, Node.js, Express, PostgreSQL.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Key Goal:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Provide a fast, reliable, and user-friendly interface for support agents to manage customer issues.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 2. Architecture &amp;amp; Design Patterns  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Database:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; We use PostgreSQL for its reliability and ACID compliance. All business logic involving payments or user accounts must be transactional.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Caching:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Redis is used for session storage and caching non-critical data. Never cache user-private data.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;State Management (Frontend):&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Use React Query for server state and Zustand for global UI state. Avoid prop-drilling.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;API Design:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; We follow RESTful principles. All API error responses must include a \`requestId\` for easier debugging.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 3. Code Standards &amp;amp; Conventions  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Formatting:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; We use Prettier with the settings in \`.prettierrc\`. All code must be formatted on commit.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Linting:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; ESLint is configured with rules in \`.eslintrc.js\`. Pay close attention to rules against using \`any\`.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Naming:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Components: \`PascalCase\` (e.g., \`TicketList.tsx\`)  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; API endpoints: \`kebab-case\` (e.g., \`/api/user-tickets\`)  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Functions: \`camelCase\` (e.g., \`fetchUserData\`)  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Testing:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Use Jest and React Testing Library. All new components must have at least 80% test coverage for critical paths.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 4. Build, Test, &amp;amp; Deploy Pipeline  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Local Setup:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Run \`npm install\` and then \`npm run dev\`.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Running Tests:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; \`npm test\`  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Build Command:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; \`npm run build\`  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Deployment:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Pushes to the \`main\` branch trigger a GitHub Actions workflow that deploys to Vercel.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 5. Common Pitfalls &amp;amp; API Nuances  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Stripe API:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; All POST requests are idempotent. It&amp;#x27;s safe to retry them.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;SendGrid API:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; This API has strict rate limits. All email-sending tasks should be pushed to our Redis queue.  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Authentication:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; If you see auth errors locally, it&amp;#x27;s likely because the Redis server died. Restart it with \`redis-server\`.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;33&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;##&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; 6. Git &amp;amp; PR Workflow  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Branch Naming:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; \`feature/ticket-123-add-search-bar\`  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Commit Messages:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Follow the Conventional Commits specification. (e.g., \`feat: add user profile page\`)  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token list punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token bold content&quot;&gt;Pull Requests:&lt;/span&gt;&lt;span class=&quot;token bold punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Must be reviewed by at least one other team member before merging. Link the associated ticket in the PR description.&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Start small, and let it grow.&lt;/em&gt; Your AGENTS.md doesn&amp;#x27;t need to be perfect on day one. Begin with the most critical information and expand it over time. Each time a developer (or an agent) learns something new about the project, add it to the file.&lt;/p&gt;&lt;h3&gt;Bridging AGENTS.md with Existing Tools&lt;/h3&gt;&lt;p&gt;While many modern agents support AGENTS.md out of the box, some older tools still look for their own native config files. For those, you can use two simple bridging strategies to get them to read your central AGENTS.md file.&lt;/p&gt;&lt;h4&gt;Method 1: Symbolic Linking&lt;/h4&gt;&lt;p&gt;A symbolic link (symlink) is a pointer to another file. You can create symlinks that trick agents into reading AGENTS.md while looking for their native file.&lt;/p&gt;&lt;p&gt;Open your terminal in the project root and run these commands for the tools you use:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-markdown&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; For Claude Code ln -s AGENTS.md CLAUDE.md # For Cursor mkdir -p .cursor/rules ln -s ../../AGENTS.md .cursor/rules/rules.mdc # For GitHub Copilot mkdir -p .github ln -s ../AGENTS.md .github/copilot-instructions.md&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Your tools continue to work as expected, but now they all draw their context from a single source.&lt;/p&gt;&lt;h4&gt;Method 2: Using Imports&lt;/h4&gt;&lt;p&gt;Some agents support importing one markdown file into another. For example, in Claude Code&amp;#x27;s CLAUDE.md file, you can simply add a line to import your universal file:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-markdown&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; In ./CLAUDE.md&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;@AGENTS.md&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token title important punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token title important&quot;&gt; You can add Claude-specific instructions below if needed&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;This approach keeps your setup clean and ensures AGENTS.md remains the primary source of truth.&lt;/p&gt;&lt;h4&gt;What&amp;#x27;s the difference between agents.md and prompt.md?&lt;/h4&gt;&lt;p&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; and &lt;code&gt;.prompt.md&lt;/code&gt; files serve different purposes in guiding an AI coding assistant. AGENTS.md provides general, project-level context, while .prompt.md files define reusable, task-specific instructions. A &lt;code&gt;.prompt.md&lt;/code&gt; file defines a reusable, task-specific prompt that can be executed directly by an AI assistant.
Purpose: Automate common, repeatable development tasks. A &lt;code&gt;.prompt.md&lt;/code&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Encapsulates complex tasks: Lets you define and reuse complex, multi-step instructions for specific jobs.&lt;/li&gt;&lt;li&gt;Task specialization: Creates a specialized prompt for common tasks, such as generating a test case or scaffolding a component.&lt;/li&gt;&lt;li&gt;Chat integration: Some AI assistants, like GitHub Copilot in VS Code, allow developers to run prompt files directly from the chat interface using a slash command.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Key differences summarized&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;|| Aspect 	|| AGENTS.md	|| .prompt.md ||
| Scope	| Project-wide | Task-specific |
| Purpose	| Defines general rules and project context for any task	| Automates specific, repeatable tasks |
| Trigger	| Automatically referenced by the AI for every interaction	| Manually invoked by the user, often via a chat command |
| Content	| High-level instructions, conventions, and setup details	| Detailed instructions and examples for a single, focused task |
| Analogy	| A handbook for the AI	| A macro or recipe for the AI |&lt;/p&gt;&lt;h3&gt;What&amp;#x27;s Next: The Future of AI Collaboration&lt;/h3&gt;&lt;p&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; is more than just a configuration file; it&amp;#x27;s a step toward a future where AI and human developers collaborate seamlessly.&lt;/p&gt;&lt;p&gt;Imagine a world where any AI agent can clone a repository and instantly understand its context, conventions, and goals. Onboarding a new AI assistant becomes as simple as pointing it to a URL. Open-source projects can accept high-quality contributions from autonomous agents because the rules of engagement are clearly defined.&lt;/p&gt;&lt;p&gt;This is the future that a common standard like &lt;code&gt;AGENTS.md&lt;/code&gt; enables. For now, we can use simple bridges like symlinks to make it work. But as the ecosystem evolves, expect more and more tools to adopt AGENTS.md as the default.&lt;/p&gt;&lt;p&gt;One file to guide them all. One file to align them. One file to bring them all and in the codebase bind them.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Meet the Maintainer: Aabid Sofi]]></title><description><![CDATA[Meet the Maintainer series with open source maintainer, Aabid Sofi]]></description><link>https://layer5.io/blog/open-source/meet-the-maintainer-aabid-sofi</link><guid isPermaLink="false">https://layer5.io/blog/open-source/meet-the-maintainer-aabid-sofi</guid><dc:creator><![CDATA[Himani Sahu]]></dc:creator><pubDate>Thu, 28 Aug 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/0f8f6f2acc1c59d31617ab038375103d/aabid-sofi-meshery-maintainer.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;div class=&quot;MeetTheMaintainerstyle__MeetTheMaintainer-sc-cimr9h-0 btYcDC&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Continuing in our Meet the Maintainer series, we have &lt;a href=&quot;/community/members/aabid-sofi&quot;&gt;Aabid Sofi&lt;/a&gt;. Aabid is a maintainer of &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery UI&lt;/a&gt;. In this interview, we get to know Aabid a little better and learn about his journey as an open source project maintainer and with Layer5 community.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;Aabid, thank you for taking the time to join me today. While many people, both within and beyond the Layer5 community, have witnessed the impact of your contributions, they may not know the story behind who you are and how you became a maintainer. Could you share your journey with us? How did you discover the Layer5 community, and what inspired you to stay?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;My journey with Layer5 began about two years ago, during a transitional phase in my career as I was moving away from regular consulting work and exploring open source more seriously. Meshery immediately caught my eye—it had a wealth of open issues that aligned well with my skillset at the time. What truly sealed the deal, though, was the community. Everyone was incredibly welcoming and supportive, especially in the areas where I had less experience. That combination of technical opportunity and community warmth made it easy to stick around and get involved deeply.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;You’re a &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery UI&lt;/a&gt; maintainer. What does being a Meshery maintainer mean to you?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;Frontend engineering has always been a space that excites me. While some people like to strictly divide frontend and backend work, I view engineering as the art of abstraction—building clients that interface with systems behind the scenes. I approach UI development with the same principles I’d apply anywhere else in engineering: scalability, robustness, and maintainability. Sure, JavaScript has its quirks (like any language), but that’s just part of the fun. Being a UI maintainer gives me the chance to ensure that the user-facing side of Meshery reflects solid engineering values.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;Have you worked with any other open source project? How does Layer5 compare?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;Yes, I’ve contributed to several open source projects, though none as deeply or meaningfully as I have with Layer5. This community holds a special place in my heart. It gave me a platform to grow, to sharpen my skills, and—importantly—to have my work recognized and valued. The level of engagement and collaboration here is unlike anything I’ve experienced elsewhere.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;&lt;a href=&quot;/projects&quot;&gt;Layer5 projects&lt;/a&gt; have a number of active, open source projects. You’ve been consistently contributing to a few of them. Which one(s) are you currently focusing on?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;There are more projects here than I can count on my fingers! I’ve been actively contributing to Meshery, Meshkit, Meshery Extensions, and Sistent, among others. Each project brings unique challenges and learning opportunities, and I enjoy bouncing between them based on where help is most needed.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;What’s the coolest Meshery UI demo you have done/seen?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;One of the coolest demos I’ve seen—and personally enjoyed showcasing—is Meshery’s capability to intelligently infer and visualize relationships between various infrastructure components. There’s always a moment of awe when users see connections and dependencies automatically materialize on the screen—it feels like magic, and it’s an incredibly powerful way to understand your system’s topology.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;What is your favorite feature or aspect of UI in this project, and why?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;My favorite aspect of the project has been the UI—especially the collaborative and visual design features we’ve built into it. I’ve always admired tools like Google Docs and Figma for how they enable real-time collaboration and intuitive design workflows. Being part of a project that offers similar capabilities for infrastructure management is an opportunity I wouldn’t trade for anything.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;What is your hot tip for working with Meshery that others may not know?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;One principle I try to follow—and would recommend to others—is to not fear making mistakes or admitting when you don’t know something. Acknowledging knowledge gaps is actually a strength—it helps you grow faster. After all, you can’t fix what you don’t realize is broken. Be curious, be humble, and you’ll find your footing.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;Where do you see opportunities for contributors to actively engage and contribute to UI within the Meshery and Layer5 community?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;Meshery is rapidly evolving—it’s currently the 9th fastest-growing project under the CNCF umbrella. There are countless ways to get involved. Start by joining the community and introducing yourself along with your skills and interests. Community managers are great at helping contributors find the right fit. At the moment, areas like Meshery’s CLI, Meshery Server, and even digital marketing are actively seeking contributions. While most of Layer5’s 100+ repositories are open, two—Kanvas and Cloud—are currently closed-source but are being actively developed by community contributors. These projects are highly collaborative, with 15+ active contributors meeting daily and nearly 100 total contributors to date. The team working on these projects meets every Monday, Tuesday, Wednesday, and Friday at 9:00 AM Central / 7:30 PM IST via meet.layer5.io/team. Anyone with interest, a collaborative spirit, and consistent participation is warmly welcomed—even into the closed-source efforts.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;Let&amp;#x27;s get to know you a bit better with some quick questions:  What&amp;#x27;s the emoji you use most often? Do you prefer movies or books? Would you consider yourself a morning person or a night owl? Over the past year, what&amp;#x27;s a project or accomplishment you&amp;#x27;re particularly proud of?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;😀&lt;p&gt;Looking at my emoji history, 🙏 and 😀 are definitely the most used—and honestly, that says a lot about this community. It’s warm, collaborative, and full of gratitude. As for me, I’d say I lean toward being a night owl, and while I do enjoy both books and movies, it depends on the mood. One project I’m particularly proud of is the real-time collaboration functionality we’ve added to the UI—bringing ideas like those in Figma or Docs to infrastructure tooling has been incredibly satisfying.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;Do you have any advice for individuals hopeful to become Meshery UI contributors or potentially maintainers?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;My advice is simple: pick an area that genuinely interests you—there are plenty to choose from here. You don’t need to know everything right away. Start with small, manageable issues and use them as a learning opportunity. Over time, your understanding will deepen, and so will your impact. Consistency and curiosity go a long way.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Himani:&lt;/span&gt;&lt;p&gt;In other words, staying curious and consistently contributing, even in small ways at first, can build the foundation for becoming a strong Meshery UI contributor or even a maintainer over time.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Aabid:&lt;/span&gt;&lt;p&gt;Exactly, Himani. It’s all about building momentum. Every small contribution—whether it’s fixing a bug, improving docs, or reviewing a PR—adds up and helps you grow into the role. What matters most is the willingness to learn, adapt, and collaborate with others in the community. That’s the real pathway to becoming a strong contributor and eventually a maintainer.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;note&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/forklift.81115a37.svg&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;p&gt;The Meshery project moves at an impressive pace thanks to maintainers like Aabid. Be like Aabid. Join the &lt;a href=&quot;https://slack.layer5.io&quot;&gt;Layer5 Slack&lt;/a&gt; and say “hi&amp;quot;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Meet the Maintainer: Ian Whitney]]></title><description><![CDATA[Meet the Maintainer series with open source maintainer, Ian Whitney]]></description><link>https://layer5.io/blog/open-source/meet-the-maintainer-ian-whitney</link><guid isPermaLink="false">https://layer5.io/blog/open-source/meet-the-maintainer-ian-whitney</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Thu, 29 May 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/4d40eb2ec567887432dc7cab5eee5af7/ian-whitney-meshery-maintainer.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;div class=&quot;MeetTheMaintainerstyle__MeetTheMaintainer-sc-cimr9h-0 btYcDC&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Continuing in our Meet the Maintainer series, we have &lt;a href=&quot;/community/members/ian-whitney&quot;&gt;Ian Whitney&lt;/a&gt;. Ian is a maintainer of &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery UI&lt;/a&gt;. In this interview, we get to know Ian a little better and learn about his journey as an open source project maintainer and with Layer5 community.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;Ian, thank you for joining me today. Many people inside and outside of the Layer5 Community have seen the effects of your contributions, but may not know the backstory as to who Ian is and how you arrived at your maintainer role. Indulge us. How did you discover the Layer5 community? What inspired you to stay?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;My journey into Layer5 began with a desire to contribute to an open source project during Hacktoberfest 2024.  I was looking for a welcoming community that was working on meaningful problems - somewhere I could operate at the intersection of what I already knew and where I wanted to grow. That&amp;#x27;s when I found Meshery and Layer5. After joining a newcomers meeting, I immediately felt it was the right fit as a place I could explore deeper cloud native topics, a new programming language like golang and contribute to the UI. What inspired me to stay was the emphasis on collaboration and developer growth. Before I knew it, I was actively contributing to Meshery and eventually invited to become a maintainer.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;You’re a &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery UI&lt;/a&gt; maintainer. What does being a Meshery maintainer mean to you?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;After being a contributor for some time, I looked to the maintainers as leaders that were champions of culture to guide and lift others up to contribute and grow their technical skills and leadership. I hope to be able to continue with this emphasis of helping others grow and develop.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;Have you worked with any other open source project? How does Layer5 compare?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;I have not contributed to any other open source projects. Meshery was my first open source experience!&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;&lt;a href=&quot;/projects&quot;&gt;Layer5 projects&lt;/a&gt; have a number of active, open source projects. You’ve been consistently contributing to a few of them. Which one(s) are you currently focusing on?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;I am currently focused on Meshery UI client and the supporting backend and ecosystems.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;What’s the coolest Meshery demo you have done/seen?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;The coolest demos I have seen always pertain to Meshery Kanvas. The interactive and intuitive UI are really cool to watch.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;What is your favorite feature or aspect of UI in this project, and why?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;The best feature of the project is the community and being able to explore technical areas with guidance of seasoned contributors.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;What is your hot tip for working with Meshery that others may not know?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;My hot tip is to just start and develop a habit to keep showing up.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;Where do you see opportunities for contributors to get involved within Meshery and Layer5 community?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;There are alot of good first issues in the UI repo. We are currently trying to mature our testing efforts around Meshery UI client with playwright. This space is a great space to learn the product and improve the user flows while increasing test coverage.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;Let&amp;#x27;s get to know you a bit better with some quick questions:  What&amp;#x27;s the emoji you use most often? Do you prefer movies or books? Would you consider yourself a morning person or a night owl? Over the past year, what&amp;#x27;s a project or accomplishment you&amp;#x27;re particularly proud of?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;😀&lt;p&gt;My favorite emoji is 😀. I prefer books - the more technical the better 😀. I&amp;#x27;m a morning person with a cup of coffee. Over the past year, I feel most accomplished by trying to give back as much as I&amp;#x27;ve gained. This includes efforts through code contributions, mentoring, or sharing what I&amp;#x27;ve learned along the way. Being part of this community has shown me the value of collaboration, and I&amp;#x27;ve made it a point to support new contributors, answer questions, and help others contribute. It&amp;#x27;s incredibly rewarding to see someone you helped gain confidence and start making meaningful contributions of their own.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewer&quot;&gt;&lt;span&gt;Vivek:&lt;/span&gt;&lt;p&gt;Do you have any advice for individuals hopeful to become Layer5 contributors or potentially maintainers?&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;interviewee&quot;&gt;&lt;span&gt;Ian:&lt;/span&gt;&lt;p&gt;Try to build a habit of learning, contributing and helping others.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;note&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/forklift.81115a37.svg&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;p&gt;The Meshery project moves at an impressive pace thanks to maintainers like Ian. Be like Ian. Join the &lt;a href=&quot;https://slack.layer5.io&quot;&gt;Layer5 Slack&lt;/a&gt; and say “hi&amp;quot;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Docker Model Runner: Engineering Summary & Future Horizons]]></title><link>https://layer5.io/blog/docker/docker-model-runner-engineering-summary-future-horizons</link><guid isPermaLink="false">https://layer5.io/blog/docker/docker-model-runner-engineering-summary-future-horizons</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Tue, 20 May 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/079679ec12e22e5eaead3990ab81da4f/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;Over the course of &lt;a href=&quot;/blog/category/docker&quot;&gt;this series&lt;/a&gt;, we&amp;#x27;ve embarked on a deep technical dive into Docker Model Runner, moving beyond surface-level descriptions to uncover the engineering principles and practical implications of this innovative toolkit. From its foundational architecture to its integration with the broader developer ecosystem, Model Runner presents a compelling vision for the future of local AI development. In this concluding post, we&amp;#x27;ll synthesize the key engineering takeaways and explore the promising horizons as Docker Model Runner matures.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Key Engineering Takeaways: A Recap&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Our journey has illuminated several critical aspects that define Docker Model Runner&amp;#x27;s value proposition for engineers:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;OCI for Robust Model Management:&lt;/strong&gt; Model Runner&amp;#x27;s strategic adoption of the Open Container Initiative (OCI) standard for packaging and distributing AI models is transformative. It brings DevOps-like rigor to model lifecycle management, enabling versioning, provenance, and the use of existing container registries and CI/CD pipelines for AI models.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Performance via Host-Native Execution:&lt;/strong&gt; The decision to run inference engines (like llama.cpp) as host-native processes, with direct GPU access (especially Metal API on Apple Silicon), prioritizes local performance. This minimizes latency and provides a responsive experience crucial for iterative development.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;OpenAI-Compatible API for Seamless Integration:&lt;/strong&gt; By offering an API compatible with OpenAI&amp;#x27;s standards, Model Runner drastically lowers the barrier to entry. Engineers can leverage existing SDKs, tools like LangChain and LlamaIndex, and familiar coding patterns with minimal friction.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Docker Compose for Orchestrated AI Stacks:&lt;/strong&gt; The introduction of the provider service type in Docker Compose allows AI models to be declared and managed as integral components of multi-service applications, simplifying the orchestration of complex local AI development environments.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Ecosystem Synergy (e.g., Spring AI):&lt;/strong&gt; Integrations with frameworks like Spring AI demonstrate Model Runner&amp;#x27;s ability to seamlessly fit into established development ecosystems, enabling Java developers, for instance, to easily incorporate local LLMs.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Advanced Local Workflows &amp;amp; Fine-Grained Control:&lt;/strong&gt; Model Runner empowers engineers to execute sophisticated, multi-stage AI pipelines locally. The ability to dynamically tune model parameters for specific tasks without API costs fosters deep experimentation and accelerates the development of nuanced AI features.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Collectively, these features address core engineering challenges in local AI development: cost, privacy, iteration speed, complexity, and environmental control.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Future Horizons: From Beta to Mainstream&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;As Docker Model Runner evolves beyond its Beta phase, several key developments will shape its impact:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;API Stability and Maturation:&lt;br/&gt;A crucial step will be the stabilization of its APIs. As noted during its Beta, APIs were subject to change. A stable API will provide the confidence developers need to build more robust and long-lasting integrations.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Expanded Platform and Hardware Support:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Windows GPU Acceleration:&lt;/strong&gt; The full realization of performant GPU acceleration on Windows (especially for NVIDIA GPUs) will be a significant milestone, broadening its accessibility to a large segment of the developer community.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Linux Enhancements:&lt;/strong&gt; While a Docker Engine plugin exists, further enhancements for Linux environments, potentially with more streamlined management features akin to Docker Desktop, will be important for server-side local development or specialized Linux-based AI workstations.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Comprehensive Custom Model Management:&lt;br/&gt;The ability for users to easily package, docker model push their own custom or fine-tuned models to any OCI-compliant registry, and then docker model pull and run them seamlessly is paramount. This will unlock Model Runner&amp;#x27;s full potential for organizations with bespoke AI needs, moving beyond curated public models.  &lt;/li&gt;&lt;li&gt;Deeper Ecosystem Integrations:&lt;br/&gt;Expect continued and deeper integrations with:  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;MLOps Tools:&lt;/strong&gt; Tighter connections with MLOps platforms for experiment tracking, model monitoring (even locally), and smoother transitions from local development to production deployment pipelines.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;IDEs:&lt;/strong&gt; More direct integrations within popular Integrated Development Environments for an even more fluid &amp;quot;inner loop&amp;quot; experience.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;More Inference Engines:&lt;/strong&gt; While llama.cpp is a strong start, the potential for a pluggable engine architecture could see Model Runner supporting a wider array of inference backends optimized for different model types or hardware.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Enhanced Observability and Debugging:&lt;br/&gt;As local AI workflows become more complex, improved tools for observing model behavior, debugging inference issues, and monitoring resource consumption locally will become increasingly valuable.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;strong&gt;The Enduring Impact: Local AI as a Standard Engineering Practice&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Docker Model Runner is more than just a feature; it represents a significant step towards making local AI development a standard, accessible, and efficient engineering practice. By integrating AI model execution directly into the familiar and powerful Docker ecosystem, it lowers barriers, fosters innovation, and empowers developers to build the next generation of AI-powered applications with greater speed, control, and confidence.&lt;br/&gt;
The journey from Beta to a fully mature product will undoubtedly bring further refinements and capabilities. However, the foundational principles and architectural choices already evident in Docker Model Runner signal a bright future for local-first AI development, driven by the needs and workflows of engineers.  &lt;/p&gt;&lt;p&gt;&lt;em&gt;This blog post series has been based on information available about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change as the product evolves.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Spring AI: Streamlining Local LLM Integration for Java Developers]]></title><link>https://layer5.io/blog/docker/spring-ai-streamlining-local-llm-integration-for-java-developers</link><guid isPermaLink="false">https://layer5.io/blog/docker/spring-ai-streamlining-local-llm-integration-for-java-developers</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Wed, 14 May 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/7a5be1548e7efed21a2ef4929e78a5ab/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;In our &lt;a href=&quot;/blog/category/docker&quot;&gt;ongoing exploration&lt;/a&gt; of Docker Model Runner, we&amp;#x27;ve covered its OCI-based model management, performance architecture, OpenAI-compatible API, and Docker Compose integration. Now, we turn to a specific, yet highly impactful, synergy: how Docker Model Runner empowers &lt;strong&gt;Java developers using the Spring AI framework&lt;/strong&gt; to seamlessly incorporate local Large Language Models (LLMs) into their applications.&lt;br/&gt;
For Java engineers vested in the Spring ecosystem, Spring AI offers a familiar and powerful abstraction layer for interacting with various AI models. Docker Model Runner&amp;#x27;s compatibility provides a straightforward path to leverage these local models without stepping outside the conventional Spring development paradigm.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Spring AI: Simplifying AI for Java Applications&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Before diving into the integration, it&amp;#x27;s worth briefly understanding Spring AI&amp;#x27;s mission. Spring AI aims to apply core Spring principles—such as autoconfiguration, dependency injection, and portable service abstractions—to the domain of artificial intelligence. It provides Java developers with:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Consistent APIs:&lt;/strong&gt; A unified API for interacting with different AI models (both local and remote), reducing the need to learn multiple vendor-specific SDKs.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Abstraction Layers:&lt;/strong&gt; Components like ChatClient, EmbeddingClient, and ImageClient abstract away the underlying model provider.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Integration with Spring Boot:&lt;/strong&gt; Easy setup and configuration within Spring Boot applications.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Docker Model Runner as a Local &amp;quot;Ollama&amp;quot; for Spring AI&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Spring AI supports various AI model providers, including commercial cloud services (like OpenAI, Azure OpenAI) and self-hosted solutions (like Ollama). From Spring AI&amp;#x27;s perspective, Docker Model Runner, with its OpenAI-compatible API, effectively acts like a local, easily manageable Ollama-style endpoint.&lt;br/&gt;
When Docker Model Runner is active and serving a model (e.g., Llama 3, Gemma) with its API endpoint accessible (typically http://localhost:12434 or &lt;a href=&quot;http://model-runner.docker.internal&quot;&gt;http://model-runner.docker.internal&lt;/a&gt; if accessed from another container), Spring AI can be configured to point to it.&lt;br/&gt;
Here&amp;#x27;s how a Java engineer benefits:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Simplified Configuration in Spring Boot&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Spring AI&amp;#x27;s autoconfiguration can often detect and set up the necessary beans to interact with an OpenAI-compatible endpoint. For Docker Model Runner, this typically involves setting a few properties in your application.properties or application.yml file:  &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-java&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;\# For Spring AI 0.8.x (or similar versions)  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spring.ai.openai.chat.base-url=http://localhost:12434/engines/v1 &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;\# Or your specific DMR endpoint  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spring.ai.openai.chat.options.model=ai/llama3.2:1B-Q8\_0 &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;\# The model you want to use  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;use  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spring.ai.openai.api-key=YOUR\_DUMMY\_API\_KEY\_OR\_EMPTY&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;\# Potentially disable API key if DMR doesn&amp;#x27;t require it strictly for local&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;(Note: The exact property names and structure might vary slightly based on the Spring AI version and whether you&amp;#x27;re configuring a generic OpenAI client or a more specific Ollama-like client type if Spring AI introduces more direct DMR support.)&lt;/em&gt;  &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leveraging Spring AI&amp;#x27;s ChatClient and EmbeddingClient&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once configured, developers can inject and use Spring AI&amp;#x27;s standard clients without needing to know that the underlying provider is Docker Model Runner. &lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-java&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;import org.springframework.ai.chat.ChatClient;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   import org.springframework.ai.chat.prompt.Prompt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   import org.springframework.beans.factory.annotation.Autowired;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   import org.springframework.stereotype.Service;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   @Service  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   public class MyAiService {&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       private final ChatClient chatClient;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       @Autowired  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       public MyAiService(ChatClient chatClient) {  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;           this.chatClient \= chatClient;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       }&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       public String getJokeAbout(String topic) {  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;           Prompt prompt \= new Prompt(&amp;quot;Tell me a short joke about &amp;quot; \+ topic);  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;           return chatClient.call(prompt).getResult().getOutput().getContent();  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;       }  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;   }&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;   This code remains the same whether Spring AI is talking to OpenAI&amp;#x27;s cloud API, a self-hosted Ollama instance, or Docker Model Runner serving a local model. This portability is a huge win.  &lt;/p&gt;&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Seamless Local Development and Testing&lt;/strong&gt;
Engineers can develop and test AI-driven features entirely locally using their preferred Java tools and the Spring framework. Docker Model Runner handles the model serving, and Spring AI provides the clean Java interface. This speeds up iteration cycles and reduces reliance on potentially costly cloud APIs during development.  &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Consistency with Production (Potentially)&lt;/strong&gt;&lt;br/&gt;
While Docker Model Runner is primarily for local development, the abstraction provided by Spring AI means that switching to a production-grade, potentially cloud-hosted model provider for deployment can be achieved mainly through configuration changes, without altering the core application logic.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;strong&gt;The Bigger Picture: Local AI in Enterprise Java&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The integration with Spring AI is significant because it brings the ease of local LLM experimentation directly into the robust, enterprise-focused Java and Spring ecosystem. It allows Java teams to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Prototype AI features rapidly.&lt;/strong&gt;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Upskill on AI concepts using familiar tools.&lt;/strong&gt;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Conduct local, private testing of AI interactions with business data.&lt;/strong&gt;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Integrate AI into existing Spring Boot applications with minimal friction.&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Docker&amp;#x27;s collaboration with Spring AI (as noted in some announcements) underscores a shared vision of making AI more accessible and developer-friendly across different programming environments. By ensuring Docker Model Runner presents an API that Spring AI can readily consume, both platforms contribute to lowering the barrier to entry for sophisticated AI development.&lt;br/&gt;
For Java engineers, this means Docker Model Runner isn&amp;#x27;t just another tool; it&amp;#x27;s a key enabler for leveraging the power of local LLMs within the comfort and productivity of the Spring framework.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Next, we&amp;#x27;ll delve into some practical, task-specific configurations and advanced use cases you can explore with Docker Model Runner, moving beyond basic chat completions.&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change. Configuration details for Spring AI may vary based on specific versions.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Docker Compose: Orchestrating Multi-Service AI Applications Locally]]></title><link>https://layer5.io/blog/docker/docker-compose-orchestrating-multi-service-ai-applications-locally</link><guid isPermaLink="false">https://layer5.io/blog/docker/docker-compose-orchestrating-multi-service-ai-applications-locally</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Thu, 24 Apr 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/97d66df31989169322ece96b70bfd7a8/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;So far in our &lt;a href=&quot;/blog/category/docker&quot;&gt;series on Docker Model Runner&lt;/a&gt;, we&amp;#x27;ve dissected its OCI-based model management, its performance-optimized execution architecture, and its OpenAI-compatible API. Now, we explore a feature that truly elevates its utility for engineers building complex systems: &lt;strong&gt;deep integration with Docker Compose via a novel provider service type.&lt;/strong&gt;  &lt;/p&gt;&lt;p&gt;For engineers, Docker Compose is the go-to tool for defining and running multi-container Docker applications. The introduction of the provider service type specifically for Model Runner bridges the gap between local AI model execution and the broader application stack, allowing you to define and manage AI models as integral components of your local development environment declaratively.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Beyond CLI: Models as First-Class Services in Compose&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;While docker model run is handy for quick tests, real-world applications often involve multiple interacting services—a web frontend, a backend API, a database, and now, an AI model. Docker Model Runner&amp;#x27;s Compose integration allows you to define the AI model itself as a service within your &lt;code&gt;docker-compose.yml&lt;/code&gt; file.  &lt;/p&gt;&lt;p&gt;The key innovation here is the provider attribute within a service definition. Here&amp;#x27;s a conceptual example based on Docker&amp;#x27;s documentation:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;model\_provider\_service&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# You can name this service as you like  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;provider&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; model        \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# Specifies this is a model provider  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; ai/llama3.2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;1B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;Q8\_0 \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# The OCI image for the model  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# No &amp;#x27;build&amp;#x27; or &amp;#x27;image&amp;#x27; directives here in the traditional sense for the provider&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;my\_app\_service&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; ./app  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      \&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;8080:80&amp;quot;&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;depends\_on&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      \&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; model\_provider\_service \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# Ensures model is ready before the app starts  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      \&lt;/span&gt;&lt;span class=&quot;token comment&quot; style=&quot;color:rgb(99, 119, 119);font-style:italic&quot;&gt;# Environment variables will be injected here (see below)  &lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;MODEL\_NAME&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; $&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;MODEL\_PROVIDER\_SERVICE\_MODEL&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;MODEL\_URL&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; $&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;MODEL\_PROVIDER\_SERVICE\_URL&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;}&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;In this setup:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;model_provider_service doesn&amp;#x27;t run a traditional container in the same way my_app_service does. Instead, it instructs Docker Compose to leverage Docker Model Runner.  &lt;/li&gt;&lt;li&gt;Docker Model Runner, when processing this provider service, will ensure the specified image (the AI model) is pulled and made available via its host-native inference engine.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Automatic Model Provisioning and Service Discovery&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;This Compose integration brings significant benefits for engineers:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Declarative Model Dependencies:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;You declare your AI model dependency directly in your docker-compose.yml. Docker Model Runner handles the provisioning (pulling and preparing the model if needed) when you run docker compose up.  &lt;/li&gt;&lt;li&gt;This is a stark improvement over manual docker model run commands or custom scripts to manage model lifecycle alongside your application stack.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Automated Service Discovery via Environment Variables:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;This is a crucial feature for seamless integration. When my_app_service starts (after model_provider_service is ready), Docker Compose automatically injects environment variables into my_app_service.  &lt;/li&gt;&lt;li&gt;These variables typically follow the pattern: PROVIDER_SERVICE_NAME_MODEL and PROVIDER_SERVICE_NAME_URL.  &lt;ul&gt;&lt;li&gt;MODEL_PROVIDER_SERVICE_MODEL: Contains the name/tag of the model being served (e.g., ai/llama3.2:1B-Q8_0).  &lt;/li&gt;&lt;li&gt;MODEL_PROVIDER_SERVICE_URL: Provides the URL your application should use to access the Model Runner&amp;#x27;s API endpoint for this model. This would often point to the internal DNS &lt;a href=&quot;http://model-runner.docker.internal&quot;&gt;http://model-runner.docker.internal&lt;/a&gt; or a host-accessible TCP port if configured.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Your application code can then dynamically use these environment variables to configure its AI client, making the connection to the local model effortless and portable.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Simplified depends_on for Startup Order:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;Using depends_on ensures that your application services only start after Model Runner has signaled that the model provider is ready. This prevents your application from trying to connect to a model that isn&amp;#x27;t yet available.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;strong&gt;Engineering Benefits for Complex AI Applications&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;This declarative, integrated approach offers tangible advantages:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Reproducible AI Development Environments:&lt;/strong&gt; Your entire local stack, including the specific AI model version, is defined in code (docker-compose.yml), making it easy to share, version control, and ensure consistency across development team members.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Simplified Onboarding:&lt;/strong&gt; New developers can get a complex AI-powered application stack running locally with a single docker compose up command.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Streamlined Local Testing of AI Features:&lt;/strong&gt; Test end-to-end flows involving your application logic and AI model interactions in a fully integrated local environment that mirrors how services would interact.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Foundation for Local MLOps Loops:&lt;/strong&gt; While focused on local development, this pattern lays a conceptual foundation for how AI models can be treated as manageable dependencies within larger application architectures, aligning with MLOps principles.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;By treating AI models as discoverable services managed by Compose, Docker Model Runner significantly lowers the barrier to building and iterating on sophisticated multi-service applications that leverage local AI capabilities. This moves beyond simply running a model in isolation to truly integrating AI into your development workflow.&lt;br/&gt;
Next up, we&amp;#x27;ll explore how Docker Model Runner specifically caters to Java developers through its integration with frameworks like Spring AI, further simplifying the adoption of local AI.  &lt;/p&gt;&lt;p&gt;&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Host-Native Execution & GPU Deep Dive]]></title><link>https://layer5.io/blog/docker/host-native-execution-gpu-deep-dive</link><guid isPermaLink="false">https://layer5.io/blog/docker/host-native-execution-gpu-deep-dive</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Tue, 15 Apr 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/a0d502a06407981844fc859ba51cbc91/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;In our series on &lt;a href=&quot;/blog/category/docker&quot;&gt;Docker Model Runner&lt;/a&gt;, we&amp;#x27;ve explored Docker Model Runner&amp;#x27;s role in simplifying local AI development and its strategic use of OCI artifacts for model management. Now, we peel back another layer to examine a critical aspect for any engineer working with Large Language Models (LLMs): &lt;strong&gt;performance&lt;/strong&gt;. How does Docker Model Runner achieve the responsiveness needed for an efficient local development loop? The answers lie in its architectural choices, particularly its embrace of host-native execution and direct GPU access.  &lt;/p&gt;&lt;p&gt;For engineers, &amp;quot;local&amp;quot; often implies a trade-off: convenience versus raw power. Docker Model Runner attempts to bridge this gap, and understanding its performance model is key to leveraging it effectively.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Architectural Pivot: Why docker model run Isn&amp;#x27;t docker container run&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;One of the most crucial, and perhaps initially counter-intuitive, aspects of Docker Model Runner is how it executes AI models. Seasoned Docker users might expect docker model run some-model to spin up an isolated Docker container housing the model and its inference engine. However, Model Runner takes a more direct path to prioritize local performance.  &lt;/p&gt;&lt;p&gt;As detailed in multiple technical breakdowns and official documentation, when you execute &lt;code&gt;docker model run&lt;/code&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;No Traditional Container for Inference:&lt;/strong&gt; The command doesn&amp;#x27;t launch a standard Docker container for the core inference task.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Host-Native Inference Server:&lt;/strong&gt; Instead, it interacts with an inference server (initially built on the efficient llama.cpp engine) that runs as a &lt;strong&gt;native process directly on your host machine&lt;/strong&gt;. This server is managed as part of Docker Desktop or the Model Runner plugin.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This is a deliberate engineering decision. Docker&amp;#x27;s own statements reveal that this approach was chosen to &amp;quot;significantly improve performance by eliminating containerization overhead for resource-intensive AI workloads&amp;quot; and to avoid the &amp;quot;performance limitations of running models inside virtual machines.&amp;quot; While Docker&amp;#x27;s traditional strength lies in containerization for isolation and portability, for the demanding task of LLM inference locally, the raw performance gains from direct host execution were deemed paramount.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Unlocking Hardware: Direct GPU Acceleration&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;A major bottleneck for LLM performance is often GPU access. Docker Model Runner addresses this head-on:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Optimized for Apple Silicon (Metal API):&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;For developers on macOS with Apple Silicon (M-series chips), Model Runner&amp;#x27;s host-native inference engine is designed to &lt;strong&gt;directly access Apple&amp;#x27;s Metal API&lt;/strong&gt;. This provides a highly optimized path to the GPU, bypassing virtualization layers that can throttle performance. This direct access can offer a noticeable speed advantage compared to running models within a container that has to go through more layers to reach the GPU.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Windows GPU Support on the Roadmap:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;Recognizing the diverse hardware landscape, Docker has explicitly included support for GPU acceleration on Windows platforms (primarily targeting NVIDIA GPUs) in its development plans. This is a critical feature for broadening Model Runner&amp;#x27;s appeal and utility.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This strategy of direct hardware access, especially for GPUs, is a pragmatic choice. It acknowledges that for the &amp;quot;inner loop&amp;quot; of local AI development—where rapid iteration and experimentation are key—minimizing inference latency is crucial.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Intelligent Resource Management: Efficiency Under the Hood&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Beyond raw execution speed, Docker Model Runner incorporates features for efficient resource utilization:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;On-Demand Model Loading:&lt;/strong&gt; Models are not kept in memory at all times. When you make a request to a specific model (e.g., via an API call from your application or a docker model run command), Model Runner loads it into memory &amp;quot;on-demand,&amp;quot; provided the model files have already been pulled locally. This means you don&amp;#x27;t necessarily have to issue a docker model run before your application can start interacting with a model.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Memory Caching with Inactivity Timeout:&lt;/strong&gt; Once loaded, a model remains in memory to serve subsequent requests quickly. However, to conserve system resources, models are automatically unloaded if they remain inactive for a predefined period. This inactivity timeout is &lt;strong&gt;currently set to 5 minutes&lt;/strong&gt;. This is a practical detail that impacts how long a model stays &amp;quot;warm&amp;quot; and ready for immediate use during an interactive development session.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This combination of on-demand loading and inactivity-based unloading helps balance responsiveness with efficient use of your local machine&amp;#x27;s memory.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Engineering Trade-Off: Performance vs. Isolation&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The decision to run the inference engine as a host-native process is a clear trade-off: Docker is prioritizing local inference speed and direct hardware access over the complete process isolation typically provided by containers &lt;em&gt;for the inference step itself&lt;/em&gt;. While the applications &lt;em&gt;using&lt;/em&gt; the model can still be containerized and benefit from Docker&amp;#x27;s isolation, the model execution core operates closer to the metal.&lt;br/&gt;
This architectural choice highlights Docker&amp;#x27;s commitment to making the local AI development experience as smooth and fast as possible, even if it means deviating slightly from its traditional container-centric execution model for this specific, performance-sensitive component.&lt;br/&gt;
Understanding this performance architecture—host-native execution, direct GPU access, and smart resource management—allows engineers to better anticipate Model Runner&amp;#x27;s behavior, optimize their local AI workflows, and appreciate the engineering decisions aimed at making local LLM development more practical and efficient.  &lt;/p&gt;&lt;p&gt;In our next post, we&amp;#x27;ll explore the API architecture of Docker Model Runner, focusing on its OpenAI compatibility and the various ways you can connect your applications to the local inference engine.  &lt;/p&gt;&lt;p&gt;&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[API Architecture, OpenAI Compatibility, and Connection Strategies]]></title><link>https://layer5.io/blog/docker/api-architecture-openai-compatibility-and-connection-strategies</link><guid isPermaLink="false">https://layer5.io/blog/docker/api-architecture-openai-compatibility-and-connection-strategies</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Wed, 09 Apr 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/7ad71d9ddffb4f0135947f5b528e0c93/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;In our last &lt;a href=&quot;/blog/category/docker&quot;&gt;post in this series&lt;/a&gt;, explored Docker Model Runner&amp;#x27;s OCI-based model management and its performance-centric execution model, we now turn our attention to another critical area for engineers: its &lt;strong&gt;API architecture and connectivity options&lt;/strong&gt;. How do your applications actually &lt;em&gt;talk&lt;/em&gt; to the models running locally via Model Runner? The answer lies in a thoughtfully designed API layer, with OpenAI compatibility at its core, and flexible connection methods to suit diverse development scenarios.  &lt;/p&gt;&lt;p&gt;For engineers, a well-defined and accessible API is paramount. It dictates the ease of integration, the reusability of existing code, and the overall developer experience when building AI-powered applications.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Heart of the Engine: llama.cpp and a Pluggable Future&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;In its initial Beta release, Docker Model Runner&amp;#x27;s inference capabilities are powered by an integrated engine built on llama.cpp. This open-source project is renowned for its efficient execution of LLMs across various hardware, making it a solid foundation for local inference.  &lt;/p&gt;&lt;p&gt;When you interact with Model Runner, you&amp;#x27;re essentially communicating with this llama.cpp-based server, which runs as a native host process. The API paths often reflect this underlying engine, for example, with endpoints structured under /engines/llama.cpp/v1/... or a more generalized &lt;code&gt;/engines/v1/...&lt;/code&gt;.&lt;br/&gt;
While llama.cpp provides a robust initial backbone, the API path structure (e.g., &lt;code&gt;/engines/...&lt;/code&gt;) hints at a potentially pluggable architecture. This is a common design pattern that could allow Docker to integrate other inference engines or model serving technologies in the future. This foresight means Model Runner could evolve to support a wider array of model types, quantization methods, or hardware acceleration frameworks without requiring a fundamental redesign of its API interaction model.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The &amp;quot;Superpower&amp;quot;: OpenAI-Compatible API&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most strategically significant aspect of Model Runner&amp;#x27;s API is its &lt;strong&gt;OpenAI compatibility&lt;/strong&gt;. This is a game-changer for several reasons:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Leverage Existing SDKs and Tools:&lt;/strong&gt; Engineers can use their existing OpenAI SDKs (Python, Node.js, etc.) and a vast ecosystem of compatible tools like LangChain or LlamaIndex with minimal, if any, code changes. This dramatically lowers the barrier to adoption.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Simplified Migration:&lt;/strong&gt; If you&amp;#x27;ve been developing against OpenAI&amp;#x27;s cloud APIs, transitioning to local models with Model Runner can often be as simple as changing the baseURL in your client configuration. This seamless switch accelerates local development and testing.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Reduced Learning Curve:&lt;/strong&gt; There&amp;#x27;s no need to learn a new, proprietary API. The familiar OpenAI request/response structures for tasks like chat completions (&lt;code&gt;/chat/completions&lt;/code&gt;) or embeddings (&lt;code&gt;/embeddings&lt;/code&gt;) remain consistent. &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This adherence to a de facto industry standard API is a deliberate choice by Docker to maximize interoperability and ease of integration, allowing developers to focus on application logic rather than wrestling with new API paradigms.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Connecting Your Applications: A Multi-Pronged Approach&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Docker Model Runner offers several ways for your applications and tools to connect to the local inference engine, providing flexibility for different development setups:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Internal DNS for Containerized Applications (model-runner.docker.internal):&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How it works:&lt;/strong&gt; For applications running as Docker containers themselves (e.g., a backend API service), Model Runner provides a stable internal DNS name: &lt;a href=&quot;http://model-runner.docker.internal.&quot;&gt;http://model-runner.docker.internal.&lt;/a&gt;  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Benefit for Engineers:&lt;/strong&gt; This is incredibly convenient. Your containerized service can simply target this DNS name to reach the Model Runner API, without needing to know the host&amp;#x27;s IP address or worry about dynamic port mappings. It simplifies network configuration within your Docker environment.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Endpoint Example:&lt;/strong&gt; &lt;a href=&quot;http://model-runner.docker.internal/engines/v1/chat/completions&quot;&gt;http://model-runner.docker.internal/engines/v1/chat/completions&lt;/a&gt;  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Host TCP Port for Direct Access:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How it works:&lt;/strong&gt; You can configure Model Runner to listen on a specific TCP port on your host machine. This is typically done via a Docker Desktop setting or a command like docker desktop enable model-runner --tcp \&amp;lt;port&amp;gt; (e.g., port 12434).  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Benefit for Engineers:&lt;/strong&gt; This allows applications running directly on your host (outside of Docker containers)—such as IDEs, local scripts, or standalone Java applications using Spring AI—to connect to the Model Runner.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Endpoint Example:&lt;/strong&gt; http://localhost:12434/engines/v1/chat/completions  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Docker Socket (Advanced/CLI Use):&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How it works:&lt;/strong&gt; For direct interactions via the Docker API or for certain CLI scripting scenarios, the Docker socket (/var/run/docker.sock on Linux/macOS) can be used. API calls through the socket might have a specific path prefix (e.g., &lt;code&gt;/exp/vDD4.40/...&lt;/code&gt; as seen in early versions).  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Benefit for Engineers:&lt;/strong&gt; This offers a lower-level interface, useful for automation scripts or tools that integrate deeply with the Docker daemon.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This multi-faceted approach to connectivity ensures that whether your application is containerized, running natively on the host, or interacting via CLI tools, there&amp;#x27;s a clear and supported path to communicate with the local AI models managed by Docker Model Runner.  &lt;/p&gt;&lt;p&gt;Understanding these API mechanics and connection options is crucial for effectively integrating Docker Model Runner into your development workflows. It allows you to choose the most appropriate method for your specific application architecture and leverage the power of local AI models with ease.&lt;br/&gt;
In our next post, we&amp;#x27;ll explore how Docker Model Runner integrates with Docker Compose, enabling the orchestration of complex, multi-service AI applications locally.  &lt;/p&gt;&lt;p&gt;&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Taming the Wild West of AI Model Management]]></title><link>https://layer5.io/blog/docker/taming-the-wild-west-of-ai-model-management</link><guid isPermaLink="false">https://layer5.io/blog/docker/taming-the-wild-west-of-ai-model-management</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Wed, 02 Apr 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/ad894700277bdd8c181ccbffc7dc4e16/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;In our [previous post](https://layer5.io/blog/docker/docker-model-runner), we introduced Docker Model Runner as a promising new toolkit for simplifying local AI development. Now, let&amp;#x27;s delve into one of its foundational—and perhaps most strategically significant—aspects: its deep reliance on the Open Container Initiative (OCI) standard for managing AI models.&lt;p&gt;If you&amp;#x27;ve wrestled with AI models, you know the &amp;quot;messy landscape&amp;quot; of model distribution. Models often arrive as loose files, tucked behind proprietary download tools, or lacking clear versioning. This fragmentation makes standardization, reproducibility, and integration into automated workflows a real headache for engineers. Docker Model Runner aims to bring order to this chaos by treating AI models as OCI artifacts, and this decision has profound implications for how you, as an engineer, can manage the entire lifecycle of your AI models.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;OCI: More Than Just docker model pull&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;You might see docker model pull &lt;code&gt;ai/llama3.2:1B-Q8_0&lt;/code&gt; and think it&amp;#x27;s just a convenient way to download models. But packaging models as OCI artifacts is a strategic move by Docker that goes far deeper. It aligns AI model management with the mature, robust ecosystem already built around OCI for container images.  &lt;/p&gt;&lt;p&gt;Essentially, Docker is working to make AI models &lt;strong&gt;first-class citizens within the Docker ecosystem&lt;/strong&gt;. This means the same trusted registries and workflows you use for your application containers can now, in principle, be applied to your AI models. Imagine the possibilities:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Unified Workflows:&lt;/strong&gt; Manage, version, and distribute your AI models using the same tools and processes you already use for your containerized applications. No more separate, bespoke systems for model management.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Leveraging Existing Infrastructure:&lt;/strong&gt; Your existing private container registries (like Docker Hub, Artifactory, Harbor, etc.) can become repositories for your AI models. This allows you to apply the same security scanning, access control policies, and auditing mechanisms you trust for your containers directly to your AI assets.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Engineering Benefits: What OCI Brings to Your AI Model Lifecycle&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Adopting OCI for models isn&amp;#x27;t just about tidiness; it brings tangible engineering benefits:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Robust Versioning &amp;amp; Provenance:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How you benefit:&lt;/strong&gt; OCI&amp;#x27;s tagging system (e.g., :1B-Q8_0, :latest, :v2.1-finetuned) provides robust version control for your models. This is critical for reproducibility in experiments and ensuring stability in deployments. You can track exactly which model version was used for a particular result or release.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Immutability:&lt;/strong&gt; Like container images, OCI artifacts can be treated as immutable. Once a version is tagged and pushed, it remains consistent, preventing accidental modifications and ensuring that when you pull my-model:v1.0, you always get the same bits.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Streamlined CI/CD for ML Models:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How you benefit:&lt;/strong&gt; This is a big one. Your existing CI/CD pipelines, likely already geared to handle OCI artifacts for application builds and deployments, can be extended to manage your AI models.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Think about it:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;Automated testing and validation of new model versions.  &lt;/li&gt;&lt;li&gt;Triggering model deployments based on updates in your model training repositories.  &lt;/li&gt;&lt;li&gt;Integrating model security scanning into your pipeline.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;This moves you closer to comprehensive MLOps automation by leveraging familiar tools and processes.  &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enhanced Governance and Security:&lt;/strong&gt;  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;How you benefit:&lt;/strong&gt; By storing models in your existing OCI-compliant registries, you can apply consistent governance. Use the same tools for vulnerability scanning on your models as you do for your container images. Enforce role-based access control (RBAC) to determine who can pull or push specific models or versions.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;strong&gt;The Future is Custom: Pushing Your Own Models&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;While Docker Model Runner currently provides access to curated models from Docker Hub (often under the ai/ namespace or from partners like Hugging Face via hf.co/), the real power of OCI will unlock when you can easily manage your &lt;em&gt;own&lt;/em&gt; custom models.  &lt;/p&gt;&lt;p&gt;The inclusion of commands like docker model push and docker model tag in the CLI strongly signals this future direction. Imagine:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Training or fine-tuning a model for your specific needs.  &lt;/li&gt;&lt;li&gt;Packaging it as an OCI artifact.  &lt;/li&gt;&lt;li&gt;Pushing it to your private or public OCI registry.  &lt;/li&gt;&lt;li&gt;Seamlessly pulling and running it with docker model pull your-namespace/your-custom-model:v1 and docker model run ....&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This capability will be transformative, allowing you to integrate bespoke AI directly into your standardized Docker workflows, free from vendor lock-in for model storage and distribution.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;A More Cohesive AI Development World&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;By embracing OCI, Docker Model Runner isn&amp;#x27;t just offering a new command; it&amp;#x27;s paving the way for a more unified and manageable AI development landscape. As an engineer, this means you can apply familiar, battle-tested DevOps principles and tools to your AI models, reducing complexity and accelerating your path from experimentation to production. This strategic choice for an open standard also offers a degree of future-proofing. As the AI ecosystem evolves, models packaged as OCI artifacts will likely be manageable by an ever-expanding array of tools and platforms that support this widely adopted standard.  &lt;/p&gt;&lt;p&gt;In our next post, we&amp;#x27;ll shift gears and look under the hood at Docker Model Runner&amp;#x27;s performance architecture, particularly its use of host-native execution and GPU acceleration.  &lt;/p&gt;&lt;p&gt;&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Docker Model Runner]]></title><link>https://layer5.io/blog/docker/docker-model-runner</link><guid isPermaLink="false">https://layer5.io/blog/docker/docker-model-runner</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Thu, 27 Mar 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/dfd3200061f7dd06b9c2ae3283e13437/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;The shift towards local-first AI development is undeniable, driven by engineers seeking to overcome the practical hurdles of cloud-centric model interaction. Escalating API costs, data privacy concerns when handling sensitive information, network latency impacting iteration speed, and the desire for finer-grained control over execution environments have all highlighted the need for robust local solutions. Docker Model Runner is Docker&amp;#x27;s response to these engineering challenges, aiming to significantly streamline how we develop and test AI models locally.  &lt;/p&gt;&lt;p&gt;This post, the first in a series, will dissect Docker Model Runner from an engineering perspective. We&amp;#x27;ll explore its core technical value propositions and how you can leverage this new toolkit to enhance your AI development workflows.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Engineering Case for Local AI Development&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;For engineers, the &amp;quot;local-first&amp;quot; approach to AI isn&amp;#x27;t just a trend; it&amp;#x27;s a pragmatic choice offering tangible benefits:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Reduced Iteration Costs:&lt;/strong&gt; Experimenting with prompts, parameters, and model variations can lead to substantial API expenses. Local execution eliminates these costs during the crucial development and debugging phases.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enhanced Data Privacy &amp;amp; Security:&lt;/strong&gt; Working with proprietary or sensitive datasets locally mitigates the risks associated with transmitting data to external services, a critical consideration for many enterprise applications.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Accelerated Development Cycles:&lt;/strong&gt; Eliminating network latency allows for near-instantaneous feedback, dramatically speeding up iterative tasks like prompt engineering, parameter tuning, and debugging model behavior.  &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Granular Environmental Control:&lt;/strong&gt; Local execution provides engineers with complete control over the model&amp;#x27;s runtime environment, dependencies, and specific configurations, facilitating reproducible experiments and precise debugging.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Docker Model Runner: Key Technical Capabilities for Engineers&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Docker Model Runner aims to integrate local AI model execution seamlessly into the familiar Docker ecosystem. Here are some of its core technical aspects beneficial for engineers:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Simplified Local Inference Setup:&lt;br/&gt;While the &amp;quot;Docker&amp;quot; name might imply traditional containerization for the model itself, Model Runner takes a different architectural path for performance. It facilitates running models like ai/llama3.2:1B-Q8_0 or hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF via commands such as docker model pull and docker model run. The key is that the inference itself often runs as a host-native process (initially leveraging llama.cpp), interacting with Docker Desktop or a Model Runner plugin. This design choice, which we&amp;#x27;ll explore in detail later, prioritizes direct hardware access.  &lt;/li&gt;&lt;li&gt;Performance through Host-Native Execution &amp;amp; GPU Access:&lt;br/&gt;To tackle the performance demands of LLMs, Model Runner enables the inference engine to directly access host resources. For macOS users with Apple Silicon, this means direct Metal API utilization for GPU acceleration. Windows GPU support is also on the roadmap. This approach aims to minimize the overhead often associated with virtualized GPU access in containerized environments, offering a potential speed advantage for local development.  &lt;/li&gt;&lt;li&gt;OpenAPI-Compatible API for Seamless Integration:&lt;br/&gt;One of the most significant engineering benefits is the provision of an OpenAI-compatible API. This allows you to reuse existing codebases, SDKs (like LangChain or LlamaIndex), and tools with minimal, if any, modification. For many, transitioning to a local model might be as simple as changing an API endpoint URL, drastically reducing the integration effort and learning curve.  &lt;/li&gt;&lt;li&gt;Standardized Model Management with OCI Artifacts:&lt;br/&gt;Docker Model Runner treats AI models as Open Container Initiative (OCI) artifacts. This is a strategic move towards standardizing model distribution, versioning, and management, aligning it with the mature ecosystem already in place for container images. This opens the door to leveraging existing container registries and CI/CD pipelines for models, a crucial step towards robust MLOps practices. We&amp;#x27;ll dedicate our next post to a deep dive into this OCI integration.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;strong&gt;Beyond Single Invocations: The Potential for Local AI Pipelines&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;While running individual models is a core function, the architecture of Docker Model Runner also supports the local orchestration of more complex, multi-stage AI workflows. As detailed in examples like the Gemma 3 Comment Processing System, engineers can design and debug entire pipelines—involving synthetic data generation, categorization, embedding generation, feature extraction, and response generation—all on their local machines. This capability for end-to-end local development of AI-driven features is invaluable.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Engineering the Future of Local AI&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Docker Model Runner, even in its Beta phase (introduced with Docker Desktop 4.40, with APIs still evolving), presents a compelling toolkit for engineers looking to overcome the traditional challenges of local AI development. It offers a pathway to faster iteration, greater control, enhanced privacy, and reduced costs.&lt;br/&gt;
In our next post, we will delve into the technical specifics of how Docker Model Runner&amp;#x27;s use of &lt;strong&gt;OCI artifacts is set to revolutionize AI model management&lt;/strong&gt;, bringing DevOps principles to your MLOps workflows.&lt;br/&gt;
&lt;em&gt;This blog post is based on information about Docker Model Runner, a Beta feature. Features, commands, and APIs are subject to change.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Supercharge Your Git Workflow with Powerful Aliases]]></title><description><![CDATA[Git command line aliases and git shortcuts]]></description><link>https://layer5.io/blog/engineering/supercharge-your-git-workflow-with-powerful-aliases</link><guid isPermaLink="false">https://layer5.io/blog/engineering/supercharge-your-git-workflow-with-powerful-aliases</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Sat, 25 Jan 2025 16:00:05 GMT</pubDate><enclosure url="https://layer5.io/static/566411427e09e80368249dd7537f1ba8/hero-image.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;&lt;strong&gt;Tired of typing long Git commands?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Git is an incredibly powerful tool, but its command-line interface can sometimes feel cumbersome. Fortunately, Git allows you to create custom aliases to simplify your workflow. By assigning short, easy-to-remember names to frequently used commands, you can significantly boost your productivity and reduce the time spent on repetitive tasks.&lt;/p&gt;&lt;div&gt;&lt;iframe width=&quot;800&quot; height=&quot;490&quot; src=&quot;https://www.youtube.com/embed/vkk2jHUgbNQ?si=ohL-fnpZJDkwHO6w&quot; title=&quot;YouTube video player&quot; frameBorder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerPolicy=&quot;strict-origin-when-cross-origin&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Video: `git lg` alias for a more visually appealing log&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Why Use Git Aliases?&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt;  Quickly execute complex commands with a single keystroke.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Consistency:&lt;/strong&gt; Reduce the risk of typos and errors in your Git commands.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Personalization:&lt;/strong&gt; Tailor your Git experience to your specific needs and preferences.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Essential Git Aliases&lt;/h3&gt;&lt;p&gt;Here are some essential Git aliases that can revolutionize your workflow:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Navigation and Branching:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;git co:&lt;/strong&gt;  Quickly switch branches.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.co checkout&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git br:&lt;/strong&gt; List all branches.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.br branch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git new:&lt;/strong&gt; Create a new branch and switch to it.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.new &amp;#x27;!git checkout -b&amp;#x27;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Staging and Committing:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;git a:&lt;/strong&gt; Stage all changes.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.a add&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git cm:&lt;/strong&gt; Commit with a message.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.cm commit -m&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git cam:&lt;/strong&gt; Amend the last commit.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.cam commit --amend -m&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git ca:&lt;/strong&gt; Stage all and commit with a message.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.ca &amp;#x27;!git add -A &amp;amp;&amp;amp; git commit -m&amp;#x27;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Viewing and Comparing:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;git st:&lt;/strong&gt; Check the state of your repository.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.st status&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git lg:&lt;/strong&gt; View a more visually appealing log.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.lg &amp;quot;log --color --graph --pretty=format:&amp;#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&amp;lt;%an&amp;gt;%Creset&amp;#x27; --abbrev-commit&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git df:&lt;/strong&gt; Show the diff of unstaged changes.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.df diff&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git dc:&lt;/strong&gt; Show the diff of staged changes.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.dc diff --cached&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Undoing Changes:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;git undo:&lt;/strong&gt; Reset the last commit, keeping your changes.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.undo &amp;#x27;reset HEAD^&amp;#x27;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Remote Interactions:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;git fch:&lt;/strong&gt; Fetch all changes from remotes.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.fch fetch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git pl:&lt;/strong&gt; Pull the latest changes from the current branch&amp;#x27;s remote.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.pl pull&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;git ps:&lt;/strong&gt; Push your local changes to the remote branch.&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.ps push&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Setting Up Git Aliases&lt;/h3&gt;&lt;p&gt;To set up these aliases, you can edit your global Git configuration file:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Open your &lt;code&gt;.gitconfig&lt;/code&gt; file:&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Global:&lt;/strong&gt; &lt;code&gt;~/.gitconfig&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Local:&lt;/strong&gt; &lt;code&gt;.git/config&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Add the aliases:&lt;/strong&gt; Use the &lt;code&gt;git config&lt;/code&gt; command to add each alias. For example:&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 gVtoQD&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 krJRTz prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 dyMzEv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;git config --global alias.co checkout&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Streamline your cloud native workflow (just like git aliases)&lt;/h3&gt;&lt;p&gt;Just as git aliases simplify your development workflow, &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; streamlines the management of your cloud native infrastructure.  This CNCF project provides a unified platform to wrangle Kubernetes and other cloud native tools, so you can focus on building and deploying amazing applications.&lt;/p&gt;&lt;p&gt;By incorporating these Git aliases into your workflow, you can streamline your development process, reduce errors, and ultimately become a more efficient developer. Experiment with different aliases to find the perfect combination that suits your needs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Happy Git-ing!&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Layer5 Launches Kanvas: A Collaborative Platform for Cloud Native Infrastructure]]></title><description><![CDATA[Layer5 announces Kanvas, a collaboration platform for engineering teams managing cloud native infrastructure. Built on Meshery, Kanvas provides an intuitive design suite for engineers to visualize, manage, and collaboratively design multi-cloud and Kubernetes-native infrastructure.]]></description><link>https://layer5.io/company/news/layer5-launches-kanvas-a-collaborative-platform-for-cloud-native-infrastructure</link><guid isPermaLink="false">https://layer5.io/company/news/layer5-launches-kanvas-a-collaborative-platform-for-cloud-native-infrastructure</guid><dc:creator><![CDATA[The Newsroom]]></dc:creator><pubDate>Fri, 15 Nov 2024 13:30:00 GMT</pubDate><enclosure url="https://layer5.io/static/d183a1a25111a497fe92979cfea33f09/kanvas-stacked-color.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 bzJNOf&quot;&gt;&lt;p&gt;[Salt Lake City, UT] [KubeCon + CloudNativeCon] - November 14th, 2024 – &lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt;Layer5&lt;/a&gt;, the open source company behind the popular &lt;a href=&quot;https://meshery.io&quot;&gt;Meshery&lt;/a&gt; project, announces Kanvas, a new collaboration platform that is like Google Workspace, but designed for engineering teams.&lt;/p&gt;&lt;a href=&quot;/static/layer5-kanvas-designer-4c521709f369987eecb50e3072328e9e.webp&quot;&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/layer5-kanvas-designer-4c521709f369987eecb50e3072328e9e.webp&quot; alt=&quot;Layer5 Kanvas Designer&quot; width=&quot;100%&quot; class=&quot;block-display align-center&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;&lt;/a&gt;&lt;p&gt;&lt;a href=&quot;https://kanvas.new/&quot;&gt;Kanvas&lt;/a&gt; is a multi-modal collaboration suite built atop one of the Cloud Native Computing Foundation’s highest velocity open source projects: Meshery. Kanvas’s two modes, Designer and Operator, offer declarative and imperative DevOps workflows, respectively. Both modes provide a visual interface for creating and managing complex cloud native infrastructure, expediting collaborative problem-solving, brainstorming and innovation, engineer onboarding, and auto-documented infrastructure. Importantly, Kanvas helps teams avoid finger-pointing and the blame-game by allowing them to be on the same page - literally.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;Partnering on Dapr’s integration with Meshery has been eye-opening. Kanvas promotes collaboration in the design and discussion of cloud native applications, eliminating misunderstandings between teams. It is a game-changer for how we navigate the complexities of relationships between system components&quot; person=&quot;Mauricio Salatino&quot; title=&quot;Software Engineer at Diagrid and author of Platform Engineering on Kubernetes&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;Partnering on Dapr’s integration with Meshery has been eye-opening. Kanvas promotes collaboration in the design and discussion of cloud native applications, eliminating misunderstandings between teams. It is a game-changer for how we navigate the complexities of relationships between system components&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Mauricio Salatino&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Software Engineer at Diagrid and author of Platform Engineering on Kubernetes&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;As an extensible, self-service engineering platform with hundreds of technology integrations, supporting multi-cloud and Kubernetes native infrastructure, Meshery is the ideal management platform upon which to build Kanvas’ novel collaboration experience. Meshery has thousands of pre-built components supporting Kubernetes and Cloud services and with over 2,000 contributors, Meshery is the 9th fastest growing CNCF (out of 200+ projects).&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 evseNu blockquote&quot; quote=&quot;Internal developer platforms, like Meshery, are rising in popularity, because engineering teams remain siloed with disparate tooling, inconsistent workflow, lack of collaboration and shared process. A lack of collaboration plagues engineering teams with 83% of IT organizations implementing DevOps practices. 62% of organizations are stuck mid-DevOps evolution, teams tightly coupled and responsibilities diffused. Engineering teams desperately need to collaborate, but lack tooling specifically designed for cloud native infrastructure.&quot; person=&quot;Lee Calcote&quot; title=&quot;Layer5 founder&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Internal developer platforms, like Meshery, are rising in popularity, because engineering teams remain siloed with disparate tooling, inconsistent workflow, lack of collaboration and shared process. A lack of collaboration plagues engineering teams with 83% of IT organizations implementing DevOps practices. 62% of organizations are stuck mid-DevOps evolution, teams tightly coupled and responsibilities diffused. Engineering teams desperately need to collaborate, but lack tooling specifically designed for cloud native infrastructure.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Lee Calcote&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Layer5 founder&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Like Figma for engineers, Kanvas users can access Kanvas from any computer with an internet connection and a web browser.&lt;/p&gt;&lt;h4&gt;Feature Highlights:&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Infrastructure as Design&lt;/strong&gt;: Intuitive drag-and-drop interface for designing and visualizing cloud native infrastructure and general architecture diagrams. Supports Kubernetes and multi-cloud services.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Self-Service DevOps&lt;/strong&gt;: Empowers engineers to create, share, and manage their own environments on demand.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Greenfields and Brownfield Infrastructure&lt;/strong&gt;: Import existing cloud environments to visualize current infrastructure or create a new design from scratch.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;GitOps Integration&lt;/strong&gt;: Pull request integration for infrastructure design reviews.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Model-Driven&lt;/strong&gt; characterization of both semantic and non-semantic infrastructure as design components.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Policy-driven intelligent inference&lt;/strong&gt; of infrastructure components and their relationships.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Real-Time Collaboration&lt;/strong&gt;: Work with others on your designs in real-time, making it easier to collaborate and share ideas, while all changes are saved automatically. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Design Patterns&lt;/strong&gt;: A catalog full of ready-made blueprints for common infrastructure and application architectures.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Kanvas Spaces&lt;/strong&gt;: provide a collaborative environment similar to Google Shared Drive, but specifically tailored for cloud-native infrastructure management.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Design Reviews&lt;/strong&gt;: Collaboratively review and provide feedback on designs and prototypes.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;iframe width=&quot;100%&quot; height=&quot;315&quot; style=&quot;margin-right:1.5rem;margin-left:1.5rem&quot; src=&quot;https://www.youtube.com/embed/4WcofErPTx4?si=UfouUV7mhADg3zkk&quot; title=&quot;YouTube video player&quot; frameBorder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerPolicy=&quot;strict-origin-when-cross-origin&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;p style=&quot;font-style:italic;font-size:1rem;margin-left:1rem&quot;&gt;Birth of Kanvas from Meshery&lt;/p&gt;&lt;/div&gt;&lt;h4&gt;Kanvas caters to a wide range of users, including:&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Teams and engineering managers for brainstorming, diagramming, wireframing, and interviewing.&lt;/li&gt;&lt;li&gt;Platform engineers for underpinning self-service and developer empowerment.&lt;/li&gt;&lt;li&gt;Site reliability engineers for curating a catalog of design patterns as a center of excellence.&lt;/li&gt;&lt;li&gt;Operators for managing and visualizing infrastructure components.&lt;/li&gt;&lt;li&gt;Solution architects designing infrastructure across multiple cloud providers from a single canvas.&lt;/li&gt;&lt;li&gt;Developer advocates and educators for facilitating real-time exploration and asynchronous study of any cloud native technology.&lt;/li&gt;&lt;li&gt;Developers and product engineers for ease of understanding and design of their application infrastructure.&lt;/li&gt;&lt;li&gt;System integrators and consultants for a service provider-grade organization hierarchy, multi-tenant, white-labelable, highly extensible delivery platform.&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 jVBIsx blockquote&quot; quote=&quot;Layer5 Kanvas is revolutionizing our approach to infrastructure design. With its collaborative environment, we&amp;#x27;re seeing significant gains in efficiency and cost-effectiveness, streamlining our workflows and fostering a shared understanding between our customers and partners. Any team that needs a shared space to collaborate and visualize ideas can benefit from using Kanvas.&quot; person=&quot;Yogi Porla&quot; title=&quot; CTO of Deeplineage&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;Layer5 Kanvas is revolutionizing our approach to infrastructure design. With its collaborative environment, we&amp;#x27;re seeing significant gains in efficiency and cost-effectiveness, streamlining our workflows and fostering a shared understanding between our customers and partners. Any team that needs a shared space to collaborate and visualize ideas can benefit from using Kanvas.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Yogi Porla&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt; CTO of Deeplineage&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Kanvas Designer is available now in beta as a service or self-hosted solution. Kanvas Operator will be available early next year. Try dragging and dropping your Kubernetes manifest into &lt;a href=&quot;https://kanvas.new&quot;&gt;https://kanvas.new&lt;/a&gt; today.&lt;/p&gt;&lt;h4&gt;Resources&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Kanvas application: &lt;a href=&quot;https://kanvas.new&quot;&gt;https://kanvas.new&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Design Catalog: &lt;a href=&quot;https://cloud.layer5.io/catalog&quot;&gt;https://cloud.layer5.io/catalog&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Kanvas website: &lt;a href=&quot;/cloud-native-management/kanvas&quot;&gt;https://layer5.io/cloud-native-management/kanvas&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Kanvas documentation: &lt;a href=&quot;https://docs.layer5.io/kanvas/&quot;&gt;https://docs.layer5.io/kanvas/&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Attend &lt;a href=&quot;https://layer5.io/community/events/kubecon-cloudnativecon-na-salt-lake-city-utah-2024&quot;&gt;KubeCon NA 2024 Session: Visualizing Kubernetes Resource Relationships with Meshery&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h5&gt;About Layer5, Inc.&lt;/h5&gt;&lt;p style=&quot;font-size:1rem&quot;&gt;Our open source and commercial products empower organizations to embrace the power of cloud native with confidence. Layer5&amp;#x27;s mission is to simplify the adoption and operation of cloud native infrastructure, enabling organizations to innovate faster and engineers to do so collaboratively. Layer5’s award-winning open source community has over 10,000 members. For more information, visit &lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt;https://layer5.io&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;About Kanvas&lt;/h5&gt;&lt;p style=&quot;font-size:1rem&quot;&gt;Kanvas is a web-based collaboration tool that allows you to create, review, and operate highly-detailed  architecture diagrams of your cloud and cloud infrastructure using a drag-and-drop interface. Kanvas is popular with site reliability engineers, platform engineers, architects, operators, and developers as an enabler of productive, collaborative infrastructure management. Try Kanvas at &lt;a href=&quot;https://kanvas.new&quot;&gt;https://kanvas.new&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Meshery at KubeCon + CloudNativeCon NA 2024]]></title><description><![CDATA[Meshery sessions at KubeCon + CloudNativeCon NA 2024]]></description><link>https://layer5.io/blog/events/meshery-at-kubecon-cloudnativecon-na-2024</link><guid isPermaLink="false">https://layer5.io/blog/events/meshery-at-kubecon-cloudnativecon-na-2024</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Sun, 10 Nov 2024 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/4ee4ed80c9c20f5efdb8445ba92a90e3/kubeconna-2024.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;p&gt;Join Layer5 at KubeCon + CloudNativeCon NA, Salt Lake City, Utah!&lt;/p&gt;&lt;p&gt;Join the Meshery project at KubeCon NA 2024 from November 11th to November 16th, 2024 and get introduced to collaborative cloud native management and Meshery open source maintainers.&lt;/p&gt;&lt;h3&gt;Session: Meshery - Visualizing Kubernetes Resource Relationships with Meshery&lt;/h3&gt;&lt;p&gt;Meshery and its extensions empower you to navigate cloud native infrastructure in complex environments. This lighting talk delves into the human-computer interaction (HCI) principles that underpin MeshMap&amp;#x27;s intuitive visualization of Kubernetes resources and the various forms of inter/relationships with other CNCF projects&amp;#x27; resources.&lt;p&gt;Human-Computer Interaction Principles in Meshery:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Cognitive Load: How Meshery reduces cognitive load by presenting complex information in a structured and visually digestible manner.&lt;/li&gt;&lt;li&gt;Mental Models: How Meshery aligns with users&amp;#x27; mental models of Kubernetes environments, facilitating comprehension and navigation.&lt;/li&gt;&lt;li&gt;Visual Perception: How Meshery leverages visual cues, colors, and layout to guide users&amp;#x27; attention and highlight critical information.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;div class=&quot;flex-row&quot; style=&quot;margin-bottom:2rem&quot;&gt;&lt;p&gt;Date: November 12, 2024&lt;br/&gt;Time: 3:04pm - 3:09pm MST&lt;/p&gt;&lt;a href=&quot;https://sched.co/1iWA9&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 cJyyqk appion__btn&quot; title=&quot;See Details&quot;&gt; See Details&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;h3&gt;Session: CNCF TAG Network - Intro &amp;amp; Deep Dive&lt;/h3&gt;&lt;p&gt;“It’s the network!” is the cry of every engineer. With the increased prevalence of microservices and distributed systems, it’s true - networking as a discipline has never been more critical in the well-architected design and efficient operation of modern infrastructure. Join this talk for an intro to the TAG, its charter and a deeper discussion of current cloud native networking topics being advanced in this TAG.&lt;/p&gt;&lt;div class=&quot;flex-row&quot; style=&quot;margin-bottom:2rem&quot;&gt;&lt;p&gt;Date: November 14, 2024 &lt;br/&gt;Time: 11:55am - 12:30pm MST&lt;/p&gt;&lt;a href=&quot; https://sched.co/1howx&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 cJyyqk appion__btn&quot; title=&quot;See Details&quot;&gt; See Details&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;h3&gt;Session: Contribfest - Meshery Contribfest: Extending the Cloud Native Manager&lt;/h3&gt;&lt;p&gt;Join the Meshery maintainers and community in improving the leading cloud native management plane. This is your chance to get hands-on with the tools shaping the future of collaborative cloud native management. Opportunities: Work on core functionality in the Server (Golang) or UI (React) or extend Meshery by building your own plugin. Contribute to the Meshery documentation by incorporating your own examples of cloud native solution architectures using Meshery Designer.&lt;/p&gt;&lt;p&gt;Why Contribute to Meshery? - Gain experience with cloud native technologies, including essentially every CNCF project and open source development practices. As is the 10th fastest growing CNCF project, Meshery has a vibrant community. Work alongside passionate maintainers and contributors. No Prior Experience Needed: We welcome contributions from all levels of experience. Join us at Meshery Contribfest and be part of the growing community shaping the future of collaborative cloud native management.&lt;/p&gt;&lt;div class=&quot;flex-row&quot; style=&quot;margin-bottom:2rem&quot;&gt;&lt;p&gt;Date: November 14, 2024 &lt;br/&gt;Time: 4:30pm - 6:00pm MST&lt;/p&gt;&lt;a href=&quot;https://kccncna2024.sched.com/event/1hoxN/contribfest-meshery-contribfest-extending-the-cloud-native-manager&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 cJyyqk appion__btn&quot; title=&quot;See Details&quot;&gt; See Details&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What is the Kanvas Catalog?]]></title><description><![CDATA[A comprehensive guide to the Kanvas Catalog, a collection of curated, pre-built, and ready-to-use cloud and cloud native infrastructure configurations.]]></description><link>https://layer5.io/blog/kanvas/what-is-the-kanvas-catalog</link><guid isPermaLink="false">https://layer5.io/blog/kanvas/what-is-the-kanvas-catalog</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Tue, 05 Nov 2024 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/e8dae3ed176ff95fd81e69c814a30306/catalog2.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 dnWeIb&quot;&gt;&lt;h3&gt;What is the Kanvas Catalog?&lt;/h3&gt;&lt;a href=&quot;/cloud-native-management/catalog&quot;&gt;Kanvas Catalog&lt;/a&gt; is a hub for sharing and discovering best practices, reusable templates, and operational patterns for Kubernetes and cloud-native infrastructure. It&amp;#x27;s like a marketplace where you can find and contribute pre-built infrastructure configurations and operational views. The Catalog is a part of the Kanvas platform, which is a comprehensive suite of tools for managing cloud-native infrastructure.&lt;div class=&quot;note&quot;&gt; &lt;a href=&quot;https://cloud.layer5.io/catalog&quot;&gt;Explore the catalog&lt;/a&gt;&lt;/div&gt;&lt;h3&gt;What can you find in the Catalog?&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Design Patterns: Ready-made blueprints for common infrastructure and application architectures. These patterns can save you significant time and effort in designing your deployments.  &lt;/li&gt;&lt;li&gt;Filters and Applications: Pre-configured filters for Envoy proxies, WebAssembly filters, and complete application deployments.&lt;/li&gt;&lt;li&gt;Meshery Designs: Share and reuse your own Meshery configurations, making it easier to collaborate and standardize your deployments.  &lt;/li&gt;&lt;li&gt;Meshery Models: Share and reuse your own Meshery models, making it easier to collaborate and standardize your component library.&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Why is the Catalog useful?&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Accelerated Development: Leverage existing patterns to jumpstart your projects and avoid reinventing the wheel.&lt;/li&gt;&lt;li&gt;Community Knowledge: Benefit from the collective experience of the Layer5 community and industry best practices.  &lt;/li&gt;&lt;li&gt;Standardization: Promote consistency and reduce errors by using predefined configurations.&lt;/li&gt;&lt;li&gt;Collaboration: Share your own designs and contribute to the growing collection of patterns.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;How can you contribute to the Catalog?&lt;/h3&gt;&lt;p&gt;You can contribute to the Catalog by creating high-quality starter templates and publishing designs for the community to use in various ways. You can also climb the leaderboard by having your designs cloned, downloaded, or viewed the most. Follow the instructions below to get started with your designs.&lt;/p&gt;&lt;h4&gt;Create or Import a Design&lt;/h4&gt;&lt;p&gt;Begin by creating a new design from scratch, using existing design patterns and templates from catalog:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;From Scratch&lt;/strong&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Open the Designs panel, Select and arrange components from the Designer Dock on the Kanvas, and customize with connections, labels, and properties.&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/start-from-scratch-21b5915673335277d79cd425627e8fe5.gif&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;From a Template&lt;/strong&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Start from a pre-built template or clone an existing design from the Catalog. This allows you to build on established designs for a quicker start.&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/catalog-d6740356d3f91ec18d50c83e0d7af6d0.gif&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Import a Design&lt;/strong&gt;: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Access the Kanvas Designer and select the &amp;quot;Import&amp;quot; button in the left Designs panel. Import your own designs from local filesystem or from a remote URL directly into the Catalog. Upload a file or provide a URL for Docker Compose, Helm Charts, Meshery Designs or Kubernetes Manifests. Choose to either import as new or merge into current design that you have open in Kanvas.&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/import-design-gif-9a9fa6ea76258783aa31d776bd5f2557.gif&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Kanvas will convert these into a usable design based on their configurations.&lt;/p&gt;&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/rendered-design-8bd347156a7001a47e7d618b32357937.webp&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;h4&gt;Publish a Design&lt;/h4&gt;&lt;p&gt;Make your designs accessible to others by publishing them in the Catalog:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;In the designs panel, locate your design and hover over it to access quick actions. Select the info button (marked with an &amp;quot;i&amp;quot;) and add any necessary details for the review process, such as relevant technologies, descriptions, and considerations and click Publish button. Once approved by the Maintainers, your design becomes available to the broader community in Kanvas catalog.&lt;div style=&quot;width:100%;height:auto&quot;&gt;&lt;img src=&quot;/static/publish-to-catalog-ad82c7ecd418bd328187784f3605ad95.gif&quot; width=&quot;100%&quot; height=&quot;auto&quot; style=&quot;object-fit:contain;margin:20px 0px&quot; loading=&quot;lazy&quot; alt=&quot;Blog content image&quot;/&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Share your designs&lt;/h4&gt;&lt;p&gt;Share your designs with your team members and effortlessly collaborate on designing and operating multi-cloud and Kubernetes native infrastrcutre with a seamless, built-in review mechanism.&lt;/p&gt;&lt;/div&gt;</content:encoded></item></channel></rss>