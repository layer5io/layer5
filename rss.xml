<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Layer5 Technical Posts]]></title><description><![CDATA[Expect more from your infrastructure. Cloud native, open source software for your cloud native infrastructure and applications. Allowing developers to focus on business logic, not infrastructure concerns. Empowering operators to confidently run modern infrastructure.]]></description><link>https://layer5.io</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 18 Jul 2023 18:52:04 GMT</lastBuildDate><item><title><![CDATA[How To Bind Kubernetes Service Account with ClusterRole]]></title><link>https://layer5.io/blog/meshery/how-to-bind-kubernetes-service-account-with-clusterrole</link><guid isPermaLink="false">https://layer5.io/blog/meshery/how-to-bind-kubernetes-service-account-with-clusterrole</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Fri, 30 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/87c3e5e43ab121617b3f31b331d94df7/blog-post.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes provides robust RBAC (Role-Based Access Control) capabilities to manage access and authorization within a cluster. This allows you to control and restrict permissions for various resources. In this blog post, we will explore the process of binding a Kubernetes Service Account with a ClusterRole. We will also discuss how Meshery, a service mesh management tool, can be utilized to streamline the lifecycle management of Kubernetes clusters using MeshMap visual diagrams.&lt;/p&gt;&lt;h2&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;Before we delve into the details, ensure that you have the following prerequisites in place:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Access to a running Kubernetes cluster.&lt;/li&gt;&lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt;, the Kubernetes command-line tool, installed and configured to communicate with your cluster.&lt;/li&gt;&lt;li&gt;Meshery, the cloud native manager, installed and &lt;a href=&quot;https://docs.meshery.io/installation/quick-start&quot;&gt;set up&lt;/a&gt; on your local machine.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Binding a Kubernetes Service Account with ClusterRole:&lt;/h2&gt;&lt;p&gt;To bind a Service Account with a ClusterRole, follow the steps outlined below:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: Create a Service Account&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;First, we need to create a Service Account that we will later bind to a ClusterRole. Use the following kubectl command to create a Service Account named &lt;code&gt;my-service-account&lt;/code&gt;:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sh kubectl create serviceaccount my-service-account&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;&lt;strong&gt;Step 2: Create a ClusterRole&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Next, let&amp;#x27;s create a ClusterRole that defines the desired permissions. You can either create a new ClusterRole or use an existing one. For the purpose of this example, we will create a ClusterRole named &lt;code&gt;my-cluster-role&lt;/code&gt; that has read-only access to Pods and Services:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; ClusterRole&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;role&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;pods&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;services&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;get&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;list&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;Save the above YAML definition to a file named &lt;code&gt;clusterrole.yaml&lt;/code&gt;, and create the ClusterRole using the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl apply -f clusterrole.yaml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;&lt;strong&gt;Step 3: Bind the Service Account with ClusterRole&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Finally, we need to bind the Service Account &lt;code&gt;my-service-account&lt;/code&gt; with the ClusterRole &lt;code&gt;my-cluster-role&lt;/code&gt;. This can be achieved by creating a ClusterRoleBinding. Execute the following command to create the binding:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl create clusterrolebinding my-cluster-role-binding --clusterrole=my-cluster-role --serviceaccount=default:my-service-account&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;The above command creates a ClusterRoleBinding named &lt;code&gt;my-cluster-role-binding&lt;/code&gt; that associates the Service Account &lt;code&gt;my-service-account&lt;/code&gt; with the ClusterRole &lt;code&gt;my-cluster-role&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Verification:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To verify the successful binding, you can use the following command to check the ClusterRoleBinding:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl describe clusterrolebinding my-cluster-role-binding&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;You should see the Service Account and ClusterRole information listed under the &lt;code&gt;Subjects&lt;/code&gt; and &lt;code&gt;RoleRef&lt;/code&gt; sections, respectively.&lt;/p&gt;&lt;h2&gt;Using Meshery and MeshMap for Kubernetes Cluster Lifecycle Management:&lt;/h2&gt;&lt;p&gt;Meshery is a powerful service mesh management tool that simplifies the management and operation of service meshes, including &lt;a href=&quot;https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot; target=&quot;_blank&quot;&gt;Kubernetes clusters&lt;/a&gt;. MeshMap, a visual diagram feature of Meshery, provides a graphical representation of the service mesh components and their interactions.&lt;/p&gt;&lt;p&gt;To utilize Meshery and MeshMap for Kubernetes cluster lifecycle management, follow these steps:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: Install Meshery&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Refer to the official Meshery &lt;a href=&quot;https://docs.meshery.io/installation/quick-start&quot; target=&quot;_blank&quot;&gt;documentation&lt;/a&gt; to install Meshery on your local machine or within your Kubernetes cluster.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 2: Connect to Your Kubernetes Cluster&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once Meshery is installed, connect it to your Kubernetes cluster by configuring the necessary authentication and connection details.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 3: Access MeshMap&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;After successfully connecting Meshery to your Kubernetes cluster, you can access MeshMap from the &lt;a href=&quot;https://playground.meshery.io/&quot; target=&quot;_blank&quot;&gt;Meshery&lt;/a&gt; user interface. MeshMap visually represents the deployed service mesh, including service endpoints, traffic flows, and workload distribution.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 4: Visualize the Kubernetes Cluster with MeshMap&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once you have accessed Meshery and connected it to your Kubernetes cluster, follow these steps to visualize the cluster using MeshMap:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;From the Meshery user interface, navigate to the MeshMap section.&lt;/li&gt;&lt;li&gt;Select your connected Kubernetes cluster from the dropdown menu.&lt;/li&gt;&lt;li&gt;Click on the &amp;quot;Generate Map&amp;quot; button to generate a visual representation of the service mesh components and their interactions within the cluster.&lt;/li&gt;&lt;li&gt;Explore the generated MeshMap to gain insights into your Kubernetes cluster&amp;#x27;s architecture, traffic patterns, and workload distribution.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this blog post, we have learned how to bind a Kubernetes Service Account with a ClusterRole to control access and authorization within a cluster. We have also explored how Meshery and its MeshMap feature can be used for visualizing the service mesh components and their interactions within a Kubernetes cluster. By following these steps, you can effectively manage and monitor your Kubernetes cluster&amp;#x27;s lifecycle using RBAC and visualization tools.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[HPE's adoption of Meshery and Meshmap]]></title><description><![CDATA[HPE uses Meshery to manage SPIRE instances]]></description><link>https://layer5.io/resources/case-study/hpes-adoption-of-meshery-and-meshmap</link><guid isPermaLink="false">https://layer5.io/resources/case-study/hpes-adoption-of-meshery-and-meshmap</guid><dc:creator><![CDATA[HPE]]></dc:creator><pubDate>Sat, 17 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/91d038ef73208e4f202eecb42cb08c1f/meshery-and-hpe.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;div class=&quot;hpestyle__HPEintro-sc-1wo7snj-1 fECvio&quot;&gt;HPE&amp;#x27;s adoption of Meshery was driven by the need to simplify Kubernetes cluster management and monitoring. Meshery is an open source cloud native management tool that provides a self-service platform for designing, visualizing, deploying, testing, and operating cloud native infrastructure.&lt;/div&gt;&lt;p&gt;HPE, a leading technology company specializing in enterprise infrastructure, adopted Meshery Extension to enhance their Kubernetes deployments. HPE uses Kubernetes as a primary platform to build and deploy their containerized applications. The company has a large and complex Kubernetes environment, which requires robust networking solutions for efficient communication between services.&lt;/p&gt;&lt;table class=&quot;hpestyle__HPEfacts-sc-1wo7snj-0 iWwfEW&quot;&gt;&lt;tr&gt;&lt;td colSpan=&quot;2&quot;&gt;&lt;h4&gt;HPE FAST FACTS&lt;/h4&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik05IDNDNi4yMzg1OCAzIDQgNS4yMzg1OCA0IDhDNCAxMC43NjE0IDYuMjM4NTggMTMgOSAxM0MxMS43NjE0IDEzIDE0IDEwLjc2MTQgMTQgOEMxNCA1LjIzODU4IDExLjc2MTQgMyA5IDNaTTUuNSA4QzUuNSA2LjA2NyA3LjA2NyA0LjUgOSA0LjVDMTAuOTMzIDQuNSAxMi41IDYuMDY3IDEyLjUgOEMxMi41IDkuOTMzIDEwLjkzMyAxMS41IDkgMTEuNUM3LjA2NyAxMS41IDUuNSA5LjkzMyA1LjUgOFoiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTQuNzUgMTQuNUMyLjEyNjY1IDE0LjUgMCAxNi42MjY2IDAgMTkuMjVWMjAuMjVDMCAyMC42NjQyIDAuMzM1Nzg2IDIxIDAuNzUgMjFDMS4xNjQyMSAyMSAxLjUgMjAuNjY0MiAxLjUgMjAuMjVWMTkuMjVDMS41IDE3LjQ1NTEgMi45NTUwNyAxNiA0Ljc1IDE2SDEzLjI1QzE1LjA0NDkgMTYgMTYuNSAxNy40NTUxIDE2LjUgMTkuMjVWMjAuMjVDMTYuNSAyMC42NjQyIDE2LjgzNTggMjEgMTcuMjUgMjFDMTcuNjY0MiAyMSAxOCAyMC42NjQyIDE4IDIwLjI1VjE5LjI1QzE4IDE2LjYyNjYgMTUuODczNCAxNC41IDEzLjI1IDE0LjVINC43NVoiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTE4LjI1IDE1LjI1QzE4LjI1IDE0LjgzNTggMTguNTg1OCAxNC41IDE5IDE0LjVIMTkuMjVDMjEuODczNCAxNC41IDI0IDE2LjYyNjYgMjQgMTkuMjVWMjAuMjVDMjQgMjAuNjY0MiAyMy42NjQyIDIxIDIzLjI1IDIxQzIyLjgzNTggMjEgMjIuNSAyMC42NjQyIDIyLjUgMjAuMjVWMTkuMjVDMjIuNSAxNy40NTUxIDIxLjA0NDkgMTYgMTkuMjUgMTZIMTlDMTguNTg1OCAxNiAxOC4yNSAxNS42NjQyIDE4LjI1IDE1LjI1WiIgZmlsbD0iIzcyNzI3NCIvPgo8cGF0aCBkPSJNMTUgM0MxNC41ODU4IDMgMTQuMjUgMy4zMzU3OSAxNC4yNSAzLjc1QzE0LjI1IDQuMTY0MjEgMTQuNTg1OCA0LjUgMTUgNC41QzE2LjkzMyA0LjUgMTguNSA2LjA2NyAxOC41IDhDMTguNSA5LjkzMyAxNi45MzMgMTEuNSAxNSAxMS41QzE0LjU4NTggMTEuNSAxNC4yNSAxMS44MzU4IDE0LjI1IDEyLjI1QzE0LjI1IDEyLjY2NDIgMTQuNTg1OCAxMyAxNSAxM0MxNy43NjE0IDEzIDIwIDEwLjc2MTQgMjAgOEMyMCA1LjIzODU4IDE3Ljc2MTQgMyAxNSAzWiIgZmlsbD0iIzcyNzI3NCIvPgo8L3N2Zz4K&quot;/&gt;Full Time Employees: 60,000+&lt;/td&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMiAxQzUuOTI0ODcgMSAxIDUuOTI0ODcgMSAxMkMxIDE4LjA3NTEgNS45MjQ4NyAyMyAxMiAyM0MxOC4wNzUxIDIzIDIzIDE4LjA3NTEgMjMgMTJDMjMgNS45MjQ4NyAxOC4wNzUxIDEgMTIgMVpNMTAuMzI2OCAyLjY0Njg4QzYuMTk5MzcgMy4zODAyOSAyLjk5MzU5IDYuNzc4ODYgMi41NTIgMTFINy4yOTkwNUM3LjUzNzkzIDcuOTc5NjcgOC41ODc4OSA1LjA4OTEgMTAuMzI2OCAyLjY0Njg4Wk0xMy42NzMyIDIuNjQ2ODhDMTUuNDEyMSA1LjA4OTEgMTYuNDYyMSA3Ljk3OTY3IDE2LjcwMDkgMTFIMjEuNDQ4QzIxLjAwNjQgNi43Nzg4NiAxNy44MDA2IDMuMzgwMjkgMTMuNjczMiAyLjY0Njg4Wk0xNS4xOTU4IDExQzE0LjkzODUgOC4wMzg3NyAxMy44MjUzIDUuMjIzMzEgMTIgMi45MTU3MkMxMC4xNzQ3IDUuMjIzMzEgOS4wNjE0OCA4LjAzODc3IDguODA0MiAxMUgxNS4xOTU4Wk04Ljc2ODk5IDEyLjVIMTUuMjMxQzE1LjA2MTMgMTUuNjQzNSAxMy45Mjc3IDE4LjY0NzIgMTIgMjEuMDg0M0MxMC4wNzIzIDE4LjY0NzIgOC45Mzg3NCAxNS42NDM1IDguNzY4OTkgMTIuNVpNNy4yNjcgMTIuNUgyLjUxMjkzQzIuNzQzNzEgMTYuOTUwNiA2LjAzNzYgMjAuNTkxIDEwLjMyNjggMjEuMzUzMUM4LjQ5MjE1IDE4Ljc3NjQgNy40MjQ0IDE1LjcwMDcgNy4yNjcgMTIuNVpNMTMuNjczMiAyMS4zNTMxQzE1LjUwNzggMTguNzc2NCAxNi41NzU2IDE1LjcwMDcgMTYuNzMzIDEyLjVIMjEuNDg3MUMyMS4yNTYzIDE2Ljk1MDYgMTcuOTYyNCAyMC41OTEgMTMuNjczMiAyMS4zNTMxWiIgZmlsbD0iIzcyNzI3NCIvPgo8L3N2Zz4K&quot;/&gt;Market Presence: HPE is one of the largest technology companies globally, serving customers in over 150 countries.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMS42NTgxIDEuMDgyNDdDMTEuODcyOCAwLjk3MjUxMSAxMi4xMjcyIDAuOTcyNTExIDEyLjM0MTkgMS4wODI0N0wyMi41OTE5IDYuMzMyNDdDMjIuODQyNCA2LjQ2MDc4IDIzIDYuNzE4NTQgMjMgN0MyMyA3LjI4MTQ2IDIyLjg0MjQgNy41MzkyMiAyMi41OTE5IDcuNjY3NTNMMTIuMzQxOSAxMi45MTc1QzEyLjEyNzIgMTMuMDI3NSAxMS44NzI4IDEzLjAyNzUgMTEuNjU4MSAxMi45MTc1TDEuNDA4MDkgNy42Njc1M0MxLjE1NzU4IDcuNTM5MjIgMSA3LjI4MTQ2IDEgN0MxIDYuNzE4NTQgMS4xNTc1OCA2LjQ2MDc4IDEuNDA4MDkgNi4zMzI0N0wxMS42NTgxIDEuMDgyNDdaTTMuMzk1MTggN0wxMiAxMS40MDczTDIwLjYwNDggN0wxMiAyLjU5MjY2TDMuMzk1MTggN1oiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTEuMDg5MDMgMTYuMzk1M0MxLjI4NDg4IDE2LjAzMDMgMS43Mzk1MyAxNS44OTMyIDIuMTA0NTIgMTYuMDg5TDExLjk5OTkgMjEuMzk4OEwyMS44OTUzIDE2LjA4OUMyMi4yNjAzIDE1Ljg5MzIgMjIuNzE0OSAxNi4wMzAzIDIyLjkxMDggMTYuMzk1M0MyMy4xMDY2IDE2Ljc2MDMgMjIuOTY5NSAxNy4yMTQ5IDIyLjYwNDUgMTcuNDEwOEwxMi4zNTQ1IDIyLjkxMDhDMTIuMTMzIDIzLjAyOTYgMTEuODY2OCAyMy4wMjk2IDExLjY0NTMgMjIuOTEwOEwxLjM5NTI5IDE3LjQxMDhDMS4wMzAzIDE3LjIxNDkgMC44OTMxODUgMTYuNzYwMyAxLjA4OTAzIDE2LjM5NTNaIiBmaWxsPSIjNzI3Mjc0Ii8+CjxwYXRoIGQ9Ik0yLjEwNDUyIDExLjA4OUMxLjczOTUzIDEwLjg5MzIgMS4yODQ4OCAxMS4wMzAzIDEuMDg5MDMgMTEuMzk1M0MwLjg5MzE4NSAxMS43NjAzIDEuMDMwMyAxMi4yMTQ5IDEuMzk1MjkgMTIuNDEwOEwxMS42NDUzIDE3LjkxMDhDMTEuODY2OCAxOC4wMjk2IDEyLjEzMyAxOC4wMjk2IDEyLjM1NDUgMTcuOTEwOEwyMi42MDQ1IDEyLjQxMDhDMjIuOTY5NSAxMi4yMTQ5IDIzLjEwNjYgMTEuNzYwMyAyMi45MTA4IDExLjM5NTNDMjIuNzE0OSAxMS4wMzAzIDIyLjI2MDMgMTAuODkzMiAyMS44OTUzIDExLjA4OUwxMS45OTk5IDE2LjM5ODhMMi4xMDQ1MiAxMS4wODlaIiBmaWxsPSIjNzI3Mjc0Ii8+Cjwvc3ZnPgo=&quot;/&gt;HPE GreenLake: HPE GreenLake is a key offering by the company, providing a flexible and scalable IT infrastructure model known as &amp;quot;everything-as-a-service.&amp;quot;&lt;/td&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,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&quot;/&gt;Research and Development: HPE invests significantly in research and development to drive innovation. It operates HPE Labs, which focuses on developing cutting-edge technologies and solutions for the future.&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;SPIRE is a toolchain of APIs for establishing trust between software systems across a wide variety of hosting platforms. SPIRE exposes the SPIFFE Workload API, which can attest running software systems and issue SPIFFE IDs and SVIDs to them. &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;div class=&quot;hpestyle__HPEbenefits-sc-1wo7snj-2 bWNoXP&quot;&gt;&lt;b&gt;Meshery offers several benefits to HPE, including:&lt;/b&gt;&lt;br/&gt;✔️ Consistent service mesh management: HPE can now manage all their service meshes consistently, regardless of the underlying infrastructure or cloud provider.&lt;br/&gt;✔️ Improved observability: With Meshery&amp;#x27;s built-in visualization and observability tools, HPE can gain insights into the behavior of their service meshes, detect anomalies, and troubleshoot issues in real-time.&lt;br/&gt;✔️ Simplified testing and validation: Meshery&amp;#x27;s service mesh validation capabilities enable HPE to easily test and validate their service meshes, ensuring that they meet their performance, security, and compliance requirements.&lt;br/&gt;✔️ Enhanced security: With Meshery&amp;#x27;s security features, HPE can ensure that their service meshes are secure and compliant with their organization&amp;#x27;s security policies.&lt;/div&gt;&lt;br/&gt;&lt;p&gt;Overall, Meshery has helped HPE to streamline their integration of the identity management control plane to reduce complexity, and improve the overall reliability and performance of their Kubernetes environment. SPIFFE is a set of open-source specifications for a framework capable of bootstrapping and issuing identity to services across heterogeneous environments and organizational boundaries. The lifecycle of SPIFFE identities, SVIDs, is managed by SPIRE, a production-ready implementation of the SPIFFE APIs that performs node and workload attestation in order to securely issue SVIDs to workloads, and verify the SVIDs of other workloads, based on a predefined set of conditions.&lt;/p&gt;&lt;p&gt;&lt;b&gt;HPE&amp;#x27;s adoption of Meshery has also been enhanced by the platform&amp;#x27;s ability to integrate with other popular technologies, such as SPIRE and Istio&lt;/b&gt;&lt;/p&gt;&lt;p style=&quot;display:flex;justify-content:center;align-item:center;padding:2%&quot;&gt;&lt;img src=&quot;/static/meshery-integrations.e82003a0.svg&quot;/&gt;&lt;/p&gt;&lt;p&gt;SPIRE is an open-source project that provides a secure and scalable solution for service identity and authentication in distributed systems. HPE uses SPIRE to authenticate and authorize services in their Kubernetes environment, which ensures that only authorized services can communicate with each other.&lt;/p&gt;&lt;p&gt;Meshery&amp;#x27;s integration with SPIRE enables HPE to manage SPIRE instances, issue and revoke service certificates, and automate the management of SPIRE agents across their Kubernetes clusters. This integration ensures that HPE&amp;#x27;s service meshes are secure, and only authorized services can communicate with each other.&lt;/p&gt;&lt;div class=&quot;Inline-quotes__QuotesWrapper-sc-hv31e3-0 hRtmBs&quot;&gt;&lt;div class=&quot;quote-box&quot;&gt;&lt;h4&gt;❝ With a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Meshery&amp;#x27;s Extension to deploy their cloud native infrastructure of choice and test the performance of our SPIFFE and SPIRE-based identity solution. ❞&lt;/h4&gt;&lt;hr/&gt;&lt;img src=&quot;data:image/webp;base64,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&quot;/&gt;&lt;div class=&quot;quote-source&quot;&gt;&lt;h5&gt;Maximiliano Churichi&lt;/h5&gt;&lt;p&gt;Software Engineer at HPE&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In addition, HPE&amp;#x27;s use of Meshery has been enhanced by its integration with Istio, an open-source service mesh that provides a comprehensive solution for traffic management, security, and observability in Kubernetes environments.&lt;/p&gt;&lt;p&gt;Meshery&amp;#x27;s integration with Istio enables HPE to manage Istio service meshes and configurations, automate the deployment of Istio components, and monitor and visualize Istio metrics and traces. This integration enables HPE to simplify the management of their Istio service meshes, ensure their security and compliance, and gain insights into their behavior for better decision-making.&lt;/p&gt;&lt;p&gt;Overall, HPE&amp;#x27;s adoption of Meshery, along with its integration with SPIRE and Istio, has enabled the company to streamline their service mesh management, ensure the security and compliance of their Kubernetes environment, and gain valuable insights into the behavior of their service meshes for improved performance and reliability.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Meshery also implements the Service Mesh Performance (SMP) specification&lt;/b&gt;&lt;/p&gt;&lt;p&gt;SMP is a community-driven effort that provides a standard for measuring and comparing the performance of different service meshes. It is designed to help users select the best service mesh for their needs by providing a common framework for benchmarking.&lt;/p&gt;&lt;div class=&quot;Inline-quotes__QuotesWrapper-sc-hv31e3-0 hRtmBs&quot;&gt;&lt;div class=&quot;quote-box&quot;&gt;&lt;h4&gt;❝ The Layer5 team has been amazing. Our project wouldn’t have been successful with out Meshery. ❞&lt;/h4&gt;&lt;hr/&gt;&lt;img src=&quot;/static/yogi-d00ca1cc48ab74938a23d4359ef3fb01.webp&quot;/&gt;&lt;div class=&quot;quote-source&quot;&gt;&lt;h5&gt;Yogi Porla&lt;/h5&gt;&lt;p&gt;Engineering Manager, HPE&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Meshery implements SMP by providing a simple and easy-to-use interface for running performance tests against different service meshes. Users can select the service mesh they want to test, configure the test parameters (such as the number of requests per second and the number of concurrent clients), and run the test. Meshery will then generate a report that shows the performance metrics for each service mesh, such as latency, throughput, and error rates.&lt;/p&gt;&lt;p&gt;By implementing SMP, Meshery provides a valuable tool for developers and operators who are evaluating different service meshes. Instead of having to create their own benchmarks, they can use SMP to get an objective and standardized view of each service mesh&amp;#x27;s performance characteristics. This can save a significant amount of time and effort, and help users make more informed decisions when choosing a service mesh.&lt;/p&gt;&lt;p&gt;Overall, HPE&amp;#x27;s use of Meshery and the Docker Extension for Meshery demonstrates the power of cloud native technologies and the importance of open source collaboration. By leveraging these tools, HPE has been able to streamline its development and deployment processes, improve performance and security, and stay at the forefront of the cloud native movement.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Changing Meshery Release Channels]]></title><description><![CDATA[Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.]]></description><link>https://layer5.io/blog/meshery/changing-meshery-release-channels</link><guid isPermaLink="false">https://layer5.io/blog/meshery/changing-meshery-release-channels</guid><dc:creator><![CDATA[Karan Thakur]]></dc:creator><pubDate>Fri, 16 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.&lt;/p&gt;&lt;p&gt;Artifacts of the builds for Meshery and its components are published under two different release channels, so that improved controls may be provided to both  Meshery users and Meshery developers. The two release channels are edge and stable release channels. Relative to stable releases, edge releases occur much more frequently. Edge releases are made with each merge to master, unless that merge to master is for a stable release. Stable releases are made with each merge to master when a GitHub release tag is also present in the workflow.&lt;/p&gt;&lt;h2&gt; How release channels offer subscription &lt;/h2&gt;&lt;p&gt;Release Channels offers a subsciption where user can subscribe to a specific  release channel and get notified when a new release is available. This is  useful for users who want to stay up to date with the latest Meshery features, while also also providing flexibility for users who want to stay on a specific version of Meshery. However, this approach can be risky because some updates may introduce bugs or compatibility issues that could break your existing installation. Depending upon your risk aversion and the nature of your deployment environment, having a subscription means that you will automatically receive these updates that you might not be ready incorporate. On the other hand, release channels also offer the ability to pin to a specific release which is a  good thing as it allows users to maintain stability and predictability of their environment by preventing unexpected changes from being introduced into their system. However, doing so cancels out any future subscription-based benefits such as receiving security patches or bug fixes that were added after that version was released.&lt;p&gt;Therefore, it&amp;#x27;s important for you to weigh the pros and cons of each option before making decisions on how you want to manage your Meshery deployment. It&amp;#x27;s recommended you and your organizations have a well-defined upgrade strategy based on testing and validation procedures prior to applying new releases in production environments whether via subscriptions or manual upgrades to ensure that system availability is maintained and risks are minimized.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;To subscribe to a specific release channel or version using mesheryctl you can use&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel &lt;/span&gt;&lt;span class=&quot;token builtin class-name&quot; style=&quot;color:rgb(255, 203, 139)&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;stable&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;stable-version&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;edge-version&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;This command will update your local Meshery configuration to use the selected channel for future updates. To set the channel to a specific version, replace Version with the desired version number. Example: &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system channel set stable&lt;/code&gt; or &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system channel set stable-v0.5.56&lt;/code&gt;&lt;/p&gt;&lt;h2&gt; Switching between Release Channels&lt;/h2&gt;&lt;p&gt;There are two ways to switch between Meshery release channels: using mesheryctl or by editing your meshconfig file. In this blog post, we&amp;#x27;ll cover both methods.&lt;/p&gt;&lt;h3&gt;What is Meshconfig?&lt;/h3&gt;&lt;p&gt;Meshconfig is a configuration file that is used to configure Meshery. It is typically located in the &lt;code&gt;~/.meshery/config.yaml&lt;/code&gt; directory. It contains information about the current release channel, the version of Meshery that is installed, and other configuration options that are specific to your Meshery installation. Meshconfig is automatically generated when you run Meshery for the first time. It is also automatically updated when you update Meshery&lt;/p&gt;&lt;ol&gt;&lt;h3&gt;Switching between Meshery release channels using meshconfig file.&lt;/h3&gt;&lt;p&gt;Open your terminal and confirm that you have mesheryctl installed by running  &lt;code&gt;mesheryctl version&lt;/code&gt;. If you don&amp;#x27;t have mesheryctl installed, you can install it by following the instructions in the  &lt;a href=&quot;https://docs.meshery.io/installation/mesheryctl&quot;&gt;Meshery documentation&lt;/a&gt;.&lt;/p&gt;&lt;li&gt;Create new Meshery config.yaml file &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-language=bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context create [context-name]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;Example: &lt;br/&gt; &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system context create new-context --components meshery-istio meshery-osm meshery-linkerd --platform docker --url http://localhost:9081 --set --yes &lt;/code&gt;&lt;li&gt; To view the newly created meshery context use &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context view &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;context-name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;After making these changes, you can switch between different context by using &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context switch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Switching between Meshery release channels using mesheryctl.&lt;/h3&gt;&lt;p&gt;mesheryctl is a command-line tool for managing Meshery. You can use it to switch between different release channels. Here&amp;#x27;s how:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Run the following command to see the current configuration for Meshery:&lt;/li&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context view&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;img src=&quot;/static/meshery-version-5dbe26bc558062b5cc58ff22a8e88b49.png&quot; class=&quot;image-center&quot; style=&quot;width:50%&quot;/&gt;&lt;p&gt;This will show you the currently channels ,&lt;b&gt;stable&lt;/b&gt; or &lt;b&gt;edge&lt;/b&gt;, along with the version number and other information.&lt;/p&gt;&lt;li&gt;Run the following command to switch to a different release channel:&lt;/li&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel switch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;This command will update your meshconfig file to switch release channel and version of context in focus. To switch the channel to a specific version, replace &lt;b&gt;Version&lt;/b&gt; with the desired version number.&lt;li&gt; To confirm that the channel has been changed, run the following command again: &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel view&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Conclusion &lt;/h2&gt;&lt;p&gt;Switching between Meshery release channels is a simple and straightforward process. You can do it using mesheryctl or by switching between your meshconfig file. Whether you want stable updates or bleeding-edge features, Meshery has a release channel that suits your needs. Just remember to carefully consider your use case and needs before making any changes to ensure that you have the best Meshery experience.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Configuring Highly Available Docker Swarm]]></title><link>https://layer5.io/resources/docker/configuring-highly-available-docker-swarm</link><guid isPermaLink="false">https://layer5.io/resources/docker/configuring-highly-available-docker-swarm</guid><pubDate>Thu, 18 May 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;Docker Swarm is a &lt;a href=&quot;/articles/kubernetes/management-of-kubernetes&quot;&gt;container orchestration&lt;/a&gt; tool that makes it easy to manage and scale your existing Docker infrastructure. It consists of a pool of Docker hosts that run in Swarm mode with some nodes acting as managers, workers, or both. Using Docker Swarm mode to manage your Docker containers brings the following benefits:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It allows you to incrementally apply updates with zero downtime.&lt;/li&gt;&lt;li&gt;It increases application resilience to outages by reconciling any differences between the actual state and your expressed desired state.&lt;/li&gt;&lt;li&gt;It eases the process of scaling your applications since you only need to define the desired number of replicas in the cluster.&lt;/li&gt;&lt;li&gt;It is built into the &lt;code&gt;docker&lt;/code&gt; CLI, so you don&amp;#x27;t need additional software to get up and running.&lt;/li&gt;&lt;li&gt;It enables multi-host networking such that containers deployed on different nodes can communicate with each other easily.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this tutorial, you will learn key concepts in Docker Swarm and set up a highly available Swarm cluster that is resilient to failures. You will also learn some best practices and recommendations to ensure that your Swarm setup is fault tolerant.&lt;/p&gt;&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;Before proceeding with this tutorial, ensure that you have access to five Ubuntu 22.04 servers. This is necessary to demonstrate a highly available set up, although it is also possible to run Docker Swarm on a single machine. You also need to configure each server with a user that has administrative privileges.&lt;/p&gt;&lt;p&gt;The following ports must also be available on each server for communication purposes between the nodes. On Ubuntu 22.04, they are open by default:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TCP port 2377 for cluster management communications,&lt;/li&gt;&lt;li&gt;TCP and UDP port 7946 for communication among nodes,&lt;/li&gt;&lt;li&gt;TCP and UDP port 4789 for overlay network traffic.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;explaining-docker-swarm-terminology&quot;&gt;Explaining Docker Swarm terminology&lt;/h2&gt;&lt;p&gt;Before proceeding with this tutorial, let&amp;#x27;s examine some terms and definitions in Docker Swarm so that you have enough understanding of what each one means when they are used in this article and in other Docker Swarm resources.&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Node&lt;/strong&gt;: refers to an instance of the Docker engine in the Swarm cluster.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Manager nodes&lt;/strong&gt;: they are tasked with handling orchestration and cluster management functions, and dispatching incoming tasks to worker nodes. They can also act as worker nodes unless placed in Drain mode (recommended).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Leader&lt;/strong&gt;: this is a specific manager node that is elected to perform orchestration tasks and management/maintenance operations by all the manager nodes in the cluster using the &lt;a rel=&quot;&quot; target=&quot;_blank&quot; class=&quot;whitespace-nowrap&quot; href=&quot;https://raft.github.io/&quot;&gt;Raft Consensus Algorithm&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Worker nodes&lt;/strong&gt;: are Docker instances whose sole purpose is to receive and execute Swarm tasks from manager nodes.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Swarm task&lt;/strong&gt;: refers to a Docker container and the commands that run inside the container. Once a task is assigned to a node, it can run or fail but it cannot be transferred to a different node.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Swarm service&lt;/strong&gt;: this is the mechanism for defining tasks that should be executed on a node. It involves specifying the container image and commands that should run inside the container.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Drain&lt;/strong&gt;: means that new tasks are no longer assigned to a node, and existing tasks are reassigned to other available nodes.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;docker-swarm-requirements-for-high-availability&quot;&gt;Docker Swarm requirements for high availability&lt;/h2&gt;&lt;p&gt;A highly available Docker Swarm setup ensures that if a node fails, services on the failed node are re-provisioned and assigned to other available nodes in the cluster. A Docker Swarm setup that consists of one or two manager nodes is not considered highly available because any incident will cause operations on the cluster to be interrupted. Therefore the minimum number of manager nodes in a highly available Swarm cluster should be three.&lt;/p&gt;&lt;p&gt;The table below shows the number of failures a Swarm cluster can tolerate depending on the number of manager nodes in the cluster:&lt;/p&gt;&lt;div&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Manager Nodes&lt;/th&gt;&lt;th&gt;Failures tolerated&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;As you can see, having an even number of manager nodes does not help with failure tolerance, so you should always maintain an odd number of manager nodes. Fault tolerance improves as you add more manager nodes, but Docker recommends no more than seven managers so that performance is not negatively impacted since each node must acknowledge proposals to update the state of the cluster.&lt;/p&gt;&lt;p&gt;You should also distribute your manager nodes in separate locations so they are not affected by the same outage. If they run on the same server, a hardware problem could cause them all to go down. The high availability Swarm cluster that you will be set up in this tutorial will therefore exhibit the following characteristics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;5 total nodes (2 workers and 3 managers) with each one running on a separate server.&lt;/li&gt;&lt;li&gt;2 worker nodes (&lt;code&gt;worker-1&lt;/code&gt; and &lt;code&gt;worker-2&lt;/code&gt;).&lt;/li&gt;&lt;li&gt;3 manager nodes (&lt;code&gt;manager-1&lt;/code&gt;, &lt;code&gt;manager-2&lt;/code&gt;, and &lt;code&gt;manager-3&lt;/code&gt;).&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;docker-extension-CTA__DockerExtensionCTAWrapper-sc-1ahss27-0 jfeaRg&quot;&gt;&lt;div class=&quot;Container__ContainerWrapper-sc-1i64mot-0 fjHmlh&quot;&gt;&lt;div class=&quot;docker-callout&quot;&gt;&lt;img src=&quot;/static/Docker_animated.d3f14ac8.svg&quot; alt=&quot;Docker and Meshery&quot; loading=&quot;lazy&quot;/&gt;&lt;div class=&quot;card-right&quot;&gt;&lt;div&gt;&lt;h2&gt;Docker Extension for Meshery&lt;br/&gt; is now available!&lt;/h2&gt;&lt;/div&gt;&lt;p&gt;Managing cloud native infrastructure has never been easier.&lt;/p&gt;&lt;a href=&quot;/docker-extension-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot;&gt;Use the Meshery Docker Extension &lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2 id=&quot;step-1-installing-docker&quot;&gt;Step 1 — Installing Docker&lt;/h2&gt;&lt;p&gt;In this step, you will install Docker on all five Ubuntu servers. Therefore, execute all the commands below (and in step 2) on all five servers. If your host offers a snapshot feature, you may be able to run the commands on a single server and use that server as a base for the other four instances.&lt;/p&gt;&lt;p&gt;Let&amp;#x27;s start by installing the latest version of the Docker Engine (20.10.18 at the time of writing). Go ahead and update the package information list from all configured sources on your system:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt update&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Afterward, install the following packages to allow &lt;code&gt;apt&lt;/code&gt; to use packages over HTTPS:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt install apt-transport-https ca-certificates curl software-properties-common&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, add the GPG key for the official Docker repository to the server:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Once the GPG key is added, include the official Docker repository in the server&amp;#x27;s apt sources list:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;echo &amp;quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Finally, update apt once again and install the Docker Engine:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt update&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt install docker-ce&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Once the relevant packages are installed, you can check the status of the &lt;code&gt;docker&lt;/code&gt; service using the command below:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo systemctl status docker&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If everything goes well, you should observe that the container engine is active and running on your server.&lt;/p&gt;&lt;h2 id=&quot;step-2-executing-the-docker-command-without-sudo&quot;&gt;Step 2 — Executing the Docker command without sudo&lt;/h2&gt;&lt;p&gt;By default, the &lt;code&gt;docker&lt;/code&gt; command can only be executed by the root user or any user in the &lt;code&gt;docker&lt;/code&gt; group (auto created on installation). If you execute a &lt;code&gt;docker&lt;/code&gt; command without prefixing it with &lt;code&gt;sudo&lt;/code&gt; or running it through a user that belongs to the &lt;code&gt;docker&lt;/code&gt; group, you will get a permission error that looks like this:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get &amp;quot;http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json&amp;quot;: dial unix /var/run/docker.sock: connect: permission denied&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;As mentioned earlier, using &lt;code&gt;sudo&lt;/code&gt; with &lt;code&gt;docker&lt;/code&gt; is a security risk, so the solution to the above error is to add the relevant user to the &lt;code&gt;docker&lt;/code&gt; group. This can be achieved through the command below:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo usermod -aG docker $USER&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, run the following command and enter the user&amp;#x27;s password when prompted for the changes to take effect:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;su - $USER&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should now be able to run &lt;code&gt;docker&lt;/code&gt; commands without prefixing them with &lt;code&gt;sudo&lt;/code&gt;. For example, when you run the command &lt;code&gt;docker ps&lt;/code&gt;, you should observe the output.&lt;/p&gt;&lt;p&gt;Before proceeding to the next step, ensure that all the commands in step 1 and step 2 have been executed on all five servers.&lt;/p&gt;&lt;h2&gt;Step 3 — Initializing the Swarm Cluster&lt;/h2&gt;&lt;p&gt;At this point, each of your five Docker instances are acting as separate hosts and not as part of a Swarm cluster. Therefore, in this step, we will initialize the Swarm cluster on the &lt;code&gt;manager-1&lt;/code&gt; server and add the hosts to the cluster accordingly.&lt;/p&gt;&lt;p&gt;Start by logging into one of the Ubuntu servers (&lt;code&gt;manager-1&lt;/code&gt;) and retrieve the private IP address of the machine using the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;hostname -I | awk &amp;#x27;{print $1}&amp;#x27;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Copy the IP address to your clipboard and replace the &lt;code&gt;&amp;lt;manager_1_server_ip&amp;gt;&lt;/code&gt; placeholder in the command below to initialize Swarm mode:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker swarm init --advertise-addr &amp;lt;manager_1_server_ip&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the command is successful, you will see output indicating that the Swarm has been initialized and that the current node is now a manager. It will also provide a command to join worker nodes to the cluster. Copy the command for later use.&lt;/p&gt;&lt;p&gt;Next, SSH into each of the other four Ubuntu servers (manager-2, manager-3, worker-1, and worker-2) and run the command you copied earlier to join them to the Swarm cluster. The command should look like this:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker swarm join --token &amp;lt;token&amp;gt; &amp;lt;manager_1_server_ip&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;After running the command on each server, you should see output indicating that the node has joined the Swarm as either a manager or a worker. To verify the status of the Swarm cluster, you can run the command &lt;code&gt;docker node ls&lt;/code&gt; on the manager node:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker node ls&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should see a list of all the nodes in the Swarm cluster, including their IDs, hostname, status, availability, and whether they are a manager or a worker.&lt;/p&gt;&lt;h2&gt;Step 4 — Deploying the Application Stack&lt;/h2&gt;&lt;p&gt;Now that you have a functioning Docker Swarm cluster, you can deploy your application stack. In this tutorial, we will use a simple example of a web application stack consisting of a front-end service and a back-end service.&lt;/p&gt;&lt;p&gt;Start by creating a new directory for your application stack on the manager node:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mkdir app-stack cd app-stack&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, create a file called &lt;code&gt;docker-compose.yml&lt;/code&gt; in the &lt;code&gt;app-stack&lt;/code&gt; directory and open it in a text editor:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;nano docker-compose.yml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Copy and paste the following YAML code into the &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;version: &amp;#x27;3.8&amp;#x27; services: frontend: image: nginx:latest ports: - 80:80 deploy: replicas: 2 restart_policy: condition: on-failure backend: image: httpd:latest ports: - 8080:80 deploy: replicas: 2 restart_policy: condition: on-failure&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;This Docker Compose file defines two services: &lt;code&gt;frontend&lt;/code&gt; and &lt;code&gt;backend&lt;/code&gt;. The &lt;code&gt;frontend&lt;/code&gt; service uses the &lt;code&gt;nginx:latest&lt;/code&gt; image and maps port 80 of the host to port 80 of the container. It is configured to have 2 replicas and to restart on failure. The &lt;code&gt;backend&lt;/code&gt; service uses the &lt;code&gt;httpd:latest&lt;/code&gt; image and maps port 8080 of the host to port 80 of the container. It is also configured to have 2 replicas and to restart on failure.&lt;/p&gt;&lt;p&gt;Save and close the &lt;code&gt;docker-compose.yml&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;To deploy the application stack, run the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker stack deploy -c docker-compose.yml app-stack&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the command is successful, you should see output indicating that the services are being deployed. You can check the status of the services by running the command &lt;code&gt;docker service ls&lt;/code&gt;:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker service ls&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should see a list of the services in the stack, including their names, mode, replicas, and ports.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this tutorial, you learned how to set up a highly available Docker Swarm cluster and deploy a simple application stack. This setup provides fault tolerance and load balancing for your applications, allowing you to scale them easily as your needs grow.&lt;/p&gt;&lt;p&gt;Next steps:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Explore more Docker Swarm features, such as service updates and rolling updates.&lt;/li&gt;&lt;li&gt;Deploy your own application stack using Docker Compose.&lt;/li&gt;&lt;li&gt;Learn about Docker networking and how to create overlay networks.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Kubernetes NodePorts - Static and Dynamic Assignments]]></title><description><![CDATA[Avoiding Port Collisions with Kubernetes NodePorts Static and Dynamic Assignments]]></description><link>https://layer5.io/blog/kubernetes/kubernetes-nodeports-static-and-dynamic-assignments</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/kubernetes-nodeports-static-and-dynamic-assignments</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 12 May 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/7ff62eaeba27512aa31c04535a060e72/k8s-nodeports.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes provides a Service to offer a unified traffic endpoint for the Pods. While it offers a VIP to the clients for access and Kubernetes ensures traffic balancing for the accessing back-end Pods, it has a limitation of routing traffic from outside the cluster. To overcome this issue, a new feature called &amp;quot;NodePort&amp;quot; has been introduced. &lt;/p&gt;&lt;p&gt;By setting up a mapping to a specific port of all nodes in the cluster, a NodePort Service redirects traffic from the outside to the inside of the cluster. When a NodePort Service is created, Kubernetes control plane allocates its corresponding ports in two ways. The first is dynamic, where Kubernetes control plane automatically assigns an unused port at the creation time. The second is static, which assigns a port within the nodeport port range configuration. It is crucial to assign a unique nodePort across the entire cluster while manually assigning nodePort, or it will result in an error if a service of type NodePort already uses that port. &lt;/p&gt;&lt;p&gt;Sometimes, there is a need to run a NodePort Service on well-known ports so that other components and users inside or outside the cluster can use them. In such cases, users need to reserve the required ports before using them. Kubernetes 1.27 introduced a new feature gate &amp;quot;ServiceNodePortStaticSubrange&amp;quot; that allows users to use a different port allocation strategy for type NodePort Services. Enabling this feature gate will divide the port range for NodePort Services based on a formula that uses nodeport size and determines the size of the static port range.&lt;/p&gt;&lt;p&gt;Here are a few examples of different port ranges and their band offset values:&lt;/p&gt;&lt;div class=&quot;table-3&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Range properties&lt;/th&gt;&lt;th&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;service-node-port-range&lt;/td&gt;&lt;td&gt;30000-32767&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Band Offset&lt;/td&gt;&lt;td&gt;86&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band start&lt;/td&gt;&lt;td&gt;30000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band end&lt;/td&gt;&lt;td&gt;30085&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band start&lt;/td&gt;&lt;td&gt;30086&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band end&lt;/td&gt;&lt;td&gt;32767&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br/&gt;&lt;div class=&quot;table-3&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Range properties&lt;/th&gt;&lt;th&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;service-node-port-range&lt;/td&gt;&lt;td&gt;30000-30015&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Band Offset&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band start&lt;/td&gt;&lt;td&gt;30000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band end&lt;/td&gt;&lt;td&gt;30015&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band start&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band end&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;NodePort Services can be useful in many scenarios. For example, consider a user that needs to expose a Minio object storage service on Kubernetes to clients running outside the Kubernetes cluster. The agreed port is 30009, and the user needs to create a Service as follows:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;apiVersion: v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kind: Service&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;metadata:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  name: minio&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spec:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  ports:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: api&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    nodePort: 30009&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    port: 9000&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    protocol: TCP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    targetPort: 9000&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  selector:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    app: minio&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  type: NodePort&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the port required for the Minio Service is not reserved and another NodePort (or possibly LoadBalancer) Service is created and dynamically allocated before or concurrently with the Minio Service, the TCP port 30009 might be allocated to that other Service. In this case, creation of the Minio Service will fail due to a node port collision. &lt;/p&gt;&lt;p&gt;In conclusion, using the NodePort Service will help Kubernetes users by allowing traffic to be routed from outside to inside the cluster, providing a unified traffic endpoint for the Pods. By enabling the ServiceNodePortStaticSubrange feature gate, users can adopt a different port allocation strategy, reducing the risk of collisions while using a different range of ports.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What are Kubernetes Validating Admission Controllers?]]></title><description><![CDATA[Kubernetes Validating Admission Controllers and Policies use the Common Expression Language (CEL) to offer a declarative, in-process alternative to Validating Admission Webhooks.]]></description><link>https://layer5.io/blog/kubernetes/what-are-kubernetes-validating-admission-controllers</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/what-are-kubernetes-validating-admission-controllers</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/0cda4651daf491c6b40dd404799ca32c/kubernetes-new.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes is an open-source container orchestration system for automating the deployment, scaling, and management of containerized applications. As part of its functionality, Kubernetes offers a feature called &amp;quot;Admission Controllers&amp;quot; that allow administrators to enforce certain policies on resources being created in the cluster.&lt;/p&gt;&lt;p&gt;In this blog post, we will be discussing a new feature in Kubernetes called &amp;quot;Validating Admission Policies&amp;quot; which is currently in alpha stage. This feature allows administrators to define custom validation rules for resources being created in the cluster and enforce those rules using admission controllers.&lt;/p&gt;&lt;h2&gt;What are Admission Controllers?&lt;/h2&gt;&lt;p&gt;Admission controllers are pluggable components in the Kubernetes API server that intercept requests to create, update, or delete resources in the cluster. They allow administrators to enforce certain policies on these requests before they are persisted in the etcd database and acted upon by the Kubernetes control plane.&lt;/p&gt;&lt;p&gt;There are various types of admission controllers available in Kubernetes, such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;NamespaceLifecycle&lt;/strong&gt;: This admission controller enforces policies related to namespace creation and deletion.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;LimitRanger&lt;/strong&gt;: This admission controller enforces resource limits on pods, such as CPU and memory limits.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;PodSecurityPolicy&lt;/strong&gt;: This admission controller enforces security policies on pods, such as privileged mode, host networking, and volumes.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Validating Admission Policies&lt;/h2&gt;&lt;p&gt;Validating admission policies allow administrators to define custom validation rules for resources being created in the cluster. These rules can be defined using a custom resource definition (CRD) called &amp;quot;ValidatingWebhookConfiguration&amp;quot; and are enforced by the ValidatingAdmissionWebhook admission controller.&lt;/p&gt;&lt;p&gt;For example, an administrator may want to enforce a policy that requires all pods in the cluster to have a specific label. They can define this rule using a ValidatingWebhookConfiguration CRD and configure the ValidatingAdmissionWebhook admission controller to enforce it. Any request to create a pod that does not have the required label will be rejected by the admission controller.&lt;/p&gt;&lt;p&gt;Validating admission policies also allow administrators to use external webhooks to perform the validation. This can be useful when the validation logic is complex or requires access to external resources.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Validating admission policies is a new feature in Kubernetes that allows administrators to define custom validation rules for resources being created in the cluster. These rules can be enforced using the ValidatingAdmissionWebhook admission controller, and external webhooks can also be used for complex validation logic. This feature can be useful for enforcing policies and ensuring compliance in a Kubernetes cluster.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[The Most Innovative Cloud Management Companies]]></title><link>https://layer5.io/company/news/the-most-innovative-cloud-management-companies</link><guid isPermaLink="false">https://layer5.io/company/news/the-most-innovative-cloud-management-companies</guid><dc:creator><![CDATA[Best Startup Texas]]></dc:creator><pubDate>Wed, 11 Jan 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/bc8c3bab97b6d1c1577838cfae767899/best-startup-texas.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 DQvaY&quot;&gt;&lt;p&gt;Layer5 is featured as one of the most innovative cloud management companies by Best Startup Texas. Out of 100,000 Texas-based startups, Layer5 was selected based on oustanding marks in the following categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Company track record&lt;/li&gt;&lt;li&gt;Executive leadership&lt;/li&gt;&lt;li&gt;Market share&lt;/li&gt;&lt;li&gt;Innovation&lt;/li&gt;&lt;li&gt;ESG rating&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Learn more about &lt;a href=&quot;/about&quot;&gt;Layer5&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Terraform with Meshery]]></title><description><![CDATA[Terraform Infrastructure as Code with Meshery]]></description><link>https://layer5.io/resources/cloud-native/terraform-with-meshery</link><guid isPermaLink="false">https://layer5.io/resources/cloud-native/terraform-with-meshery</guid><dc:creator><![CDATA[Gaurav Chadha]]></dc:creator><pubDate>Thu, 22 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/895ec8ea35cf68449389f73e4285cb39/terraform-color.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;Terraform is a powerful tool that helps users manage and provision infrastructure resources in a consistent and efficient manner. With Terraform, you can define your infrastructure as code, using human-readable configuration files that can be versioned, shared, and reused. This makes it easy to create, modify, and manage your infrastructure resources, whether they are cloud-based or on-premises.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;One way to further enhance your use of Terraform is by integrating it with Meshery. Meshery is a cloud-native management platform that provides a unified interface for managing and monitoring your infrastructure resources, including those managed by Terraform. By integrating Terraform with Meshery, you can leverage the power and flexibility of both tools to streamline your infrastructure management process.&lt;/p&gt;&lt;p&gt;One of the key benefits of using Terraform with Meshery is the ability to manage and monitor infrastructure resources in a consistent and centralized manner. With Meshery, you can view and manage all of your infrastructure resources, whether they are managed by Terraform or other tools, from a single dashboard. This allows you to quickly identify any issues or potential problems with your infrastructure, and take action to resolve them in a timely manner.&lt;/p&gt;&lt;p&gt;Another benefit of using Terraform with Meshery is the ability to automate your infrastructure management process. With Meshery, you can create and manage automated pipelines for provisioning and managing your infrastructure resources. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks.&lt;/p&gt;&lt;p&gt;In addition to these benefits, using Terraform with Meshery also provides a number of other advantages. For example, Meshery integrates with a wide range of tools and platforms, allowing you to easily incorporate your existing infrastructure resources into your management process. This can help to reduce the complexity of managing your infrastructure, and make it easier to keep everything running smoothly.&lt;/p&gt;&lt;p&gt;Overall, the use of Terraform with Meshery can help to streamline and improve your infrastructure management process. By integrating these two powerful tools, you can gain greater visibility and control over your infrastructure resources, and automate many of the tasks involved in managing them. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks. So, it is a good idea to use Terraform with Meshery to improve the efficiency and effectiveness of your infrastructure management process.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Kubernetes 1.26 Highlights, Features, and Deprecations]]></title><description><![CDATA[Release Notes: What changed in Kubernetes 1.26?]]></description><link>https://layer5.io/blog/kubernetes/kubernetes-126-highlights-features-and-deprecations</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/kubernetes-126-highlights-features-and-deprecations</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Tue, 06 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/0cda4651daf491c6b40dd404799ca32c/kubernetes-new.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;As the final Kubernetes release of 2022, Kubernetes 1.26 is an exciting new release of the popular container orchestration platform. It offers a number of new features and improvements that will help platform engineers and DevOps engineers manage their Kubernetes clusters more effectively. Here are some of the highlights of this release.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;As a longstanding CNCF member, Layer5 has donated two of its open source projects to the CNCF: &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery&lt;/a&gt; and &lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance&lt;/a&gt;. As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;While there are a number of enhancments tracked in this release (38), you need to be aware that there are also a number of features being deprecated (10) in 1.26. In this article, we will focus on some highlighted enhancements, important deprecations, and removals so that you can be confident before upgrading your clusters. &lt;/p&gt;&lt;p&gt;We&amp;#x27;ll breakdown new K8s features by category, starting with networking.&lt;/p&gt;&lt;h2&gt;Networking in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2086&quot;&gt;Service Internal Traffic Policy&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;When requests are made to a Kubernetes service, they are randomly distributed to all available endpoints. The new enhancement enriches the API of a service to use node-local and topology-aware routing for internal traffic. The new internalTrafficPolicy field has two options: Cluster (default) and Local. The Cluster option works like before and tries distributing requests to all available endpoints. On the other hand, the Local option only sends requests to node-local endpoints and drops the request if there is no available instance on the same node. The Local option is useful for sending metrics or logs to an agent running as a DaemonSet. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3070&quot;&gt;Reserve Service IP Ranges for Dynamic and Static IP Allocation&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;Kubernetes services are assigned a virtual ClusterIP to be reachable inside the cluster. The ClusterIP is either assigned dynamically from a configured Service IP range, or statically set while creating the service resource. There was no possibility of knowing whether another service in the cluster had already used the static ClusterIP before this new stable enhancement. With this change, the IP range is divided into two; this prevents conflicts between services implementing dynamic IP allocation and static IP assignment. The flag --service-cluster-ip-range, with CIDR notation, is part of the Kubernetes API server configuration and is ready to use with the 1.26 release. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/1435&quot;&gt;Support of Mixed Protocols in Services with Type LoadBalancer&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;Kubernetes Services that use the LoadBalancer type have only supported a single Layer 4 protocol until now. With this enhancement going from graduating to stable in v1.26, it is possible to define a mix of protocols in the same service definition. In other words, this enhancement allows a LoadBalancer Service to serve different protocols (e.g. UDP, TCP) under the same port (e.g. 443). For example, serving both UDP and TCP requests for a DNS or SIP server on the same port. For instance, you can expose a DNS server with a single load balancer IP for both TCP and UDP requests, such as the following:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Service&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; multi&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;server&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; LoadBalancer&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;udp&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; UDP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;tcp&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; TCP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;server&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h2&gt;Security in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2133&quot;&gt;kubelet Credential Provider&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;The kubelet agent has a built-in credential provider mechanism to retrieve credentials for container image registries. It natively supports Azure, Google Cloud, and AWS container image registries for dynamically retrieving their credentials. The new stable enhancement in v1.26 offers a replacement for the in-tree implementations, and creates an API for extensible plugins in the future. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3031&quot;&gt;SignedSigning Release Artifacts&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;Every Kubernetes release produces a set of artifacts such as binaries, container images, documentation, and metadata. Since the 1.24 release, the artifacts have been signed as an alpha feature. In the 1.26 release, artifact signing graduates to beta to increase software supply chain security for the Kubernetes release process and mitigate man-in-the-middle attacks.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2799&quot;&gt;Reduction of Secret-Based Service Account Tokens&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;&lt;code&gt;BoundServiceAccountTokenVolume&lt;/code&gt; has been GA since version 1.22: Service account tokens for pods are obtained via the TokenRequest API and stored as a projected volume. The new enhancement, in beta, eliminates the need to auto-generate secret-based service account tokens. In addition, Kubernetes will warn about using auto-created secret-based service account tokens, and purge the unused ones.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/1981&quot;&gt;Windows Privileged Containers&lt;/a&gt; [Stable] and &lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3503&quot;&gt;Host Networking&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Privileged containers are the ones that have similar access and capabilities to the host processes running on the servers. In Linux environments, they are used heavily in Kubernetes for storage, networking, and management. In this release, support for privileged containers for the Windows environment graduates to stable. Management of processes is heavily different from the operating system standpoint in Linux and Windows. Therefore, privileged containers will also work differently in two environments, but they will ensure the same level of security and operational experience.&lt;/p&gt;&lt;p&gt;In addition, there is a new alpha-level enhancement in this release to support host networking for Windows pods. Currently, Windows has all the functionality to make containers use the networking namespace of the nodes. The new alpha enhancement enables this functionality from the Kubernetes side, increasing the parity between Linux and Windows containers.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/33250&quot;&gt;Self-User Attribute and Authentication API&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Kubernetes has no resources to identify and manage users as part of its API. Instead, it uses authenticators to get user attributes from tokens, certificates, OIDC providers, or webhooks. The new alpha feature adds a new API endpoint to see what attributes the current users have. The new API is under authentication.k8s.io with the name SelfSubjectReview, and there is a new corresponding command as well: kubectl auth who-am-i. The new feature will reduce the obscurity of complex authentication and help users debug the authentication stack. &lt;/p&gt;&lt;h2&gt;Scheduling in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2268&quot;&gt;Non-Graceful Node Shutdown for StatefulSet Pods&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;As a platform Kubernetes is hardened and has been deploy by thousands and thousands of users. Hardening of Kubernetes makes itself resistant to disasters. The kubelet agent that runs on each node in a Kubernetes cluster already uses graceful node shutdown to detect and offboard workloads to other nodes. However, when the shutdown is not detected by the kubelet, the pods of a &lt;code&gt;StatefulSet&lt;/code&gt; are stuck as &lt;code&gt;Terminating&lt;/code&gt; and not transferred to a healthy node. The kubelet on the downed node will not delete its pods from Kubernetes API, and the StatefulSet controller will not create new pods with the same name. This happens due to a conflict in the Kubernetes machinery. With this enhancement moving into beta, though, pods will be forcefully deleted along with their volume attachments and new pods will be migrated (created) on healthy nodes.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3521&quot;&gt;Pod Scheduling Readiness&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Currently, pods are considered ready for scheduling as soon as they are created. However, not every pod requires a node, resource allocation, and the start of all its containers immediately after its creation. The new alpha enhancement adds an API to mark pods with their scheduling status: paused and ready. Pods with the .spec.schedulingGates field will be parked in the scheduler and only be assigned to nodes when they are ready to be scheduled.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3515&quot;&gt;kubectl explain to use OpenAPI v3 for &lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Use of OpenAPI v3 means supporting rich type information in &lt;code&gt;kubectl explan&lt;/code&gt;. Kubernetes has supported OpenAPI v3 as a beta since version 1.24. This richer representation of the fields in the Kubernetes API, means that users can use the &lt;code&gt;kubectl explain&lt;/code&gt; command to get information that is only detailed in  OpenAPI v3, and not the subset defined OpenAPI v2.&lt;/p&gt;&lt;h2&gt;Deprecations and Removals&lt;/h2&gt;&lt;p&gt;Consistent to the Kubernetes API lifecycle is deprecations and removals of APIs in each release. It is strongly suggested to check whether you are using the following APIs and flags before there are breaking changes.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Removal of the `flowcontrol.apiserver.k8s.io/v1beta1` API group for `FlowSchema` and `PriorityLevelConfiguration` requires a migration to the v1beta2 API version.&lt;/li&gt;&lt;li&gt;Removal of the `autoscaling/v2beta2` API version for HorizontalPodAutoscaler requires a migration to the autoscaling/v2 API version.&lt;/li&gt;&lt;li&gt;Removal of legacy and vendor-specific authentication client-go and kubectl for Azure and Google Cloud requires migration to vendor-neutral authentication plugin mechanisms.&lt;/li&gt;&lt;li&gt;Removal of in-tree CSI integration for OpenStack—namely, the `cinder` volume type—requires a migration to use the CSI driver for OpenStack.&lt;/li&gt;&lt;li&gt;Some unused options and flags for the kubectl run command are marked as deprecated in the 1.26 release, such as `--grace-period`, `--timeout`, and `--wait`.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Last Kubernetes release of 2022&lt;/h2&gt;&lt;p&gt;Kubernetes is an ever-evolving platform. For those of you running workloads on Kubernetes taking detailed note of API changes and enhancements is an important activity as you endevour to keep your clusters upgraded with release releases. A more secure, scalable, and flexible Kubernetes is our collective goal. Dign into more details about deprecation, removals, and the latest changes in the 1.26 &lt;a href=&quot;https://relnotes.k8s.io/&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;On behalf of the Layer5 community and all of the CNCF projects that its contributors steward, thank you to everyone who participated in this Kubernetes release, and congratulations! &lt;/p&gt;&lt;p&gt;As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Structured logging in Kubernetes with Klog]]></title><description><![CDATA[Structured logging in Kubernetes 1.26 with Klog]]></description><link>https://layer5.io/blog/kubernetes/structured-logging-in-kubernetes-with-klog</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/structured-logging-in-kubernetes-with-klog</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Mon, 05 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a125a7ad56dafd70886f09d8c408e114/kubernetes-logs.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;As a platform for developers and system administrators to easily deploy and manage applications in a distributed environment, Kubernetes clusters generate logs and lots of them. One of the key components of Kubernetes is its logging and instrumentation capabilities. The upcoming Kubernetes 1.26 release has a handful of noteworthy changes to its system component logger, &lt;code&gt;klog&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;Kubernetes System Log&lt;/h2&gt;&lt;p&gt;System component logs record events happening in K8s clusters. More than metrics or traces, logs are the telemetric signal often found to be most useful for debugging. You can configure K8s log verbosity to see more or less detail. Logs can be as coarse-grained as showing errors within a component, or as fine-grained as showing step-by-step traces of events (like HTTP access logs, pod state changes, controller actions, or scheduler decisions).&lt;/p&gt;&lt;h2&gt;Klog&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/klog&quot;&gt;klog&lt;/a&gt; is a Kubernetes logging library that provides an API for developers and system administrators to instrument their applications for logging and tracing. klog generates log messages for the Kubernetes system components. It provides a comprehensive set of features, including log levels, structured logging and logging context.&lt;/p&gt;&lt;p&gt;Kubernetes 1.23 introduced structured logging (in beta) in &lt;code&gt;klog&lt;/code&gt;. Structured logging is a uniform structure in log messages allowing for programmatic extraction of information. Structured logs can be stored and processed with less effort and cost. The code which generates a log message determines whether it uses the traditional unstructured &lt;code&gt;klog&lt;/code&gt; output or structured logging.&lt;/p&gt;&lt;p&gt;As a dependency to structured logging (gated behind &lt;code&gt;StructuredLogging&lt;/code&gt; feature gate), Kubernetes 1.24 introducted contextual logging (in alpha) in &lt;code&gt;klog&lt;/code&gt;. Contextual logging builds on top of structured logging. It is primarily about how developers use logging calls: code based on that concept is more flexible and supports additional use cases which will be the topic of a future blog post. &lt;/p&gt;&lt;h3&gt;Klog Deprecations in Kubernetes 1.26&lt;/h3&gt;&lt;p&gt;Kubernetes has recently announced that it intends to deprecate certain flags related to Klog in its components. This means that Klog-specific flags, such as &lt;code&gt;--klog-verbosity&lt;/code&gt;, &lt;code&gt;--klog-vmodule&lt;/code&gt; and &lt;code&gt;--klog-stderrthreshold&lt;/code&gt; will no longer be supported. This is due to the fact that Klog has been largely superseded by the more comprehensive OpenTelemetry project, which provides a more complete solution for logging and instrumentation.&lt;/p&gt;&lt;p&gt;The deprecation of Klog-specific flags is a positive step forward for Kubernetes as it moves to OpenTelemetry. This move will ensure that Kubernetes is using the industry-standard logging and instrumentation solution. It will also provide developers and system administrators with a more comprehensive, reliable and consistent experience when instrumenting their applications.
A goal of this deprecation is one of unblocking development of alternative logging formats. Why does Kubnernetes need another logging format? One reason is performance. Klog performance is much worse than alternatives, for example 7-8x than JSON format:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;logger&lt;/th&gt;&lt;th&gt;time [ns/op]&lt;/th&gt;&lt;th&gt;bytes[B/op]&lt;/th&gt;&lt;th&gt;allocations[alloc/op]&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Text Infof&lt;/td&gt;&lt;td&gt;2252&lt;/td&gt;&lt;td&gt;248&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Text InfoS&lt;/td&gt;&lt;td&gt;2455&lt;/td&gt;&lt;td&gt;280&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JSON Infof&lt;/td&gt;&lt;td&gt;1406&lt;/td&gt;&lt;td&gt;19&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JSON InfoS&lt;/td&gt;&lt;td&gt;319&lt;/td&gt;&lt;td&gt;67&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Proof of concept implementation of new logging formats were completed to assess the potentional gains of using an alternative format. Results measured on 30s benchmark for passing 2 arguments to format function.&lt;/p&gt;&lt;div class=&quot;tip&quot;&gt;&lt;h3&gt;Tip: Logger Performance Comparison&lt;/h3&gt;&lt;p&gt;Interestingly, Klog isn&amp;#x27;t the fastest logger in the West, but Uber&amp;#x27;s open source project &lt;a href=&quot;https://github.com/uber-go/zap&quot;&gt;zap &lt;/a&gt; appears to hold that title instead. The following performance test benchmark is an examle of one of a number of scenarios in which loggers can be performance analyzed.&lt;/p&gt;&lt;p&gt;Log a message and 10 fields:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Package&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Time&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Time % to zap&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Objects Allocated&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zap&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2900 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+0%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;5 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zap (sugared)&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;3475 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+20%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;10 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zerolog&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;10639 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+267%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;32 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;go-kit&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;14434 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+398%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;59 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;logrus&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;17104 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+490%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;81 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;apex/log&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;32424 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+1018%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;66 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;log15&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;33579 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+1058%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;76 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;Output will always be written to stderr, regardless of the output format. Output redirection is expected to be handled by the component which invokes a Kubernetes component. This can be a POSIX shell or a tool like systemd.&lt;/p&gt;&lt;p&gt;The deprecation of Klog-specific flags is part of a larger effort to transition Kubernetes to a more modern and comprehensive logging and instrumentation solution. This will provide Kubernetes users with a more reliable, secure and consistent experience when instrumenting and monitoring their applications.&lt;/p&gt;&lt;p&gt;Kubernetes will continue to provide support for Klog-specific flags for the foreseeable future. However, it is recommended that developers and system administrators begin transitioning their applications to the OpenTelemetry framework. This will ensure that their applications are using the industry-standard solution for logging and instrumentation.&lt;/p&gt;&lt;p&gt;Overall, the deprecation of Klog-specific flags is a positive step forward for Kubernetes. It will ensure that Kubernetes users have access to the most reliable and comprehensive solution for logging and instrumentation. It will also help ensure that Kubernetes is using the industry-standard solution and will provide developers and system administrators with a more reliable and consistent experience when instrumenting their applications.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Management of Kubernetes]]></title><description><![CDATA[Management of Kubernetes]]></description><link>https://layer5.io/resources/kubernetes/management-of-kubernetes</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/management-of-kubernetes</guid><dc:creator><![CDATA[Tolulope Ola-David]]></dc:creator><pubDate>Mon, 21 Nov 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/9287b4a708bb510f64057ea305498b77/kubernetes-logo.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;h3&gt; What is Kubernetes Management, and Why Should You Care? &lt;/h3&gt;&lt;p&gt; It is easy to understand why Kubernetes has become one of the most popular tools on the market today. Primarily, it allows you to easily manage Docker containers across your entire infrastructure with very little overhead, making it easier than ever to manage massive amounts of information in a timely manner. But what are you supposed to do with all this information? That’s where Kubernetes management comes into play—the process of using that information in an effective manner can make or break your efforts, so it’s essential that you choose the right solutions from the get-go.&lt;/p&gt;&lt;h3&gt; Defining Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management is the process of managing your containers on a Kubernetes cluster. This can include things like adding or removing clusters, scaling clusters up or down, balancing workloads across nodes in a cluster, and restarting failed containers or nodes in a cluster. These tasks are complicated and involve many different types of actions. Figuring out how to do them all manually would be extremely time-consuming. Fortunately, there are tools like Meshery that automate these tasks for you, making it easier to see what’s going on within your cluster so you can make informed decisions about what needs to happen next. Staying on top of Kubernetes management will not only keep your cluster running smoothly but also help prevent problems before they occur. Automating this process will save you time and money, leaving more time to focus on other aspects of the business. When things go wrong, automated Kubernetes management allows you to have a plan and know exactly what steps need to be taken to recover from an incident. With these benefits in mind, it’s important that companies with containerized infrastructure use some type of automation for their Kubernetes management.&lt;/p&gt;&lt;h3&gt; The benefits of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management can seem like a daunting task. In the past, IT teams had to worry about maintaining large clusters of machines that required constant tweaking and monitoring. Kubernetes simplifies this process by automating tasks such as:&lt;ul&gt;&lt;li&gt; Monitoring cluster health &lt;/li&gt;&lt;li&gt; Deploying apps across nodes &lt;/li&gt;&lt;li&gt; Running rolling updates &lt;/li&gt;&lt;li&gt; Scaling up or down resources on demand &lt;/li&gt;&lt;li&gt; Auto-recover from failures &lt;/li&gt;&lt;li&gt; Application deployment consistency &lt;/li&gt;&lt;li&gt; Managing container upgrades &lt;/li&gt;&lt;/ul&gt;After reading through these benefits, you may be asking yourself, &amp;quot;Why should I care? Here are two reasons why you should care about Kubernetes management: - Kubernetes management has been shown to improve software development efficiency because it reduces time spent waiting for containers to restart and redeploy. A recent study showed that developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution.&lt;/p&gt;&lt;blockquote&gt; Developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution. &lt;/blockquote&gt;&lt;p&gt; Kubernetes management has also been shown to reduce operational costs because it eliminates the need for manual intervention in scaling applications, updating running containers with new versions, etc. If your IT team was spending 10 hours per week on manual operations before adopting Kubernetes, they&amp;#x27;ll spend only 2 hours after switching over! &lt;/p&gt;&lt;div class=&quot;CTA_FullWidth__CTA_FullWidthWrapper-sc-1rsxguj-0 yZijj get-start-kubernetes-resource&quot;&gt;&lt;img src=&quot;/static/multi-cluster-kubernetes-management-with-meshery-21f7b4f3cce3b8315ba9474f874cdd52.webp&quot; alt=&quot;Multi-Cluster Kubernetes Management with Meshery&quot;/&gt;&lt;div class=&quot;cta-content&quot;&gt;&lt;div&gt;&lt;h3&gt;Layer5 Community&lt;/h3&gt;&lt;p&gt;Multi-Cluster Kubernetes Management with Meshery&lt;/p&gt;&lt;/div&gt;&lt;a href=&quot;/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot; title=&quot;Read blog post&quot;&gt; Read blog post&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt; The challenges of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management can seem like a difficult endeavour. Between determining how to automate deployment and scaling and comprehending the fundamentals of how it operates, there are numerous factors to consider. Fortunately, there are numerous frameworks that simplify this procedure. But before going into new frameworks or technologies, you must grasp what Kubernetes administration comprises so that you know what you&amp;#x27;re attempting to automate. Kubernetes management comprises a variety of activities, such as building up clusters, keeping apps running on those clusters up-to-date, monitoring usage and providing alarms to keep things running smoothly, and shutting down clusters when they are no longer required. &lt;/p&gt;&lt;p&gt; There are numerous ways to manage these tasks: manually, with containers, with an orchestration system such as Ansible Tower, Cloud Control 12c, or ServiceNow NMS, with containers-as-a-service providers such as Docker Datacenter or AWS EKS, with container service offerings from cloud providers such as Azure Container Instances, by configuring Kubernetes with your own framework, and by installing Kubectl on your laptop for direct control. Each strategy has advantages and disadvantages that may make one more suitable for your organisation than another. Regardless of the approach you adopt, you must plan accordingly. &lt;/p&gt;&lt;p&gt; Importantly, the fact that Kubernetes is gaining popularity does not imply that it will replace your existing infrastructure layers. It augments their capabilities with scalability and large-scale application management (which would have been difficult without automation). In addition, the definition of management varies based on the size of the organisation: small businesses may prefer self-hosted platforms, whilst larger businesses would often primarily rely on SaaS solutions. &lt;/p&gt;&lt;h3&gt; How Meshery makes it easier to run Kubernetes &lt;/h3&gt;&lt;p&gt; Meshery is the only cloud-native manager in the world that supports more adapters than any other project or product. &lt;/p&gt;&lt;img src=&quot;/static/meshery-core-architecture-ada2489fcafbb125bde85de34ba3116e.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery has been designed for the world of many service meshes and many Kubernetes clusters. As such, great attention was made to guarantee that it is an extensible management platform, able to handle a diverse range of infrastructure and new use cases quickly through its plugin mechanism. Meshery Server acts as an operation delegator, determining which Meshery Adapter has registered its capacity for the given operation. The operation is then sent to the appropriate component using a gRPC call. This could be one of Meshery&amp;#x27;s service mesh adapters, like the Istio adapter. &lt;/p&gt;&lt;p&gt; Meshery&amp;#x27;s capability is constantly expanding, from multi-mesh to now multi-cluster, to give developers, operators, and security engineers more control over their infrastructure. Each part of Meshery&amp;#x27;s architecture makes a big difference in how it manages multiple Kubernetes clusters. &lt;/p&gt;&lt;h3&gt; Meshery management across many clusters &lt;/h3&gt;&lt;p&gt; From the settings page, users can do things related to clusters, like add more clusters, remove data from existing clusters, or delete existing clusters. &lt;/p&gt;&lt;img src=&quot;/static/settings-ad3405d125c81cc83695f10d49b51ae3.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery also deploys Meshery operators throughout the cluster it is about to manage. This operator is in charge of the Meshery broker and the MeshSync lifecycle. MeshSync is responsible for monitoring various types of resources by establishing a watch stream over each of them. MeshSync then sends the data to the NATS server, of which the Meshery server is a client. Meshery server then receives all necessary data relating to cluster activity. &lt;/p&gt;&lt;img src=&quot;/static/context-switcher-dcf6363d7932bb835366e0bd322d32c9.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery, by default, wants to be as aware of your infrastructure as possible in order to deliver value. As such, it deploys its operator across each identified cluster. However, you can fine-tune this configuration by going over each one. &lt;/p&gt;&lt;h3&gt; The future of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management has been one of the buzzwords since 2018. But what does it actually mean? And why should you care about it? At its core, Kubernetes management is a system that helps make sense of the nuances of how different containers work together to create an application. As we rely more on containers for our everyday apps, there needs to be a way to keep track of them all. That&amp;#x27;s where Kubernetes comes in with its ability to manage these containers that are spread out across different servers and understand which ones need more resources or want to be shut down because they&amp;#x27;re no longer needed. The easier it becomes for developers and engineers to deploy applications without worrying about how they are going to be managed, the better off everyone will be. Fortunately, as containerization grows in popularity among developers and IT teams alike, so does the number of tools for managing it. &lt;/p&gt;&lt;p&gt; A lot of container platforms provide native management functionality: Docker Swarm allows you to use simple commands like swarm stop or swarm pull when your swarm is up-to-date; Kargo automatically manages clusters using zero-touch configuration; Rancher provides tools to manage containers using any infrastructure stack; and Mesos offers both orchestration capabilities through Marathon as well as advanced resource scheduling features. It&amp;#x27;s not always easy to know which platform will work best for your organization, but it&amp;#x27;s important to find one that suits your company&amp;#x27;s needs—especially if IT is looking forward to a future without manual management tasks! &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Getting Started with Kubernetes]]></title><description><![CDATA[Introduction to Kubernetes]]></description><link>https://layer5.io/resources/kubernetes/getting-started-with-kubernetes</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/getting-started-with-kubernetes</guid><dc:creator><![CDATA[Tolulope Ola-David]]></dc:creator><pubDate>Wed, 02 Nov 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/b1a646c34f1a9ed49dcf37dd7b9b4662/kubernetes-logo.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt; Kubernetes, an open-source container orchestration platform, is growing in popularity for deploying and managing cloud-native applications. Kubernetes was created by Google in 2014, and it is now used by many major companies, including IBM, Microsoft, Red Hat, and Amazon. In this article, we&amp;#x27;ll talk about Kubernetes, its benefits, and the best ways for your organization to use it.&lt;/p&gt;&lt;h3&gt; What is Kubernetes? &lt;/h3&gt;&lt;p&gt; Kubernetes offers fully managed and adapted architecture services that optimize your cloud-native application. Kubernetes is a platform that hides virtual machines, shows the infrastructure as an infrastructure-as-a-service (IAAS), network, and load balancer, and offers data storage and operations that are consistent across containers.&lt;/p&gt;&lt;p&gt; For example, Kubernetes nodes work as Kubernetes containers, such as an application, an application server, and control processes in Docker containers. Kubernetes components such as Kubernetes nodes and Kubernetes containers can be defined or modified via configuration files or can be specified subsequently. Individual Kubernetes components can be scaled according to elasticity needs to optimize performance.&lt;/p&gt;&lt;p&gt; Kubernetes optimizes a Kubernetes environment in the cloud, Docker containers on a system for development or testing, and the master or control plane of its cloud cluster management infrastructure.&lt;/p&gt;&lt;h3&gt; What&amp;#x27;s the Difference between Kubernetes and Docker? &lt;/h3&gt;&lt;p&gt; Over the past few years, containers have become increasingly popular within the software development community, and they have now evolved into two major platforms — Docker and Kubernetes. Both are incredibly powerful tools that allow developers to containerize their applications, but they are also slightly different in a number of ways, with more differences on the horizon as Docker announces its new focus on Kubernetes and containers orchestration. How do you decide which one to use? What does the future hold for each? Here’s what you need to know about the difference between Docker and Kubernetes.&lt;/p&gt;&lt;p&gt; Docker is an open-source platform designed to help developers and IT professionals create, deploy, and run applications. This containerization technology is often used in conjunction with orchestration software such as Kubernetes. However, these two technologies are not interchangeable; they serve different purposes. &lt;/p&gt;&lt;h3&gt; Why Should You Care About Kubernetes? &lt;/h3&gt;&lt;p&gt; Kubernetes was first made available for Google&amp;#x27;s internal use for DNS hosting. Open-source software projects were not able to use it. &lt;/p&gt;&lt;p&gt; Today, Kubernetes is in use by large-scale companies that use container orchestration. And in January 2019, The New Stack reported that a survey conducted in that month, which included the Kubernetes user group, discovered that Kubernetes reached more than 40,000 users and 200 companies were working on Kubernetes at that point. In addition, Gartner indicated that Kubernetes Inc. would make some $8.5 billion in 2019. &lt;/p&gt;&lt;h3&gt; What does Kubernetes Do? &lt;/h3&gt;&lt;p&gt; In contrast to an overall infrastructure, Kubernetes is a dynamic layer-oriented computing infrastructure. The essence of Kubernetes is how an entire infrastructure hops! Kubernetes is a container orchestration and management platform that has built-in features for self-replication, elasticity, and scalability. Through these and more features, Kubernetes &amp;quot;promovi-is&amp;quot; for container orchestrators for both production and lab environments. &lt;/p&gt;&lt;h3&gt; Kubernetes Architecture &lt;/h3&gt;&lt;p&gt; Even though Kubernetes is a software platform that lets organizations manage their application workloads in containers, a traditional Kubernetes cluster may not be the best solution for a number of business needs. &lt;/p&gt;&lt;img src=&quot;/static/meshery-core-architecture-ada2489fcafbb125bde85de34ba3116e.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;p&gt; A cluster of virtual computing resources is only one option, and it has its drawbacks. What happens when you lose disk space (which can happen if you don&amp;#x27;t add new containers, users, or workloads to a cluster)? Do you have another cluster for redundancy, and how do you integrate the two together? &lt;/p&gt;&lt;p&gt; Hyperconverged infrastructures like Red Hat OpenShift are an alternative that combine several technologies into a single virtual machine or physical machine. &lt;/p&gt;&lt;h3&gt; Best Practices for Kubernetes &lt;/h3&gt;&lt;p&gt; Kubernetes is a container orchestration platform created by Google in 2014. It provides a way for companies to build fully self-sufficient, scalable, multi-container applications every time they need to deploy and manage their own containers. It&amp;#x27;s aimed at pretty much the same audience as Docker and other container orchestration platforms—that is, organizations that run containerized applications and want to deploy scalable, repeatable deployments.&lt;/p&gt;&lt;p&gt; At the most basic and most simplistic level, a group of containers (usually 16) is cross-linked together in a cluster, based on Docker. Containers run inside a cluster of virtual machines (Kubernetes VM) as a single Linux file system. Kubernetes organizes the creation, deletion, and management of containers into container concepts that provide fault tolerance, availability, scaling, permission management, and secure containers that should be able to run together and share resources. Each host runs one or more containers, providing the abstraction of which containers can run on which hosts.&lt;/p&gt;&lt;p&gt; Since Kubernetes services are usually very easy to use, the user experience is very similar to that of centralized solutions. &lt;/p&gt;&lt;p&gt; With Kubernetes, businesses can make data repositories and containers, federate their resources in an efficient way, manage billing, certify capacity, quota, access rights, and more. &lt;/p&gt;&lt;p&gt; It can scale to many nodes simultaneously, so when their machines scale up, then their containers could scale up too. &lt;/p&gt;&lt;h3&gt; Kubernetes Concepts and Terminology &lt;/h3&gt;&lt;p&gt; Kubernetes was developed in 2014 as a Google container orchestrator, a container scheduler and more. Kubernetes was created to manage distributed applications, including Docker containers. According to SUSE, Kubernetes is simple to learn, easy to manage, and supports an on-premise, private, public, or hybrid architecture. Kubernetes is flexible enough to be split up over many servers in your data center. &lt;/p&gt;&lt;p&gt; This simplificator, one example of many, allows one to scale independent containers. &lt;/p&gt;&lt;p&gt; Let&amp;#x27;s understand better what Kubernetes is: &lt;/p&gt;&lt;p&gt; In an application ecosystem of operating system Docker containers, Kubernetes acts as a centralized management guided by distributed logic. Kubernetes can be used to deliver web traffic, graphics work, or IP traffic from IoT devices. The main benefit is that clusters can be easily expanded to a huge size with all functions. &lt;/p&gt;&lt;p&gt; What are pods? Pods are Docker instances that you can use to deploy your containers in environments like Kubernetes, which can be private, public, or a mix of the two.&lt;/p&gt;&lt;p&gt; Environments may be private services or public clouds. &lt;/p&gt;&lt;p&gt; Kubernetes can be used to manage containers because they are easy to use and make it easy to scale your containers. &lt;/p&gt;&lt;p&gt; Installation tutorials are sometimes yoinked without ever reading the help. &lt;/p&gt;&lt;h3&gt; RBAC and Firewall Security &lt;/h3&gt;&lt;p&gt; Today, everything is hackable, and so is your Kubernetes cluster. Hackers often try to find vulnerabilities in the system in order to exploit them and gain access. So, keeping your Kubernetes cluster secure should be a high priority. The first thing to do is make sure you are using RBAC in Kubernetes. RBAC is role-based access control. Assign roles to each user in your cluster and to each service account running in your cluster. Roles in RBAC contain several permissions that a user or service account can perform. You can assign the same role to multiple people, and each role can have multiple permissions.&lt;/p&gt;&lt;p&gt; RBAC settings can also be applied to namespaces, so if you assign roles to a user allowed in one namespace, they will not have access to other namespaces in the cluster. Kubernetes provides RBAC properties such as role and cluster role to define security policies. &lt;/p&gt;&lt;p&gt; You can create a firewall for your API server to prevent attackers from sending connection requests to your API server from the Internet. To do this, you can either use regular firewalling rules or port firewalling rules. If you are using something like GKE, you can use a master authorized network feature in order to limit the IP addresses that can access the API server. &lt;/p&gt;&lt;h3&gt; Managing Kubernetes Clusters &lt;/h3&gt;&lt;p&gt; Kubernetes is a project that lets you create and manage individual containers or a container cluster on a mainframe. Clusters may consist of physical, virtual, or cloud-based computing resources.&lt;/p&gt;&lt;div class=&quot;CTA_FullWidth__CTA_FullWidthWrapper-sc-1rsxguj-0 yZijj get-start-kubernetes-resource&quot;&gt;&lt;img src=&quot;/static/multi-cluster-kubernetes-management-with-meshery-21f7b4f3cce3b8315ba9474f874cdd52.webp&quot; alt=&quot;Multi-Cluster Kubernetes Management with Meshery&quot;/&gt;&lt;div class=&quot;cta-content&quot;&gt;&lt;div&gt;&lt;h3&gt;Layer5 Community&lt;/h3&gt;&lt;p&gt;Multi-Cluster Kubernetes Management with Meshery&lt;/p&gt;&lt;/div&gt;&lt;a href=&quot;/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot; title=&quot;Read blog post&quot;&gt; Read blog post&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt; The Kubernetes projects auto-deploy container clusters anywhere there is a pluggable environment and an open-source base that includes system-config service, service account manager, and kubelet. So, developers and system administrators can easily put containers on a single machine or on nodes of machines in any scalable cluster to save money and time.&lt;/p&gt;&lt;p&gt; Kubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications. Kubernetes was made by Google, and the Cloud Native Computing Foundation now takes care of it.&lt;/p&gt;&lt;h3&gt;Kubernetes Cluster Visualization and Designing using MeshMap&lt;/h3&gt;&lt;p&gt; MeshMap has been developed for visualizing and managing kubernetes clusters. You can learn more about MeshMap &lt;a href=&quot;https://layer5.io/cloud-native-management/meshmap&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Users can drag-and-drop your cloud native infrastructure using a pallete of thousands of versioned Kubernetes components. Integrate advanced performance analysis into your pipeline.&lt;/p&gt;&lt;img src=&quot;/static/MeshmapDesigner-e3bbc66d72dedf1345a87890103e31c0.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;p&gt;Users can deploy their designs, apply patterns, manage and operate their deployments in real-time bringing all the Kubernetes clusters under a common point of management. Interactively connect to terminal sessions or initiate and search log streams from your containers.&lt;/p&gt;&lt;img src=&quot;/static/MeshmapVisualizer-7d853e953fa58d40fd3315f44ba34ba0.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;h3&gt; Set Resource Requests &amp;amp; Limits&lt;/h3&gt;&lt;p&gt; Occasionally, deploying an application to a production cluster can fail due to the limited resources available on that cluster. This is a common challenge when working with a Kubernetes cluster, and it’s caused when resource requests and limits are not set. Without resource requests and limits, pods in a cluster can start utilizing more resources than required. If the pod starts consuming more CPU or memory on the node, then the scheduler may not be able to place new pods, and even the node itself may crash. Resource requests specify the minimum amount of resources a container can use. &lt;/p&gt;&lt;p&gt; For both requests and limits, it’s typical to define CPU in millicores and memory in megabytes or mebibytes. Containers in a pod do not run if the request for resources made is higher than the limit you set.&lt;/p&gt;&lt;p&gt; In this example, we have set the limit of the CPU to 800 millicores and the memory to 256 mebibytes. The maximum request which the container can make at a time is 400 millicores of CPU and 128 mebibyte of memory.&lt;/p&gt;&lt;h3&gt; Guide to Containers &lt;/h3&gt;&lt;p&gt; Containers have been around for a while, but it wasn’t until Docker came along that they really took off. In its early days, developers were using it to build their applications in containers. Now companies like Walmart are using containers to deploy their entire infrastructure.&lt;/p&gt;&lt;p&gt; Containers are lighter-weight than virtual machines because they don&amp;#x27;t need to emulate an entire operating system. This is why containers are typically faster to start up and use less resources. However, containers cannot be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case.&lt;/p&gt;&lt;p&gt; Because they&amp;#x27;re so lightweight and take up less space than VMs do, containers are great for running lots of them at once! If your application needs more computing power or memory than your machine can provide on its own, using multiple containers in parallel will help balance out any resource shortages without having to invest in additional physical hardware like you would with traditional VM-based deployments.&lt;/p&gt;&lt;p&gt; As they&amp;#x27;re isolated from each other, containers are great for running multiple apps at once without worrying about them stepping all over each other&amp;#x27;s toes! This makes them perfect for things like hosting websites or email services where you want lots of different people to be able to use it at the same time without slowing down or crashing because there&amp;#x27;s not enough resources available for everyone. &lt;/p&gt;&lt;p&gt; What&amp;#x27;s more, since they&amp;#x27;re so easy to spin up and take down, they&amp;#x27;re also great for testing out new ideas quickly without having to worry about making permanent changes to your system (or losing any data along the way!). So if you want to try out a new CMS but don&amp;#x27;t want to go through the trouble of installing it on your machine first, just fire up a container with it inside and see how it goes! &lt;/p&gt;&lt;p&gt; One downside to using containers is that they can&amp;#x27;t easily be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case. Fortunately, there are some great open source projects out there that help solve this problem!&lt;/p&gt;&lt;h3&gt; Conclusion &lt;/h3&gt;&lt;p&gt; Kubernetes is a popular containerization solution that continues to see increasing adoption rates. That being said, using it successfully requires thorough consideration of your workflows and departmental best practices. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh: Istio]]></title><description><![CDATA[Explanation of Istio]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-istio</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-istio</guid><dc:creator><![CDATA[Deepesha Burse]]></dc:creator><pubDate>Wed, 31 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/731763d720780a49c2ffdfede8c28f4b/istio.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt; Microservice architectures offer some solutions while posing new ones. Application division into separate services makes scaling, updating, and development easier. It also provides you with a lot more moving pieces to connect and secure. It can get quite complicated to manage all of the network services, including load balancing, traffic management, authentication and authorisation, etc. &lt;/p&gt;&lt;p&gt; Istio, an open-source service mesh created by Google, IBM, and Lyft, enables you to connect, monitor, and secure microservices that are hosted on-premises, in the cloud, or with orchestration systems like Kubernetes and Mesos. The beta version of Istio was announced in the year 2018 in KubeCon on Google Cloud. &lt;/p&gt;&lt;p&gt; Before moving on to what Istio is and how it works, let us look into what service meshes are and why there was an urgent need for them as microservices started getting used more. &lt;/p&gt;&lt;h3&gt; Service Mesh &lt;/h3&gt;&lt;p&gt; A service mesh is an infrastructural layer that is used to provide secure communication between different services for on-prem, cloud or multi-cloud infrastructure. It allows us to add features like observability, traffic management, and security without having to add that to our code. The term &amp;quot;service mesh&amp;quot; refers to both the kind of software you employ to carry out this pattern and the security or network domain that results from its application. &lt;/p&gt;&lt;p&gt; Service meshes are divided into two parts: the control plane and the data plane. The control plane&amp;#x27;s responsibilities include securing the mesh, facilitating service discovery, doing regular health checks, enforcing policies, and handling other operational issues. A central registration of services and their corresponding IP addresses is referred to as service discovery. To share with other services how to communicate with it and to assist enforce rules on which services are allowed to communicate with which other services, the application must be registered on the control plane. &lt;/p&gt;&lt;p&gt; The communication between services, on the other hand, is handled by the data plane. Because many service mesh solutions use a sidecar proxy to manage data plane connections, the amount of knowledge that the services must have about the network environment is constrained. &lt;/p&gt;&lt;img src=&quot;/static/service-mesh.609aa147.svg&quot; class=&quot;image-center&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;h3&gt; Inside the Istio service mesh &lt;/h3&gt;&lt;p&gt; A data plane and a control plane are logically separate parts of an Istio service mesh.&lt;ul&gt;&lt;li&gt; A group of intelligent proxies (Envoy) that are deployed as sidecars make up the data plane. All network connection among the microservices is mediated and managed by these proxies. Additionally, they gather and compile data on all mesh communications. &lt;/li&gt;&lt;li&gt; The proxies are controlled and set up by the control plane to route traffic. &lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;img src=&quot;/static/arch.04060307.svg&quot; class=&quot;image-center&quot; alt=&quot;Istio Service Mesh Architecture&quot;/&gt;&lt;h4&gt; Envoy &lt;/h4&gt;&lt;p&gt; The data plane of Istio consists of the Envoy sidecar proxy. Envoy is an edge and service proxy that is open source and free that aids in separating network concerns from core applications. Applications don&amp;#x27;t care about the network topology; they just transmit and receive messages to and from localhost. Envoy is fundamentally a network proxy that operates at the OSI model&amp;#x27;s L3 and L4 layers. It operates by processing connections through a series of pluggable network filters. Envoy additionally provides support for an extra L7 layer filter for HTTP-based traffic. Envoy also offers excellent support for the HTTP/2 and gRPC transports. &lt;/p&gt;&lt;p&gt; Many of the features provided by Istio such as security, traffic control, network resiliency are possible due to Envoy. &lt;/p&gt;&lt;h4&gt; Istiod &lt;/h4&gt;&lt;p&gt; Service discovery, configuration, and certificate management are offered by Istiod. &lt;/p&gt;&lt;p&gt; High level routing rules that govern traffic behavior are transformed into Envoy-specific configurations by Istiod and propagated to the sidecars during runtime. Any sidecar that complies with the Envoy API can use Pilot, which synthesizes platform-specific service discovery techniques into an abstract form. &lt;/p&gt;&lt;p&gt; Istio can handle discovery in a variety of settings, including Kubernetes or virtual machines. &lt;/p&gt;&lt;p&gt; To exert finer control over the traffic in your service mesh, you can ask Istiod to modify the Envoy configuration using the Traffic Management API. &lt;/p&gt;&lt;p&gt; Strong service-to-service and end-user authentication are made possible by Istiod security&amp;#x27;s integrated identity and credential management. Istio can be used to enhance unencrypted service mesh traffic. &lt;/p&gt;&lt;p&gt; Operators can enforce regulations with Istio based on service identity rather than on layer 3 or layer 4 network IDs, which are more prone to instability. Additionally, you can limit who has access to your services by using Istio&amp;#x27;s authorisation capability. &lt;/p&gt;&lt;p&gt; In order to enable secure mTLS connection in the data plane, Istiod performs the role of a Certificate Authority (CA) and issues certificates. &lt;/p&gt;&lt;h3&gt; Features &lt;/h3&gt;&lt;h4&gt; Traffic Management &lt;/h4&gt;&lt;p&gt; Performance is impacted by traffic routing, both within and across clusters, which improves deployment strategy. You can simply manage the flow of traffic and API requests between services using Istio&amp;#x27;s traffic routing rules. Istio makes it simple to configure critical activities like A/B testing, canary deployments, and staged rollouts with percentage-based traffic divides, as well as service-level attributes like circuit breakers, timeouts, and retries. &lt;/p&gt;&lt;h4&gt; Observability &lt;/h4&gt;&lt;p&gt; It becomes harder to comprehend behaviour and performance as services become more complicated. Istio produces comprehensive telemetry for each communication taking place within a service mesh. This telemetry makes service activity observable, enabling operators to maintain, optimise, and debug their applications. Even better, you can implement practically all of this instrumentation without making any changes to your applications. Operators are able to fully comprehend how the monitored services are communicating with Istio. &lt;/p&gt;&lt;p&gt; Detailed metrics, distributed traces, and complete access logs are all included in Istio&amp;#x27;s telemetry. You get complete and thorough service mesh observability with Istio. &lt;/p&gt;&lt;h4&gt; Security Capabilities &lt;/h4&gt;&lt;p&gt; Particular security requirements for microservices include defense against man-in-the-middle attacks, adaptable access rules, auditing tools, and mutual TLS. Istio comes with a comprehensive security solution that enables administrators to handle each of these problems. To safeguard your services and data, it offers strong identity, strong policy, transparent TLS encryption, and authentication, authorization, and audit (AAA) tools. &lt;/p&gt;&lt;p&gt; The security architecture used by Istio is built on security-by-default, and it aims to provide in-depth defense so you may deploy security-conscious apps even across networks with a low level of trust. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[The Ultimate List of Open Source Cloud-Native Tools]]></title><link>https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</link><guid isPermaLink="false">https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</guid><dc:creator><![CDATA[Bill Doerrfeld]]></dc:creator><pubDate>Mon, 29 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/d933bb2908d2076307a5899a5cb48295/tools.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 DQvaY&quot;&gt;&lt;div class=&quot;test&quot;&gt;&lt;p&gt;There are so many great open source cloud-native tools for nearly everything you want to do.
And they’re all in one place—look no further than the Cloud Native Computing Foundation (CNCF).This Linux Foundation body has become a locus of some stellar cloud-native open source projects. The CNCF now hosts an array of helpful packages, spanning container scheduling, observability, persistent storage, container runtime and other areas.&lt;/p&gt;&lt;p&gt;Odds are the cloud-native DevOps tool you need has already been developed—it’s only a matter of finding it. In recent posts, we highlighted many CNCF tools across various areas. Below, we’ll gloss over each category from a birds-eye view. Click each headline for the full rundown, or read below for a summary of the tools in each category.&lt;/p&gt;&lt;h3&gt;Scheduling  Orchestration&lt;/h3&gt;&lt;br/&gt;Kubernetes is the most popular container scheduling tool. It can be used to automate the deployment and management of multi-cloud applications. Other scheduling and orchestration utilities from CNCF include Crossplane, Fluid, Karmada, kube-rs, Open Cluster Management and Volcano.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Observability and Analysis&lt;/h3&gt;&lt;br/&gt;Prometheus tops the list of observability and analysis tools. The platform can be used to power your monitoring and alerting systems with fine-grained metrics and excellent querying capabilities. Other CNCF tools for observability and analysis include Jaeger, Fluentd, Thanos, Cortex and OpenTelemetry.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Security and Compliance&lt;/h3&gt;&lt;br/&gt;Open Policy Agent (OPA) can be used to unify cloud-native policies across the cloud-native stack. OPA uses a common language to express authorization policies and provides a policy engine to make authorization decisions. Other CNCF projects that deliver security-as-code include The Update Framework (TUF), Falco, Notary, cert-manager and Curiefense.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;CI/CD&lt;/h3&gt;&lt;br/&gt;Argo is a suite of packages that help direct jobs on Kubernetes to aid a continuous delivery pipeline. Using Argo, developers can create multi-step custom workflows and share these workflows across a cluster. Other CI/CD tools hosted by CNCF include Flux, Brigade, Keptn, OpenGitOps and OpenKruise.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Mesh Tools&lt;/h3&gt;&lt;br/&gt;Linkerd is a highly performant developer-favorite service mesh comprised of a control plane to apply configurations and a data plane that deploys its own unique proxy. This proxy can apply consistent security, observability, monitoring and telemetry features across distributed microservices. Other service mesh tools from CNCF include Kuma, Open Service Mesh (OSM), &lt;a href=&quot;/projects/service-mesh-interface-conformance&quot;&gt;Service Mesh Interface (SMI) &lt;/a&gt; , &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; and &lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance(SMP)&lt;/a&gt;.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Proxies&lt;/h3&gt;&lt;br/&gt;Envoy is a service proxy commonly used within service meshes like Istio and Kuma. Envoy is intended to run alongside applications to help standardize networking and observability within large microservices networks. Other service proxy projects include Contour BFE and OpenELB.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Persistent Storage&lt;/h3&gt;&lt;br/&gt;Rook is a tool that helps automate away some of the pains of managing cloud-native persistent storage. Rook supports file, block and object storage types and can be used for programmatic storage, migration, disaster recovery, monitoring and resource management. Other cloud-native persistent storage projects include Longhorn, CubeFS, K8up, OpenEBS, ORAS, Piraeus Datastore and Vineyard.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Database Tools&lt;/h3&gt;&lt;br/&gt;TiKV is a unified distributed storage layer that can process large amounts of data. The project supports a key-value API and has rapid response times. Other cloud-native database utilities include Vitess, a clustering system for horizontal scaling of MySQL and SchemaHero, a Kubernetes operator for declarative database schema management.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Container Runtime&lt;/h3&gt;&lt;br/&gt;Containerd is an industry-standard container runtime supported by most container-based systems. Originally built as part of Docker, containerd was donated to the Linux Foundation in 2015. Other notable CNCF container runtime utilities include CRI-O, Inclavare Containers and WasmEdge Runtime.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;App Definition and Build Tools&lt;/h3&gt;&lt;br/&gt;Helm is a prevalent Kubernetes package manager widely used to share a manifest of dependencies. Operators often use Helm charts to find and install third-party applications. Other notable tools which help address operational concerns of Kubernetes include Buildpacks, KubeVirt, Operator Framework and Backstage.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Networking&lt;/h3&gt;&lt;br/&gt;Cilium is a tool that brings eBPF-based networking, security and observability. Cilium helps build out networking between container workloads and cross-cluster connectivity. Additional cloud-native networking utilities include Antrea, CNI-Genie, Kube-OVN, Network Service Mesh (NSM) and Submariner. There’s also the Container Network Interface (CNI), an interface specification for container networking.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Streaming and Messaging&lt;/h3&gt;&lt;br/&gt;CloudEvents offers a specification intended to help standardize the event-based communication from various event publisher systems. By having a way to describe events consistently, developers could solve interoperability issues. Other CNCF streaming and messaging projects include NATS, Pravega, Strimzi and Tremor.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;br/&gt;Chaos Mesh is a chaos engineering platform for Kubernetes. Using Chaos Mesh, operators can push their Kubernetes deployments to the limit with stress testing, fault injections, and other testing behaviors. You can also schedule routine tests. Other cloud-native chaos testing tools from CNCF include Litmus and ChaosBlade.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Key Management&lt;/h3&gt;&lt;br/&gt;SPIFFE is defined as a universal identity control plane for a distributed architecture. Using SPIFFE, engineers can quickly construct a standard method to identify workloads and automatically secure service-to-service communication. SPIRE is the product-ready reference implementation of SPIFFE. Other key management tools from CNCF include Athenz and Teller.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Edge Computing and Bare Metal&lt;/h3&gt;&lt;br/&gt;KubeEdge helps extend cloud-native capabilities into edge computing. It’s specifically designed with the constraints of edge nodes in mind, such as reliability and resource limitations. Other projects that help extend Kubernetes to the edge include Akri, OpenYurt and SuperEdge. Other tools aid in provisioning K8s on bare metal, such as Metal3.io and Tinkerbell.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;The Forecast Looks Cloud-Native&lt;/h3&gt;&lt;br/&gt;By 2023, the &lt;a href=&quot;https://containerjournal.com/features/majority-of-apps-will-use-cloud-native-development-by-2023/&quot;&gt;majority of applications will be cloud-native&lt;/a&gt;. The cloud-native world is here to stay, and open source is the foundation to support our new era of microservices, containerization and DevOps.&lt;p&gt;Although you could technically self-host your way through development and operations using these open source projects, organizations will most likely adopt a blend of open source, proprietary and as-a-service cloud offerings to get the job done. Regardless, it’s cool to know what’s available for free use.&lt;/p&gt;&lt;p&gt;It should also be mentioned that tools change from time to time. As such, you can always view the up-to-date CNCF landscape here. Stay tuned as we keep an eye on CNCF and related bodies that continue to carry the cloud-native torch forward!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[DevOps Adoption: Identifying the Right Metrics]]></title><link>https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</link><guid isPermaLink="false">https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</guid><pubDate>Tue, 23 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;According to Puppet’s State of DevOps Report 2021, 83% of IT professionals report that their organizations have previously implemented DevOps practices or are doing so right now to unlock higher business value, achieve faster time to delivery, and boost security of systems.&lt;/p&gt;&lt;p&gt;However, DevOps teams from many industries frequently struggle to identify the right metrics to monitor and measure success. In this &lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;infographic&lt;/a&gt;, we highlight the metrics all DevOps professionals should measure to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Identify places in the pipeline to speed up deployments.&lt;/li&gt;&lt;li&gt;Make data-driven decisions to improve the deployment process.&lt;/li&gt;&lt;li&gt;Analyze the speed at which products are reaching the market in comparison to competitors.&lt;/li&gt;&lt;/ul&gt;&lt;h3 style=&quot;margin-top:1rem&quot;&gt;Monitor these 5 metrics to understand how to speed up your DevOps toolchain:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Deployment Time&lt;/li&gt;&lt;li&gt;Change Failure Rate&lt;/li&gt;&lt;li&gt;Recovery Time&lt;/li&gt;&lt;li&gt;Release Cadence&lt;/li&gt;&lt;li&gt;Lead Time&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;&lt;img src=&quot;/static/devops-adoption-a44cb4bc65c93dfa8fa404e38f05233a.webp&quot; alt=&quot;Right metrics for adopting DevOps&quot;/&gt;&lt;/a&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What is GitOps?]]></title><link>https://layer5.io/resources/cloud-native/what-is-gitops</link><guid isPermaLink="false">https://layer5.io/resources/cloud-native/what-is-gitops</guid><pubDate>Tue, 16 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a8d747801f0e266dbc9bb2b192cd3dc1/github-dark.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;GitOps revolves around the central notion that infrastructure can be treated as code. It is an operational framework that incorporates DevOps best practices for infrastructure automation, including version control, collaboration, compliance, and CI/CD tooling, which are often used for application development. Like code, not only can you store your infrastructure configuration in a source code version system, but you can also take your infrastructure configuration and any changes to its configuration through the same change management process that you do when updating your applications and services. In part, GitOps is about change management, and consequently, it is about risk reduction and risk management. When you automate a process and classify the manner in which you systemize the process, risk is reduced through the consistency and series of processes and reviews changes go through.&lt;/p&gt;&lt;p&gt;GitOps is the acknowledgement that declarative systems that everything is (or should be) defined as code. With all code in a source code system, that system becomes the source of truth and in the system of record for how your infrastructure is running. Well, that is, assuming that your infrastructure configuration hasn&amp;#x27;t drifted from its desired state defined in your source code system. If Git is the source of truth, you cannot run operations manually by executing random commands. Doing so would mean that Git would stop being the only source of truth. Instead, the only goal of operations is to define the desired state as code and store it in git. Then, let the machines synchronize that with the actual state. Such synchronization must be continuous so that the two states are (almost) always in sync. In other words, GitOps is about defining everything as code, storing that code in Git, and letting the machines detect the drift between the desired and the actual state – and making sure that drifts are resolved as soon as possible, hence resulting in the two states being almost always in sync.&lt;/p&gt;&lt;h2&gt; Principles of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Declarative&lt;/h3&gt;&lt;p&gt; According to this principle, the entire system should have a declarative description. Let us first understand what a system description is. What is committed to your Git repository is called the System Description. One or more files that define each system component and its state will be included in the system description. According to GitOps, the way in which we store those definitions is crucial, and we must do so declaratively. That implies that the description of our system will be saved as data.&lt;/p&gt;&lt;p&gt; In the declarative approach, we specify how we want the system to look not how we can achieve that state. If we want to make any changes, we change the description instead of the series of steps to get there. Declarative configuration is critical for GitOps because it provides a description of the system that an automated agent can understand and utilize to take action.&lt;/p&gt;&lt;h3&gt; 2) Single Source of Truth&lt;/h3&gt;&lt;p&gt; The second principle mandates that we keep that system description inside of Git. Therefore, we decide to maintain the official blueprints, which outline the ideal system state version in Git. A git commit is required if we wish to modify the blueprint. The blueprint can also be called the desired state. This helps developers, testers, operations, security, and automations to have a single reference and keep uniformity in everyone’s vision.&lt;/p&gt;&lt;p&gt; GitOps also improves a system&amp;#x27;s ability to recover from failure because it&amp;#x27;s simple to roll back an unsuccessful change or restore the entire system from the repository.&lt;/p&gt;&lt;h3&gt; 3) Automated Change Delivery&lt;/h3&gt;&lt;p&gt; Only automation allows us to apply modifications made to the blueprint to systems already in operation. Delivery of changes is entirely automatic. GitOps doesn&amp;#x27;t allow manual editing. Because standard workflows only need GitHub, which is such a well-known platform, automation enables changes to be delivered through simpler for developers to use workflows. Additionally, automation standardizes your delivery processes, improving the predictability and consistency of system operations.&lt;/p&gt;&lt;h3&gt; 4) Automated State Control&lt;/h3&gt;&lt;p&gt; The fourth principle uses automation to keep our operating system in alignment with the desired state. Drift is the deviation of the runtime state of our system from the desired state. The system&amp;#x27;s blueprints and what is actually operating in the system don&amp;#x27;t match. Therefore, if the operating system drifts from what we have specified in Git, an operator will restore it by bringing it back to the intended condition.&lt;/p&gt;&lt;h2&gt; Benefits of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Improves compliance and security:&lt;/h3&gt;&lt;p&gt; Since teams use a single platform for infrastructure management, a streamlined toolchain reduces attack surfaces. Teams can use the version control system to roll back to a desired state in the event of an assault. GitOps lessens outages and downtime as a result, allowing teams to continue working on projects in a secure environment.&lt;/p&gt;&lt;h3&gt; 2) Boosts productivity and cooperation:&lt;/h3&gt;&lt;p&gt; GitOps includes CI/CD pipelines, Git workflows, and infrastructure as code best practices for software development. These prerequisite tools, knowledge, and skill sets are already present in operations teams, thus adopting GitOps won&amp;#x27;t need a steep learning curve. GitOps workflows streamline procedures in order to improve visibility, establish a single source of truth, and have a small number of tools on hand.&lt;/p&gt;&lt;h3&gt; 3) Automation enhances developer efficiency and lowers costs:&lt;/h3&gt;&lt;p&gt; Productivity rises with CI/CD tooling and continuous deployment since teams can concentrate on development rather than laboriously manual processes thanks to automation. Since team members can use any language and tools they like before pushing updates to GitHub, GitOps workflows enhance the developer experience. Infrastructure automation increases output and decreases downtime while enabling better cloud resource management, which can also save costs.&lt;/p&gt;&lt;h3&gt; 4) Increases stability and reliability:&lt;/h3&gt;&lt;p&gt; Human mistake is decreased through infrastructure that is codified and repeatable. Code reviews and collaboration are made easier by merge requests, which also assist teams in finding and fixing issues before they are released to the public. Additionally, there is less risk because all infrastructure changes are tracked through merge requests and may be undone if an iteration is unsuccessful. By allowing rollbacks to a more stable state and providing distributed backup copies in the event of a significant outage, Git processes speed up recovery time. GitOps gives teams the freedom to iterate more quickly and release new features without worrying about creating an unstable environment.&lt;/p&gt;&lt;h3&gt; 5) Faster development and deployment:&lt;/h3&gt;&lt;p&gt; GitOps provides quicker and more frequent deployments, making it easier for teams to make a minimum viable change. Teams can ship many times per day and roll back changes if there is a problem by utilizing GitOps best practices. Team members can offer business and customer value more quickly thanks to high velocity deployments. Teams are more flexible and able to react to customer needs more quickly with continuous integration.&lt;/p&gt;&lt;h2&gt; Key Components of a GitOps workflow&lt;/h2&gt;&lt;p&gt; To summarize, the following are the four components we require to a GitOps workflow:&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Git repository: The code and configuration of the application are verified there. &lt;/li&gt;&lt;li&gt; CD pipeline: It is responsible for building, testing, and deploying the application. &lt;/li&gt;&lt;li&gt; Application deployment tool: It is employed to manage the target environment&amp;#x27;s application resources. &lt;/li&gt;&lt;li&gt; Monitoring system: It keeps tabs on the performance of the application and gives the development team feedback. &lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh: Consul]]></title><description><![CDATA[Explanation of Consul Connect]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-consul</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-consul</guid><dc:creator><![CDATA[Deepesha Burse]]></dc:creator><pubDate>Fri, 05 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/ed21c2c53f2c64e86b016cfdfe7018ae/consul.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;h3&gt; What is a Service Mesh? &lt;/h3&gt;&lt;p&gt; A service mesh is a dedicated layer that provides secure service-to-service communication for on-prem, cloud, or multi-cloud infrastructure. Although service meshes are typically used with a microservice architectural pattern, they are useful in any situation involving complex networking. Their functionalities include traffic control, resiliency, observability and security. Traffic steering is used for content and it allows optimal usage of our resources. Service meshes provide control over chaotic situations (which usually arise in complex networks) along with proper identification and policies to enhance security. &lt;/p&gt;&lt;p&gt; Service meshes can be divided into the control plane and the data plane. The role of the control plane is to secure the mesh, facilitate service discovery, conduct frequent health checks, enforce policies and other operational concerns. Service discovery refers to a central registry of the services and their respective IP addresses. The application needs to be registered on the control plane for it to be able to share with other services how to communicate with it and helps to enforce rules on which service gets to communicate with which other services. &lt;/p&gt;&lt;p&gt; The data plane, on the other hand, handles the communication between services. The amount of knowledge that the services need to have about the network environment is limited by the fact that many service mesh solutions use a sidecar proxy to conduct data plane connections. &lt;/p&gt;&lt;img src=&quot;/static/service-mesh.609aa147.svg&quot; class=&quot;image-center&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;h3&gt; What is Consul? &lt;/h3&gt;&lt;p&gt; Consul Service Mesh (also known as Consul Connect) provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS). Consul is the control plane of the service mesh. Consul can be used with Virtual Machines (VMs), containers, or with container orchestration platforms such as Nomad and Kubernetes. Applications can use sidecar proxies to establish TLS connections for inbound and outbound connections or natively integrate with Connect by using Connect aware SDKs for optimal performance and security. &lt;/p&gt;&lt;p&gt; It is a multi-networking tool that provides a fully functional service mesh solution to address the networking and security issues associated with running cloud infrastructure and microservices. Consul offers a software technique for segmentation and routing. It also offers advantages such as handling failures, retries, and network observability. You can utilize any of these characteristics alone as required or combine them to create a full service mesh and achieve zero trust security. &lt;/p&gt;&lt;h3&gt; Architecture &lt;/h3&gt;&lt;p&gt; Consul is a distributed system built for a node cluster to operate on. A physical server, cloud instance, virtual machine, or container can all function as a Consul node. The collection of interconnected nodes that Consul runs on is known as a datacenter. Consul supports multiple datacenters and considers this as a common case. It is expected that there will be many clients and three to five servers in a datacenter. This creates a balance between performance and availability in the event of a breakdown because consensus slows down as more machines are added. The number of clients, however, is unlimited and can easily increase to thousands or tens of thousands. &lt;/p&gt;&lt;img src=&quot;/static/datacenter-architecture-c4fc960e23f5893df81a9d8ce380a912.webp&quot; class=&quot;image-center&quot; alt=&quot;Image of datacenter&quot;/&gt;&lt;p&gt; The Consul Agent is responsible for maintaining membership information, registering services, running checks, responding to queries, etc. It is required to run on every node that is a part of the Consul cluster. In some places, client agents may cache data from the servers to make it available locally for performance and reliability. They can either run in server mode or client mode. Client nodes make up for most of the cluster and are lightweight processes. They act as an interface between server nodes for most operations. They run on every node where services are running. &lt;/p&gt;&lt;p&gt; Along with core agent operations, a server node participates in the consensus quorum. The Raft protocol, which offers excellent consistency and availability in the event of failure, serves as the foundation for the quorum. Because they consume more resources than client nodes, server nodes should run on dedicated instances. &lt;/p&gt;&lt;img src=&quot;/static/consul-agent-architecture-c43b9bdc77878048a3df80dca16fa381.webp&quot; class=&quot;image-center&quot; alt=&quot;Consul Agent&quot;/&gt;&lt;p&gt; A per-service proxy sidecar manages incoming and outgoing service connections by automatically wrapping and verifying TLS connections. Consul includes its own built-in L4 proxy and has first class support for Envoy. Other than this, we can choose to use any other proxy to plug in as well. The following diagram shows how proxies work: &lt;/p&gt;&lt;img src=&quot;data:image/webp;base64,UklGRpYcAABXRUJQVlA4IIocAAAQnQCdASpHA9gAPm02l0ikIqKhIpQqQIANiWVu/HyY+tD+grO/HL+R3dbkf8b+XPTRck+KeXxLd1Pfwv6/+TPzo/Yj2v+YH+ln+e/uXYB/b7+q+wD9X/+v/mPeA/1P7Je8P9lfYA/nv+Z///Yh+gh+4Hphfs/8IH9Z/3X7de03/7NaP8Sf2Ls//tP5Meg/4x82/avyF/KDnpxLPkX1N+7/2/9wf8J7g/5v7R/QvgBfkX8i/vH5f/4P91+OO1X/Yf8b1AvYn6T/tP8D/d/+z/gPQl/mPzA91/rp/qvzA+gD+Tf1H/Sf2790+ZF+8f5v9mfgB/lf9Z/6H98/Mz6Zv57/1f6fzp/on+S/73+k+Ar+bf1n/g/4P8nfnH///t5/db//+6J+1n//HkG1A2wSeugdCddOm5CmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmZmURq+1aSMDg4N+DA2rXoy8HTchTMzMzMzMzMzMzMzMqRJniLi4uLi316sAiHihQAagGq4q6urq55nugvToCcmwDuxMS5cyoAAugOK/31zjOhOI55JfFHh4eD2Lthf1gBWV6JpaWlpUKiGX065309AU9/f39+xq/a4o/GrP4Ed3QbjZCRZoB/3NOkZkYLXE+fkqUCOdflJT6iuOdz4UoILSc5FZpm1EX/pMMqBNu6jAFhKPcbAwoGt7CDB8yLxQEtF7sJeZ5VFHG7C/9Z9idgyo5Sv+PJ7N4lqyHhAWVIWiBgvYgBq5A1cn8KuymuIr1a+YuTtS3Gr1VWExzLvnaxp9m4dRph/p7JUlfOWudmYIplernsCrsclDCjWDNKauL//9G393NcRrKEQ2aL/L7KQxkCu5MzV6qjz764MaMijLK+3CScznZ4+u8yaoWrAh+XqulWnXa8S43lz+V3X+zy8vAAAvLgqRaZPL5gbTeGTgrlZE2Nxgz7+L0jEDZckxsKao3UWdykZcna4tq97bQctnSrlSERnem/VGiO5L/80naTTSR7FYSaQWclCfrxnqIeY9T9VunINQQXHY9ChTUzJMGbFkYamT0k+VVVVFzb8Y05Q0tY0p6buRFKI2BG913TioO35cKdfOfON0BZ9uY587jZbEMsLuKkhrqDaGg7tuGhdNEJR+xdvuiXjCuUQNZJVk0jBJ66Bz287cOalYd0LaVTU4EgX7PwZgQJmMQwlBod+Kc4pzfP0vaHO8S5nX0WZRPwcHBwbT1uqVQDzOCIkaa6sX5KUGr+7wuJ4flFBKWaIeYadUTXWiZOm5CmZmZlCsoTAi/iCMwtwhnOCECNbnMEqt1ptKCVxa8aYYgPc4BrLGnjAVI+nVX5HIgyU2GgpRvPBQZjC18XOgv4pO+5xmvEyGB1dO/ZeE32md6Tb3yoSjJvkys+5NTvXeeO/Koom/gVQC+lfgbgIDZtwB2pkdmIiSoNqBtgk9c1Q69wEPfTSFmVd1fouQwDhxHRbkJRFVIXInt01v5FEObzpU70MT/5U2ByaXJfPhvjQYvHzKBrEWpPeWVaQ1xID6MnrW7Zntr9fds1YiUo62ADRCbdwjFeECyT10DoTrnmiwcVDxjd7n0MCoYG2CWxrolTZOunTchTMzMzMzMzMzMzMzMzZeLMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMoAAD++60AAAAAAAAAUuAJg0mS3GYyY2LaDS+rptBTbNC51y6CcLA//hw/HKhG+EuDeJaU+3gh+ImSDB2ZcSNtK+h76T5qEs+gPQs/wQ/mRK3S7iEdDAHobx0BA8Wg+MtjrovH1tO62ftUnAk3HpCBeww+DOAAJDniUygKZ62KILNjSX8lIWsUjsUP56Xgp/nAs/fJ1ZklUNy0fJYnLC4bhiGGj0wigFYntYuoQnpNJjFJ5APgvAOhI8aecyQjqKIiVSNv4T/8czT77i7HPJhyo7/Fm/ueyge5ZDNaL85pmdGds21Vpu9IQcw7nZ8myGrfdP+H+9HIkI6oKYzzjVZD3TdERd2Ef4lX6Oiq3gs9asRDmgCYB5+vxXXOMIi5Q+FBoY+nhmpRs1aR7HyhS29fOxJEFu39dNZZByUHaQoW9lahObgSU2ABVLVmwIEVdI0uF6AFyKiyDNW9N3rWNG9hIdD+DL0/dr7tyZguQdp66wgcw6tnVOPc3LYvi3B1AMZUxxC72x5ohzFd/f9o3EHx3GRwRz3RcPZGGqx1DcOGd1Z79iIc/x5mlYt+xCQwh6CiZAXiQlmqYoaibsKDqtpS3eCF+V8HaPNa+gHRtuaUwyDGUqKt5VgLF7gE+H6ZHYDzu+4lWOqrkSlVnnB+M6ULIrDBV+bTAItZ/FDczDu+qnLXl/p5nXfDPsu2uBBmWPCMUONCnvavtvOp9HLMbt/YiBaf4oJpEVe8E8WDXjmTmpZ1cWTOV5/v43e8mI8RbSAHAn/GtR2mkd4R3lNImwne1qsQU3+MmkGctrqW4Qhoi6m2yM1hWO+bGV87rnl2KlfDj5wW5Y1fbnin4shs4PSxZji1rviulKMXCmTXMc5UCSVdJUoiHZR+ZFzpT7Av/Ps38KyUCKTFkIXsSS8uhDQ9nvt+mmyOkYMJIpCcdWa6EASzdtXTq6LnCVAB0tLNWTiP0SiayzZ1rAOqwFer3uRkJyYWxpTJsfZaqMnNBpWAEtDDwJs7nIryXtaYCKMBzEwv4SF0ngwjZTsZPzbw32/WOu8aE74BzsKByx/pj3VUupjcARRS+HxS65nGBwZpjALzRfajkvptbJ8Tl7yy1ssMs141lCoDBKQD3m58riD/P25QuU4K8WHfwhjIi7CygOWL5MfpzNkzbEqsHh1qk8FRa/MU+aylBVYYGmj3kCKqZeWbD3vlKfIhGJmqYIEtFcS56RaS7cch4rjf8MOUrlmvquUoPlInmlK/WmBA1U9mQJdQ4vSEnK7+6zWRmhEhP6TJtmi2+75zAqNMgU7hN+zaf7VCd8xM56s0eS9erhqUQU1FkHm91QgxPrQyF2dEEzkR/nyykizJNbXeCpooxvLnGRaQ8Yb6p7nNERska1TzNgPL3tBJbenFnyCBPocfyrp4EwRuTF0IyrTF+2nqcrBcs9YqniozQjGE94Ls/DlxW7orAsF1t6fZFDYkKEMhiasf/bBKnV47rm+i/ytdCnl5JMjz1fvMMkYPRusd1R98AioMoC8wIkYdAzX7XpnK+GA++V6LwHXN3FsJLuh2S+Iqu48p9lf+5ZfoblNZZr2TngRtElJmKQt4pYhLzhsW8CpoogYZAREZMGJNJO0Qtq/s2cJK59nsNBD3ZqGvgi4yBmCPLpXnUX43C80TiPXspmYlFKh7Gq6xvnodSVqnbNTTV2LSK14b29GZzYH8GvWK2b+Y+3/peJjxi1/uhHP/9LdgAib4OtsLJdN7E593sq9eruIUfhhf/hjtkVE2XBpgK+yxD+DZkHGkYSvx8w9XfyzEdYjgpVLDHqFEPhf6rmto1aBbEQjIHO92d+s88IgFCuUErzvk3sZiTEs0dIsnxe/ZydCF1FeqIhVv/YHiBzqCWNxeqA7AcFzsVvQFVAuze4+a8Wnfi/C0ZqEFwiugkDw5xn7SP0vi96uueDb+RudVVUX3Ckc/P5GsV1+qF3dsb6VqWckFIHkuqPIAQz7LTRh661hVxzuS5FL/j3x6uxHhMbSt9IXbsiPh/wM8w+E11U9kCNglbLTDZN1OY72vvBlbsX1c92A6dHvtH0q29aw7fXYr4Dguy/VypDM7EYMd1SVyI3qWkt2PE+RJ/gHUiNGqmXKLU+J7wADEPE0d17vCSU30UmwGWXbC0OfzGjYB+rsXDSoldf8OfGZ5+B38b+kIILVKAwHVXYLdyQrP2NizdRlaPIgvuBBb1AM2d4NW8wrX/hH84Xt1dYkT7fx14LfYD6tgFuDNqBnfoYx3ovUJlrJ8aIuczf8G/BWMA9+ycAcXisngpYj480AGJcevgcOh1oeu9XdkglZKSrbPr9n+AkORj0mfh+hOU4jW8NiB2zHBYVvm5CWpnlmw/3RyqoNM3U24SSFgl8hNp3DGLzDmIw7IXn0SV4gbBdEw05KauLPjv6oVlnDrposyubM+CTt37X0Q3O5lXZsMlLNIqUZ/XfKtUyb4ME5TuSZHoP8GrOiW2ZPYmEJ6Y6yhP4jJjZB/aAJNbnXc+wyh9BagBR4ZXNYGczjTT+VQPwgZkNhcSdz/kDCGgCbu6vq94LQM3XIytojwuKJTe5fR5UXi/9rWvakCyGdGn93pWnocJX0s3weOvmEHIdPNjcIKqPGLcCkTc2P/1XWJWZ4hILyddqwj5THVNZbvhRtEUeD+QsuBs2yPX1K1LOSRw+b8Jvrn1MQH+uEE+FDlxedbrdg0DS0jI3wSUjVIoCYSaIRoYqKZzV1BZ0E8zzn93OLTGXvN3r9k4SGIGGvNwk4slK36vC5D1uhl6S8tfkLJnDgy51/752dnOm3rH4VV5tn5MAnDihu+JL4gppIRCYEGd8/Dc/WHdQWZkj96KP4FMUSECUSmOPC0wGQq4Qa1280leTBXZ5N0pDlIovp8jWOom2re1fgC11cP9IZ99294iTxHMW350seUFl1qqWLKTA5+QetW3bOSPBv/FgSiQHwkF06RXQsOanYEUZTuFkSBYDJVmCU8klNpyyO3IptMhR+GKGVg5SaLRcs8cp1cgscA3VFoxThWjjW/paRtQe3gOtCnYBmWYuBYT7BPqKGAkW0FAq2G9TdQlwbTXgePgaquhvXZy8OS7qV3J0zZUrkrxK/gFBEnRJirzSz0qp4ApZjTKGtov0z8H7lOgTeVrZ638YjwRHLlLmCo4ABRX50v372KTjK+/4cyLkD9QZmEPjBPe/nH92S58jLiL1ertveile+cKPDuNrxEOsbSuI/GaFfiKK9Oh9aiXLAT4XYyPTwqGq5YtN40bsEWU4TfHkBl+pEmkhEMVQPyqkNePVyV1+tejxlB7z2GBL90OHLN1Kl5R3lf8wYrRoQKoT9R7T5f+nYst0m8ZYNAllEwX61Icf9MnQeTKIpOCX3lf0lvycOdDyqW5KKUVNRXW0uAcSo86+TMakRhAVUnoVKNaHmOmVlILF7F+lUcZ9edHdK6OU5U5LD4aEGpdMDxXtZ9ECIPFIvpOaFA9dlQlaEoWiM6HDMYn2pVTFoDm5OJCD3YEFJe6pBp/Sxie84uvase4q0Q3P+kenHZ5rrtWFUZgxTuBkMFwDwzWSrNwYGdFkwdw2J9APXwGU+9o76UnM/iaXaqYWrrfpinzxeXUcSzy1iY+S0hfuPSb9iAIzqXt6TSrRmrgwPpV+jWbcvamsxc3sZMC1+W7l2wJe+mErcKN278pW+CzHj7o0bZVGHVYjYKeNfWv0QuT5u9BN//DhLEBWNq7c3fO8QA7tuUNmsNimz/fF71cIqh+kssuS6f1AW0ZC9XcJ2bUUZyC/Q5Fksa4UY74pTkQp05ciUHhw1E0OlcA1h9otsfozUeHJ7SRMjL36gA0CGZKT5OK2+AusL8jVK+u5Y2GCmB7m1kDTMncvK6spgAkku8fYYwSf9Ki/oO2fBXbon7/f6H593t8t0JpEC60jVf5f2t1JG1Su7NuUC9gZ87D+y0N90dGtjWa7gCX65A9ZdEx70BbBIVk69mJA6S42thVXe0CNLxSCUi3m1V/wORw3BqLOFm4vDwdq6bXp1BYuQSkbAsBQm+yqHPsJIGqH1izx5WEKmFBL2bOX3/i0EZmwrjCKQ0DaTQyYM5WXPJdbN4Zy4JMqgMoS7qVqL7x8TOj+yAaQFuZ5GryTZMWJZzbdgbmLrJjMlQz6G0Fv1FlhzdA5MK1k7xH2TpcU86gFlbqhJ5mQ8cG6MTnYAgQQQnWQh1Im6xWzsUzFHylnmy2HkfcWD5+q4vujwcKGN072lOFl6GwM9CH8xShbVdPtdtsWSU4n1UaldjnUBJ2I+5bPY15jiiNWRoz27l1av2XkiN8aHFg54Uikkbr+lLnFo2CTtgGBVJRSLrnG1O2EsZ39SH/AjQnmaoHAa78XZ1PPpGa/t2HzGSZstjYvJ/njUREj/HvlmPCty3pJROjoR7IpNVig+tJR6vdbjNmOzyPpveITHRb8M/owDALuw8vkhpUu2Zs07+lMfm+8+DoYlFB79LCQ8PZnbSL8N4fjfU/tzay91FKIUO35AmPiRCJD9p1B0h70DGkKqMlO0mCyoaH73x61h5gOr+mr0XpQMMKXnDVMTUyr3j2HcysK+pU9diOYOiwWSFSRQRZj+H4lSsAE1D8AgksH+9Mxt3JDOzgFA0Zl3hFdbWfCEPcCiiLR7BntcXPuFCmvThsOwZ1JojeaRvcaK2FHE0gJL8E5MqBmiYaVrEa2aB6OJ3Jf3THAsh0vtDDhC+2zgr/JNW2Un5ZCREjMaEs6hs2ApaWK9qiGh53v+ChCXmz/rgvCJSsmVFkt5eYf1FiGKvta/MYRIYt+Ws0Z+L6K6gWIMvjG+uCWYjffmv4v+33xL9Ev95LnDlcZQTwRx8m/eOaApgsevnD/O7h8Vx2maa+iqJld9H3Qh5fNOsWmbPKlsWO+cE5fEOj1JU34e/Dy9+PX6TsnKQqpEv/amUVo5fwwuY5MQz8xSPQXBvwoV+QbRwbyHohQbXkWIxHTWY7MqvPsnJ+MGdoqXS1+Onk0fUs2gIStNNGxFahF1MTxRlB46++6sNNniBxoPaNDPD6707xYQcRywWUPJABp2NhatUh4SU7Fq2bBx9Yv6umI8JllhdpAh8WqMsUe34JUEP3mx1idtyncpf/5d/U7nbKoQ5yCnrMhD2jljNIT0DhSi0EWEsWrUd0/+u0R+ueBL2KtNe1plhXLvP0Rnj/+qiGDEsnUpIN70N0ogoeOP9UQlJcr9HOemFzPHXjHo5KHM8Iq4pXkNJwwfWq1Ek8GtgbuS/iBdbvti7SfQt0Sm6wzj1JzqpL9wSlRk19xhyLQEJVvG01FB+w60ajh1j4tffiWdsjj+3VxhTfKN4XXe5PYXuHMHxWs8z1Qr/IZKsHLapGAm9c9hQLq0lcI570xP0yhzsf4divtT1UgnjLNDuqk1LCQ364g73Lpmednv+DHFv2HAd1OKVSAhJdSjyThw/OlAdIP82lZvzsjLCPXV5Cv+Bkcwnd68+LirrTFQCs7IOlnCUdh54wrhTRkb0Tyy5bQHIMBP08+i3rYZV7Crm0mctnQt3fMaKgVAZAlU9VNBwzoFgBU95l5jIKmDwiBCFHoPrIJP1pjKzpT2PzdXVujr/H44MaBt2HCOn5h+LQi9gWjqPAd/3iPe14/jvqElwBuu+NnjVT5f/mqUcLeidEgvvvvBjU0bezok9fXufU1sKn/MRyNxyz2M8ju8QXe4pqcmOYVZhF8azqxh3nIpHWulg9yLcdrjYXBGHfpbd8a3SXE7IQMCEtaqtWoXjfkK4fUempdWdBXxjQDTDsDS1/64PARBjj2f4w/Q3xwukdsAVqmAvnX0K+CBrPAMZxfXMUNMPpmhNzgbyMUAGqCw+JN+diQQiysc2JxJW6jI8GPcH3FL3jM/6YLV34D6p1dZ9WVLI+h13d0sp9xKZW0Hbhjf4Uzsl/C2kPsnewlXuWCe9wuop20PlDtFBoAdcZ4tgAEvXcW3M5J4RX/yi8vTzdjwumybqWUPOlaui46uiUx2RvIDE2QoQmcHnJkqyuAQH97bakJ5OYPb5u4l2SlZbWTD9JY7bjgt4A1Uv+IyyLSLFcSf79K9NB/8AYT9AvEdUFsvKRpzU1OotXbaZKawQ6Fp3C89/qz8/F8XdbVBhgkB/Q9K+Lhv9st3l5C3UUQC5HMKtKS6xSSS9KE/2hntA/55jC4kwyYKNl+xlxj8Y9BwY7YFHCAeK8TZM++STuduW+lLm9hd3V9Wh3Uk/+Jpy64jFCGBPbW3I8eLzkcKkzi2+9+IgkyO7JVQ0b1ZPP+ht0VDGkUetNKG3etsL70IE0kq820ZtnI8fFY8HV+qgyXVFNANGO8URxtzHwZ9Pl1mzn/2RgMYY8JEbRoELv6BvtDJRrIpB/kAtEMYF0+g3JtkhiXkikYvgZeX3YPNzZ1oZ3NWH5m1J6V0QC+Nl1BfL91CHe82+s/5IfgrPHQomvlcVFJ7iMc8V4e8SR5hkQpptUG7DwwJnftN1TEaBP3VTyqy1ZesfSzS46wi0I8U+6JDhSXq4SNDQP0AjpGB8wqc834O1GvK+EAprR5E7gzbe5x7Q6RcNUbo4R7aInG6dv1DzTiyNWf35x9h80QwmJAbXn6kpZliBOQ3lqIj07RRoqcj77B8cAhO260CHSdY2Mg/TNDCfbf6W9wHB7wCT9fFRu802OR13JCDKQ3B6PY9p65hhUcPojttzm0qq1UI9kx7P/LaBQDDVbvled44MU2QuFLrR1JuIGPwcG01KxQstG7Mbwb1kL/UKEN0JoxGZksH4xr4UsD3w06Q2bOhX2K5GymbIGTXxs9n5+TGCOk8FraRacoe3K8xXS5RoGOSQKpIpfA7e/djsLc7NPZa1I2WT4fjSreMnwE7iLSXPDPPUFScb9vvZT9+HOL8/LPsC1Zcbq7sahGqJ92ifrl9qq47So4upZ/nDmd/hm/ElHD96NxhCLiMJ+xKufh9XR/kDa8yfAy9CIoE/e3bbV7h3sFuPOIf0NY8AXPssE9bw2rrhpPtUyYxi4dCz5HxrrVH6x2UU+p4EYWT2zSHfsUq6Vlp/2WhcTY16D1rRydJ9Ap16T/rht88aE71ttlpxMhyDVR3k1+qpT2THEGO2qQ3GJwNo3T53HQalb5CxRISvoytCv7LREFi7m7tZ5lEFdBIfhj6Jd9OSUvrR/yV+n89OUGsX3V/IwbuQuZvXQFv9jTp/6fiK01QD/AHgRTnERGKVgbQxKeuNfE/sNlxWA/AXxRt9etemcZtphynZ5pWG1WL+d+XeU6E3pw8rG1QAaYZrJ6szB/C0a6oNSWbiGNwgkEEeaNpgY7/4UGhYf1HLVbVN+0hRZLU1iZSTFErgD+Ktuy3kuoUQ13t4fff3CXd0dXDU4g2o1CyPpSRux3rD1ZJH8+WXpiHI/p4PgG/VxShdHqWDFMRPEqVyDRKv9t6QI9kWgUNnVzfD36OzL+c+ocgDRc7PHETrMMgzj84iBLHfQnaXjIBNrV3jXk26TZXDBQL68QNQ3l1Lwn1duxYECbdY8i1+aZvfTUspWJWRJVkh4HNfI3+VC4PPCYacmMMwdPV0a7+Wsr4tKTIGfu+K5IZUn/VkeYq1N8nf2nC6t+N/0ocoZBixMwZGtlqpTf/VnZdSdoPZP2E6GnWlLXh79BJfmE7AyP3+3G1Cc0NXUfX+R9+FzpSLXCB1/dlM6p+nUCIFhn8dXwBhP0C2D/oCk+VGXOpH+WL5mdFw6Um75cqyjeqCn6qm+wCuJbSgJZelByEZGXkguPVzuGZdLUHFjl+c+/+/pA9VdYSG6C4Hn0kBR9B1K3QHQ86oGKlcCUZDflyYgUn0iFusr8g+px8esq/Gh8K6VnCqPjXPl2NwaCxQG/K0JpC8U7AgTXjj3loCZRcVLOxcPLk6Hg44QziQHkBAW6d3c7YEMUvSp2B2mgZfmW/ZEvh2C3YoLnB6/SEdrAfLk0HY3jWvx3kh4WaOvYfnG4n75jPtq098KbR/mWa/AD6tBfkuFw0NnsArZUSisZD8p7IVq2574WR08/p8j7wH/U4MlngzR8dgnvahSXV69HQAAAAAAAAAAAAA&quot; class=&quot;image-center&quot; alt=&quot;Side-car proxy&quot;/&gt;&lt;p&gt; The lifecycle of a Consul cluster:&lt;ol&gt;&lt;li&gt; An agent is started. &lt;/li&gt;&lt;li&gt; An agent joins the cluster. &lt;/li&gt;&lt;li&gt; Information of the agent is communicated throughout the cluster&lt;/li&gt;&lt;li&gt; Existing servers will begin replicating to the new node. &lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;h3&gt; Benefits and Compatibility of Consul Connect &lt;/h3&gt;&lt;p&gt; New methods of networking are necessary due to the development of cloud infrastructure and microservices designs. There are numerous tools and companies, all of which make different attempts to address the issue. The Consul service mesh solution offers a pure software approach with an emphasis on simplicity and wide compatibility and makes no assumptions about the underlying network. &lt;/p&gt;&lt;p&gt; Consul service mesh streamlines application deployment into a zero-trust network and makes service discovery easier in complex networking situations. &lt;/p&gt;&lt;p&gt; Features of Consul Service Mesh:&lt;br/&gt;&lt;ol&gt;&lt;li&gt; Service Discovery&lt;p&gt; Consul provides a service catalog, configurable service routing, health checks, automatic load balancing, and geo-failover across multiple instances of the same service. The capacity to control changes in the service landscape of your network becomes essential when new versions of a service are introduced and must coexist with existing instances of the same application, frequently running on different versions. The agent provides a simple service definition format to declare the availability of a service and to potentially associate it with a health check. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Zero-trust Security Model&lt;p&gt; Trust can be exploited and with the increasing number of services, there are higher chances of breach. The Consul service mesh control plane can be configured to enforce mutual TLS (mTLS), and will automatically generate and distribute the TLS certificates for every service in the mesh. The certificates are used for both service identity verification and communication encryption. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Simplify Application Security with Intentions&lt;p&gt; Communication between services is secure within the mesh once the service sidecar proxies have been set up. To designate which services are permitted to communicate with one another, you might want to build a more granular set of policies. Consul Intentions are used to limit which services can make requests or create connections and define access control for services through Connect. We can manage intentions via the UI, CLI, or API. The proxy or a natively integrated application enforces intentions on inbound connections or requests. &lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;p&gt; Compatibility of Consul Connect:&lt;br/&gt;&lt;ol&gt;&lt;li&gt; First-Class Kubernetes Support&lt;p&gt; By offering an official Helm chart for installing, configuring, and upgrading Consul on Kubernetes, Consul enables first-class Kubernetes support. The chart automates Kubernetes&amp;#x27;s Consul service mesh installation and configuration. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Platform Agnostic and Multi-Cluster Mesh&lt;p&gt; Consul works with all cloud providers and architectures. You can expand the scope of your Kubernetes clusters to include services that aren&amp;#x27;t run using Kubernetes by using the service catalog sync and auto-join features. In order to facilitate safe service-to-service communication between Nomad tasks and jobs, Consul additionally interfaces with HashiCorp Nomad. &lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Multi-Cluster Kubernetes Management with Meshery]]></title><description><![CDATA[Manage all of your Kubernetes clusters with the cloud native management plane, Meshery. Learn how Meshery makes connecting, discovering, and configuring multiple clusters a breeze.]]></description><link>https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery</link><guid isPermaLink="false">https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery</guid><dc:creator><![CDATA[Ashish Tiwari]]></dc:creator><pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/93e4b9e86c2d9eabe418ca1f023b3e26/multi-cluster-kubernetes-management-with-meshery.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;From multi-mesh to now multi-cluster, &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; is continuously expanding its capability to give developers, operators, and security engineers more control over their infrastructure. In this post, we&amp;#x27;ll take a look behind the scenes at how each component in Meshery&amp;#x27;s architecture plays a role in the management of many Kubernetes clusters.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Philosophy behind Meshery&amp;#x27;s multi-cluster management approach&lt;/h2&gt;&lt;p&gt;While designing Meshery for the world of many service meshes, and many Kubernetes clusters, much care has been taken to ensure that Meshery is an &lt;a href=&quot;https://docs.meshery.io/extensibility&quot;&gt;extensible management platform&lt;/a&gt;, ready for handling new types of infrastructure and new use cases rapidly through its plugin model. Under the hood, &lt;a href=&quot;https://docs.meshery.io&quot;&gt;Meshery Server&lt;/a&gt; acts as a delegator of operations by figuring out which Meshery Adapter registered its capability against the given operation. The operation is then sent to that given component (like one of Meshery’s service mesh adapters,e.g. Istio adapter) via a gRPC call. &lt;img src=&quot;/static/meshery-core-architecture-ada2489fcafbb125bde85de34ba3116e.webp&quot; alt=&quot;deploy modal&quot; class=&quot;image-right&quot;/&gt; When the operation involves a Kubernetes cluster(s), the kubeconfig(s) is sent as a parameter to the RPCs. It is then the job of the handling adapter to respect that and perform the operation across the passed clusters from kubeconfigs as needed. The operations not requiring a kubeconfig are managed through the same RPC, with the only difference being that the handling component would ignore the &lt;code&gt;kubeconfigs&lt;/code&gt; field altogether making the system work not just for Kubernetes, but for other cloud native use cases. This approach of reusing the same RPC for different types of requests is pretty common and sometimes debatable with the other approach of being strict with the RPCs. This is what makes Meshery completely pluggable and extensible.&lt;/p&gt;&lt;h2&gt;Using multi cluster with Meshery&lt;/h2&gt;&lt;p&gt;From a client&amp;#x27;s perspective, there are two uses of the multi context feature in general. While deploying a &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt; design or performing any other operation on their cluster(s), selecting any number of Kubernetes contexts will allow them to uniformly and parallely perform the operation across the clusters. And while visualizing the state of their cluster(s), the same context switcher will allow them to filter across the clusters whose view they want to see.&lt;/p&gt;&lt;p&gt;All cluster specific operations are now applied over a number of clusters uniformly. So if you have 10 clusters to manage and 8 of those start with the exact same set of pods, deployments, service mesh, etc then &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; can help you to apply these operations quickly and easily.&lt;/p&gt;&lt;p&gt;It is as simple as selecting the specific cluster(s) from the Kubernetes context switcher in the navbar, and then applying whatever operation you wanted to, whether that be deploying a sample app, a service mesh, or a &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt; design.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/static/context-switcher-dcf6363d7932bb835366e0bd322d32c9.webp&quot; alt=&quot;context switcher&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;/p&gt;&lt;p&gt;Just before applying the operation, you will be prompted with a confirmation modal which will provide the information about which cluster(s) that operation will be performed against. As the User interface improves, this same modal will also convey more useful information about the operation they are going to perform.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/static/deploy-modal-62d44a1425d7894167d37e07a4d24669.webp&quot; alt=&quot;deploy modal&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;/p&gt;&lt;br/&gt;&lt;h3&gt;Using MeshMap visualizer&lt;/h3&gt;&lt;p&gt;You can switch between views of your cluster in visualizer mode while using &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt;.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/static/meshmap-cluster2-98abf7107400581278b61b40eeb4c2ec.webp&quot; alt=&quot;visualizer showing data of context1&quot; class=&quot;slides-right&quot;/&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/static/meshmap-cluster1-aa93c5ce5b36cbf174c2b55a7bd2d323.webp&quot; alt=&quot;visualizer showing data of context2&quot; class=&quot;slides-left&quot;/&gt;&lt;/p&gt;&lt;h3&gt;Managing Meshery on multiple clusters&lt;/h3&gt;&lt;p&gt;Users can perform cluster related operations from the settings page like adding more clusters, removing data from existing clusters and removing existing clusters.&lt;/p&gt;&lt;img src=&quot;/static/settings-ad3405d125c81cc83695f10d49b51ae3.webp&quot; alt=&quot;Settings page&quot; class=&quot;slides-right&quot;/&gt;&lt;p&gt;Meshery also deploys Meshery operator across the cluster it’s about to manage. This operator manages the lifecycle of a Meshery broker and MeshSync. MeshSync pumps the blood into Meshery’s core, in other words, it is responsible for watching all different types of resources by establishing a watch stream over each of them. MeshSync then pumps that data into the NATS server, of which Meshery server itself is a client. From there, Meshery server gets all the relevant data related to activities in the cluster.&lt;/p&gt;&lt;p&gt;By default, &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; wants to be as much aware about your infrastructure as possible to provide value so it deploys its operator across each detected cluster. But you can fine tune this configuration by going over each one of them from the table as shown.&lt;/p&gt;&lt;img src=&quot;/static/cluster-mgmt-d0c0c8822a1a873e99f27e2b48aa5858.webp&quot; alt=&quot;Kubernetes multi-cluster management with Meshery&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;p&gt;If you disconnect your cluster and do not want to persist the data from that cluster then you can perform a fine-grained deletion by deleting all MeshSync data (which are the Kubernetes objects) for that specific cluster.&lt;/p&gt;&lt;img src=&quot;/static/flush-meshsync-110748df93f37b576d8451c64d429cc2.webp&quot; alt=&quot;flushing MeshSync data&quot; class=&quot;image-center-shadow&quot;/&gt;## Future of multi-cluster&lt;p&gt;Meshery as an extension point to your infrastructure provides out-of-the-box value by adding components which can be Kubernetes specific, service mesh specific or custom components to add new functionality. We can now add multi-cluster specific components to provide more abstraction. This model can be used along with Meshery’s multi-mesh capabilities to give an overall multi-mesh multi-cluster experience to the user. For instance, your Istio service mesh spanning across multiple clusters can be abstracted and managed by Meshery using custom components such as VirtualGateway and VirtualDestinationRules. In this case, Meshery’s Istio adapter will handle the logic of converting a VirtualGateway into gateways across the clusters. This abstraction provides high value by powering the service mesh to span across the clusters while the Ops team can configure the mesh with minimal effort.&lt;/p&gt;&lt;p&gt;Just like the example above, many such Meshery extension points are in Meshery to add logic into and add useful functionality. And as more of such extension points are added, Meshery will continue to give more and more power to your cloud native infrastructure.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[How to deploy Meshery on AKS]]></title><description><![CDATA[How to deploy Meshery on Azure Kubernetes service(AKS).]]></description><link>https://layer5.io/blog/meshery/how-to-deploy-meshery-on-aks</link><guid isPermaLink="false">https://layer5.io/blog/meshery/how-to-deploy-meshery-on-aks</guid><dc:creator><![CDATA[Srinivas Karnati]]></dc:creator><pubDate>Thu, 21 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/3fe6493b7ebec3694bc03967df3a3a83/Meshery-on-AKS.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://meshery.io/&quot;&gt;Meshery&lt;/a&gt;&amp;#x27;s goal is to make the operation of cloud native infrastructure and the service mesh layer of cloud simplified. Originally created by Layer5, Meshery is an open source project with hundreds of contributors world-wide and is actively maintained by engineers from Red Hat, VMware, Intel, Layer5 and others.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Setup and run Meshery on AKS&lt;/h2&gt;&lt;p&gt;The following instructions expects you to have an active Azure subscription, and Azure CLI installed on your system. &lt;/p&gt;&lt;h3&gt; Spin up the AKS Cluster&lt;/h3&gt;&lt;p&gt;Create the resource group (a logical group where all our resources will be deployed). The following command creates  a resource group named MesheryGroup in &lt;code&gt;southindia&lt;/code&gt; location. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az group create --name MesheryGroup --location southindia&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Create AKS cluster using &lt;code&gt;az aks create&lt;/code&gt;. The following command creates aks cluster with a single node. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az aks create --resource-group MesheryGroup --name MesheryAKS --node-count &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; --generate-ssh-keys&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;After a few minutes, the command completes and returns a JSON formatted information about the cluster.&lt;/p&gt;&lt;p&gt;You can connect with your cluster by using &lt;code&gt;az aks get-credentials&lt;/code&gt; ,  which basically downloads credentials and configure the Kubernetes CLI. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az aks get-credentials --resource-group MesheryGroup --name MesheryAKS&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Verify the connection to your cluster using the &lt;code&gt;kubectl get command&lt;/code&gt;. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$kubectl get nodes&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h3&gt;Install Meshery into your AKS cluster&lt;/h3&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm repo add meshery https://meshery.io/charts/&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm install meshery meshery/meshery --namespace meshery --create-namespace&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Meshery server supports customizing authentication flow callback URL, which can be configured in the following way.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm install meshery meshery/meshery --namespace meshery --set env.MESHERY_SERVER_CALLBACK_URL=https://custom-host --create-namespace&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Port forward to Meshery UI&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;export POD_NAME=$(kubectl get pods --namespace meshery -l &amp;quot;app.kubernetes.io/name=meshery,app.kubernetes.io/instance=meshery&amp;quot; -o jsonpath=&amp;quot;{.items[0].metadata.name}&amp;quot;)&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl --namespace meshery port-forward $POD_NAME 9081:8080&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Meshery should now be running in your AKS cluster and the Meshery UI should be accessible at the specified endpoint you’ve exposed to. Navigate to the meshery service endpoint to log into Meshery.&lt;/p&gt;&lt;div&gt;&lt;img src=&quot;/static/mesheryui-c85131f04313bafd3a0b677304a229a3.webp&quot; class=&quot;image-center&quot; alt=&quot;Meshery UI Dashboard&quot;/&gt;&lt;/div&gt;&lt;p&gt;From here, your Meshery deployment on AKS is ready to use. In order to login to Meshery, authenticate with your chosen provider from the list.&lt;/p&gt;&lt;p&gt;There are different ways to configure a Meshery on AKS. Join the &lt;a href=&quot;https://layer5.io/community&quot;&gt;community&lt;/a&gt; and share your deployment’s configuration on the &lt;a href=&quot;https://discuss.layer5.io/&quot;&gt; discussion forum &lt;/a&gt;today! &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Managing Containers]]></title><link>https://layer5.io/resources/kubernetes/managing-containers</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/managing-containers</guid><pubDate>Wed, 06 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/70f4c7f444e8b3494ddc0fb955f86d40/docker.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about managing containers with our &lt;a class=&quot;blog&quot; href=&quot;https://github.com/layer5io/containers-101-workshop&quot;&gt;Containers 101 Workshop&lt;/a&gt;. Walk-through four hands-on exercises with Docker.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Container management refers to a set of practices that govern and maintain containerization software. Container management tools automate the creation, deployment, destruction and scaling of application or systems containers. Containerization is an approach to software development that isolates processes that share an OS kernel -- unlike virtual machines (VMs), which require their own -- and binds application libraries and dependencies into one deployable unit. This makes containers lightweight to run, as they require only the application configuration information and code from the host OS. This design also increases interoperability compared to VM hosting. Each container instance can scale independently with demand.&lt;/p&gt;&lt;p&gt;Modern Linux container technology was popularized by the Docker project, which started in 2013. Interest soon expanded beyond containerization itself, to the intricacies of how to effectively and efficiently deploy and manage containers.&lt;/p&gt;&lt;p&gt;In 2015, Google introduced the container orchestration platform Kubernetes, which was based on its internal data center management software called Borg. At its most basic level, open source Kubernetes automates the process of running, scheduling, scaling and managing a group of Linux containers. With more stable releases throughout 2017 and 2018, Kubernetes rapidly attracted industry adoption, and today it is the de facto container management technology.&lt;/p&gt;&lt;p&gt;IT teams use containers for cloud-native, distributed -- often microservices- based -- applications, and to package legacy applications for increased portability and efficient deployment. Containers have surged in popularity as IT organizations embrace DevOps, which emphasizes rapid application deployment. Organizations can containerize application code from development through test and deployment.&lt;/p&gt;&lt;h2&gt;Benefits of container management&lt;/h2&gt;&lt;p&gt;The chief benefit of container management is simplified management for clusters of container hosts. IT admins and developers can start, stop and restart containers, as well as release updates or check health status, among other actions. Container management includes orchestration and schedulers, security tools, storage, and virtual network management systems and monitoring.&lt;/p&gt;&lt;h3&gt;Wrangling container sprawl&lt;/h3&gt;&lt;p&gt;Organizations can set policies that ensure containers share a host -- or cannot share a host -- based on application design and resource requirements For example, IT admins should colocate containers that communicate heavily to avoid latency. Or, containers with large resource requirements might require an anti-affinity rule to avoid physical storage overload. Container instances can spin up to meet demand -- then shut down -- frequently. Containers also must communicate for distributed applications to work, without opening an attack surface to hackers.&lt;/p&gt;&lt;p&gt;A container management ecosystem automates orchestration, log management, monitoring, networking, load balancing, testing and secrets management, along with other processes. Automation enables IT organizations to manage large containerized environments that are too vast for a human operator to keep up with.&lt;/p&gt;&lt;h2&gt;Challenges of container management&lt;/h2&gt;&lt;p&gt;One drawback to container management is its complexity, particularly as it relates to open source container orchestration platforms such as Kubernetes and Apache Mesos. The installation and setup for container orchestration tools can be arduous and error prone. IT operations staff need container management skills and training. It is crucial, for example, to understand the relationships between clusters of host servers as well as how the container network corresponds to applications and dependencies.&lt;/p&gt;&lt;p&gt;Issues of persistence and storage present significant container management challenges. Containers are ephemeral -- designed to exist only when needed. Stateful application activities are difficult because any data produced within a container ceases to exist when the container spins down.&lt;/p&gt;&lt;p&gt;Container security is another concern. Container orchestrators have several components, including an API server and monitoring and management tools. These pieces make it a major attack vector for hackers. Container management system vulnerabilities mirror standard types of OS vulnerabilities, such as those related to access and authorization, images and intercontainer network traffic. Organizations should minimize risk with security best practices -- for example, identify trusted image sources and close network connections unless they&amp;#x27;re needed.&lt;/p&gt;&lt;h2&gt;Container management strategy&lt;/h2&gt;&lt;p&gt;Forward-thinking enterprise IT organizations and startups alike use containers and container management tools to quickly deploy and update applications. IT organizations must first implement the correct infrastructure setup for containers, with a solid grasp of the scope and scale of the containerization project in terms of business projections for growth and developers&amp;#x27; requirements. IT admins must also know how the existing infrastructure&amp;#x27;s pieces connect and communicate to preserve those relationships in a containerized environment. Containers can run on bare-metal servers, VMs or in the cloud -- or in a hybrid setup -- based on IT requirements.&lt;/p&gt;&lt;p&gt;In addition, the container management tool or platform should meet the project&amp;#x27;s needs for multi-tenancy; user and application isolation; authentication; resource requirements and constraints; logging, monitoring and alerts; backup management; license management; and other management tasks. IT organizations should understand their hosting commitment and future container plans, such as if the company will adopt multiple cloud platforms or a microservices architecture.&lt;/p&gt;&lt;h2&gt;Kubernetes implementation considerations&lt;/h2&gt;&lt;p&gt;As described above, containers are arranged into pods in Kubernetes, which run on clusters of nodes; pods, nodes and clusters are controlled by a master. One pod can include one or multiple containers. IT admins should carefully consider the relationships between pods, nodes and clusters when they set up Kubernetes.&lt;/p&gt;&lt;p&gt;Organizations should plan their container deployment based on how many pieces of the application can scale under load -- this depends on the application, not the deployment method. Additionally, capacity planning is vital for balanced pod-to-node mapping, and IT admins should ensure high availability with redundancy with master node components.&lt;/p&gt;&lt;p&gt;IT organizations can address container security concerns by applying some general IT security best practices to containerization. For example, create multiple security layers throughout the environment, scan all container images for vulnerabilities, enforce signed certificates and run the most up-to-date version of any container or application image. Containers introduce the benefits of an immutable infrastructure methodology as well; the regular disposal and redeployment of containers, with their associated components and dependencies, improves overall system availability and security. Additionally, Kubernetes multi-tenancy promises greater resource isolation, but recently revealed security vulnerabilities make multicluster management preferred for now.&lt;/p&gt;&lt;p&gt;Networking is another significant factor. Kubernetes networking occurs within pods, between pods and in user-to-containerized resource connections. Kubernetes enables pods and nodes to communicate without address translation, allocating subnets as necessary. Lastly, IT admins working with Kubernetes should prepare to troubleshoot common container performance problems, including those caused by unavailable nodes and noisy neighbors, in an implementation.&lt;/p&gt;&lt;/div&gt;</content:encoded></item></channel></rss>