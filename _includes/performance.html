<br/>
<div class="post-content" style="padding: 2em;" itemprop="articleBody">
    <!-- <div class="col s8 m6" style="vertical-align:bottom;margin:auto;padding-top:60px;">
    <img src="/assets/projects/smp/client-capacity.png"
          class="light-shadow" style="margin: auto;min-width:300px;height:300px;float: left;" /><br><br>
    <img src="/assets/projects/smp/kubecon-eu/client-capacity.png" />

    <img src="/assets/projects/smp/kubecon-eu/latency-at-scale.png" />

    <img src="/assets/projects/smp/kubecon-eu/native-and-wasm-at-capacity-100rps.png" />

</div> -->

    <div>
        <h4 class="black-text center">
            Discreetly Studying the Effects of Individual Traffic Control Functions
        </h4>
        <div style="display: flex; justify-content:center;">
            <iframe
            style="margin: auto;"
            width="560"
            height="315"
            src="https://www.youtube.com/embed/rgnb0-ntPko"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen
            >
            </iframe>
        </div>        
        <p style="font-size: 1rem; text-align: center; font-style: italic;">
            KubeCon EU 2020 - Lee Calcote & Prateek Sahu
        </p>

        <!-- <div style="margin: auto;">
            <img
                src="/assets/projects/smp/kubecon-eu/Lee Calcote - Prateek Sahu - KubeCon EU 2020.jpg"
                class="light-shadow"
                style="margin: auto; min-width: 145px; height: 225px;"
            />
        </div> -->
    </div> 

    <div style="margin: auto;">
        <h4 class="black-text" style="text-align: center; margin-top: 50px;">Performance of Envoy Filters</h4>
        <p>
            The following analysis compares native Envoy filter performance to WebAssembly (WASM) filter performance using Rust.
        </p>
        <div>
            <a href="/assets/projects/smp/kubecon-eu/native-and-wasm-at-capacity-100rps.png">
                <img
                    src="/assets/projects/smp/kubecon-eu/native-and-wasm-at-capacity-100rps.png"
                    class="light-shadow perf-imgs"
                    style="
                        margin: auto;
                        min-width: 300px;
                        height: 300px;
                    "/>
            </a>
            <div>
                <p style="font-weight: bold;">
                    Native WASM at Capacity:
                </p>
                <p>
                    When every request goes via the
                    rate-limit check and then the actual program logic, we see that
                    the latency incurred for the WASM code is higher than the Native
                    client. This is expected since the native client has processing
                    for rate-limiting locally in a process whereas the rust module
                    is invoked as an additional thread to do the processing and the
                    communication involved with the module incurs an overhead. This
                    is prominent in the minimum response time case which represents
                    latency just due to rate-limiting logic where every other part
                    of the request is already "warm". As we move towards average
                    latency, the overhead gets slightly amortized but is still above
                    the native rate-limiting case. Our max latency is slightly lower
                    than native, but we attribute it to various other system effects
                    like TLS handshake and network latencies that usually contribute
                    to the maximum tail latency.
                </p>
            </div>
        </div>
        <div>
            <a href="/assets/projects/smp/kubecon-eu/latency-at-scale.png">
                <img
                    src="/assets/projects/smp/kubecon-eu/latency-at-scale.png"
                    class="light-shadow perf-imgs"
                    style="
                        margin: auto;
                        min-width: 300px;
                        height: 300px;
                    "/>
            </a>
            <div>
                <p style="font-weight: bold;">
                    Latency at scale:
                </p>
                <p>
                    When we go beyond the
                    application capacity (100 in our example), we start noticing the
                    power of a in-line ight wasm module which starts terminating
                    requests at the side-car and the core application logic is never
                    invoked/loaded. We notice that even the minimum response time
                    for a terminated request is about 15-20% faster than invoking of
                    application logic since the wasm is a dynamic module in the
                    sidecar and we start to avoid complex network redirection and
                    invocation of a new container/instance. We also notice that the
                    average latency of requests is lower than in the case of native
                    client.
                </p>
            </div>
        </div>
        <div>
            <a href="/assets/projects/smp/kubecon-eu//client-capacity.png">
                <img
                    src="/assets/projects/smp/kubecon-eu//client-capacity.png"
                    class="light-shadow perf-imgs"
                    style="margin: auto; height: 300px; width: 200px;" 
                    />
            </a>
            <div>
                <p style="font-weight: bold;">
                    Client Capacity:
                </p>
                <p>
                    Client Capacity figure also shows us that we are able to handle
                    more requests than in the native case, although this infometric
                    needs to be taken with a grain of salt, i.e. the difference
                    might reduce if our application capacity was significantly
                    larger than 100.
                </p>
            </div>
        </div>
    </div>
</div>
<br/>
<div class="post-content" style="padding: 2em;" itemprop="articleBody">
    <div class="row">
        <div class="smp-twitter-widget">           
        <a class="twitter-timeline"
            href="https://twitter.com/smp_spec"
            data-chrome="nofooter noscrollbar"
            data-height="300"
        >
          Tweets by Service Mesh Performance(@smp_spec)
        </a>
        </div>

        <div class="smp-twitter-widget" style="margin: auto;">
            <h5
                class="l5-dark-grey-text"
                style="font-weight: bold; text-align: center;"
            >
                Jump into the
                <a href="http://slack.layer5.io">#SMP channel</a> to learn more
                about these initatives.
            </h5>
        </div>
    </div>
</div>
<script
    async
    src="https://platform.twitter.com/widgets.js"
    charset="utf-8"
></script>
